{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Homepage","text":"<p>There is no doubt that building containerized applications and following a microservices architecture is one of the most common software architecture patterns observed in the past couple of years.</p> <p>Microsoft Azure offers different services to package, deploy, and manage cloud-native applications, each of which serves a certain purpose and has its own pros and cons. This page provides a good comparison between the available services to host and manage cloud-native containerized applications in Azure.</p> <p>Whereas building cloud-native apps on Azure Kubernetes Service (AKS) is powerful,  there is a bit of a learning curve needed when it comes to creating and configuring the cluster, configuring networking between microservices, services discovery, certificates provisioning, and, lastly, managing the cluster over the lifetime of the application.</p> <p>In this workshop, we will be focusing on a new containerization service offered by Microsoft called Azure Container Apps (ACA). Microsoft announced the public preview of Azure Container Apps in November 2021, and in May 2022 it announced the General Availability of Azure Container Apps. In brief, Azure Container Apps is a fully managed, serverless, Kubernetes-based container runtime for building and running cloud-native applications which focuses on the business logic of the apps rather than on cloud infrastructure management.</p>"},{"location":"#contributions","title":"Contributions","text":"<p>We are most grateful for community involvement. Please see CONTRIBUTING.md for details. Thank you!</p>"},{"location":"#acknowledgment","title":"Acknowledgment","text":"<p>The workshop's material, concepts, and code samples draw inspiration from a collection of blog articles authored by Taiseer Joudeh and published on his personal blog. The workshop authors have worked collaboratively to modify and augment the content, resulting in the current version of the workshop.</p>"},{"location":"aca/00-workshop-intro/","title":"Introduction","text":""},{"location":"aca/00-workshop-intro/#description","title":"Description","text":"<p>The Building Microservice Applications with Azure Container Apps workshop will provide you with the practical knowledge to create, deploy, and operate an enterprise level microservice application deployed on the latest serverless containers offering, Azure Container Apps. We will demonstrate enabling different components like Dapr which will allow you to address common challenges when building an event driven distributed application while keeping your code platform agnostic. In addition to this, you will get familiar with the built-in autoscaling capabilities in Azure Container Apps using KEDA and how to control spending by scaling down to zero replicas.</p>"},{"location":"aca/00-workshop-intro/#objectives-outcomes","title":"Objectives &amp; Outcomes","text":"<p>After completing the workshop, you should:</p> <ul> <li>Gain practical knowledge to create, deploy, and operate a distributed application with multiple microservices deployed to ACA.</li> <li>Set up Dapr locally and configure VS Code to support a complete, local debugging experience for your distributed microservice application project.</li> <li>Use various building blocks of Dapr to simplify the building of Microservice applications, utilizing different building blocks like service-to-service Invocation using HTTP and gRPC, State management, Pub and Sub, and Input &amp; output bindings.</li> <li>Get familiar with autoscaling features in ACA using KEDA.</li> <li>Configure Monitoring, Observability, and distributed tracings of ACA using Application Insights.</li> <li>Set up continuous deployment for your microservice application using GitHub Actions.</li> <li>Recreate your entire microservice application components and generate IaC scripts using Bicep.</li> </ul>"},{"location":"aca/00-workshop-intro/1-aca-core-components/","title":"ACA Core Components Overview","text":""},{"location":"aca/00-workshop-intro/1-aca-core-components/#overview-of-azure-container-apps-core-components","title":"Overview of Azure Container Apps Core Components","text":"<p>The main components of Azure Container Apps are:</p> <p></p> <ol> <li> <p>Environments The Container App Environment is a secure boundary around several Container Apps. It contains one or more container apps. All container apps within an environment are deployed into a dedicated Azure Virtual Network, which makes it possible for these different container apps to communicate securely. In addition, all the logs produced from all container apps in the environment are sent to a dedicated Log Analytics workspace.</p> </li> <li> <p>Log Analytics workspace Used to provide monitoring and observability functionality. Each environment will have its own Log Analytics workspace and will be shared among all container apps within the environment.</p> </li> <li> <p>Container Apps Each container App represents a single deployable unit that can contain one or more related containers. Using more than one container in a container app is an advanced use case. For this workshop we will deploy a single container in each container app. More about multiple containers in the same single Azure Container App can be found here.</p> </li> <li> <p>Revisions For each container app, you can create up to 100 revisions. Revisions are a way to deploy multiple versions of an app where you have the option to send the traffic to a certain revision. You can select if revision mode will support one or multiple active revisions at the same time to support A/B testing scenarios or canary deployments. A container app running in single revision mode will have a single revision that is backed by zero-many Pods/replicas.</p> </li> <li> <p>Containers Containers in the Azure Container Apps are grouped together in pods/replicas inside revision snapshots. A pod/replica is composed of the application container and any required sidecar containers. Containers can be deployed from any public or private container registry, and they support any Linux-based x86-64 (linux/amd64) images. At the time of creating this workshop Windows based images are not supported.</p> </li> </ol>"},{"location":"aca/00-workshop-intro/2-scenario-architecture/","title":"Scenario and Solution Architecture","text":""},{"location":"aca/00-workshop-intro/2-scenario-architecture/#workshop-scenario","title":"Workshop Scenario","text":"<p>In this workshop we will build a tasks management application following the microservices architecture pattern. This application will consist of three microservices where each microservice has certain capabilities to demonstrate how ACA and Dapr can simplify the building of a microservices application. Below is the architecture diagram of the application we are going to build in this workshop.</p>"},{"location":"aca/00-workshop-intro/2-scenario-architecture/#solution-architecture","title":"Solution Architecture","text":"<ol> <li> <p>ACA Web App-Frontend is a simple ASP.NET Razor pages web app that accepts requests from public users to manage their tasks. It invokes the component \"ACA WebAPI-Backend\" endpoints via HTTP or gRPC.</p> </li> <li> <p>ACA WebAPI-Backend is a backend Web API which contains the business logic of tasks management service, data storage, and publishing messages to Azure Service Bus Topic.</p> </li> <li> <p>ACA Processor-Backend is an event-driven backend processor which is responsible for sending emails to task owners based on messages coming from Azure Service Bus Topic. Here there is a continuously running background processor, which is based on Dapr Cron timer configuration, to flag overdue tasks.</p> </li> <li> <p>Autoscaling rules using KEDA are configured in the \"ACA Processor-Backend\" service to scale out/in replicas based on the number of messages in the Azure Service Bus Topic.</p> </li> <li> <p>Azure Container Registry is used to build and host container images and deploy images from ACR to Azure Container Apps.</p> </li> <li> <p>Application Insights and Azure Log Analytics are used for Monitoring, Observability, and distributed tracings of ACA.</p> </li> </ol>"},{"location":"aca/00-workshop-intro/3-dapr-integration/","title":"Dapr Integration in ACA","text":""},{"location":"aca/00-workshop-intro/3-dapr-integration/#dapr-overview","title":"Dapr Overview","text":"<p>As developers, we are often tasked with creating scalable, resilient, and distributed applications using microservices. But more often than not we face the same challenges:</p> <ul> <li>Recovering state after failures</li> <li>Services discovery and calling other microservices</li> <li>Integration with external resources</li> <li>Asynchronous communications between different services</li> <li>Distributed tracing</li> <li>Measuring message calls and performance across components and networked services</li> </ul> <p>Dapr (Distributed Application Runtime) offers a solution for the common challenges that are faced in any distributed microservice application. Dapr can be used with any language (Go, .NET python, Node, Java, C++) and can run anywhere (On-premise, Kubernetes, and any public cloud (e.g. Azure)).</p> <p>Dapr's core component is the concept of a Building Block. So far, Dapr supports nine Building Blocks. Simply put, a Building Block is a modular component which encapsulates best practices and can be accessed over standard HTTP or gRPC APIs.</p> <p>Building Blocks address common challenges faced in building resilient microservices applications and implement best practices and patterns. Building Blocks provide consistent APIs and abstract the implementation details to keep your code simple and portable.</p> <p>The diagram below shows the nine Building Blocks which expose public APIs that can be called from your code and can be configured using components to implement the building block's capability. Remember that you can pick whatever building block suites your distributed microservice application, and you can incorporate other building blocks as needed.</p> <p></p>"},{"location":"aca/00-workshop-intro/3-dapr-integration/#dapr-microservices","title":"Dapr &amp; Microservices","text":"<p>Dapr exposes its Building Blocks and components through a sidecar architecture. A sidecar enables Dapr to run in a separate memory process or separate container alongside your service. Sidecars provide isolation and encapsulation as they aren't part of the service, but connected to it. This separation enables each service to have its own runtime environment and be built upon different programming platforms.</p> <p></p> <p>This pattern is named Sidecar because it resembles a sidecar attached to a motorcycle. In the previous figure, note how the Dapr sidecar is attached to your service to provide distributed application capabilities.</p>"},{"location":"aca/00-workshop-intro/3-dapr-integration/#dapr-usage-in-the-workshop","title":"Dapr usage in the workshop","text":"<p>We are going to enable Dapr for all Azure Container Apps in the solution. The Dapr APIs/Building Blocks used in this workshop are:</p> <ul> <li>Service to Service invocation: \"ACA Web App-Frontend\" microservice invokes the \"ACA WebAPI-Backend\" microservice using Dapr sidecar via the Service-to-service invocation building block</li> <li>State Management: \"ACA WebAPI-Backend\" stores data on Azure Cosmos DB and stores email logs on Azure Table Storage using Dapr State Management building blocks.</li> <li>Pub/Sub: \"ACA WebAPI-Backend\" publishes messages to Azure Service Bus when a task is saved and the \"ACA Processor-Backend\" microservices consumes those messages and sends emails using SendGrid.</li> <li>Bindings: \"ACA Processor-Backend\" is triggered based on an incoming event such as a Cron job.</li> </ul>"},{"location":"aca/00-workshop-intro/4-prerequisites/","title":"Prerequisites","text":""},{"location":"aca/00-workshop-intro/4-prerequisites/#prerequisites","title":"Prerequisites","text":"<p>The workshop is divided into separate modules. Each module will guide you through building the solution code step-by-step. Ensure that you finish the modules in the right order as they have dependencies on each other.  </p> <p>Make sure you have your development environment set up and configured.</p> <ol> <li>An Azure account with an active subscription - Create an account for free</li> <li>dotnet 6.0 or a higher version - Install</li> <li>PowerShell 7.0 or higher version (For Windows Users only!) - Install</li> <li>Docker Desktop - Install</li> <li>Visual Studio Code - Install</li> <li>VS Code Docker extension - Install</li> <li>Dapr CLI - Install and Initialize</li> <li>VS Code Dapr extension. Depends on Dapr CLI - Install</li> <li>Azure CLI - Install</li> <li>Git CLI - Install</li> </ol>"},{"location":"aca/00-workshop-intro/4-prerequisites/#set-up-git-repository-variable-scripts","title":"Set up Git Repository &amp; Variable Scripts","text":""},{"location":"aca/00-workshop-intro/4-prerequisites/#git-repository","title":"Git Repository","text":"<p>This workshop typically spans several days. As such, you may close your tools, end CLI sessions, reboot, or simply want to persist working implementations in a repository as each module builds upon the one before it. A local Git repository can help.</p> <ul> <li> <p>Open a command-line terminal and create a folder for your project, then switch to that folder.</p> WindowsLinux <pre><code>md TasksTracker.ContainerApps\ncd TasksTracker.ContainerApps\n</code></pre> <pre><code>mkdir ~\\TasksTracker.ContainerApps\ncd ~\\TasksTracker.ContainerApps\n</code></pre> </li> <li> <p>Initialize the git repository.</p> <pre><code>git init\n</code></pre> </li> <li> <p>Use the <code>code</code> command to launch Visual Studio Code from that directory as shown:</p> <pre><code>code .\n</code></pre> </li> <li> <p>From VS Code's Terminal tab, select New Terminal to open a (PowerShell) terminal in the project folder TasksTracker.ContainerApps.</p> </li> </ul> <p>Note</p> <p>Throughout the documentation, we may refer to the TasksTracker.ContainerApps directory as root to keep documentation simpler.</p> <ul> <li> <p>In the root create a <code>.gitignore</code> file. This ensures we keep our git repo clean of build assets and other artifacts.</p> .gitignore <pre><code># Exclude build artifacts\n**/obj/\n**/bin/\n**/dist/\n</code></pre> </li> <li> <p>Commit the <code>.gitignore</code> file.</p> <pre><code>git add .\\.gitignore\ngit commit -m \"Add .gitignore\"\n</code></pre> </li> </ul>"},{"location":"aca/00-workshop-intro/4-prerequisites/#set-variables-variables-script","title":"Set-Variables &amp; Variables Script","text":"<ul> <li> <p>In the root create a new file called <code>Set-Variables.ps1</code>.</p> </li> <li> <p>Copy the Set-Variables.ps1 script into the newly-created <code>Set-Variables.ps1</code> file and save it.</p> </li> <li> <p>Perform an initial commit of the <code>Set-Variables.ps1</code> file.</p> <pre><code>git add .\\Set-Variables.ps1\ngit commit -m \"Initialize Set-Variables.ps1\"\n</code></pre> </li> <li> <p>Execute the script. You will do this repeatedly throughout the modules. The output of the script will inform you how many variables are written out.</p> <pre><code>.\\Set-Variables.ps1\n</code></pre> </li> <li> <p>Perform an initial commit of the variables file.</p> <pre><code>git add .\\Variables.ps1\ngit commit -m \"Initialize Variables.ps1\"\n</code></pre> </li> </ul> <p>This completes the basic setup for Git and the variables to be used. You are ready to proceed to Module 1!</p>"},{"location":"aca/00-workshop-intro/4-prerequisites/#jump-ahead","title":"Jump Ahead","text":"<p>If you don't want to build the solution code from scratch, you can clone the source code repository final version by utilizing below command, and you can use the modules to deploy Azure resources using the provided Azure CLI commands.</p> <pre><code>git clone https://github.com/Azure/aca-dotnet-workshop.git\n</code></pre>"},{"location":"aca/01-deploy-api-to-aca/","title":"Module 1 - Deploy Backend API to ACA","text":"<p>Module Duration</p> <p>60 minutes</p> <p>Prerequisities</p> <p>Please ensure that all prerequisites have been taken care of prior to continuing.</p>"},{"location":"aca/01-deploy-api-to-aca/#objective","title":"Objective","text":"<p>In this module, we will accomplish three objectives:</p> <ol> <li>Create the first microservice, <code>ACA API - Backend</code>, which serves as the API for our tasks.</li> <li>Create the initial Azure infrastructure that we will need throughout this workshop.</li> <li>Deploy the <code>`ACA API - Backend</code> container app to Azure.</li> </ol>"},{"location":"aca/01-deploy-api-to-aca/#module-sections","title":"Module Sections","text":""},{"location":"aca/01-deploy-api-to-aca/#1-create-the-backend-api-project-web-api","title":"1. Create the backend API project (Web API)","text":"<ul> <li> <p>From VS Code's Terminal tab, select New Terminal to open a (PowerShell) terminal in the project folder TasksTracker.ContainerApps (also referred to as root).</p> </li> <li> <p>We need to define the .NET version we will use throughout this workshop. In the terminal execute <code>dotnet --info</code>. Take note of the intalled .NET SDK versions and select the one with which you wish to proceed.</p> </li> <li> <p>In the root folder create a new file and set the .NET SDK version from the above command:</p> global.json <pre><code>{\n    \"sdk\": {\n        \"version\": \"8.0.100\",\n        \"rollForward\": \"latestFeature\"\n    }\n}\n</code></pre> </li> <li> <p>Now we can initialize the backend API project. This will create and ASP.NET Web API project scaffolded with a single controller.</p> <p>Controller-Based vs. Minimal APIs</p> <p>APIs can be created via the traditional, expanded controller-based structure with Controllers and Models folders, etc. or via the newer minimal APIs approach where controller actions are written inside Program.cs. The latter approach is preferential in a microservices project where the endpoints are overseeable and may easily be represented by a more compact view.  </p> <p>As our workshop takes advantage of microservices, the use case for minimal APIs is given. However, in order to make the workshop a bit more demonstrable, we will, for now, stick with controller-based APIs.</p> .NET 7 or below.NET 8 or above <pre><code>dotnet new webapi -o TasksTracker.TasksManager.Backend.Api\n</code></pre> <pre><code>dotnet new webapi --use-controllers -o TasksTracker.TasksManager.Backend.Api\n</code></pre> </li> <li> <p>Delete the boilerplate <code>WeatherForecast.cs</code> and <code>Controllers\\WeatherForecastController.cs</code> files from the new <code>TasksTracker.TasksManager.Backend.Api</code> project folder.</p> </li> <li> <p>We need to containerize this application, so we can push it to the Azure Container Registry before we deploy it to Azure Container Apps:</p> <ul> <li>Open the VS Code Command Palette (Ctrl+Shift+P) and select Docker: Add Docker Files to Workspace...</li> <li>Use <code>.NET: ASP.NET Core</code> when prompted for the application platform.</li> <li>Choose the newly-created project, if prompted.</li> <li>Choose <code>Linux</code> when prompted to choose the operating system.</li> <li>Set the application port to <code>5000</code>. This is arbitrary but memorable for this workshop.</li> <li>You will be asked if you want to add Docker Compose files. Select <code>No</code>.</li> <li><code>Dockerfile</code> and <code>.dockerignore</code> files are added to the workspace.</li> <li> <p>Open <code>Dockerfile</code> and replace <code>FROM --platform=$BUILDPLATFORM mcr.microsoft.com/dotnet/sdk:8.0 AS build</code> with <code>FROM mcr.microsoft.com/dotnet/sdk:8.0 AS build</code></p> <p>Dockerfile Build Platform</p> <p>Azure Container Registry does not set <code>$BUILDPLATFORM</code> presently when building containers. This consequently causes the build to fail. See this issue for details. Therefore, we remove it from the file for the time being. We expect this to be corrected in the future.</p> </li> </ul> </li> <li> <p>In the project root add a new folder named Models and create a new file with name below. These are the DTOs that will be used across the projects.</p> TaskModel.cs <pre><code>namespace TasksTracker.TasksManager.Backend.Api.Models\n{\n    public class TaskModel\n    {\n        public Guid TaskId { get; set; }\n        public string TaskName { get; set; } = string.Empty;\n        public string TaskCreatedBy { get; set; } = string.Empty;\n        public DateTime TaskCreatedOn { get; set; }\n        public DateTime TaskDueDate { get; set; }\n        public string TaskAssignedTo { get; set; } = string.Empty;\n        public bool IsCompleted { get; set; }\n        public bool IsOverDue { get; set; }\n    }\n\n    public class TaskAddModel\n    {\n        public string TaskName { get; set; } = string.Empty;\n        public string TaskCreatedBy { get; set; } = string.Empty;\n        public DateTime TaskDueDate { get; set; }\n        public string TaskAssignedTo { get; set; } = string.Empty;\n    }\n\n    public class TaskUpdateModel\n    {\n        public Guid TaskId { get; set; }\n        public string TaskName { get; set; } = string.Empty;\n        public DateTime TaskDueDate { get; set; }\n        public string TaskAssignedTo { get; set; } = string.Empty;\n    }\n}\n</code></pre> </li> <li> <p>In the project root create a new folder named Services and add the two files below. Ensure to create it as a sibling to the Models folder. Add the Fake Tasks Manager service. This will be the interface of Tasks Manager service. In this module we will work with data in memory. Later on, we will implement a data store.</p> ITasksManager.csFakeTasksManager.cs <pre><code>using TasksTracker.TasksManager.Backend.Api.Models;\n\nnamespace TasksTracker.TasksManager.Backend.Api.Services\n{\n    public interface ITasksManager\n    {\n        Task&lt;List&lt;TaskModel&gt;&gt; GetTasksByCreator(string createdBy);\n        Task&lt;TaskModel?&gt; GetTaskById(Guid taskId);\n        Task&lt;Guid&gt; CreateNewTask(string taskName, string createdBy, string assignedTo, DateTime dueDate);\n        Task&lt;bool&gt; UpdateTask(Guid taskId, string taskName, string assignedTo, DateTime dueDate);\n        Task&lt;bool&gt; MarkTaskCompleted(Guid taskId);\n        Task&lt;bool&gt; DeleteTask(Guid taskId);\n    }\n}\n</code></pre> <pre><code>using TasksTracker.TasksManager.Backend.Api.Models;\n\nnamespace TasksTracker.TasksManager.Backend.Api.Services\n{\n    public class FakeTasksManager : ITasksManager\n    {\n        List&lt;TaskModel&gt; _tasksList = new List&lt;TaskModel&gt;();\n        Random rnd = new Random();\n\n        private void GenerateRandomTasks()\n        {\n            for (int i = 0; i &lt; 10; i++)\n            {\n                var task = new TaskModel()\n                {\n                    TaskId = Guid.NewGuid(),\n                    TaskName = $\"Task number: {i}\",\n                    TaskCreatedBy = \"tjoudeh@bitoftech.net\",\n                    TaskCreatedOn = DateTime.UtcNow.AddMinutes(i),\n                    TaskDueDate = DateTime.UtcNow.AddDays(i),\n                    TaskAssignedTo = $\"assignee{rnd.Next(50)}@mail.com\",\n                };\n                _tasksList.Add(task);\n            }\n        }\n\n        public FakeTasksManager()\n        {\n            GenerateRandomTasks();\n        }\n\n        public Task&lt;Guid&gt; CreateNewTask(string taskName, string createdBy, string assignedTo, DateTime dueDate)\n        {\n            var task = new TaskModel()\n            {\n                TaskId = Guid.NewGuid(),\n                TaskName = taskName,\n                TaskCreatedBy = createdBy,\n                TaskCreatedOn = DateTime.UtcNow,\n                TaskDueDate = dueDate,\n                TaskAssignedTo = assignedTo,\n            };\n\n            _tasksList.Add(task);\n\n            return Task.FromResult(task.TaskId);\n        }\n\n        public Task&lt;bool&gt; DeleteTask(Guid taskId)\n        {\n            var task = _tasksList.FirstOrDefault(t =&gt; t.TaskId.Equals(taskId));\n\n            if (task != null)\n            {\n                _tasksList.Remove(task);\n                return Task.FromResult(true);\n            }\n\n            return Task.FromResult(false);\n        }\n\n        public Task&lt;TaskModel?&gt; GetTaskById(Guid taskId)\n        {\n            var taskModel = _tasksList.FirstOrDefault(t =&gt; t.TaskId.Equals(taskId));\n            return Task.FromResult(taskModel);\n        }\n\n        public Task&lt;List&lt;TaskModel&gt;&gt; GetTasksByCreator(string createdBy)\n        {\n            var tasksList = _tasksList.Where(t =&gt; t.TaskCreatedBy.Equals(createdBy)).OrderByDescending(o =&gt; o.TaskCreatedOn).ToList();\n            return Task.FromResult(tasksList);\n        }\n\n        public Task&lt;bool&gt; MarkTaskCompleted(Guid taskId)\n        {\n            var task = _tasksList.FirstOrDefault(t =&gt; t.TaskId.Equals(taskId));\n\n            if (task != null)\n            {\n                task.IsCompleted = true;\n                return Task.FromResult(true);\n            }\n\n            return Task.FromResult(false);\n        }\n\n        public Task&lt;bool&gt; UpdateTask(Guid taskId, string taskName, string assignedTo, DateTime dueDate)\n        {\n            var task = _tasksList.FirstOrDefault(t =&gt; t.TaskId.Equals(taskId));\n\n            if (task != null)\n            {\n                task.TaskName = taskName;\n                task.TaskAssignedTo = assignedTo;\n                task.TaskDueDate = dueDate;\n                return Task.FromResult(true);\n            }\n\n            return Task.FromResult(false);\n        }\n    }\n}\n</code></pre> </li> <li> <p>The code above generates ten tasks and stores them in a list in memory. It also has some operations to add/remove/update those tasks.</p> </li> <li> <p>Now we need to register <code>FakeTasksManager</code> on project startup. Open file <code>Program.cs</code> and register the newly created service by adding the highlighted lines from below snippet. Don't forget to include the required <code>using</code> statement for the task interface and class.</p> Program.cs <pre><code>using TasksTracker.TasksManager.Backend.Api.Services;\n\nvar builder = WebApplication.CreateBuilder(args);\n\n// Add services to the container.\n\nbuilder.Services.AddSingleton&lt;ITasksManager, FakeTasksManager&gt;();\nbuilder.Services.AddControllers();\n// Learn more about configuring Swagger/OpenAPI at https://aka.ms/aspnetcore/swashbuckle\nbuilder.Services.AddEndpointsApiExplorer();\nbuilder.Services.AddSwaggerGen();\n\nvar app = builder.Build();\n\n// Configure the HTTP request pipeline.\nif (app.Environment.IsDevelopment())\n{\n    app.UseSwagger();\n    app.UseSwaggerUI();\n}\n\napp.UseHttpsRedirection();\n\napp.UseAuthorization();\n\napp.MapControllers();\n\napp.Run();\n</code></pre> </li> <li> <p>Inside the Controllers folder create a new controller with the below filename. We need to create API endpoints to manage tasks.</p> TasksController.cs <pre><code>using Microsoft.AspNetCore.Mvc;\nusing TasksTracker.TasksManager.Backend.Api.Models;\nusing TasksTracker.TasksManager.Backend.Api.Services;\n\nnamespace TasksTracker.TasksManager.Backend.Api.Controllers\n{\n    [Route(\"api/tasks\")]\n    [ApiController]\n    public class TasksController : ControllerBase\n    {\n        private readonly ILogger&lt;TasksController&gt; _logger;\n        private readonly ITasksManager _tasksManager;\n\n        public TasksController(ILogger&lt;TasksController&gt; logger, ITasksManager tasksManager)\n        {\n            _logger = logger;\n            _tasksManager = tasksManager;\n        }\n\n        [HttpGet]\n        public async Task&lt;IEnumerable&lt;TaskModel&gt;&gt; Get(string createdBy)\n        {\n            return await _tasksManager.GetTasksByCreator(createdBy);\n        }\n\n        [HttpGet(\"{taskId}\")]\n        public async Task&lt;IActionResult&gt; GetTask(Guid taskId)\n        {\n            var task = await _tasksManager.GetTaskById(taskId);\n\n            return (task != null) ? Ok(task) : NotFound();\n        }\n\n        [HttpPost]\n        public async Task&lt;IActionResult&gt; Post([FromBody] TaskAddModel taskAddModel)\n        {\n            var taskId = await _tasksManager.CreateNewTask(\n                taskAddModel.TaskName,\n                taskAddModel.TaskCreatedBy,\n                taskAddModel.TaskAssignedTo,\n                taskAddModel.TaskDueDate\n            );\n\n            return Created($\"/api/tasks/{taskId}\", null);\n\n        }\n\n        [HttpPut(\"{taskId}\")]\n        public async Task&lt;IActionResult&gt; Put(Guid taskId, [FromBody] TaskUpdateModel taskUpdateModel)\n        {\n            var updated = await _tasksManager.UpdateTask(\n                taskId,\n                taskUpdateModel.TaskName,\n                taskUpdateModel.TaskAssignedTo,\n                taskUpdateModel.TaskDueDate\n            );\n\n            return updated ? Ok() : BadRequest();\n        }\n\n        [HttpPut(\"{taskId}/markcomplete\")]\n        public async Task&lt;IActionResult&gt; MarkComplete(Guid taskId)\n        {\n            var updated = await _tasksManager.MarkTaskCompleted(taskId);\n\n            return updated ? Ok() : BadRequest();\n        }\n\n        [HttpDelete(\"{taskId}\")]\n        public async Task&lt;IActionResult&gt; Delete(Guid taskId)\n        {\n            var deleted = await _tasksManager.DeleteTask(taskId);\n\n            return deleted ? Ok() : NotFound();\n        }\n    }\n}\n</code></pre> </li> <li> <p>From VS Code Terminal tab, open developer command prompt or PowerShell terminal and navigate to the parent directory which hosts the <code>.csproj</code> project folder and build the project.</p> <pre><code>cd ~\\TasksTracker.ContainerApps\\TasksTracker.TasksManager.Backend.Api\ndotnet build\n</code></pre> </li> </ul> <p>Note</p> <p>Throughout the documentation, we will use the the tilde character [~] to represent the base / parent folder where you chose to install the workshop assets.</p> <p>Make sure that the build is successful and that there are no build errors. Usually you should see a \"Build succeeded\" message in the terminal upon a successful build.</p> <ul> <li> <p>Navigate to the root and persist the module to Git.</p> <pre><code>git add .\ngit commit -m \"Add Module 1\"\n</code></pre> </li> </ul>"},{"location":"aca/01-deploy-api-to-aca/#2-create-azure-infrastructure","title":"2. Create Azure Infrastructure","text":""},{"location":"aca/01-deploy-api-to-aca/#21-define-the-basics","title":"2.1 Define the Basics","text":"<p>We will be using Azure CLI to deploy the Web API Backend to ACA as shown in the following steps:</p> <ul> <li> <p>First, we need to ensure that our CLI is updated. Then we log in to Azure.</p> <pre><code># Upgrade the Azure CLI\naz upgrade\n\n# Install/upgrade the Azure Container Apps &amp; Application Insights extensions\naz extension add --upgrade --name containerapp\naz extension add --upgrade --name application-insights\n\n# Log in to Azure\naz login \n</code></pre> </li> <li> <p>You may be able to use the queried Azure subscription ID or you may need to set it manually depending on your setup.</p> <pre><code># Retrieve the currently active Azure subscription ID\n$AZURE_SUBSCRIPTION_ID = az account show --query id --output tsv\n\n# Set a specific Azure Subscription ID (if you have multiple subscriptions)\n# $AZURE_SUBSCRIPTION_ID = \"&lt;Your Azure Subscription ID&gt;\" # Your Azure Subscription id which you can find on the Azure portal\n# az account set --subscription $AZURE_SUBSCRIPTION_ID\n\necho $AZURE_SUBSCRIPTION_ID\n</code></pre> </li> <li> <p>Execute the variables below in the PowerShell console to use them across the different modules in the workshop. Some of these variables must be globally unique, which we attempt by using <code>$RANDOM_STRING</code>:</p> <pre><code># Create a random, 6-digit, Azure safe string\n$RANDOM_STRING=-join ((97..122) + (48..57) | Get-Random -Count 6 | ForEach-Object { [char]$_})\n$RESOURCE_GROUP=\"rg-tasks-tracker-$RANDOM_STRING\"\n$LOCATION=\"eastus\"\n$ENVIRONMENT=\"cae-tasks-tracker\"\n$WORKSPACE_NAME=\"log-tasks-tracker-$RANDOM_STRING\"\n$APPINSIGHTS_NAME=\"appi-tasks-tracker-$RANDOM_STRING\"\n$BACKEND_API_NAME=\"tasksmanager-backend-api\"\n$AZURE_CONTAINER_REGISTRY_NAME=\"crtaskstracker$RANDOM_STRING\"\n$VNET_NAME=\"vnet-tasks-tracker\"\n$TARGET_PORT=5000\n</code></pre> </li> </ul> Cloud Adoption Framework Abbreviations <p>Unless you have your own naming convention, we suggest to use Cloud Adoption Framework (CAF) abbreviations for resource prefixes.</p> <ul> <li> <p>Create a resource group to organize the services related to the application, run the below command:</p> <pre><code>az group create `\n--name $RESOURCE_GROUP `\n--location \"$LOCATION\"\n</code></pre> </li> </ul>"},{"location":"aca/01-deploy-api-to-aca/#22-create-network-infrastructure","title":"2.2 Create Network Infrastructure","text":"<p>Note</p> <p>We are keeping this implementation simple. A production workload should have Network Security Groups and a firewall.</p> <ul> <li> <p>We need to create a virtual network (VNet) to secure our container apps. Note that while the VNet size with <code>/16</code> CIDR is arbitrary, the container app subnet must have at least a <code>/27</code> CIDR.</p> <pre><code>az network vnet create `\n--name $VNET_NAME `\n--resource-group $RESOURCE_GROUP `\n--address-prefix 10.0.0.0/16 `\n--subnet-name ContainerAppSubnet `\n--subnet-prefix 10.0.0.0/27\n</code></pre> </li> <li> <p>Azure Container Apps requires management of the subnet, so we must delegate exclusive control.</p> <pre><code>az network vnet subnet update `\n--name ContainerAppSubnet `\n--resource-group $RESOURCE_GROUP `\n--vnet-name $VNET_NAME `\n--delegations Microsoft.App/environments\n</code></pre> </li> <li> <p>Retrieve the Azure Container App subnet resource ID as it will be referenced when the Azure Container App Environment is created later.</p> <pre><code>$ACA_ENVIRONMENT_SUBNET_ID=$(az network vnet subnet show `\n--name ContainerAppSubnet `\n--resource-group $RESOURCE_GROUP `\n--vnet-name $VNET_NAME `\n--query id `\n--output tsv)\n</code></pre> </li> </ul>"},{"location":"aca/01-deploy-api-to-aca/#23-create-log-analytics-workspace-application-insights","title":"2.3 Create Log Analytics workspace &amp; Application Insights","text":"<ul> <li> <p>Create an Azure Log Analytics workspace which will provide a common place to store the system and application log data from all container apps running in the environment. Each environment should have its own Log Analytics workspace.</p> <pre><code># Create the Log Analytics workspace\naz monitor log-analytics workspace create `\n--resource-group $RESOURCE_GROUP `\n--workspace-name $WORKSPACE_NAME\n\n# Retrieve the Log Analytics workspace ID\n$WORKSPACE_ID=az monitor log-analytics workspace show `\n--resource-group $RESOURCE_GROUP `\n--workspace-name $WORKSPACE_NAME `\n--query customerId `\n--output tsv\n\n# Retrieve the Log Analytics workspace secret\n$WORKSPACE_SECRET=az monitor log-analytics workspace get-shared-keys `\n--resource-group $RESOURCE_GROUP `\n--workspace-name $WORKSPACE_NAME `\n--query primarySharedKey `\n--output tsv\n</code></pre> </li> <li> <p>Create an Application Insights instance which will be used mainly for distributed tracing between different container apps within the ACA environment to provide searching for and visualizing an end-to-end flow of a given execution or transaction. To create it, run the command below:</p> <pre><code># Create Application Insights instance\naz monitor app-insights component create `\n--resource-group $RESOURCE_GROUP `\n--location $LOCATION `\n--app $APPINSIGHTS_NAME `\n--workspace $WORKSPACE_NAME\n\n# Get Application Insights Instrumentation Key\n$APPINSIGHTS_INSTRUMENTATIONKEY=($(az monitor app-insights component show `\n--resource-group $RESOURCE_GROUP `\n--app $APPINSIGHTS_NAME ) | ConvertFrom-Json).instrumentationKey\n</code></pre> </li> </ul>"},{"location":"aca/01-deploy-api-to-aca/#24-azure-container-infrastructure","title":"2.4 Azure Container Infrastructure","text":"<ul> <li> <p>Create an Azure Container Registry (ACR) instance in the resource group to store images of all Microservices we are going to build during this workshop. Make sure that you set the <code>admin-enabled</code> flag to true in order to seamlessly authenticate the Azure container app when trying to create the container app using the image stored in ACR.</p> <pre><code>az acr create `\n--name $AZURE_CONTAINER_REGISTRY_NAME `\n--resource-group $RESOURCE_GROUP `\n--sku Basic `\n--admin-enabled true\n</code></pre> </li> </ul> <p>Note</p> <p>Notice that we create the registry with admin rights <code>--admin-enabled</code> flag set to <code>true</code> which is not suited for real production, but good for our workshop.</p> <ul> <li> <p>Now we will create an Azure Container Apps Environment. As a reminder of the different ACA components, see this link in the workshop introduction. The ACA environment acts as a secure boundary around a group of container apps that we are going to provision during this workshop.</p> <pre><code># Create the ACA environment\naz containerapp env create `\n--name $ENVIRONMENT `\n--resource-group $RESOURCE_GROUP `\n--location $LOCATION `\n--logs-workspace-id $WORKSPACE_ID `\n--logs-workspace-key $WORKSPACE_SECRET `\n--dapr-instrumentation-key $APPINSIGHTS_INSTRUMENTATIONKEY `\n--enable-workload-profiles `\n--infrastructure-subnet-resource-id $ACA_ENVIRONMENT_SUBNET_ID\n</code></pre> </li> </ul> <p>Note</p> <p>We are not creating an <code>internal-only</code> Azure Container App Environment. This means that the static IP will be a public IP, and container apps, by default, will be publicly available on the internet. While this is not advised in a production workload, it is suitable for the workshop to keep the architecture confined to Azure Container Apps.</p> Want to learn what above command does? <ul> <li>It creates an ACA environment and associates it with the Log Analytics workspace created in the previous step.</li> <li>We are setting the <code>--dapr-instrumentation-key</code> value to the instrumentation key of the Application Insights instance. This will come handy when we introduce Dapr in later modules and show how the distributed tracing between microservices/container apps are captured and visualized in Application Insights.   <p>NOTE: You can set the <code>--dapr-instrumentation-key</code> after you create the ACA environment but this is not possible via the AZ CLI right now. There is an open issue which is being tracked by the product group.</p> </li> </ul>"},{"location":"aca/01-deploy-api-to-aca/#3-deploy-web-api-backend-project-to-aca","title":"3. Deploy Web API Backend Project to ACA","text":"<ul> <li> <p>Build the Web API project on ACR and push the docker image to ACR. Use the below command to initiate the image build and push process using ACR. The <code>.</code> at the end of the command represents the docker build context, in our case, we need to be on the parent directory which hosts the <code>.csproj</code>.</p> <pre><code>az acr build `\n--registry $AZURE_CONTAINER_REGISTRY_NAME `\n--image \"tasksmanager/$BACKEND_API_NAME\" `\n--file 'TasksTracker.TasksManager.Backend.Api/Dockerfile' .\n</code></pre> <p>Once this step is completed, you can verify the results by going to the Azure portal and checking that a new repository named <code>tasksmanager/tasksmanager-backend-api</code> has been created, and that there is a new Docker image with a <code>latest</code> tag.</p> </li> <li> <p>The last step here is to create and deploy the Web API to ACA following the below command:</p> <pre><code>$fqdn=(az containerapp create `\n--name $BACKEND_API_NAME `\n--resource-group $RESOURCE_GROUP `\n--environment $ENVIRONMENT `\n--image \"$AZURE_CONTAINER_REGISTRY_NAME.azurecr.io/tasksmanager/$BACKEND_API_NAME\" `\n--registry-server \"$AZURE_CONTAINER_REGISTRY_NAME.azurecr.io\" `\n--target-port $TARGET_PORT `\n--ingress 'external' `\n--min-replicas 1 `\n--max-replicas 1 `\n--cpu 0.25 `\n--memory 0.5Gi `\n--query properties.configuration.ingress.fqdn `\n--output tsv)\n\n$BACKEND_API_EXTERNAL_BASE_URL=\"https://$fqdn\"\n\necho \"See a listing of tasks created by the author at this URL:\"\necho \"https://$fqdn/api/tasks/?createdby=tjoudeh@bitoftech.net\"\n</code></pre> </li> </ul> Want to learn what above command does? <ul> <li>Ingress param is set to <code>external</code> which means that this container app (Web API) project will be accessible from the public internet. When Ingress is set to <code>Internal</code> or <code>External</code> it will be assigned a fully qualified domain name (FQDN). Important notes about IP addresses and domain names can be found here.</li> <li>The target port param is set to 80, this is the port our Web API container listens to for incoming requests.</li> <li>We didn't specify the ACR registry username and password, <code>az containerapp create</code> command was able to look up ACR username and password and add them as a secret under the created Azure container app for future container updates.</li> <li>The minimum and the maximum number of replicas are set. More about this when we cover Autoscaling in later modules. For the time being, only a single instance of this container app will be provisioned as Auto scale is not configured.</li> <li>We set the size of the Container App. The total amount of CPUs and memory requested for the container app must add up to certain combinations, for full details check the link here.</li> <li>The <code>query</code> property will filter the response coming from the command and just return the FQDN. Take note of this FQDN as you will need it for the next step.</li> </ul> <p>For full details on all available parameters for this command, please visit this page.</p> <ul> <li>You can now verify the deployment of the first ACA by navigating to the link at the end of the above script or to the Azure portal and selecting the resource group named <code>tasks-tracker-rg</code> that you created earlier. You should see the 5 resourses created below. </li> </ul> <p>Success</p> <p>To test the backend api service, either click on the URL output by the last command or copy the FQDN (Application URL) of the Azure container app named <code>tasksmanager-backend-api</code>, then issue a <code>GET</code> request similar to this one: <code>https://tasksmanager-backend-api.&lt;your-aca-env-unique-id&gt;.eastus.azurecontainerapps.io/api/tasks/?createdby=tjoudeh@bitoftech.net</code> and you should receive an array of the 10 tasks similar to the below image.</p> <p>Note that the specific query string matters as you may otherwise get an empty result back. </p> <p>Tip</p> <p>You can find your Azure container app application url on the Azure portal overview tab.</p> <p></p> <ul> <li> <p>Execute the <code>Set-Variables.ps1</code> in the root to update the <code>variables.ps1</code> file with all current variables. The output of the script will inform you how many variables are written out.</p> <pre><code>.\\Set-Variables.ps1\n</code></pre> </li> <li> <p>From the root, persist a list of all current variables.</p> <pre><code>git add .\\Variables.ps1\ngit commit -m \"Update Variables.ps1\"\n</code></pre> </li> </ul>"},{"location":"aca/01-deploy-api-to-aca/#review","title":"Review","text":"<p>In this module, we have accomplished three objectives:</p> <ol> <li>Created the first microservice, <code>ACA API - Backend</code>, which serves as the API for our tasks.</li> <li>Created the initial Azure infrastructure that we will need throughout this workshop.</li> <li>Deployed the <code>ACA API - Backend</code> microservice to Azure.</li> </ol> <p>In the next module, we will add a new frontend web app as a microservice to communicate with the backend API.</p>"},{"location":"aca/02-aca-comm/","title":"Module 2 - Communication Between Microservices in ACA","text":"<p>Module Duration</p> <p>60 minutes</p>"},{"location":"aca/02-aca-comm/#objective","title":"Objective","text":"<p>In this module, we will accomplish three objectives:</p> <ol> <li>Create a web app named <code>ACA Web - Frontend</code>, which is the UI to interact with <code>ACA API - Backend</code>.</li> <li>Deploy the <code>ACA Web - Frontend</code> container app to Azure.</li> <li>Shield <code>ACA API - Backend</code> from external access.</li> </ol>"},{"location":"aca/02-aca-comm/#module-sections","title":"Module Sections","text":"<ul> <li> <p>From the VS Code Terminal tab, open developer command prompt or PowerShell terminal in the project folder <code>TasksTracker.ContainerApps</code> (root):</p> <pre><code>cd ~\\TasksTracker.ContainerApps\n</code></pre> </li> <li> <p>Restore the previously-stored variables by executing the local script. The output informs you how many variables have been set.</p> <pre><code>.\\Variables.ps1\n</code></pre> </li> </ul>"},{"location":"aca/02-aca-comm/#1-create-the-frontend-web-app-project","title":"1. Create the Frontend Web App project","text":"<ul> <li> <p>Initialize the web project. This will create and ASP.NET Razor Pages web app project.</p> <pre><code>dotnet new webapp -o TasksTracker.WebPortal.Frontend.Ui\n</code></pre> </li> <li> <p>We need to containerize this application, so we can push it to the Azure Container Registry before we deploy it to Azure Container Apps:</p> <ul> <li>Open the VS Code Command Palette (Ctrl+Shift+P) and select Docker: Add Docker Files to Workspace...</li> <li>Use <code>.NET: ASP.NET Core</code> when prompted for the application platform.</li> <li>Choose the newly-created project, if prompted.</li> <li>Choose <code>Linux</code> when prompted to choose the operating system.</li> <li>Set the application port to <code>5000</code>. This is arbitrary but memorable for this workshop.</li> <li>You will be asked if you want to add Docker Compose files. Select <code>No</code>.</li> <li><code>Dockerfile</code> and <code>.dockerignore</code> files are added to the workspace.</li> <li> <p>Open <code>Dockerfile</code> and replace <code>FROM --platform=$BUILDPLATFORM mcr.microsoft.com/dotnet/sdk:8.0 AS build</code> with <code>FROM mcr.microsoft.com/dotnet/sdk:8.0 AS build</code></p> <p>Dockerfile Build Platform</p> <p>Azure Container Registry does not set <code>$BUILDPLATFORM</code> presently when building containers. This consequently causes the build to fail. See this issue for details. Therefore, we remove it from the file for the time being. We expect this to be corrected in the future.</p> </li> </ul> </li> <li> <p>From inside the Pages folder, add a new folder named Tasks. Within that folder, add a new folder named Models, then create file as shown below.</p> TasksModel.cs <pre><code>using Microsoft.AspNetCore.Mvc;\nusing System.ComponentModel.DataAnnotations;\n\nnamespace TasksTracker.WebPortal.Frontend.Ui.Pages.Tasks.Models\n{\n    public class TaskModel\n    {\n        public Guid TaskId { get; set; }\n        public string TaskName { get; set; } = string.Empty;\n        public string TaskCreatedBy { get; set; } = string.Empty;\n        public DateTime TaskCreatedOn { get; set; }\n        public DateTime TaskDueDate { get; set; }\n        public string TaskAssignedTo { get; set; } = string.Empty;\n        public bool IsCompleted { get; set; }\n        public bool IsOverDue { get; set; }\n    }\n\n    public class TaskAddModel\n    {\n        [Display(Name = \"Task Name\")]\n        [Required]\n        public string TaskName { get; set; } = string.Empty;\n\n        [Display(Name = \"Task DueDate\")]\n        [Required]\n        public DateTime TaskDueDate { get; set; }\n\n        [Display(Name = \"Assigned To\")]\n        [Required]\n        public string TaskAssignedTo { get; set; } = string.Empty;\n        public string TaskCreatedBy { get; set; } = string.Empty;\n    }\n\n    public class TaskUpdateModel\n    {\n        public Guid TaskId { get; set; }\n\n        [Display(Name = \"Task Name\")]\n        [Required]\n        public string TaskName { get; set; } = string.Empty;\n\n        [Display(Name = \"Task DueDate\")]\n        [Required]\n        public DateTime TaskDueDate { get; set; }\n\n        [Display(Name = \"Assigned To\")]\n        [Required]\n        public string TaskAssignedTo { get; set; } = string.Empty;\n    }\n}\n</code></pre> </li> <li> <p>Now, in the Tasks folder, we will add 3 Razor pages for CRUD operations which will be responsible for listing tasks, creating a new task, and updating existing tasks. By looking at the cshtml content notice that the page is expecting a query string named <code>createdBy</code> which will be used to group tasks for application users.</p> <p>Note</p> <p>We are following this approach here to keep the workshop simple, but for production applications, authentication should be applied and the user email should be retrieved from the claims identity of the authenticated users.</p> Index.cshtmlIndex.cshtml.csCreate.cshtmlCreate.cshtml.csEdit.cshtmlEdit.cshtml.cs <pre><code>@page \n@model TasksTracker.WebPortal.Frontend.Ui.Pages.Tasks.IndexModel\n@{\n}\n\n&lt;h1&gt;Tasks Manager&lt;/h1&gt;\n@if (!String.IsNullOrEmpty(Model.TasksCreatedBy)) {\n    &lt;h4&gt;Tasks for (@Model.TasksCreatedBy)&lt;/h4&gt;\n}\n&lt;form method=\"post\"&gt;\n    &lt;table class=\"table\"&gt;\n        &lt;thead&gt;\n            &lt;tr&gt;\n                &lt;th&gt;Name&lt;/th&gt;\n                &lt;th&gt;Due Date&lt;/th&gt;\n                &lt;th&gt;Assigned To&lt;/th&gt;\n                &lt;th&gt;Completed&lt;/th&gt;\n                &lt;th&gt;Overdue&lt;/th&gt;\n                &lt;th&gt;&lt;/th&gt;\n            &lt;/tr&gt;\n        &lt;/thead&gt;\n        &lt;tbody&gt;\n            @if (Model.TasksList != null)\n            {\n                foreach (var task in Model.TasksList)\n                {\n                    &lt;tr&gt;\n                        &lt;td&gt;&lt;a asp-page=\"./Edit\" asp-route-id=\"@task.TaskId\"&gt;@task.TaskName&lt;/a&gt;&lt;/td&gt;\n                        &lt;td&gt;@task.TaskDueDate.Date.ToString(\"dd-MM-yyyy\")&lt;/td&gt;\n                        &lt;td&gt;@task.TaskAssignedTo&lt;/td&gt;\n                        &lt;td&gt;@Html.CheckBox(\"IsCompleted\",@task.IsCompleted)&lt;/td&gt;\n                        &lt;td&gt;@Html.CheckBox(\"IsOverDue\",@task.IsOverDue)&lt;/td&gt;\n                        &lt;td&gt;\n                            &lt;button type=\"submit\" asp-page-handler=\"complete\" asp-route-id=\"@task.TaskId\"&gt;Complete&lt;/button&gt;\n                            &lt;button type=\"submit\" asp-page-handler=\"delete\" asp-route-id=\"@task.TaskId\"&gt;Delete&lt;/button&gt;\n                        &lt;/td&gt;\n                    &lt;/tr&gt;\n                }\n            }\n        &lt;/tbody&gt;\n    &lt;/table&gt;\n    &lt;a asp-page=\"Create\"&gt;Create New&lt;/a&gt;\n&lt;/form&gt;\n</code></pre> <pre><code>using Microsoft.AspNetCore.Mvc;\nusing Microsoft.AspNetCore.Mvc.RazorPages;\nusing TasksTracker.WebPortal.Frontend.Ui.Pages.Tasks.Models;\n\nnamespace TasksTracker.WebPortal.Frontend.Ui.Pages.Tasks\n{\n    public class IndexModel : PageModel\n    {\n        private readonly IHttpClientFactory _httpClientFactory;\n        public List&lt;TaskModel&gt;? TasksList { get; set; }\n\n        [BindProperty]\n        public string? TasksCreatedBy { get; set; }\n\n        public IndexModel(IHttpClientFactory httpClientFactory)\n        {\n            _httpClientFactory = httpClientFactory;\n        }\n\n        public async Task&lt;IActionResult&gt; OnGetAsync()\n        {\n            TasksCreatedBy = Request.Cookies[\"TasksCreatedByCookie\"];\n\n            if (!String.IsNullOrEmpty(TasksCreatedBy)) {\n                // direct svc to svc http request\n                var httpClient = _httpClientFactory.CreateClient(\"BackEndApiExternal\");\n                TasksList = await httpClient.GetFromJsonAsync&lt;List&lt;TaskModel&gt;&gt;($\"api/tasks?createdBy={TasksCreatedBy}\");\n                return Page();\n            } else {\n                return RedirectToPage(\"../Index\");\n            }\n        }\n\n        public async Task&lt;IActionResult&gt; OnPostDeleteAsync(Guid id)\n        {\n            // direct svc to svc http request\n            var httpClient = _httpClientFactory.CreateClient(\"BackEndApiExternal\");\n            var result = await httpClient.DeleteAsync($\"api/tasks/{id}\");\n            return RedirectToPage();\n        }\n\n        public async Task&lt;IActionResult&gt; OnPostCompleteAsync(Guid id)\n        {\n            // direct svc to svc http request\n            var httpClient = _httpClientFactory.CreateClient(\"BackEndApiExternal\");\n            var result = await httpClient.PutAsync($\"api/tasks/{id}/markcomplete\", null);\n            return RedirectToPage();\n        }\n    }\n}\n</code></pre> <p>What does this code do?</p> <p>In the code above we've injected named HttpClientFactory which is responsible to call the Backend API service as HTTP request. The index page supports deleting and marking tasks as completed along with listing tasks for certain users based on the <code>createdBy</code> property stored in a cookie named <code>TasksCreatedByCookie</code>. More about populating this property later in the workshop.</p> <pre><code>@page\n@model TasksTracker.WebPortal.Frontend.Ui.Pages.Tasks.CreateModel\n@{\n}\n\n&lt;h1&gt;Create Task&lt;/h1&gt;\n\n&lt;h4&gt;Task&lt;/h4&gt;\n&lt;hr /&gt;\n&lt;div class=\"row\"&gt;\n    &lt;div class=\"col-md-4\"&gt;\n        &lt;form method=\"post\"&gt;\n            &lt;div asp-validation-summary=\"ModelOnly\" class=\"text-danger\"&gt;&lt;/div&gt;\n            &lt;div class=\"form-group\"&gt;\n                &lt;label asp-for=\"TaskAdd!.TaskName\" class=\"control-label\"&gt;&lt;/label&gt;\n                &lt;input asp-for=\"TaskAdd!.TaskName\" class=\"form-control\" /&gt;\n                &lt;span asp-validation-for=\"TaskAdd!.TaskName\" class=\"text-danger\"&gt;&lt;/span&gt;\n            &lt;/div&gt;\n\n            &lt;div class=\"form-group\"&gt;\n                &lt;label asp-for=\"TaskAdd!.TaskDueDate\" class=\"control-label\"&gt;&lt;/label&gt;\n                &lt;input asp-for=\"TaskAdd!.TaskDueDate\" class=\"form-control\" type=\"date\" /&gt;\n                &lt;span asp-validation-for=\"TaskAdd!.TaskDueDate\" class=\"text-danger\"&gt;&lt;/span&gt;\n            &lt;/div&gt;\n\n            &lt;div class=\"form-group\"&gt;\n                &lt;label asp-for=\"TaskAdd!.TaskAssignedTo\" class=\"control-label\"&gt;&lt;/label&gt;\n                &lt;input asp-for=\"TaskAdd!.TaskAssignedTo\" class=\"form-control\" type=\"email\" /&gt;\n                &lt;span asp-validation-for=\"TaskAdd!.TaskAssignedTo\" class=\"text-danger\"&gt;&lt;/span&gt;\n            &lt;/div&gt;\n\n            &lt;div class=\"form-group\"&gt;\n                &lt;input type=\"submit\" value=\"Save\" class=\"btn btn-primary\" /&gt;\n            &lt;/div&gt;\n        &lt;/form&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div&gt;\n    &lt;a asp-page=\"./Index\"&gt;Back to List&lt;/a&gt;\n&lt;/div&gt;\n\n@section Scripts {\n    @{\n        await Html.RenderPartialAsync(\"_ValidationScriptsPartial\");\n    }\n}\n</code></pre> <pre><code>using Microsoft.AspNetCore.Mvc;\nusing Microsoft.AspNetCore.Mvc.RazorPages;\nusing TasksTracker.WebPortal.Frontend.Ui.Pages.Tasks.Models;\n\nnamespace TasksTracker.WebPortal.Frontend.Ui.Pages.Tasks\n{\n    public class CreateModel : PageModel\n    {\n        private readonly IHttpClientFactory _httpClientFactory;\n        public CreateModel(IHttpClientFactory httpClientFactory)\n        {\n            _httpClientFactory = httpClientFactory;\n        }\n        public string? TasksCreatedBy { get; set; }\n\n        public IActionResult OnGet()\n        {\n            TasksCreatedBy = Request.Cookies[\"TasksCreatedByCookie\"];\n\n            return (!String.IsNullOrEmpty(TasksCreatedBy)) ? Page() : RedirectToPage(\"../Index\");\n        }\n\n        [BindProperty]\n        public TaskAddModel? TaskAdd { get; set; }\n\n        public async Task&lt;IActionResult&gt; OnPostAsync()\n        {\n            if (!ModelState.IsValid)\n            {\n                return Page();\n            }\n\n            if (TaskAdd != null)\n            {\n                var createdBy = Request.Cookies[\"TasksCreatedByCookie\"];\n\n                if (!string.IsNullOrEmpty(createdBy))\n                {\n                    TaskAdd.TaskCreatedBy = createdBy;\n\n                    // direct svc to svc http request\n                    var httpClient = _httpClientFactory.CreateClient(\"BackEndApiExternal\");\n                    var result = await httpClient.PostAsJsonAsync(\"api/tasks/\", TaskAdd);\n                }\n            }\n\n            return RedirectToPage(\"./Index\");\n        }\n    }\n}\n</code></pre> <p>What does this code do?</p> <p>The code is self-explanatory here. We just injected the type HttpClientFactory in order to issue a POST request and create a new task.</p> <pre><code>@page \"{id:guid}\"\n@model TasksTracker.WebPortal.Frontend.Ui.Pages.Tasks.EditModel\n@{\n    ViewData[\"Title\"] = \"Edit\";\n}\n\n\n&lt;h1&gt;Edit Task&lt;/h1&gt;\n\n&lt;h4&gt;Task&lt;/h4&gt;\n&lt;hr /&gt;\n&lt;div class=\"row\"&gt;\n    &lt;div class=\"col-md-4\"&gt;\n        &lt;form method=\"post\"&gt;\n            &lt;div asp-validation-summary=\"ModelOnly\" class=\"text-danger\"&gt;&lt;/div&gt;\n            &lt;input type=\"hidden\" asp-for=\"TaskUpdate!.TaskId\" /&gt;\n            &lt;div class=\"form-group\"&gt;\n                &lt;label asp-for=\"TaskUpdate!.TaskName\" class=\"control-label\"&gt;&lt;/label&gt;\n                &lt;input asp-for=\"TaskUpdate!.TaskName\" class=\"form-control\" /&gt;\n                &lt;span asp-validation-for=\"TaskUpdate!.TaskName\" class=\"text-danger\"&gt;&lt;/span&gt;\n            &lt;/div&gt;\n\n            &lt;div class=\"form-group\"&gt;\n                &lt;label asp-for=\"TaskUpdate!.TaskDueDate\" class=\"control-label\"&gt;&lt;/label&gt;\n                &lt;input asp-for=\"TaskUpdate!.TaskDueDate\" class=\"form-control\" type=\"date\" /&gt;\n                &lt;span asp-validation-for=\"TaskUpdate!.TaskDueDate\" class=\"text-danger\"&gt;&lt;/span&gt;\n            &lt;/div&gt;\n\n            &lt;div class=\"form-group\"&gt;\n                &lt;label asp-for=\"TaskUpdate!.TaskAssignedTo\" class=\"control-label\"&gt;&lt;/label&gt;\n                &lt;input asp-for=\"TaskUpdate!.TaskAssignedTo\" class=\"form-control\" /&gt;\n                &lt;span asp-validation-for=\"TaskUpdate!.TaskAssignedTo\" class=\"text-danger\"&gt;&lt;/span&gt;\n            &lt;/div&gt;\n\n            &lt;div class=\"form-group\"&gt;\n                &lt;input type=\"submit\" value=\"Save\" class=\"btn btn-primary\" /&gt;\n            &lt;/div&gt;\n        &lt;/form&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div&gt;\n    &lt;a asp-page=\"./Index\"&gt;Back to List&lt;/a&gt;\n&lt;/div&gt;\n\n@section Scripts {\n    @{\n        await Html.RenderPartialAsync(\"_ValidationScriptsPartial\");\n    }\n}\n</code></pre> <pre><code>using Microsoft.AspNetCore.Mvc;\nusing Microsoft.AspNetCore.Mvc.RazorPages;\nusing TasksTracker.WebPortal.Frontend.Ui.Pages.Tasks.Models;\n\nnamespace TasksTracker.WebPortal.Frontend.Ui.Pages.Tasks\n{\n    public class EditModel : PageModel\n    {\n        private readonly IHttpClientFactory _httpClientFactory;\n\n        [BindProperty]\n        public TaskUpdateModel? TaskUpdate { get; set; }\n        public string? TasksCreatedBy { get; set; }\n\n        public EditModel(IHttpClientFactory httpClientFactory)\n        {\n            _httpClientFactory = httpClientFactory;\n        }\n\n        public async Task&lt;IActionResult&gt; OnGetAsync(Guid? id)\n        {\n            TasksCreatedBy = Request.Cookies[\"TasksCreatedByCookie\"];\n\n            if (String.IsNullOrEmpty(TasksCreatedBy)) {\n                return RedirectToPage(\"../Index\");\n            }\n\n            if (id == null)\n            {\n                return NotFound();\n            }\n\n            // direct svc to svc http request\n            var httpClient = _httpClientFactory.CreateClient(\"BackEndApiExternal\");\n            var Task = await httpClient.GetFromJsonAsync&lt;TaskModel&gt;($\"api/tasks/{id}\");\n\n            if (Task == null)\n            {\n                return NotFound();\n            }\n\n            TaskUpdate = new TaskUpdateModel()\n            {\n                TaskId = Task.TaskId,\n                TaskName = Task.TaskName,\n                TaskAssignedTo = Task.TaskAssignedTo,\n                TaskDueDate = Task.TaskDueDate,\n            };\n\n            return Page();\n        }\n\n        public async Task&lt;IActionResult&gt; OnPostAsync()\n        {\n            if (!ModelState.IsValid)\n            {\n                return Page();\n            }\n\n            if (TaskUpdate != null)\n            {\n                // direct svc to svc http request\n                var httpClient = _httpClientFactory.CreateClient(\"BackEndApiExternal\");\n                var result = await httpClient.PutAsJsonAsync($\"api/tasks/{TaskUpdate.TaskId}\", TaskUpdate);\n            }\n\n            return RedirectToPage(\"./Index\");\n        }\n    }\n}\n</code></pre> <p>What does this code do?</p> <p>The code added is similar to the create operation. The Edit page accepts the TaskId as a Guid, loads the task, and then updates the task by sending an HTTP PUT operation.</p> </li> <li> <p>Now we will inject an HTTP client factory and define environment variables. To do so we will register the HttpClientFactory named <code>BackEndApiExternal</code> to make it available for injection in controllers. Open the <code>Program.cs</code> file and update it with highlighted code below. Your file may be flattened rather than indented and not contain some of the below elements. Don't worry. Just place the highlighted lines in the right spot:</p> Program.cs <pre><code>var builder = WebApplication.CreateBuilder(args);\n\n// Add services to the container.\nbuilder.Services.AddRazorPages();\n\nbuilder.Services.AddHttpClient(\"BackEndApiExternal\", httpClient =&gt;\n{\n    var backendApiBaseUrlExternalHttp = builder.Configuration.GetValue&lt;string&gt;(\"BackendApiConfig:BaseUrlExternalHttp\");\n\n    if (!string.IsNullOrEmpty(backendApiBaseUrlExternalHttp)) {\n        httpClient.BaseAddress = new Uri(backendApiBaseUrlExternalHttp);\n    } else {\n        throw new(\"BackendApiConfig:BaseUrlExternalHttp is not defined in App Settings.\");\n    }\n});\n\nvar app = builder.Build();\n\n// Configure the HTTP request pipeline.\nif (!app.Environment.IsDevelopment())\n{\n    app.UseExceptionHandler(\"/Error\");\n    // The default HSTS value is 30 days. You may want to change this for production scenarios, see https://aka.ms/aspnetcore-hsts.\n    app.UseHsts();\n}\n\napp.UseHttpsRedirection();\n\napp.UseStaticFiles();\n\napp.UseRouting();\n\napp.UseAuthorization();\n\napp.MapRazorPages();\n\napp.Run();\n</code></pre> </li> <li> <p>Next, we will add a new environment variable named <code>BackendApiConfig:BaseUrlExternalHttp</code> into <code>appsettings.json</code> file. This variable will contain the Base URL for the backend API deployed in the previous module to ACA. Later on in the workshop, we will see how we can set the environment variable once we deploy it to ACA. Use the output from this script as the <code>BaseUrlExternalHttp</code> value.</p> <pre><code>$BACKEND_API_EXTERNAL_BASE_URL\n</code></pre> appsettings.json <pre><code>    {\n      \"Logging\": {\n        \"LogLevel\": {\n          \"Default\": \"Information\",\n          \"Microsoft.AspNetCore\": \"Warning\"\n        }\n      },\n      \"AllowedHosts\": \"*\",\n      \"BackendApiConfig\": {\n        \"BaseUrlExternalHttp\": \"url to your backend api goes here. You can find this on the Azure portal overview tab. Look for the Application url property there.\"\n      }\n    }\n</code></pre> </li> <li> <p>Lastly, we will update the web app landing page <code>Index.html</code> and <code>Index.cshtml.cs</code> inside Pages folder to capture the email of the tasks owner user and assign this email to a cookie named <code>TasksCreatedByCookie</code>.</p> Index.cshtmlIndex.cshtml.cs <pre><code>@page\n@model IndexModel\n@{\n    ViewData[\"Title\"] = \"Tasks Tracker\";\n}\n\n&lt;form method=\"post\"&gt;\n    &lt;div class=\"container\"&gt;\n        &lt;div class=\"row\"&gt;\n            &lt;div class=\"col-sm-9 col-md-7 col-lg-5 mx-auto\"&gt;\n                &lt;div class=\"card border-0 shadow rounded-3 my-5\"&gt;\n                    &lt;div class=\"card-body p-4 p-sm-5\"&gt;\n                        &lt;h5 class=\"card-title text-center mb-5 fw-light fs-5\"&gt;Welcome to Tasks Tracker!&lt;/h5&gt;\n                        &lt;form&gt;\n                            &lt;div class=\"form-floating mb-3\"&gt;\n                                &lt;input type=\"email\" class=\"form-control\" id=\"floatingInput\"\n                                    placeholder=\"name@example.com\" asp-for=\"TasksCreatedBy\" required&gt;\n                                &lt;label for=\"floatingInput\"&gt;Email address&lt;/label&gt;\n                            &lt;/div&gt;\n\n                            &lt;div class=\"d-grid\"&gt;\n                                &lt;input type=\"submit\" class=\"btn btn-primary btn-login text-uppercase fw-bold\"\n                                    value=\"Load My Tasks\" /&gt;\n                            &lt;/div&gt;\n                        &lt;/form&gt;\n                    &lt;/div&gt;\n                &lt;/div&gt;\n            &lt;/div&gt;\n        &lt;/div&gt;\n    &lt;/div&gt;\n&lt;/form&gt;\n</code></pre> <pre><code>using Microsoft.AspNetCore.Mvc;\nusing Microsoft.AspNetCore.Mvc.RazorPages;\nusing TasksTracker.WebPortal.Frontend.Ui.Pages.Tasks.Models;\n\nnamespace TasksTracker.WebPortal.Frontend.Ui.Pages\n{\n    [IgnoreAntiforgeryToken(Order = 1001)]\n    public class IndexModel : PageModel\n    {\n        private readonly ILogger&lt;IndexModel&gt; _logger;\n        [BindProperty]\n        public string? TasksCreatedBy { get; set; }\n\n        public IndexModel(ILogger&lt;IndexModel&gt; logger)\n        {\n            _logger = logger;\n        }\n\n        public void OnGet()\n        {\n        }\n\n        public IActionResult OnPost()\n        {\n            if (!string.IsNullOrEmpty(TasksCreatedBy))\n            {\n                Response.Cookies.Append(\"TasksCreatedByCookie\", TasksCreatedBy);\n            }\n\n            return RedirectToPage(\"./Tasks/Index\");\n        }\n    }\n}\n</code></pre> </li> <li> <p>From VS Code Terminal tab, open developer command prompt or PowerShell terminal and navigate to the frontend directory which hosts the <code>.csproj</code> project folder and build the project.</p> <pre><code>cd ~\\TasksTracker.ContainerApps\\TasksTracker.WebPortal.Frontend.Ui\ndotnet build\n</code></pre> </li> </ul> <p>Note</p> <p>Make sure that the build is successful and that there are no build errors. Usually you should see a Build succeeded message in the terminal upon a successful build.</p>"},{"location":"aca/02-aca-comm/#2-deploy-razor-pages-web-app-frontend-project-to-aca","title":"2. Deploy Razor Pages Web App Frontend Project to ACA","text":"<ul> <li> <p>We need to add the below PS variables:</p> <pre><code>$FRONTEND_WEBAPP_NAME=\"tasksmanager-frontend-webapp\"\n</code></pre> </li> <li> <p>Now we will build and push the Web App project docker image to ACR. Use the below command to initiate the image build and push process using ACR. The <code>.</code> at the end of the command represents the docker build context. In our case, we need to be on the parent directory which hosts the .csproject.</p> <pre><code>cd ~\\TasksTracker.ContainerApps\n</code></pre> <pre><code>az acr build `\n--registry $AZURE_CONTAINER_REGISTRY_NAME `\n--image \"tasksmanager/$FRONTEND_WEBAPP_NAME\" `\n--file 'TasksTracker.WebPortal.Frontend.Ui/Dockerfile' .\n</code></pre> </li> <li> <p>Once this step is completed you can verify the results by going to the Azure portal and checking that a new repository named <code>tasksmanager/tasksmanager-frontend-webapp</code> has been created and that a new docker image with a <code>latest</code> tag has been created.</p> </li> <li> <p>Next, we will create and deploy the Web App to ACA using the following command:</p> <pre><code>$fqdn=(az containerapp create `\n--name \"$FRONTEND_WEBAPP_NAME\"  `\n--resource-group $RESOURCE_GROUP `\n--environment $ENVIRONMENT `\n--image \"$AZURE_CONTAINER_REGISTRY_NAME.azurecr.io/tasksmanager/$FRONTEND_WEBAPP_NAME\" `\n--registry-server \"$AZURE_CONTAINER_REGISTRY_NAME.azurecr.io\" `\n--env-vars \"BackendApiConfig__BaseUrlExternalHttp=$BACKEND_API_EXTERNAL_BASE_URL/\" `\n--target-port $TARGET_PORT `\n--ingress 'external' `\n--min-replicas 1 `\n--max-replicas 1 `\n--cpu 0.25 `\n--memory 0.5Gi `\n--query properties.configuration.ingress.fqdn `\n--output tsv)\n\n$FRONTEND_UI_BASE_URL=\"https://$fqdn\"\n\necho \"See the frontend web app at this URL:\"\necho $FRONTEND_UI_BASE_URL\n</code></pre> </li> </ul> <p>Tip</p> <p>Notice how we used the property <code>env-vars</code> to set the value of the environment variable named <code>BackendApiConfig_BaseUrlExternalHttp</code> which we added in the AppSettings.json file. You can set multiple environment variables at the same time by using a space between each variable. The <code>ingress</code> property is set to <code>external</code> as the Web frontend App will be exposed to the public internet for users.</p> <p>After your run the command, copy the FQDN (Application URL) of the Azure container app named <code>tasksmanager-frontend-webapp</code> and open it in your browser, and you should be able to browse the frontend web app and manage your tasks.</p>"},{"location":"aca/02-aca-comm/#3-update-backend-web-api-container-app-ingress-property","title":"3. Update Backend Web API Container App Ingress property","text":"<p>So far the Frontend App is sending HTTP requests to the publicly exposed Web API. This means that any REST client can invoke the Web API. We need to change the Web API ingress settings and make it accessible only by applications deployed within our Azure Container Environment. Any application outside the Azure Container Environment should not be able to access the Web API.</p> <ul> <li> <p>To change the settings of the Backend API, execute the following command:</p> <pre><code>$fqdn=(az containerapp ingress enable `\n--name $BACKEND_API_NAME  `\n--resource-group $RESOURCE_GROUP `\n--target-port $TARGET_PORT `\n--type \"internal\" `\n--query fqdn `\n--output tsv)\n\n$BACKEND_API_INTERNAL_BASE_URL=\"https://$fqdn\"\n\necho \"The internal backend API URL:\"\necho $BACKEND_API_INTERNAL_BASE_URL\n</code></pre> </li> </ul> Want to know more about the command? <p>When you do this change, the FQDN (Application URL) will change, and it will be similar to the one shown below. Notice how there is an <code>Internal</code> part of the URL. <code>https://tasksmanager-backend-api.internal.[Environment unique identifier].eastus.azurecontainerapps.io/api/tasks/</code></p> <p>If you try to invoke the URL directly it will return 403 - Forbidden as this internal Url can only be accessed successfully from container apps within the container environment. This means that while the API is not accessible, it still provides a clue that something exists at that URL. Ideally, we would want to see a 404 - Not Found. However, recall from module 1 that we did not set <code>internal-only</code> for simplicity's sake of the workshop. In a production scenario, this should be done with completely private networking to not reveal anything.</p> <p>The FQDN consists of multiple parts. For example, all our Container Apps will be under a specific Environment unique identifier (e.g. <code>agreeablestone-8c14c04c</code>) and the Container App will vary based on the name provided, check the image below for a better explanation. </p> <ul> <li> <p>Now we will need to update the Frontend Web App environment variable to point to the internal backend Web API FQDN. The last thing we need to do here is to update the Frontend WebApp environment variable named <code>BackendApiConfig_BaseUrlExternalHttp</code> with the new value of the internal Backend Web API base URL, to do so we need to update the Web App container app and it will create a new revision implicitly (more about revisions in the upcoming modules). The following command will update the container app with the changes:</p> <pre><code>az containerapp update `\n--name \"$FRONTEND_WEBAPP_NAME\" `\n--resource-group $RESOURCE_GROUP `\n--set-env-vars \"BackendApiConfig__BaseUrlExternalHttp=$BACKEND_API_INTERNAL_BASE_URL/\"\n</code></pre> </li> </ul> <p>Success</p> <p>Browse the web app again, and you should be able to see the same results and access the backend API endpoints from the Web App. You can obtain the frontend URL from executing this variable.</p> <pre><code>$FRONTEND_UI_BASE_URL\n</code></pre> <ul> <li> <p>Navigate to the root and persist the module to Git.</p> <pre><code>git add .\ngit commit -m \"Add Module 2\"\n</code></pre> </li> <li> <p>Execute the <code>Set-Variables.ps1</code> in the root to update the <code>variables.ps1</code> file with all current variables. The output of the script will inform you how many variables are written out.</p> <pre><code>.\\Set-Variables.ps1\n</code></pre> </li> <li> <p>From the root, persist a list of all current variables.</p> <pre><code>git add .\\Variables.ps1\ngit commit -m \"Update Variables.ps1\"\n</code></pre> </li> </ul>"},{"location":"aca/02-aca-comm/#review","title":"Review","text":"<p>In this module, we have accomplished three objectives:</p> <ol> <li>Created a web app named <code>ACA Web - Frontend</code>, which is the UI to interact with <code>ACA API - Backend</code>.</li> <li>Deployed the <code>ACA Web - Frontend</code> container app to Azure.</li> <li>Shielded <code>ACA API - Backend</code> from external access.</li> </ol> <p>In the next module, we will start integrating Dapr and use the service to service Building block for services discovery and invocation.</p>"},{"location":"aca/03-aca-dapr-integration/","title":"Module 3 - Dapr Integration with ACA","text":"<p>Module Duration</p> <p>60 minutes</p>"},{"location":"aca/03-aca-dapr-integration/#objective","title":"Objective","text":"<p>In this module, we will accomplish two objectives:</p> <ol> <li>Introduce the Distributed Application Runtime (Dapr).</li> <li>Decouple <code>ACA Web - Frontend</code> from <code>ACA API - Backend</code> locally via Dapr.</li> </ol>"},{"location":"aca/03-aca-dapr-integration/#module-sections","title":"Module Sections","text":"<ul> <li> <p>From the VS Code Terminal tab, open developer command prompt or PowerShell terminal in the project folder <code>TasksTracker.ContainerApps</code> (root):</p> <pre><code>cd ~\\TasksTracker.ContainerApps\n</code></pre> </li> <li> <p>Restore the previously-stored variables by executing the local script. The output informs you how many variables have been set.</p> <pre><code>.\\Variables.ps1\n</code></pre> </li> </ul>"},{"location":"aca/03-aca-dapr-integration/#1-introduce-dapr","title":"1. Introduce Dapr","text":""},{"location":"aca/03-aca-dapr-integration/#11-benefits-of-integrating-dapr-in-azure-container-apps","title":"1.1 Benefits of Integrating Dapr in Azure Container Apps","text":"<p>The Tasks Tracker microservice application is composed of multiple microservices. Function calls are spread across the network. To support the distributed nature of microservices, we need to account for failures, retries, and timeouts. While Azure Container Apps features the building blocks for running microservices, using the Distributed Application Runtime (Dapr) provides an even richer microservices programming model.</p> <p>Dapr includes features like service discovery, pub/sub, service-to-service invocation with mutual TLS, retries, state store management, and more. Here is a good link which touches on some of the benefits of the Dapr service invocation building block which we will be building upon in this module. Because the calls will flow through container sidecars, Dapr can inject some useful cross-cutting behaviors that are meaningfully abstracted from our application containers.</p> <p>Although we won't tap into all these benefits in this workshop, it's worth noting that you will probably need to rely on these features in production:</p> <ul> <li>Automatically retry calls upon failure.</li> <li>Make calls between services secured  with mutual authentication (mTLS), including automatic certificate rollover.</li> <li>Control what operations clients can perform using access control policies.</li> <li>Capture traces and metrics for all calls between services to provide insights and diagnostics.</li> </ul>"},{"location":"aca/03-aca-dapr-integration/#12-configure-dapr-on-a-local-development-machine","title":"1.2 Configure Dapr on a Local Development Machine","text":"<p>In order to run applications using Dapr, we need to install and initialize Dapr CLI locally. The official documentation is quite clear, and we can follow the steps needed to install Dapr and then Initialize it.</p>"},{"location":"aca/03-aca-dapr-integration/#2-decouple-aca-web-frontend-from-aca-web-frontend-locally-via-dapr","title":"2. Decouple <code>ACA Web - Frontend</code> from <code>ACA Web - Frontend</code> Locally via Dapr","text":""},{"location":"aca/03-aca-dapr-integration/#21-configure-local-variables","title":"2.1 Configure Local Variables","text":"<p>You are now ready to run the applications locally using the Dapr sidecar in a self-hosted mode. The Dapr VS Code extension will allow you to run, debug, and interact with Dapr-enabled applications.</p> <ul> <li> <p>Let's start by capturing the UI and API localhost ports:</p> <pre><code>$API_APP_PORT=&lt;web api https port in Properties-&gt;launchSettings.json (e.g. 7112)&gt;\n$UI_APP_PORT=&lt;web ui https port in Properties-&gt;launchSettings.json (e.g. 7000)&gt;\n</code></pre> <p>Note</p> <p>Remember to replace the placeholders with your own values based on image below. Remember to use https port number for the Web API application.</p> <p></p> </li> <li> <p>Now that we know the <code>UI_APP_PORT</code>, we can also declare the local frontend UI URL:</p> <pre><code>$FRONTEND_UI_BASE_URL_LOCAL=\"https://localhost:$UI_APP_PORT\"\n</code></pre> </li> <li> <p>Execute the <code>Set-Variables.ps1</code> in the root to update the <code>variables.ps1</code> file with all current variables. The output of the script will inform you how many variables are written out.</p> </li> </ul>"},{"location":"aca/03-aca-dapr-integration/#22-test-aca-api-backend-locally","title":"2.2 Test <code>ACA API - Backend</code> Locally","text":".NET 6 or below.NET 7 or above <pre><code>cd ~\\TasksTracker.ContainerApps\\TasksTracker.TasksManager.Backend.Api\n\ndapr run `\n--app-id tasksmanager-backend-api `\n--app-port $API_APP_PORT `\n--dapr-http-port 3500 `\n--app-ssl `\n-- dotnet run\n</code></pre> <pre><code>cd ~\\TasksTracker.ContainerApps\\TasksTracker.TasksManager.Backend.Api\n\ndapr run `\n--app-id tasksmanager-backend-api `\n--app-port $API_APP_PORT `\n--dapr-http-port 3500 `\n--app-ssl `\n-- dotnet run --launch-profile https\n</code></pre> Want to learn more about Dapr run command above? <p>When using Dapr run command you are running a Dapr process as a sidecar next to the Web API application. The properties you have configured are as follows:</p> <ul> <li>app-id: The unique identifier of the application. Used for service discovery, state encapsulation, and the pub/sub consumer identifier.</li> <li>app-port: This parameter tells Dapr which port your application is listening on. You can get the app port from <code>Properties-&gt;launchSettings.json</code> file in the Web API Project as shown in the image above. Make sure you use the https port listed within the <code>Properties-&gt;launchSettings.json</code> as we are using the --app-ssl when running the Dapr cli locally. Don't use the port inside the DockerFile. The DockerFile port will come in handy when you deploy to ACA at which point the application would be running inside a container.</li> <li>dapr-http-port: The HTTP port for Dapr to listen on.</li> <li>app-ssl: Sets the URI scheme of the app to https and attempts an SSL connection.</li> </ul> <p>For a full list of properties, you can check this link.</p> <p>If all is working as expected, you should receive an output similar to the one below where your app logs and Dapr logs will appear on the same PowerShell terminal:</p> <p></p> <p>Now to test invoking the Web API using Dapr sidecar, you can issue an GET request to the following URL: http://localhost:3500/v1.0/invoke/tasksmanager-backend-api/method/api/tasks?createdBy=tjoudeh@bitoftech.net</p> Want to learn more about what is happening here? <p>What happened here is that Dapr exposes its HTTP and gRPC APIs as a sidecar process which can access our Backend Web API. We didn't do any changes to the application code to include any Dapr runtime code. We also ensured separation of the application logic for improved supportability.</p> <p>Looking back at the HTTP GET request, we can break it as follows:</p> <ul> <li><code>/v1.0/invoke</code> Endpoint: is the Dapr feature identifier for the \"Service to Service invocation\" building block. This building block enables applications to communicate with each other through well-known endpoints in the form of http or gRPC messages. Dapr provides an endpoint that acts as a combination of a reverse proxy with built-in service discovery while leveraging built-in distributed tracing and error handling.</li> <li><code>3500</code>: the HTTP port that Dapr is listening on.</li> <li><code>tasksmanager-backend-api</code>: is the Dapr application unique identifier.</li> <li><code>method</code>: reserved word when using invoke endpoint.</li> <li><code>api/tasks?createdBy=tjoudeh@bitoftech.net</code>: the path of the action method that needs to be invoked in the webapi service.</li> </ul> <p>Another example is that we want to create a new task by invoking the POST operation, we need to issue the below POST request:</p> <pre><code>POST /v1.0/invoke/tasksmanager-backend-api/method/api/tasks/ HTTP/1.1\nHost: localhost:3500\nContent-Type: application/json\n{\n        \"taskName\": \"Task number: 51\",\n        \"taskCreatedBy\": \"tjoudeh@bitoftech.net\",\n        \"taskDueDate\": \"2022-08-31T09:33:35.9256429Z\",\n        \"taskAssignedTo\": \"assignee51@mail.com\"\n}\n</code></pre>"},{"location":"aca/03-aca-dapr-integration/#23-configure-aca-web-frontend-locally","title":"2.3 Configure <code>ACA Web - Frontend</code> Locally","text":"<ul> <li> <p>Next, we will be using Dapr SDK in the frontend Web App to invoke Backend API services, The Dapr .NET SDK provides .NET developers with an intuitive and language-specific way to interact with Dapr.</p> <p>The SDK offers developers three ways of making remote service invocation calls:</p> <ol> <li>Invoke HTTP services using HttpClient</li> <li>Invoke HTTP services using DaprClient</li> <li>Invoke gRPC services using DaprClient</li> </ol> <p>We will be using the second approach in this workshop (HTTP services using DaprClient), but it is worth spending some time explaining the first approach (Invoke HTTP services using HttpClient). We will go over the first approach briefly and then discuss the second in details.</p> </li> <li> <p>Install Dapr SDK for .NET Core in the Frontend Web APP, so we can use the service discovery and service invocation offered by Dapr Sidecar. To do so, add below nuget package to the project.</p> .NET 6.NET 7.NET 8 TasksTracker.WebPortal.Frontend.Ui.csproj <pre><code>&lt;ItemGroup&gt;\n  &lt;PackageReference Include=\"Dapr.AspNetCore\" Version=\"1.12.0\" /&gt;\n&lt;/ItemGroup&gt;\n</code></pre> TasksTracker.WebPortal.Frontend.Ui.csproj <pre><code>&lt;Project Sdk=\"Microsoft.NET.Sdk.Web\"&gt;\n\n  &lt;PropertyGroup&gt;\n    &lt;TargetFramework&gt;net7.0&lt;/TargetFramework&gt;\n    &lt;Nullable&gt;enable&lt;/Nullable&gt;\n    &lt;ImplicitUsings&gt;enable&lt;/ImplicitUsings&gt;\n  &lt;/PropertyGroup&gt;\n\n  &lt;ItemGroup&gt;\n    &lt;PackageReference Include=\"Dapr.AspNetCore\" Version=\"1.12.0\" /&gt;\n  &lt;/ItemGroup&gt;\n\n&lt;/Project&gt;\n</code></pre> TasksTracker.WebPortal.Frontend.Ui.csproj <pre><code>&lt;Project Sdk=\"Microsoft.NET.Sdk.Web\"&gt;\n\n  &lt;PropertyGroup&gt;\n    &lt;TargetFramework&gt;net8.0&lt;/TargetFramework&gt;\n    &lt;Nullable&gt;enable&lt;/Nullable&gt;\n    &lt;ImplicitUsings&gt;enable&lt;/ImplicitUsings&gt;\n  &lt;/PropertyGroup&gt;\n\n  &lt;ItemGroup&gt;\n    &lt;PackageReference Include=\"Dapr.AspNetCore\" Version=\"1.12.0\" /&gt;\n  &lt;/ItemGroup&gt;\n\n&lt;/Project&gt;\n</code></pre> <ul> <li>Next, open the file <code>Programs.cs</code> of the Frontend Web App and register the DaprClient as the highlighted below.</li> </ul> .NET 6.NET 7 or above Program.cs <pre><code>namespace TasksTracker.WebPortal.Frontend.Ui\n{\n    public class Program\n    {\n        public static void Main(string[] args)\n        {\n            var builder = WebApplication.CreateBuilder(args);\n            // Add services to the container.\n            builder.Services.AddRazorPages();\n            // Code removed for brevity\n            builder.Services.AddDaprClient();\n            var app = builder.Build();\n            // Code removed for brevity \n        }\n    }\n}\n</code></pre> Program.cs <pre><code>var builder = WebApplication.CreateBuilder(args);\n\n// Add services to the container.\nbuilder.Services.AddRazorPages();\n\nbuilder.Services.AddDaprClient();\n\nbuilder.Services.AddHttpClient(\"BackEndApiExternal\", httpClient =&gt;\n{\n    var backendApiBaseUrlExternalHttp = builder.Configuration.GetValue&lt;string&gt;(\"BackendApiConfig:BaseUrlExternalHttp\");\n\n    if (!string.IsNullOrEmpty(backendApiBaseUrlExternalHttp)) {\n        httpClient.BaseAddress = new Uri(backendApiBaseUrlExternalHttp);\n    } else {\n        throw new(\"BackendApiConfig:BaseUrlExternalHttp is not defined in App Settings.\");\n    }\n});\n\nvar app = builder.Build();\n\n// Configure the HTTP request pipeline.\nif (!app.Environment.IsDevelopment())\n{\n    app.UseExceptionHandler(\"/Error\");\n    // The default HSTS value is 30 days. You may want to change this for production scenarios, see https://aka.ms/aspnetcore-hsts.\n    app.UseHsts();\n}\n\napp.UseHttpsRedirection();\n\napp.UseStaticFiles();\n\napp.UseRouting();\n\napp.UseAuthorization();\n\napp.MapRazorPages();\n\napp.Run();\n</code></pre> </li> <li> <p>Now, we will inject the DaprClient into the <code>.cshtml</code> pages to use the method <code>InvokeMethodAsync</code> (second approach). Update files under folder Pages\\Tasks and use the code below for different files.</p> Index.cshtml.csCreate.cshtml.csEdit.cshtml.cs <pre><code>using Dapr.Client;\nusing Microsoft.AspNetCore.Mvc;\nusing Microsoft.AspNetCore.Mvc.RazorPages;\nusing TasksTracker.WebPortal.Frontend.Ui.Pages.Tasks.Models;\n\nnamespace TasksTracker.WebPortal.Frontend.Ui.Pages.Tasks\n{\n    public class IndexModel : PageModel\n    {\n        private readonly IHttpClientFactory _httpClientFactory;\n        private readonly DaprClient _daprClient;\n        public List&lt;TaskModel&gt;? TasksList { get; set; }\n\n        [BindProperty]\n        public string? TasksCreatedBy { get; set; }\n\n        public IndexModel(IHttpClientFactory httpClientFactory, DaprClient daprClient)\n        {\n            _httpClientFactory = httpClientFactory;\n            _daprClient = daprClient;\n        }\n\n        public async Task&lt;IActionResult&gt; OnGetAsync()\n        {\n            TasksCreatedBy = Request.Cookies[\"TasksCreatedByCookie\"];\n\n            if (!String.IsNullOrEmpty(TasksCreatedBy)) {\n                // Invoke via internal URL (Not Dapr)\n                //var httpClient = _httpClientFactory.CreateClient(\"BackEndApiExternal\");\n                //TasksList = await httpClient.GetFromJsonAsync&lt;List&lt;TaskModel&gt;&gt;($\"api/tasks?createdBy={TasksCreatedBy}\");\n\n                // Invoke via Dapr SideCar URL\n                //var port = 3500;//Environment.GetEnvironmentVariable(\"DAPR_HTTP_PORT\");\n                //HttpClient client = new HttpClient();\n                //var result = await client.GetFromJsonAsync&lt;List&lt;TaskModel&gt;&gt;($\"http://localhost:{port}/v1.0/invoke/tasksmanager-backend-api/method/api/tasks?createdBy={TasksCreatedBy}\");\n                //TasksList = result;\n\n                // Invoke via DaprSDK (Invoke HTTP services using HttpClient) --&gt; Use Dapr Appi ID (Option 1)\n                //var daprHttpClient = DaprClient.CreateInvokeHttpClient(appId: \"tasksmanager-backend-api\"); \n                //TasksList = await daprHttpClient.GetFromJsonAsync&lt;List&lt;TaskModel&gt;&gt;($\"api/tasks?createdBy={TasksCreatedBy}\");\n\n                // Invoke via DaprSDK (Invoke HTTP services using HttpClient) --&gt; Specify Custom Port (Option 2)\n                //var daprHttpClient = DaprClient.CreateInvokeHttpClient(daprEndpoint: \"http://localhost:3500\"); \n                //TasksList = await daprHttpClient.GetFromJsonAsync&lt;List&lt;TaskModel&gt;&gt;($\"http://tasksmanager-backend-api/api/tasks?createdBy={TasksCreatedBy}\");\n\n                // Invoke via DaprSDK (Invoke HTTP services using DaprClient)\n                TasksList = await _daprClient.InvokeMethodAsync&lt;List&lt;TaskModel&gt;&gt;(HttpMethod.Get, \"tasksmanager-backend-api\", $\"api/tasks?createdBy={TasksCreatedBy}\");\n                return Page();\n            } else {\n                return RedirectToPage(\"../Index\");\n            }\n        }\n\n        public async Task&lt;IActionResult&gt; OnPostDeleteAsync(Guid id)\n        {\n            // Dapr SideCar Invocation\n            await _daprClient.InvokeMethodAsync(HttpMethod.Delete, \"tasksmanager-backend-api\", $\"api/tasks/{id}\");\n\n            return RedirectToPage();\n        }\n\n        public async Task&lt;IActionResult&gt; OnPostCompleteAsync(Guid id)\n        {\n            // Dapr SideCar Invocation\n            await _daprClient.InvokeMethodAsync(HttpMethod.Put, \"tasksmanager-backend-api\", $\"api/tasks/{id}/markcomplete\");\n\n            return RedirectToPage();\n        }\n    }\n}\n</code></pre> <pre><code>using Dapr.Client;\nusing Microsoft.AspNetCore.Mvc;\nusing Microsoft.AspNetCore.Mvc.RazorPages;\nusing TasksTracker.WebPortal.Frontend.Ui.Pages.Tasks.Models;\n\nnamespace TasksTracker.WebPortal.Frontend.Ui.Pages.Tasks\n{\n    public class CreateModel : PageModel\n    {\n        private readonly IHttpClientFactory _httpClientFactory;\n        private readonly DaprClient _daprClient;\n\n        public CreateModel(IHttpClientFactory httpClientFactory, DaprClient daprClient)\n        {\n            _httpClientFactory = httpClientFactory;\n            _daprClient = daprClient;\n        }\n        public string? TasksCreatedBy { get; set; }\n\n        public IActionResult OnGet()\n        {\n            TasksCreatedBy = Request.Cookies[\"TasksCreatedByCookie\"];\n\n            return (!String.IsNullOrEmpty(TasksCreatedBy)) ? Page() : RedirectToPage(\"../Index\");\n        }\n\n        [BindProperty]\n        public TaskAddModel? TaskAdd { get; set; }\n\n        public async Task&lt;IActionResult&gt; OnPostAsync()\n        {\n            if (!ModelState.IsValid)\n            {\n                return Page();\n            }\n\n            if (TaskAdd != null)\n            {\n                var createdBy = Request.Cookies[\"TasksCreatedByCookie\"];\n\n                if (!string.IsNullOrEmpty(createdBy))\n                {\n                    TaskAdd.TaskCreatedBy = createdBy;\n\n                    // Dapr SideCar Invocation\n                    await _daprClient.InvokeMethodAsync(HttpMethod.Post, \"tasksmanager-backend-api\", $\"api/tasks\", TaskAdd);\n                }\n            }\n\n            return RedirectToPage(\"./Index\");\n        }\n    }\n}\n</code></pre> <pre><code>using Dapr.Client;\nusing Microsoft.AspNetCore.Mvc;\nusing Microsoft.AspNetCore.Mvc.RazorPages;\nusing TasksTracker.WebPortal.Frontend.Ui.Pages.Tasks.Models;\n\nnamespace TasksTracker.WebPortal.Frontend.Ui.Pages.Tasks\n{\n    public class EditModel : PageModel\n    {\n        private readonly IHttpClientFactory _httpClientFactory;\n        private readonly DaprClient _daprClient;\n\n        [BindProperty]\n        public TaskUpdateModel? TaskUpdate { get; set; }\n        public string? TasksCreatedBy { get; set; }\n\n        public EditModel(IHttpClientFactory httpClientFactory, DaprClient daprClient)\n        {\n            _httpClientFactory = httpClientFactory;\n            _daprClient = daprClient;\n        }\n\n        public async Task&lt;IActionResult&gt; OnGetAsync(Guid? id)\n        {\n            TasksCreatedBy = Request.Cookies[\"TasksCreatedByCookie\"];\n\n            if (String.IsNullOrEmpty(TasksCreatedBy)) {\n                return RedirectToPage(\"../Index\");\n            }\n\n            if (id == null)\n            {\n                return NotFound();\n            }\n\n            // Dapr SideCar Invocation\n            var Task = await _daprClient.InvokeMethodAsync&lt;TaskModel&gt;(HttpMethod.Get, \"tasksmanager-backend-api\", $\"api/tasks/{id}\");\n\n            if (Task == null)\n            {\n                return NotFound();\n            }\n\n            TaskUpdate = new TaskUpdateModel()\n            {\n                TaskId = Task.TaskId,\n                TaskName = Task.TaskName,\n                TaskAssignedTo = Task.TaskAssignedTo,\n                TaskDueDate = Task.TaskDueDate,\n            };\n\n            return Page();\n        }\n\n\n        public async Task&lt;IActionResult&gt; OnPostAsync()\n        {\n            if (!ModelState.IsValid)\n            {\n                return Page();\n            }\n\n            if (TaskUpdate != null)\n            {\n                // Dapr SideCar Invocation\n                await _daprClient.InvokeMethodAsync&lt;TaskUpdateModel&gt;(HttpMethod.Put, \"tasksmanager-backend-api\", $\"api/tasks/{TaskUpdate.TaskId}\", TaskUpdate);\n            }\n\n            return RedirectToPage(\"./Index\");\n        }\n    }\n}\n</code></pre> </li> </ul> Tip <p>Notice how we are not using the <code>HttpClientFactory</code> anymore and how we were able from the Frontend Dapr Sidecar to invoke backend API Sidecar using the method <code>InvokeMethodAsync</code> which accepts the Dapr remote App ID for the Backend API <code>tasksmanager-backend-api</code> and it will be able to discover the URL and invoke the method based on the specified input params.</p> <p>In addition to this, notice how in POST and PUT operations, the third argument is a <code>TaskAdd</code> or <code>TaskUpdate</code> Model, those objects will be serialized internally (using System.Text.JsonSerializer) and sent as the request payload. The .NET SDK takes care of the call to the Sidecar. It also deserializes the response in case of the GET operations to a <code>List&lt;TaskModel&gt;</code> object.</p> <p>Looking at the first option of invoking the remote service \"Invoke HTTP services using HttpClient\", you can see that we can create an HttpClient by invoking <code>DaprClient.CreateInvokeHttpClient</code> and specify the remote service app id, custom port if needed and then use the HTTP methods such as <code>GetFromJsonAsync</code>, this is a good approach as well at it gives you full support of advanced scenarios, such as custom headers and full control over request and response messages.</p> <p>In both options, the final request will be rewritten by the Dapr .NET SDK before it gets executed. In our case and for the GET operation it will be written to this request: <code>http://127.0.0.1:3500/v1/invoke/tasksmanager-backend-api/method/api/tasks?createdBy=tjoudeh@bitoftech.net</code></p>"},{"location":"aca/03-aca-dapr-integration/#24-run-aca-web-frontend-and-aca-api-backend-locally-using-dapr","title":"2.4 Run <code>ACA Web - Frontend</code> and <code>ACA API - Backend</code> Locally Using Dapr","text":"<p>We are ready now to verify the changes on the Frontend Web App and test locally. Therefore, we need to run the Frontend Web App along with the Backend Web API to ensure the Dapr Sidecar containers are working as expected.</p> <ul> <li> <p>Open another terminal inside VS Code, so that we can run the two commands shown below (ensure that you are on the right project directory when running each command).</p> </li> <li> <p>In the second terminal, run <code>.\\Variables.ps1</code> to apply all session variables.</p> </li> <li> <p>Obtain the local frontend UI URL to test shortly once the frontend UI and backend API are running in the next step.</p> <pre><code>$FRONTEND_UI_BASE_URL_LOCAL\n</code></pre> </li> <li> <p>In each of the two terminals previously opened, run the frontend UI and backend API respectively.</p> .NET 6 or below.NET 7 or above <pre><code>cd ~\\TasksTracker.ContainerApps\\TasksTracker.WebPortal.Frontend.Ui \n\ndapr run `\n--app-id tasksmanager-frontend-webapp `\n--app-port $UI_APP_PORT `\n--dapr-http-port 3501 `\n--app-ssl `\n-- dotnet run \n</code></pre> <pre><code>cd ~\\TasksTracker.ContainerApps\\TasksTracker.TasksManager.Backend.Api\n\ndapr run `\n--app-id tasksmanager-backend-api `\n--app-port $API_APP_PORT `\n--dapr-http-port 3500 `\n--app-ssl `\n-- dotnet run\n</code></pre> <pre><code>cd ~\\TasksTracker.ContainerApps\\TasksTracker.WebPortal.Frontend.Ui\n\ndapr run `\n--app-id tasksmanager-frontend-webapp `\n--app-port $UI_APP_PORT `\n--dapr-http-port 3501 `\n--app-ssl `\n-- dotnet run --launch-profile https\n</code></pre> <pre><code>cd ~\\TasksTracker.ContainerApps\\TasksTracker.TasksManager.Backend.Api\n\ndapr run `\n--app-id tasksmanager-backend-api `\n--app-port $API_APP_PORT `\n--dapr-http-port 3500 `\n--app-ssl `\n-- dotnet run --launch-profile https\n</code></pre> </li> </ul> <p>Notice how we assigned the Dapr App Id \u201ctasksmanager-frontend-webapp\u201d to the Frontend WebApp.</p> <p>Note</p> <p>If you need to run both microservices together, you need to keep calling <code>dapr run</code> manually each time in the terminal. And when you have multiple microservices talking to each other you need to run at the same time to debug the solution. This can be a convoluted process. You can refer to the debug and launch Dapr applications in VSCode to see how to configure VScode for running and debugging Dapr applications.</p>"},{"location":"aca/03-aca-dapr-integration/#25-test-aca-web-frontend-and-aca-api-backend-locally-using-dapr","title":"2.5 Test <code>ACA Web - Frontend</code> and <code>ACA API - Backend</code> Locally Using Dapr","text":"<p>Success</p> <p>Now both Applications are running using Dapr sidecar. Open the local frontend UI URL, ignore the certificate warning locally, then provide an email to load the tasks for the user (e.g. <code>tjoudeh@bitoftech.net</code>). If the application is working as expected you should see tasks list associated with the email you provided.</p> <ul> <li> <p>Close the sessions and navigate to the root.</p> </li> <li> <p>From the root, persist a list of all current variables.</p> <pre><code>git add .\\Variables.ps1\ngit commit -m \"Update Variables.ps1\"\n</code></pre> </li> <li> <p>Navigate to the root and persist the module to Git.</p> <pre><code>git add .\ngit commit -m \"Add Module 3\"\n</code></pre> </li> </ul>"},{"location":"aca/03-aca-dapr-integration/#review","title":"Review","text":"<p>In this module, we have accomplished two objective:</p> <ol> <li>Introduced the Distributed Application Runtime (Dapr).</li> <li>Decoupled <code>ACA Web - Frontend</code> from <code>ACA API - Backend</code> locally via Dapr.</li> </ol> <p>In the next module, we will integrate the Dapr state store building block by saving tasks to Azure Cosmos DB. We will also deploy the updated applications to Azure Container Apps.</p>"},{"location":"aca/04-aca-dapr-stateapi/","title":"Module 4 - ACA State Store With Dapr State Management API","text":"<p>Module Duration</p> <p>60 minutes</p>"},{"location":"aca/04-aca-dapr-stateapi/#objective","title":"Objective","text":"<p>In this module, we will accomplish three objectives:</p> <ol> <li>Learn about Dapr State Management with Redis Cache.</li> <li>Use the Dapr Client SDK.</li> <li>Provision Azure Cosmos DB resources &amp; Update app and API in Azure.</li> </ol>"},{"location":"aca/04-aca-dapr-stateapi/#module-sections","title":"Module Sections","text":"<ul> <li> <p>From the VS Code Terminal tab, open developer command prompt or PowerShell terminal in the project folder <code>TasksTracker.ContainerApps</code> (root):</p> <pre><code>cd ~\\TasksTracker.ContainerApps\n</code></pre> </li> <li> <p>Restore the previously-stored variables by executing the local script. The output informs you how many variables have been set.</p> <pre><code>.\\Variables.ps1\n</code></pre> </li> </ul>"},{"location":"aca/04-aca-dapr-stateapi/#1-state-management","title":"1. State Management","text":""},{"location":"aca/04-aca-dapr-stateapi/#11-overview-of-dapr-state-management-api","title":"1.1 Overview of Dapr State Management API","text":"<p>By using the Dapr State Management Building Block, we will see how we can store the data in Azure Cosmos DB without installing any Cosmos DB SDK or write specific code to integrate our Backend API with Azure Cosmos DB. Moreover, we will use Redis to store tasks when we are running the application locally. You will see that we can switch between different stores without any code changes, thanks to the Dapr pluggable state stores feature. It is a matter of adding new Dapr Component files and the underlying store will be changed. This page shows the supported state stores in Dapr.</p> <p></p> <p>Dapr's state management API allows you to save, read, and query key/value pairs in the supported state stores. To try this out, and without doing any code changes or installing any NuGet packages, we can directly invoke the State Management API and store the data on Redis locally. When you initialized Dapr in your local development environment, it installed Redis container instance locally. So we can use Redis locally to store and retrieve state. If you navigate to the path <code>%USERPROFILE%\\.dapr\\components</code> (assuming you are using Windows) you will find a file named <code>statestore.yaml</code>. Inside this file, you will see the properties needed to access the local Redis instance. The state store template component file structure can be found on this link.</p> <p>To try out the State Management APIs, run the Backend API from VS Code by running the following command.</p> .NET 6 or below.NET 7 or above <pre><code>cd ~\\TasksTracker.ContainerApps\\TasksTracker.TasksManager.Backend.Api\n\ndapr run `\n--app-id tasksmanager-backend-api `\n--app-port $API_APP_PORT `\n--dapr-http-port 3500 `\n--app-ssl `\n-- dotnet run\n</code></pre> <pre><code>cd ~\\TasksTracker.ContainerApps\\TasksTracker.TasksManager.Backend.Api\n\ndapr run `\n--app-id tasksmanager-backend-api `\n--app-port $API_APP_PORT `\n--dapr-http-port 3500 `\n--app-ssl `\n-- dotnet run --launch-profile https\n</code></pre> <p>Now from any rest client, invoke the below POST request to the endpoint: http://localhost:3500/v1.0/state/statestore</p> <pre><code>POST /v1.0/state/statestore HTTP/1.1\nHost: localhost:3500\nContent-Type: application/json\n[\n    {\n        \"key\": \"Book1\",\n        \"value\": {\n            \"title\": \"Parallel and High Performance Computing\",\n            \"author\": \"Robert Robey\",\n            \"genre\": \"Technical\"\n        }\n    },\n    {\n        \"key\": \"Book2\",\n        \"value\": {\n            \"title\": \"Software Engineering Best Practices\",\n            \"author\": \"Capers Jones\",\n            \"genre\": \"Technical\"\n        }\n    },\n    {\n        \"key\": \"Book3\",\n        \"value\": {\n            \"title\": \"The Unstoppable Mindset\",\n            \"author\": \"Jessica Marks\",\n            \"genre\": \"Self Improvement\",\n            \"formats\":[\"kindle\", \"audiobook\", \"papercover\"]\n        }\n    }\n]\n</code></pre> <p>You should see an HTTP 204 No Content response.</p> <p>What we've done here is the following:</p> <ul> <li>The value <code>statestore</code> in the endpoint should match the <code>name</code> value in the global component file <code>statestore.yaml</code></li> <li>We have sent a request to store 3 entries of books, you can put any JSON representation in the value property</li> </ul>"},{"location":"aca/04-aca-dapr-stateapi/#12-local-redis-cache","title":"1.2 Local Redis Cache","text":"<p>To see the results visually, you can install a VS Code extension to connect to Redis DB and see the results. There are several Redis extensions available for VS Code. For this workshop we will use an extension named \"Redis Xplorer\".</p> <p>Once you install the extension it will add a tab under the explorer section of VS Code called \"REDIS XPLORER\". Next you will need to connect to the Redis server locally by adding a new \"REDIS XPLORER\" profile. Click on the + sign in the \"REDIS XPLORER\" section in VS Code. This will ask you to enter the nickname (e.g. dapr_redis) as well as the hostname and port. For the hostname and port you can get this information by executing the following command in your powershell terminal:</p> <pre><code>docker ps\n</code></pre> <p>Look under the Ports column and use the server and port specified there. In the image below the server is <code>0.0.0.0</code> and the port is <code>6379</code>. Use the values that you see on your own terminal. Leave the password empty.</p> <p></p> <p>After you connect to Redis locally, you should see the 3 entries similar to the ones shown in the image below. Notice how each entry key is prefixed by the Dapr App Id. In our case it is <code>tasksmanager-backend-api</code>. More about key prefix strategy in later sections in this module.</p> <p></p> <p>To get the value of a key, you need to issue a GET request to the endpoint <code>http://localhost:3500/v1.0/state/statestore/{YourKey}</code>. This will return the value from the key store. For example if you execute the following GET http://localhost:3500/v1.0/state/statestore/Book3 the results will be the below object:</p> <pre><code>{\n    \"formats\": [\n        \"kindle\",\n        \"audiobook\",\n        \"papercover\"\n    ],\n    \"title\": \"The Unstoppable Mindset\",\n    \"author\": \"Jessica Marks\",\n    \"genre\": \"Self Improvement\"\n}\n</code></pre>"},{"location":"aca/04-aca-dapr-stateapi/#2-use-dapr-client-sdk-for-state-store-management","title":"2. Use Dapr Client SDK For State Store Management","text":"<p>Whereas in the previous section we demonstrated using Dapr State Store without code changes, we will now introduce a change on the Backend API and create a new service named <code>TasksStoreManager.cs</code> which will implement the interface <code>ITasksManager.cs</code> to start storing tasks data on the persist store. Locally, we will start testing with Redis, then we are going to change the state store to use Azure Cosmos DB.</p>"},{"location":"aca/04-aca-dapr-stateapi/#21-add-dapr-client-sdk-with-the-backend-api","title":"2.1 Add Dapr Client SDK With The Backend API","text":"<p>Similar to what we have done in the Frontend Web App, we need to use Dapr Client SDK to manage the state store. Update the below file with the added Dapr package reference:</p> .NET 6.NET 7.NET 8 TasksTracker.TasksManager.Backend.Api.csproj <pre><code>&lt;ItemGroup&gt;\n    &lt;PackageReference Include=\"Dapr.AspNetCore\" Version=\"1.12.0\" /&gt;\n&lt;/ItemGroup&gt;\n</code></pre> TasksTracker.TasksManager.Backend.Api.csproj <pre><code>&lt;Project Sdk=\"Microsoft.NET.Sdk.Web\"&gt;\n\n  &lt;PropertyGroup&gt;\n    &lt;TargetFramework&gt;net7.0&lt;/TargetFramework&gt;\n    &lt;Nullable&gt;enable&lt;/Nullable&gt;\n    &lt;ImplicitUsings&gt;enable&lt;/ImplicitUsings&gt;\n  &lt;/PropertyGroup&gt;\n\n  &lt;ItemGroup&gt;\n    &lt;PackageReference Include=\"Dapr.AspNetCore\" Version=\"1.12.0\" /&gt;\n    &lt;PackageReference Include=\"Microsoft.AspNetCore.OpenApi\" Version=\"7.0.13\" /&gt;\n    &lt;PackageReference Include=\"Swashbuckle.AspNetCore\" Version=\"6.5.0\" /&gt;\n  &lt;/ItemGroup&gt;\n\n&lt;/Project&gt;\n</code></pre> TasksTracker.TasksManager.Backend.Api.csproj <pre><code>&lt;Project Sdk=\"Microsoft.NET.Sdk.Web\"&gt;\n\n  &lt;PropertyGroup&gt;\n    &lt;TargetFramework&gt;net8.0&lt;/TargetFramework&gt;\n    &lt;Nullable&gt;enable&lt;/Nullable&gt;\n    &lt;ImplicitUsings&gt;enable&lt;/ImplicitUsings&gt;\n    &lt;InvariantGlobalization&gt;true&lt;/InvariantGlobalization&gt;\n  &lt;/PropertyGroup&gt;\n\n  &lt;ItemGroup&gt;\n    &lt;PackageReference Include=\"Dapr.AspNetCore\" Version=\"1.12.0\" /&gt;\n    &lt;PackageReference Include=\"Microsoft.AspNetCore.OpenApi\" Version=\"7.0.13\" /&gt;\n    &lt;PackageReference Include=\"Swashbuckle.AspNetCore\" Version=\"6.5.0\" /&gt;\n  &lt;/ItemGroup&gt;\n\n&lt;/Project&gt;\n</code></pre>"},{"location":"aca/04-aca-dapr-stateapi/#22-create-a-new-concrete-implementation-to-manage-tasks-persistence","title":"2.2 Create a New Concrete Implementation to Manage Tasks Persistence","text":"<p>As you recall from the previous module, we were storing the tasks in memory. Now we need to store them in Redis and, later on, Azure Cosmos DB. The key thing to keep in mind here is that switching from Redis to Azure Cosmos DB won't require changing the code below which is a huge advantage of using Dapr.</p> <p>Add below file to the Services folder. This file will implement the interface <code>ITasksManager</code>.</p> TasksStoreManager.cs <pre><code>using Dapr.Client;\nusing TasksTracker.TasksManager.Backend.Api.Models;\n\nnamespace TasksTracker.TasksManager.Backend.Api.Services\n{\n    public class TasksStoreManager : ITasksManager\n    {\n        private static string STORE_NAME = \"statestore\";\n        private readonly DaprClient _daprClient;\n        private readonly IConfiguration _config;\n        private readonly ILogger&lt;TasksStoreManager&gt; _logger;\n\n        public TasksStoreManager(DaprClient daprClient, IConfiguration config, ILogger&lt;TasksStoreManager&gt; logger)\n        {\n            _daprClient = daprClient;\n            _config = config;\n            _logger = logger;\n        }\n        public async Task&lt;Guid&gt; CreateNewTask(string taskName, string createdBy, string assignedTo, DateTime dueDate)\n        {\n            var taskModel = new TaskModel()\n            {\n                TaskId = Guid.NewGuid(),\n                TaskName = taskName,\n                TaskCreatedBy = createdBy,\n                TaskCreatedOn = DateTime.UtcNow,\n                TaskDueDate = dueDate,\n                TaskAssignedTo = assignedTo,\n            };\n\n            _logger.LogInformation(\"Save a new task with name: '{0}' to state store\", taskModel.TaskName);\n            await _daprClient.SaveStateAsync&lt;TaskModel&gt;(STORE_NAME, taskModel.TaskId.ToString(), taskModel);\n            return taskModel.TaskId;\n        }\n\n        public async Task&lt;bool&gt; DeleteTask(Guid taskId)\n        {\n            _logger.LogInformation(\"Delete task with Id: '{0}'\", taskId);\n            await _daprClient.DeleteStateAsync(STORE_NAME, taskId.ToString());\n            return true;\n        }\n\n        public async Task&lt;TaskModel?&gt; GetTaskById(Guid taskId)\n        {\n            _logger.LogInformation(\"Getting task with Id: '{0}'\", taskId);\n            var taskModel = await _daprClient.GetStateAsync&lt;TaskModel&gt;(STORE_NAME, taskId.ToString());\n            return taskModel;\n        }\n\n        public async Task&lt;List&lt;TaskModel&gt;&gt; GetTasksByCreator(string createdBy)\n        {\n            var query = \"{\" +\n                    \"\\\"filter\\\": {\" +\n                        \"\\\"EQ\\\": { \\\"taskCreatedBy\\\": \\\"\" + createdBy + \"\\\" }\" +\n                    \"}}\";\n\n            var queryResponse = await _daprClient.QueryStateAsync&lt;TaskModel&gt;(STORE_NAME, query);\n\n            var tasksList = queryResponse.Results.Select(q =&gt; q.Data).OrderByDescending(o=&gt;o.TaskCreatedOn);\n            return tasksList.ToList();\n        }\n\n        public async Task&lt;bool&gt; MarkTaskCompleted(Guid taskId)\n        {\n            _logger.LogInformation(\"Mark task with Id: '{0}' as completed\", taskId);\n            var taskModel = await _daprClient.GetStateAsync&lt;TaskModel&gt;(STORE_NAME, taskId.ToString());\n            if (taskModel != null)\n            {\n                taskModel.IsCompleted = true;\n                await _daprClient.SaveStateAsync&lt;TaskModel&gt;(STORE_NAME, taskModel.TaskId.ToString(), taskModel);\n                return true;\n            }\n            return false;\n        }\n\n        public async Task&lt;bool&gt; UpdateTask(Guid taskId, string taskName, string assignedTo, DateTime dueDate)\n        {\n            _logger.LogInformation(\"Update task with Id: '{0}'\", taskId);\n            var taskModel = await _daprClient.GetStateAsync&lt;TaskModel&gt;(STORE_NAME, taskId.ToString());\n            var currentAssignee = taskModel.TaskAssignedTo;\n            if (taskModel != null)\n            {\n                taskModel.TaskName = taskName;\n                taskModel.TaskAssignedTo = assignedTo;\n                taskModel.TaskDueDate = dueDate;\n                await _daprClient.SaveStateAsync&lt;TaskModel&gt;(STORE_NAME, taskModel.TaskId.ToString(), taskModel);\n                return true;\n            }\n            return false;\n        }\n    }\n}\n</code></pre> Curious about the code? <p>Looking at the code above, we have injected the <code>DaprClient</code> into the new service and DaprClient has a set of methods to support CRUD operations. Notice how we are using the state store named <code>statestore</code>  which should match the name in the component file.</p> <p>Note</p> <p>The query API will not work against the local Redis store as you need to install RediSearch locally on your machine which is out of the scope for this workshop. It will work locally once we switch to Azure Cosmos DB.</p>"},{"location":"aca/04-aca-dapr-stateapi/#23-register-the-tasksstoremanager-new-service-and-daprclient","title":"2.3 Register the TasksStoreManager New Service and DaprClient","text":"<p>Now we need to register the new service named <code>TasksStoreManager</code> and <code>DaprClient</code> when the Backend API app starts up. Update the below file with the highlighted text as shown below.</p> <p>Note</p> <p>Do not forget to comment out the registration of the <code>FakeTasksManager</code> service as we don't want to store tasks in memory anymore.</p> Program.cs <pre><code>using TasksTracker.TasksManager.Backend.Api.Services;\n\nvar builder = WebApplication.CreateBuilder(args);\n\n// Add services to the container.\n\nbuilder.Services.AddDaprClient();\nbuilder.Services.AddSingleton&lt;ITasksManager, TasksStoreManager&gt;();\n//builder.Services.AddSingleton&lt;ITasksManager, FakeTasksManager&gt;();\nbuilder.Services.AddControllers();\n// Learn more about configuring Swagger/OpenAPI at https://aka.ms/aspnetcore/swashbuckle\nbuilder.Services.AddEndpointsApiExplorer();\nbuilder.Services.AddSwaggerGen();\n\nvar app = builder.Build();\n\n// Configure the HTTP request pipeline.\nif (app.Environment.IsDevelopment())\n{\n    app.UseSwagger();\n    app.UseSwaggerUI();\n}\n\napp.UseHttpsRedirection();\n\napp.UseAuthorization();\n\napp.MapControllers();\n\napp.Run();\n</code></pre> <ul> <li> <p>Let's verify that the Dapr dependency is restored properly and that the project compiles. From VS Code Terminal tab, open developer command prompt or PowerShell terminal and navigate to the parent directory which hosts the <code>.csproj</code> project folder and build the project.</p> <pre><code>cd ~\\TasksTracker.ContainerApps\\TasksTracker.TasksManager.Backend.Api\ndotnet build\n</code></pre> </li> </ul> <p>Now you are ready to run both applications and debug them. You can store new tasks, update them, delete existing tasks and mark them as completed. The data should be stored on your local Redis instance.</p> <p>Info</p> <p>For now don't try running the application as you will get an error running the query against the local Redis. As mentioned earlier setting up the local Redis store is out of scope for this workshop. Instead, we will focus on wiring the Azure Cosmos DB as the store for our tasks.</p>"},{"location":"aca/04-aca-dapr-stateapi/#3-use-azure-cosmos-db-with-dapr-state-store-management-api","title":"3. Use Azure Cosmos DB with Dapr State Store Management API","text":""},{"location":"aca/04-aca-dapr-stateapi/#31-provision-cosmos-db-resources","title":"3.1 Provision Cosmos DB Resources","text":"<p>Now we will create an Azure Cosmos DB account, Database, and a new container that will store our tasks. You can use the PowerShell script below to create the Cosmos DB resources on the same resource group we used in the previous module. You need to set the variable name of the <code>$COSMOS_DB_ACCOUNT</code> to a unique name as it needs to be unique globally. Remember to replace the placeholders with your own values:</p> <pre><code>$COSMOS_DB_ACCOUNT=\"cosmos-tasks-tracker-state-store-$RANDOM_STRING\"\n$COSMOS_DB_DBNAME=\"tasksmanagerdb\"\n$COSMOS_DB_CONTAINER=\"taskscollection\" \n\n# Check if Cosmos account name already exists globally\n$result = az cosmosdb check-name-exists `\n--name $COSMOS_DB_ACCOUNT\n\n# Continue if the Cosmos DB account does not yet exist\nif ($result -eq \"false\") {\n    echo \"Creating Cosmos DB account...\"\n\n    # Create a Cosmos account for SQL API\n    az cosmosdb create `\n    --name $COSMOS_DB_ACCOUNT `\n    --resource-group $RESOURCE_GROUP\n\n    # Create a SQL API database\n    az cosmosdb sql database create `\n    --name $COSMOS_DB_DBNAME `\n    --resource-group $RESOURCE_GROUP `\n    --account-name $COSMOS_DB_ACCOUNT\n\n    # Create a SQL API container\n    az cosmosdb sql container create `\n    --name $COSMOS_DB_CONTAINER `\n    --resource-group $RESOURCE_GROUP `\n    --account-name $COSMOS_DB_ACCOUNT `\n    --database-name $COSMOS_DB_DBNAME `\n    --partition-key-path \"/id\" `\n    --throughput 400\n\n    $COSMOS_DB_ENDPOINT=(az cosmosdb show `\n    --name $COSMOS_DB_ACCOUNT `\n    --resource-group $RESOURCE_GROUP `\n    --query documentEndpoint `\n    --output tsv)\n\n    echo \"Cosmos DB Endpoint: \"\n    echo $COSMOS_DB_ENDPOINT\n}\n</code></pre> <p>Note</p> <p>The <code>primaryMasterKey</code> connection string is only needed for our local testing on the development machine, we'll be using a different approach (Managed Identities) when deploying Dapr component to Azure Container Apps Environment.</p> <p>Once the scripts execution is completed, we need to get the <code>primaryMasterKey</code> of the Cosmos DB account next. You can do this using the PowerShell script below. Copy the value of <code>primaryMasterKey</code> as we will use it in the next step.</p> <pre><code># List Azure Cosmos DB keys\n$COSMOS_DB_PRIMARY_MASTER_KEY=(az cosmosdb keys list `\n--name $COSMOS_DB_ACCOUNT `\n--resource-group $RESOURCE_GROUP `\n--query primaryMasterKey `\n--output tsv)\n\necho \"Cosmos DB Primary Master Key:\"\necho $COSMOS_DB_PRIMARY_MASTER_KEY\n</code></pre>"},{"location":"aca/04-aca-dapr-stateapi/#32-create-a-component-file-for-state-store-management","title":"3.2. Create a Component File for State Store Management","text":"<p>Dapr uses a modular design where functionality is delivered as a component. Each component has an interface definition. All the components are pluggable so that you can swap out one component with the same interface for another.</p> <p>Components are configured at design-time with a YAML file which is stored in either a components/local folder within your solution, or globally in the <code>.dapr</code> folder created when invoking <code>dapr init</code>. These YAML files adhere to the generic Dapr component schema, but each is specific to the component specification.</p> <p>It is important to understand that the component spec values, particularly the spec <code>metadata</code>, can change between components of the same component type. As a result, it is strongly recommended to review a component's specs, paying particular attention to the sample payloads for requests to set the metadata used to interact with the component.</p> <p>The diagram below is from Dapr official documentation which shows some examples of the components for each component type. We are now looking at the State Stores components. Specifically the one for Azure Cosmos DB.</p> <p></p> <p>To add the component file state store, add a new folder named components under the directory TasksTracker.ContainerApps and add a new yaml file as show below. The values for <code>url</code> and <code>masterKey</code> can be found in the console output from the most recent commands.</p> <p>Info</p> <p>You need to replace the masterKey value with your Cosmos Account key. Remember this is only needed for local development debugging, we will not be using the masterKey when we deploy to ACA.</p> <p>Replace the url value with the URI value of your Azure Cosmos DB account. You can get that from the Azure portal by navigating to the Azure Cosmos DB account overview page and get the uri value from there.  Basically the uri should have the following structure. https://COSMOS_DB_ACCOUNT.documents.azure.com:443/.</p> dapr-statestore-cosmos.yaml <pre><code>apiVersion: dapr.io/v1alpha1\nkind: Component\nmetadata:\n  name: statestore\nspec:\n  type: state.azure.cosmosdb\n  version: v1\n  metadata:\n    - name: url\n      value: https://cosmos-tasks-tracker-state-store-&lt;$RANDOM_STRING&gt;.documents.azure.com:443/\n    - name: masterKey\n      value: \"&lt;value&gt;\"\n    - name: database\n      value: tasksmanagerdb\n    - name: collection\n      value: taskscollection\nscopes:\n  - tasksmanager-backend-api\n</code></pre> Curious to learn more about the contents of the yaml file? <ul> <li>We've used the name <code>statestore</code> which should match the name of statestore we've used in the <code>TaskStoreManager.cs</code> file. As well, we have set the metadata key/value to allow us to connect to Azure Cosmos DB.</li> <li>We've updated the other metadata keys such as <code>database</code>, <code>collection</code>, etc... to match the values of your Cosmos DB instance. For full metadata specs, you can check this page.</li> <li>By default, all dapr-enabled container apps within the same environment will load the full set of deployed components. By adding <code>scopes</code> to a component, you tell the Dapr sidecars for each respective container app which components to load at runtime. Using scopes is recommended for production workloads. In our case, we have set the scopes to <code>tasksmanager-backend-api</code> which represents the dapr-app-id which is associated to the container app that needs access to Azure Cosmos DB State Store as this will be the application that needs access to Azure Cosmos DB State Store. More about scopes can be found on this link.</li> </ul> <p>Note</p> <p>Dapr component scopes correspond to the Dapr application ID of a container app, not the container app name.</p> <p>Now you should be ready to launch both applications and start doing CRUD operations from the Frontend Web App including querying the store. All your data will be stored in Cosmos DB Database you just provisioned.</p> <p>If you have been running the different microservices using the debug and launch Dapr applications in VSCode then remember to uncomment the following line inside tasks.json file. This will instruct dapr to load the local projects components located at ./components instead of the global components' folder.</p> <pre><code>{\n    \"componentsPath\": \"./components\"\n}\n</code></pre> <p>If you have been using the dapr cli commands instead of the aforementioned debugging then you will need to execute the backend api with the resources-path property as follows.</p> .NET 6 or below.NET 7 or above <pre><code>cd ~\\TasksTracker.ContainerApps\\TasksTracker.TasksManager.Backend.Api\n\ndapr run `\n--app-id tasksmanager-backend-api `\n--app-port $API_APP_PORT `\n--dapr-http-port 3500 `\n--app-ssl `\n--resources-path \"../components\" `\n-- dotnet run\n</code></pre> <pre><code>cd ~\\TasksTracker.ContainerApps\\TasksTracker.TasksManager.Backend.Api\n\ndapr run `\n--app-id tasksmanager-backend-api `\n--app-port $API_APP_PORT `\n--dapr-http-port 3500 `\n--app-ssl `\n--resources-path \"../components\" `\n-- dotnet run --launch-profile https\n</code></pre> <p>Deprecation Warning</p> <p>components-path is being deprecated in favor of --resources-path. At the time of producing this workshop the --resources-path was not supported yet by the VS code extension. Hence, you will notice the use of the property \"componentsPath\": \"./components\" in the tasks.json file. Check the extension documentation in case that has changed.</p> <p>After creating a new record you can navigate to the Data explorer on the Azure portal for the Azure Cosmos DB account. It should look like the image below:</p> <p></p>"},{"location":"aca/04-aca-dapr-stateapi/#key-prefix-strategies","title":"Key Prefix Strategies","text":"<p>When you look at the key stored per entry and for example <code>tasksmanager-backend-api||aa3eb856-8309-4e68-93af-119be0d400e8</code>, you will notice that the key is prefixed with the Dapr application App Id responsible to store this entry which in our case is <code>tasksmanager-backend-api</code>. There might be some scenarios which you need to have another service to access the same data store (not recommended as each service should be responsible about its own data store), in which case you can change the default behavior.</p> <p>This can be done by adding the meta tag below to the component file. For example, if we need to set the value of the prefix to a constant value such as <code>TaskId</code> we can do the following:</p> <pre><code>spec:\n    metadata:\n    - name: keyPrefix\n    - value: TaskId\n</code></pre> <p>If we need to totally omit the key prefix, so it is accessed across multiple Dapr applications, we can set the value to <code>none</code>.</p>"},{"location":"aca/04-aca-dapr-stateapi/#33-configure-managed-identities-in-container-app","title":"3.3 Configure Managed Identities in Container App","text":"<p>As we highlighted earlier, we'll not use a connection strings to establish the relation between our Container App and Azure Cosmos DB when we deploy to ACA. Cosmos DB Master Key/Connection string was only used when debugging locally. Now we will rely on Managed Identities to allow our container app to access Cosmos DB. With Manged Identities you do't worry about storing the keys securely and rotate them inside your application. This approach is safer and easier to manage.</p> <p>We will be using a <code>system-assigned</code> identity with a role assignment to grant our Backend API container app permissions to access data stored in Cosmos DB. We need to assign it a custom role for the Cosmos DB data plane. In this example ae are going to use a built-in role, named <code>Cosmos DB Built-in Data Contributor</code>, which grants our application full read-write access to the data. You can optionally create custom, fine-tuned roles following the instructions in the official docs.</p>"},{"location":"aca/04-aca-dapr-stateapi/#331-create-system-assigned-identity-for-our-backend-api-container-app","title":"3.3.1 Create system-assigned identity for our Backend API Container App","text":"<p>Run the command below to create <code>system-assigned</code> identity for our Backend API container app:</p> <pre><code>az containerapp identity assign `\n--name $BACKEND_API_NAME `\n--resource-group $RESOURCE_GROUP `\n--system-assigned\n\n$COSMOS_DB_PRIMARY_MASTER_KEY=(az cosmosdb keys list `\n--name $COSMOS_DB_ACCOUNT `\n--resource-group $RESOURCE_GROUP `\n--query primaryMasterKey `\n--output tsv)\n\n$BACKEND_API_PRINCIPAL_ID=(az containerapp identity show `\n--name $BACKEND_API_NAME `\n--resource-group $RESOURCE_GROUP `\n--query principalId `\n--output tsv)\n</code></pre> <p>This command will create an Enterprise Application (basically a Service Principal) within Azure AD, which is linked to our container app. The output of this command will be similar to the one shown below. Keep a note of the property <code>principalId</code> as we are going to use it in the next step.</p> <pre><code>{\n    \"principalId\": \"[your principal id will be displayed here]\",\n    \"tenantId\": \"[your tenant id will be displayed here]\",\n    \"type\": \"SystemAssigned\"\n}\n</code></pre>"},{"location":"aca/04-aca-dapr-stateapi/#332-assign-the-container-app-system-identity-to-the-built-in-cosmos-db-role","title":"3.3.2 Assign the Container App System-Identity To the Built-in Cosmos DB Role","text":"<p>Next, we need to associate the container app system-identity with the target Cosmos DB resource. You can read more about Azure built-in roles for Cosmos DB or how to create custom fine-tuned roles here. Run the command below to associate the container app <code>system-assigned</code> identity with <code>Cosmos DB Built-in Data Contributor</code> role.</p> <p>Note</p> <p>Make sure you save this principal id somewhere as you will need it in later modules. You can't rely on having it saved in powershell under <code>$BACKEND_API_PRINCIPAL_ID</code> as this variable could replace later on. Remember to replace the placeholders with your own values:</p> <pre><code>$ROLE_ID = \"00000000-0000-0000-0000-000000000002\" #\"Cosmos DB Built-in Data Contributor\" \n\naz cosmosdb sql role assignment create `\n--resource-group $RESOURCE_GROUP `\n--account-name  $COSMOS_DB_ACCOUNT `\n--scope \"/\" `\n--principal-id $BACKEND_API_PRINCIPAL_ID `\n--role-definition-id $ROLE_ID\n</code></pre>"},{"location":"aca/04-aca-dapr-stateapi/#34-deploy-the-backend-api-and-frontend-web-app-projects-to-aca","title":"3.4 Deploy the Backend API and Frontend Web App Projects to ACA","text":"<p>We are almost ready to deploy all local changes from this module and the previous module to ACA. But before we do that, we need one last addition.</p> <p>We have to create a dapr component schema file for Azure Cosmos DB which meets the specs defined by Azure Container Apps. The reason for this variance is that ACA Dapr schema is slightly simplified to support Dapr components and removes unnecessary fields, including <code>apiVersion</code>, <code>kind</code>, and redundant metadata and spec properties.</p>"},{"location":"aca/04-aca-dapr-stateapi/#341-create-an-aca-dapr-component-file-for-state-store-management","title":"3.4.1 Create an ACA-Dapr Component File For State Store Management","text":"<p>Here it is recommended to separate the component files that will be used when deploying to Azure Container Apps from the ones which we will use when running our application locally (Dapr self-hosted).</p> <p>Create a new folder named aca-components under the directory TasksTracker.ContainerApps, then add a new file as shown below:</p> <p>Info</p> <p>Remember to replace the url value with the URI value of your cosmos database account. You can get that from the Azure portal by navigating to the Azure Cosmos DB account overview page and get the uri value from there. Basically the uri should have the following structure <code>https://COSMOS_DB_ACCOUNT.documents.azure.com:443/</code></p> containerapps-statestore-cosmos.yaml <pre><code>componentType: state.azure.cosmosdb\nversion: v1\nmetadata:\n  - name: url\n    value: https://cosmos-tasks-tracker-state-store-&lt;$RANDOM_STRING&gt;.documents.azure.com:443/\n  - name: database\n    value: tasksmanagerdb\n  - name: collection\n    value: taskscollection\nscopes:\n  - tasksmanager-backend-api\n</code></pre> Curious to learn more about the contents of the yaml file? <ul> <li>We didn't specify the Cosmos DB component name <code>statestore</code> when we created this component file. We are going to specify it once we add this dapr component to Azure Container Apps Environment via CLI.</li> <li>We are not referencing any Cosmos DB Keys/Connection strings as the authentication between Dapr and Cosmos DB will be configured using Managed Identities.</li> <li>We are setting the <code>scopes</code> array value to <code>tasksmanager-backend-api</code> to ensure Cosmos DB component is loaded at runtime by only the appropriate container apps. In our case it will be needed only for the container apps with Dapr application IDs <code>tasksmanager-backend-api</code>. In future modules we are going to include another container app which needs to access Cosmos DB.</li> </ul>"},{"location":"aca/04-aca-dapr-stateapi/#342-build-frontend-web-app-and-backend-api-app-images-in-azure-container-registry","title":"3.4.2 Build Frontend Web App and Backend API App Images in Azure Container Registry","text":"<p>As we have done previously, we need to build and deploy both app images to ACR, so they are ready to be deployed to Azure Container Apps. To do so, continue using the same PowerShell console and paste the code below. Ensure you are in the root directory:</p> <pre><code>az acr build `\n--registry $AZURE_CONTAINER_REGISTRY_NAME `\n--image \"tasksmanager/$BACKEND_API_NAME\" `\n--file 'TasksTracker.TasksManager.Backend.Api/Dockerfile' .\n\naz acr build `\n--registry $AZURE_CONTAINER_REGISTRY_NAME `\n--image \"tasksmanager/$FRONTEND_WEBAPP_NAME\" `\n--file 'TasksTracker.WebPortal.Frontend.Ui/Dockerfile' .\n</code></pre>"},{"location":"aca/04-aca-dapr-stateapi/#343-add-cosmos-db-dapr-state-store-to-azure-container-apps-environment","title":"3.4.3 Add Cosmos DB Dapr State Store to Azure Container Apps Environment","text":"<p>We need to run the command below to add the yaml file <code>.\\aca-components\\containerapps-statestore-cosmos.yaml</code> to Azure Container Apps Environment.</p> <pre><code>az containerapp env dapr-component set `\n--name $ENVIRONMENT `\n--resource-group $RESOURCE_GROUP `\n--dapr-component-name statestore `\n--yaml '.\\aca-components\\containerapps-statestore-cosmos.yaml'\n</code></pre>"},{"location":"aca/04-aca-dapr-stateapi/#344-enable-dapr-for-the-frontend-web-app-and-backend-api-container-apps","title":"3.4.4 Enable Dapr for the Frontend Web App and Backend API Container Apps","text":"<p>Until this moment Dapr was not enabled on the Container Apps we have provisioned. Enable Dapr for both Container Apps by running the two commands below in the PowerShell console.</p> <pre><code>az containerapp dapr enable `\n--name $BACKEND_API_NAME `\n--resource-group $RESOURCE_GROUP `\n--dapr-app-id  $BACKEND_API_NAME `\n--dapr-app-port $TARGET_PORT\n\naz containerapp dapr enable `\n--name $FRONTEND_WEBAPP_NAME `\n--resource-group $RESOURCE_GROUP `\n--dapr-app-id  $FRONTEND_WEBAPP_NAME `\n--dapr-app-port $TARGET_PORT\n</code></pre> Curious to learn more about the command above? <ul> <li>We've enabled Dapr on both container apps and specified a unique Dapr identifier for the Back End API and Front End Web App container apps. This <code>dapr-app-id</code> will be used for service discovery, state encapsulation and the pub/sub consumer ID.</li> <li>We've set the <code>dapr-app-port</code> which is the port our applications are listening on which will be used by Dapr for communicating to our applications.</li> </ul> <p>For a complete list of the supported Dapr sidecar configurations in Container Apps, you can refer to this link.</p>"},{"location":"aca/04-aca-dapr-stateapi/#345-deploy-new-revisions-of-the-frontend-web-app-and-backend-api-to-container-apps","title":"3.4.5 Deploy New Revisions of the Frontend Web App and Backend API to Container Apps","text":"<p>The last thing we need to do here is to update both container apps and deploy the new images from ACR. To do so we need to run the commands found below.</p> <pre><code># Update Frontend web app container app and create a new revision \naz containerapp update `\n--name $FRONTEND_WEBAPP_NAME  `\n--resource-group $RESOURCE_GROUP `\n--revision-suffix v$TODAY\n\n# Update Backend API App container app and create a new revision \naz containerapp update `\n--name $BACKEND_API_NAME  `\n--resource-group $RESOURCE_GROUP `\n--revision-suffix v$TODAY-1\n\necho \"Azure Frontend UI URL:\" \necho $FRONTEND_UI_BASE_URL\n</code></pre> <p>Tip</p> <p>Notice here that we used a <code>revision-suffix</code> property, so it will append to the revision name which offers you better visibility on which revision you are looking at.</p> <p>Success</p> <p>With this final step, we should be able to access the Frontend Web App, call the backend API app using Dapr sidecar, and store tasks to Azure Cosmos DB.</p> <ul> <li> <p>Execute the <code>Set-Variables.ps1</code> in the root to update the <code>variables.ps1</code> file with all current variables. The output of the script will inform you how many variables are written out.</p> <pre><code>.\\Set-Variables.ps1\n</code></pre> </li> <li> <p>From the root, persist a list of all current variables.</p> <pre><code>git add .\\Variables.ps1\ngit commit -m \"Update Variables.ps1\"\n</code></pre> </li> <li> <p>Navigate to the root and persist the module to Git.</p> <pre><code>git add .\ngit commit -m \"Add Module 4\"\n</code></pre> </li> </ul>"},{"location":"aca/04-aca-dapr-stateapi/#review","title":"Review","text":"<p>In this module, we accomplished three objectives:</p> <ol> <li>Learned about Dapr State Management with Redis Cache.</li> <li>Used the Dapr Client SDK.</li> <li>Provisioned Azure Cosmos DB resources &amp; Update app and API in Azure.</li> </ol> <p>In the next module, we will introduce the Dapr Pub/Sub Building block which we will publish messages to Azure Service Bus when a task is saved. We will also introduce a new background service will process those incoming messages and send an email to the task assignee.</p>"},{"location":"aca/05-aca-dapr-pubsubapi/","title":"Module 5 - ACA Async Communication with Dapr Pub/Sub API","text":"<p>Module Duration</p> <p>90 minutes</p>"},{"location":"aca/05-aca-dapr-pubsubapi/#objective","title":"Objective","text":"<p>In this module, we will accomplish five objectives:</p> <ol> <li>Learn how Azure Container Apps uses the Publisher-Subscriber (Pub/Sub) pattern with Dapr.</li> <li>Introduce a new background service, <code>ACA Processor - Backend</code> configured for Dapr.</li> <li>Use Azure Service Bus as a Service Broker for Dapr Pub/Sub API.</li> <li>Deploy the Backend Background Processor and the updated Backend API Projects to Azure Container Apps.</li> <li>Configure Managed Identities for the Backend Background Processor and the Backend API Azure Container Apps.</li> </ol>"},{"location":"aca/05-aca-dapr-pubsubapi/#module-sections","title":"Module Sections","text":"<ul> <li> <p>From the VS Code Terminal tab, open developer command prompt or PowerShell terminal in the project folder <code>TasksTracker.ContainerApps</code> (root):</p> <pre><code>cd ~\\TasksTracker.ContainerApps\n</code></pre> </li> <li> <p>Restore the previously-stored variables by executing the local script. The output informs you how many variables have been set.</p> <pre><code>.\\Variables.ps1\n</code></pre> </li> </ul>"},{"location":"aca/05-aca-dapr-pubsubapi/#1-pubsub-pattern-with-dapr","title":"1. Pub/Sub Pattern with Dapr","text":"<p>As a best practice, it is recommended that we decouple services from each other. A conventional way to do so is by employing the Publisher-Subscriber (Pub/Sub) pattern. The primary advantage of this pattern is that it offers loose coupling between services where the sender/publisher of the message doesn't know anything about the receivers/consumers. This can be done in a 1-1 or 1-many constellation in which  multiple consumers each receive a copy of the message in a totally different way. For example, imagine adding another consumer which is responsible for sending push notifications to the task owner (e.g. if we had a mobile app channel).</p> <p>In module 3 we introduced you to decoupling <code>ACA Web - Frontend</code> from <code>ACA API - Backend</code> through asynchronous HTTP calls via Dapr. And in module 4 we added integrations with Redis Cache locally and Azure Cosmos DB in the cloud. In this module we will configure such a Pub/Sub pattern to faciliate asynchronous messaging between the microservices. Specifically, the publisher/subscriber pattern relies on a message broker which is responsible for receiving the message from the publisher, storing the message to ensure durability, and delivering this message to the interested consumer(s) to process it. There is no need for the consumers to be available when the message is stored in the message broker. Consumers can process the messages at a later time in an async fashion. The below diagram gives a high-level overview of how the Pub/Sub pattern works:</p> <p></p> <p>If you implemented the Pub/Sub pattern before, you already know that there is a lot of plumbing needed on the publisher and subscriber components in order to publish and consume messages. In addition, each message broker has its own SDK and implementation. So you need to write your code in an abstracted way to hide the specific implementation details for each message broker SDK and make it easier for the publisher and consumers to re-use this functionality. What Dapr offers here is a building block that significantly simplifies implementing Pub/Sub functionality by abstracting the implementation of the provider from the usage of the pattern in the container. Differently, the container does not know who it is interacting with - and this is entirely intentional and favorable for container portability and immutability.</p> <p>Put simply, the Dapr Pub/Sub building block provides a platform-agnostic API framework to send and receive messages. Your producer/publisher services publish messages to a named topic. Your consumer services subscribe to a topic to consume messages.</p>"},{"location":"aca/05-aca-dapr-pubsubapi/#11-testing-pubsub-locally","title":"1.1 Testing Pub/Sub Locally","text":"<p>To try this out we can directly invoke the Pub/Sub API and publish a message to Redis locally. If you remember from module 3, when we initialized Dapr in a local development environment, it installed Redis container instance locally. Therefore, we can use Redis locally to publish and subscribe to a message. If you navigate to the path <code>%USERPROFILE%\\.dapr\\components (assuming you are using windows)</code> you will find a file named <code>pubsub.yaml</code>. Inside this file, you will see the properties needed to access the local Redis instance. The publisher/subscriber brokers template component file structure can be found here.</p> <p>However, we want to have more control and provide our own component file, so let's create Pub/Sub component file in our components folder as shown below:</p> dapr-pubsub-redis.yaml <pre><code>apiVersion: dapr.io/v1alpha1\nkind: Component\nmetadata:\n  name: taskspubsub\nspec:\n  type: pubsub.redis\n  version: v1\n  metadata:\n    - name: redisHost\n      value: localhost:6379\n    - name: redisPassword\n      value: \"\"\n</code></pre> <p>To try out the Pub/Sub API, run the Backend API from VS Code by running the below command or using the Run and Debug tasks we have created in the appendix.</p> .NET 6 or below.NET 7 or above <pre><code>cd ~\\TasksTracker.ContainerApps\\TasksTracker.TasksManager.Backend.Api\n\ndapr run `\n--app-id tasksmanager-backend-api `\n--app-port $API_APP_PORT `\n--dapr-http-port 3500 `\n--app-ssl `\n--resources-path \"../components\" `\n-- dotnet run\n</code></pre> <pre><code>cd ~\\TasksTracker.ContainerApps\\TasksTracker.TasksManager.Backend.Api\n\ndapr run `\n--app-id tasksmanager-backend-api `\n--app-port $API_APP_PORT `\n--dapr-http-port 3500 `\n--app-ssl `\n--resources-path \"../components\" `\n-- dotnet run --launch-profile https\n</code></pre> <p>Let's try to publish a message by sending a POST request to http://localhost:3500/v1.0/publish/taskspubsub/tasksavedtopic with the below request body, don't forget to set the <code>Content-Type</code> header to <code>application/json</code></p> <pre><code>{\n    \"taskId\": \"fbc55b2c-d9fa-405e-aec8-22e53f4306dd\",\n    \"taskName\": \"Testing Pub Sub Publisher\",\n    \"taskCreatedBy\": \"user@mail.net\",\n    \"taskCreatedOn\": \"2023-02-12T00:24:37.7361348Z\",\n    \"taskDueDate\": \"2023-02-20T00:00:00\",\n    \"taskAssignedTo\": \"user2@mail.com\"\n}\n</code></pre> Curious about the details of the endpoint? <p>We can break the endpoint into the following:</p> <ul> <li>The value <code>3500</code>: is the Dapr app listing port, it is the port number upon which the Dapr sidecar is listening.</li> <li>The value <code>taskspubsub</code>: is the name of the selected Dapr Pub/Sub-component.</li> <li>The value <code>tasksavedtopic</code>: is the name of the topic to which the message is published.</li> </ul> <p>If all is configured correctly, you should see an HTTP 204 No Content response from this endpoint which indicates that the message was published successfully by the service broker (Redis) into the topic named <code>tasksavedtopic</code>. You can also check that topic is created successfully by using the Redis Xplorer extension in VS Code which should look like this:</p> <p></p> <p>Right now those published messages are just hanging out in the message broker topic. We  don't yet have any subscribers bound to the service broker on the topic <code>tasksavedtopic</code>, which are interested in consuming and processing those messages. We will set up such a consumer in the next section.</p> <p>Note</p> <p>Some Service Brokers allow the creation of topics automatically when sending a message to a topic which has not been created before. That's the reason why the topic <code>tasksavedtopic</code> was created automatically here for us.</p>"},{"location":"aca/05-aca-dapr-pubsubapi/#2-setting-up-the-backend-background-processor-project","title":"2. Setting up the Backend Background Processor Project","text":""},{"location":"aca/05-aca-dapr-pubsubapi/#21-create-the-backend-service-project","title":"2.1 Create the Backend Service Project","text":"<p>In this module, we will also introduce a new background service which is named <code>ACA Processor - Backend</code> according to our architecture diagram. This new service will be responsible for sending notification emails (simulated) to the task owners to notify them that a new task has been assigned to them. We can do this in the Backend API and send the email right after saving the task, but we want to offload this process to another service and keep the Backend API service responsible for managing tasks data only.</p> <p>Now we will add a new ASP.NET Core Web API project named TasksTracker.Processor.Backend.Svc. Open a command-line terminal and navigate to the workshop's root.</p> <p>Controller-Based vs. Minimal APIs</p> <p>APIs can be created via the traditional, expanded controller-based structure with Controllers and Models folders, etc. or via the newer minimal APIs approach where controller actions are written inside Program.cs. The latter approach is preferential in a microservices project where the endpoints are overseeable and may easily be represented by a more compact view.  </p> <p>As our workshop takes advantage of microservices, the use case for minimal APIs is given. However, in order to make the workshop a bit more demonstrable, we will, for now, stick with controller-based APIs.</p> .NET 7 or below.NET 8 or above <pre><code>dotnet new webapi -o TasksTracker.Processor.Backend.Svc\n</code></pre> <pre><code>dotnet new webapi --use-controllers -o TasksTracker.Processor.Backend.Svc\n</code></pre> <ul> <li> <p>Delete the boilerplate <code>WeatherForecast.cs</code> and <code>Controllers\\WeatherForecastController.cs</code> files from the new <code>TasksTracker.Processor.Backend.Svc</code> project folder.</p> </li> <li> <p>We need to containerize this application, so we can push it to the Azure Container Registry before we deploy it to Azure Container Apps:</p> <ul> <li>Open the VS Code Command Palette (Ctrl+Shift+P) and select Docker: Add Docker Files to Workspace...</li> <li>Use <code>.NET: ASP.NET Core</code> when prompted for the application platform.</li> <li>Choose the newly-created project, if prompted.</li> <li>Choose <code>Linux</code> when prompted to choose the operating system.</li> <li>Set the application port to <code>5000</code>. This is arbitrary but memorable for this workshop.</li> <li>You will be asked if you want to add Docker Compose files. Select <code>No</code>.</li> <li><code>Dockerfile</code> and <code>.dockerignore</code> files are added to the workspace.</li> <li> <p>Open <code>Dockerfile</code> and replace <code>FROM --platform=$BUILDPLATFORM mcr.microsoft.com/dotnet/sdk:8.0 AS build</code> with <code>FROM mcr.microsoft.com/dotnet/sdk:8.0 AS build</code></p> <p>Dockerfile Build Platform</p> <p>Azure Container Registry does not set <code>$BUILDPLATFORM</code> presently when building containers. This consequently causes the build to fail. See this issue for details. Therefore, we remove it from the file for the time being. We expect this to be corrected in the future.</p> </li> </ul> </li> </ul>"},{"location":"aca/05-aca-dapr-pubsubapi/#22-add-models","title":"2.2 Add Models","text":"<p>Now we will add the model which will be used to deserialize the published message. Create a Models folder and add this file:</p> TaskModel.cs <pre><code>namespace TasksTracker.Processor.Backend.Svc.Models\n{\n    public class TaskModel\n    {\n        public Guid TaskId { get; set; }\n        public string TaskName { get; set; } = string.Empty;\n        public string TaskCreatedBy { get; set; } = string.Empty;\n        public DateTime TaskCreatedOn { get; set; }\n        public DateTime TaskDueDate { get; set; }\n        public string TaskAssignedTo { get; set; } = string.Empty;\n        public bool IsCompleted { get; set; }\n        public bool IsOverDue { get; set; }\n    }\n}\n</code></pre> <p>Tip</p> <p>For sake of simplicity we are recreating the same model <code>TaskModel.cs</code> under each project. For production purposes it is recommended to place the <code>TaskModel.cs</code> in a common project that can be referenced by all the projects and thus avoid code repetition which increases the maintenance cost.</p>"},{"location":"aca/05-aca-dapr-pubsubapi/#23-install-dapr-sdk-client-nuget-package","title":"2.3 Install Dapr SDK Client NuGet package","text":"<p>Now we will install Dapr SDK to be able to subscribe to the service broker topic in a programmatic way. Add the highlighted NuGet package to the file shown below:</p> .NET 6.NET 7.NET 8 TasksTracker.Processor.Backend.Svc.csproj <pre><code>&lt;ItemGroup&gt;\n  &lt;PackageReference Include=\"Dapr.AspNetCore\" Version=\"1.12.0\" /&gt;\n&lt;/ItemGroup&gt;\n</code></pre> TasksTracker.Processor.Backend.Svc.csproj <pre><code>&lt;Project Sdk=\"Microsoft.NET.Sdk.Web\"&gt;\n\n  &lt;PropertyGroup&gt;\n    &lt;TargetFramework&gt;net7.0&lt;/TargetFramework&gt;\n    &lt;Nullable&gt;enable&lt;/Nullable&gt;\n    &lt;ImplicitUsings&gt;enable&lt;/ImplicitUsings&gt;\n  &lt;/PropertyGroup&gt;\n\n  &lt;ItemGroup&gt;\n    &lt;PackageReference Include=\"Dapr.AspNetCore\" Version=\"1.12.0\" /&gt;\n    &lt;PackageReference Include=\"Microsoft.AspNetCore.OpenApi\" Version=\"7.0.13\" /&gt;\n    &lt;PackageReference Include=\"Swashbuckle.AspNetCore\" Version=\"6.5.0\" /&gt;\n  &lt;/ItemGroup&gt;\n\n&lt;/Project&gt;\n</code></pre> TasksTracker.Processor.Backend.Svc.csproj <pre><code>&lt;Project Sdk=\"Microsoft.NET.Sdk.Web\"&gt;\n\n  &lt;PropertyGroup&gt;\n    &lt;TargetFramework&gt;net8.0&lt;/TargetFramework&gt;\n    &lt;Nullable&gt;enable&lt;/Nullable&gt;\n    &lt;ImplicitUsings&gt;enable&lt;/ImplicitUsings&gt;\n    &lt;InvariantGlobalization&gt;true&lt;/InvariantGlobalization&gt;\n  &lt;/PropertyGroup&gt;\n\n  &lt;ItemGroup&gt;\n    &lt;PackageReference Include=\"Dapr.AspNetCore\" Version=\"1.12.0\" /&gt;\n    &lt;PackageReference Include=\"Microsoft.AspNetCore.OpenApi\" Version=\"7.0.13\" /&gt;\n    &lt;PackageReference Include=\"Swashbuckle.AspNetCore\" Version=\"6.5.0\" /&gt;\n  &lt;/ItemGroup&gt;\n\n&lt;/Project&gt;\n</code></pre>"},{"location":"aca/05-aca-dapr-pubsubapi/#24-create-an-api-endpoint-for-the-consumer-to-subscribe-to-the-topic","title":"2.4 Create an API Endpoint for the Consumer to Subscribe to the Topic","text":"<p>Now we will add an endpoint that will be responsible to subscribe to the topic in the message broker we are interested in. This endpoint will start receiving the message published from the Backend API producer. Add a new controller under Controllers folder.</p> TasksNotifierController.cs <pre><code>using Dapr;\nusing Dapr.Client;\nusing Microsoft.AspNetCore.Mvc;\nusing TasksTracker.Processor.Backend.Svc.Models;\n\nnamespace TasksTracker.Processor.Backend.Svc.Controllers\n{\n    [Route(\"api/tasksnotifier\")]\n    [ApiController]\n    public class TasksNotifierController : ControllerBase\n    {\n        private readonly IConfiguration _config;\n        private readonly ILogger _logger;\n        private readonly DaprClient _daprClient;\n\n        public TasksNotifierController(IConfiguration config, ILogger&lt;TasksNotifierController&gt; logger, DaprClient daprClient)\n        {\n            _config = config;\n            _logger = logger;\n            _daprClient = daprClient;\n        }\n\n        [Topic(\"dapr-pubsub-servicebus\", \"tasksavedtopic\")]     //Dapr Pub Sub Service Bus\n        [Topic(\"taskspubsub\", \"tasksavedtopic\")]                //Redis\n        [HttpPost(\"tasksaved\")]\n        public IActionResult TaskSaved([FromBody] TaskModel taskModel)\n        {\n            var msg = string.Format(\"Started processing message with Task Name '{0}'\", taskModel.TaskName);\n            _logger.LogInformation(\"Started processing message with Task Name '{0}'\", taskModel.TaskName);\n\n            return Ok(msg);\n        }\n    }\n}\n</code></pre> Curious about what we have done so far? <ul> <li>We have added an action method named <code>TaskSaved</code> which can be accessed on the route <code>api/tasksnotifier/tasksaved</code></li> <li>We have attributed this action method with the attribute <code>Dapr.Topic</code> which accepts the Dapr Pub/Sub component to target as the first argument,  and the second argument is the topic to subscribe to, which in our case is <code>tasksavedtopic</code>.</li> <li>The action method expects to receive a <code>TaskModel</code> object.</li> <li>Now once the message is received by this endpoint, we can start out the business logic to trigger sending an email (more about this next) and then return <code>200 OK</code> response to indicate that the consumer  processed the message successfully and the broker can delete this message.</li> <li>If anything went wrong during sending the email (i.e. Email service not responding) and we want to retry processing this message at a later time, we return <code>400 Bad Request</code>,  which will inform the message broker that the message needs to be retired based on the configuration in the message broker.</li> <li>If we need to drop the message as we are aware it will not be processed even after retries (i.e Email to is not formatted correctly) we return a <code>404 Not Found</code> response.  This will tell the message broker to drop the message and move it to dead-letter or poison queue.</li> </ul> <p>You may be wondering how the consumer was able to identify what are the subscriptions available and on which route they can be found at. The answer for this is that at startup on the consumer service (more on that below after we add <code>app.MapSubscribeHandler())</code>, the Dapr runtime will call the application on a well-known endpoint to identify and create the required subscriptions.</p> <p>The well-known endpoint can be reached on this endpoint: <code>http://localhost:&lt;appPort&gt;/dapr/subscribe</code>. When you invoke this endpoint, the response will contain an array of all available topics for which the applications will subscribe. Each includes a route to call when the topic receives a message. This was generated as we used the attribute <code>Dapr.Topic</code> on the action method <code>api/tasksnotifier/tasksaved</code>.</p> <p>That means when a message is published on the PubSubname <code>taskspubsub</code> on the topic <code>tasksavedtopic</code>, it will be routed to the action method <code>/api/tasksnotifier/tasksaved</code> and will be consumed in this action method.</p> <p>In our case, a sample response will be as follows:</p> <pre><code>[\n    {\n    \"pubsubname\": \"taskspubsub\",\n    \"topic\": \"tasksavedtopic\",\n    \"route\": \"/api/tasksnotifier/tasksaved\"\n    }\n]\n</code></pre> <p>Tip</p> <p>Follow this link to find a detailed diagram of how the consumers will discover and subscribe to those endpoints.</p>"},{"location":"aca/05-aca-dapr-pubsubapi/#25-register-dapr-and-subscribe-handler-at-the-consumer-startup","title":"2.5 Register Dapr and Subscribe Handler at the Consumer Startup","text":"<p>Update below file in TasksTracker.Processor.Backend.Svc project.</p> .NET 6.NET 7 or above Program.cs <pre><code>namespace TasksTracker.Processor.Backend.Svc\n{\n    public class Program\n    {\n        public static void Main(string[] args)\n        {\n            var builder = WebApplication.CreateBuilder(args);\n            // Add services to the container.\n            builder.Services.AddControllers().AddDapr();\n            var app = builder.Build();\n            app.UseHttpsRedirection();\n            app.UseAuthorization();\n            app.UseCloudEvents();\n            app.MapControllers();\n            app.MapSubscribeHandler();\n            app.Run();\n        }\n    }\n}\n</code></pre> Program.cs <pre><code>var builder = WebApplication.CreateBuilder(args);\n\n// Add services to the container.\n\nbuilder.Services.AddControllers().AddDapr();\n// Learn more about configuring Swagger/OpenAPI at https://aka.ms/aspnetcore/swashbuckle\nbuilder.Services.AddEndpointsApiExplorer();\nbuilder.Services.AddSwaggerGen();\n\nvar app = builder.Build();\n\n// Configure the HTTP request pipeline.\nif (app.Environment.IsDevelopment())\n{\n    app.UseSwagger();\n    app.UseSwaggerUI();\n}\n\napp.UseHttpsRedirection();\n\napp.UseAuthorization();\n\napp.UseCloudEvents();\n\napp.MapControllers();\n\napp.MapSubscribeHandler();\n\napp.Run();\n</code></pre> <ul> <li> <p>Let's verify that the Dapr dependency is restored properly and that the project compiles. From VS Code Terminal tab, open developer command prompt or PowerShell terminal and navigate to the parent directory which hosts the <code>.csproj</code> project folder and build the project.</p> <pre><code>cd ~\\TasksTracker.ContainerApps\\TasksTracker.TasksManager.Backend.Svc\ndotnet build\n</code></pre> </li> </ul> Curious about the code above? <ul> <li>On line <code>builder.Services.AddControllers().AddDapr();</code>, the extension method <code>AddDapr</code> registers the necessary services to integrate Dapr into the MVC pipeline.  It also registers a <code>DaprClient</code> instance into the dependency injection container, which then can be injected anywhere into your service. We will see how we are injecting DaprClient in the controller constructor later on.</li> <li>On line <code>app.UseCloudEvents();</code>, the extension method <code>UseCloudEvents</code> adds CloudEvents middleware into the ASP.NET Core middleware pipeline.  This middleware will unwrap requests that use the CloudEvents structured format, so the receiving method can read the event payload directly.  You can read more about CloudEvents here which includes specs for describing event data in a common and standard way.</li> <li>On line <code>app.MapSubscribeHandler();</code>, we make the endpoint <code>http://localhost:&lt;appPort&gt;/dapr/subscribe</code> available for the consumer so it responds and returns available subscriptions.  When this endpoint is called, it will automatically find all WebAPI action methods decorated with the <code>Dapr.Topic</code> attribute and instruct Dapr to create subscriptions for them.</li> </ul> <p>With all those bits in place, we are ready to run the publisher service <code>Backend API</code> and the consumer service <code>Backend Background Service</code> and test Pub/Sub pattern end to end.</p> <pre><code>$BACKEND_SERVICE_APP_PORT=&lt;backend service https port in Properties-&gt;launchSettings.json (e.g. 7051)&gt;\n</code></pre> <ul> <li> <p>Execute the <code>Set-Variables.ps1</code> in the root to update the <code>variables.ps1</code> file with all current variables. The output of the script will inform you how many variables are written out.</p> <pre><code>.\\Set-Variables.ps1\n</code></pre> </li> </ul> <p>To do so, run the below commands in two separate PowerShell console, ensure you are on the right root folder of each respective project.</p> <ul> <li> <p>Restore the previously-stored variables by executing the local script. The output informs you how many variables have been set.</p> <pre><code>.\\Variables.ps1\n</code></pre> </li> </ul> .NET 6 or below.NET 7 or above <p><pre><code>cd ~\\TasksTracker.ContainerApps\\TasksTracker.TasksManager.Backend.Api\n\ndapr run `\n--app-id tasksmanager-backend-api `\n--app-port $API_APP_PORT `\n--dapr-http-port 3500 `\n--app-ssl `\n--resources-path \"../components\" `\n-- dotnet run\n</code></pre> <pre><code>cd ~\\TasksTracker.ContainerApps\\TasksTracker.Processor.Backend.Svc\n\ndapr run `\n--app-id tasksmanager-backend-processor `\n--app-port $BACKEND_SERVICE_APP_PORT `\n--dapr-http-port 3502 `\n--app-ssl `\n--resources-path \"../components\" `\n-- dotnet run\n</code></pre></p> <p><pre><code>cd ~\\TasksTracker.ContainerApps\\TasksTracker.TasksManager.Backend.Api\n\ndapr run `\n--app-id tasksmanager-backend-api `\n--app-port $API_APP_PORT `\n--dapr-http-port 3500 `\n--app-ssl `\n--resources-path \"../components\" `\n-- dotnet run --launch-profile https\n</code></pre> <pre><code>cd ~\\TasksTracker.ContainerApps\\TasksTracker.Processor.Backend.Svc\n\ndapr run `\n--app-id tasksmanager-backend-processor `\n--app-port $BACKEND_SERVICE_APP_PORT `\n--dapr-http-port 3502 `\n--app-ssl `\n--resources-path \"../components\" `\n-- dotnet run --launch-profile https\n</code></pre></p> <p>Note</p> <p>Notice that we gave the new Backend background service a Dapr App Id with the name <code>tasksmanager-backend-processor</code> and a Dapr HTTP port with the value <code>3502</code>.</p> <p>Now let's try to publish a message by sending a POST request to http://localhost:3500/v1.0/publish/taskspubsub/tasksavedtopic with the below request body, don't forget to set the <code>Content-Type</code> header to <code>application/json</code></p> <pre><code>POST /v1.0/publish/taskspubsub/tasksavedtopic HTTP/1.1\nHost: localhost:3500\nContent-Type: application/json\n\n{\n    \"taskId\": \"fbc55b2c-d9fa-405e-aec8-22e53f4306dd\",\n    \"taskName\": \"Testing Pub Sub Publisher\",\n    \"taskCreatedBy\": \"user@mail.net\",\n    \"taskCreatedOn\": \"2023-02-12T00:24:37.7361348Z\",\n    \"taskDueDate\": \"2023-02-20T00:00:00\",\n    \"taskAssignedTo\": \"user2@mail.com\"\n}\n</code></pre> <p>Keep an eye on the terminal logs of the Backend background processor as you will see that the message is received and consumed by the action method <code>api/tasksnotifier/tasksaved</code> and an information message is logged in the terminal to indicate the processing of the message.</p> VS Code Dapr Extension <p>You can use the VS Code Dapr Extension to publish the message directly. It will be similar to the below image:</p> <p></p> <p>Shut down the sessions.</p>"},{"location":"aca/05-aca-dapr-pubsubapi/#26-optional-update-vs-code-tasks-and-launch-configuration-files","title":"2.6 Optional: Update VS Code Tasks and Launch Configuration Files","text":"<p>If you have followed the steps in the appendix so far in order to be able to run the three services together (frontend, backend api, and backend processor) and debug them in VS Code, we need to update the files <code>tasks.json</code> and <code>launch.json</code> to include the new service we have added.</p> Click to expand the files to update <p>You can use the below files to update the existing ones.</p> tasks.jsonlaunch.json <pre><code>{\n    \"version\": \"2.0.0\",\n    \"tasks\": [\n        {\n            \"label\": \"build-backend-api\",\n            \"command\": \"dotnet\",\n            \"type\": \"process\",\n            \"args\": [\n                \"build\",\n                \"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api/TasksTracker.TasksManager.Backend.Api.csproj\",\n                \"/property:GenerateFullPaths=true\",\n                \"/consoleloggerparameters:NoSummary\"\n            ],\n            \"problemMatcher\": \"$msCompile\"\n        },\n        {\n            \"label\": \"publish-backend-api\",\n            \"command\": \"dotnet\",\n            \"type\": \"process\",\n            \"args\": [\n                \"publish\",\n                \"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api/TasksTracker.TasksManager.Backend.Api.csproj\",\n                \"/property:GenerateFullPaths=true\",\n                \"/consoleloggerparameters:NoSummary\"\n            ],\n            \"problemMatcher\": \"$msCompile\"\n        },\n        {\n            \"label\": \"watch-backend-api\",\n            \"command\": \"dotnet\",\n            \"type\": \"process\",\n            \"args\": [\n                \"watch\",\n                \"run\",\n                \"--project\",\n                \"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api/TasksTracker.TasksManager.Backend.Api.csproj\"\n            ],\n            \"problemMatcher\": \"$msCompile\"\n        },\n        {\n            \"label\": \"build-webapp-ui\",\n            \"command\": \"dotnet\",\n            \"type\": \"process\",\n            \"args\": [\n                \"build\",\n                \"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui/TasksTracker.WebPortal.Frontend.Ui.csproj\",\n                \"/property:GenerateFullPaths=true\",\n                \"/consoleloggerparameters:NoSummary\"\n            ],\n            \"problemMatcher\": \"$msCompile\"\n        },\n        {\n            \"label\": \"publish-webapp-ui\",\n            \"command\": \"dotnet\",\n            \"type\": \"process\",\n            \"args\": [\n                \"publish\",\n                \"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui/TasksTracker.WebPortal.Frontend.Ui.csproj\",\n                \"/property:GenerateFullPaths=true\",\n                \"/consoleloggerparameters:NoSummary\"\n            ],\n            \"problemMatcher\": \"$msCompile\"\n        },\n        {\n            \"label\": \"watch-webapp-ui\",\n            \"command\": \"dotnet\",\n            \"type\": \"process\",\n            \"args\": [\n                \"watch\",\n                \"run\",\n                \"--project\",\n                \"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui/TasksTracker.WebPortal.Frontend.Ui.csproj\"\n            ],\n            \"problemMatcher\": \"$msCompile\"\n        },\n        {\n            \"label\": \"build-processor-svc\",\n            \"command\": \"dotnet\",\n            \"type\": \"process\",\n            \"args\": [\n                \"build\",\n                \"${workspaceFolder}/TasksTracker.Processor.Backend.Svc/TasksTracker.Processor.Backend.Svc.csproj\",\n                \"/property:GenerateFullPaths=true\",\n                \"/consoleloggerparameters:NoSummary\"\n            ],\n            \"problemMatcher\": \"$msCompile\"\n        },\n        {\n            \"label\": \"publish-processor-svc\",\n            \"command\": \"dotnet\",\n            \"type\": \"process\",\n            \"args\": [\n                \"publish\",\n                \"${workspaceFolder}/TasksTracker.Processor.Backend.Svc/TasksTracker.Processor.Backend.Svc.csproj\",\n                \"/property:GenerateFullPaths=true\",\n                \"/consoleloggerparameters:NoSummary\"\n            ],\n            \"problemMatcher\": \"$msCompile\"\n        },\n        {\n            \"label\": \"watch-processor-svc\",\n            \"command\": \"dotnet\",\n            \"type\": \"process\",\n            \"args\": [\n                \"watch\",\n                \"run\",\n                \"--project\",\n                \"${workspaceFolder}/TasksTracker.Processor.Backend.Svc/TasksTracker.Processor.Backend.Svc.csproj\"\n            ],\n            \"problemMatcher\": \"$msCompile\"\n        },\n        {\n            \"label\": \"build-all\",\n            \"dependsOn\": [\n                \"build-backend-api\",\n                \"build-webapp-ui\",\n                \"build-processor-svc\"\n            ],\n            \"problemMatcher\": [],\n            \"group\": {\n                \"kind\": \"build\",\n                \"isDefault\": true\n            }\n        },\n        {\n            \"appId\": \"tasksmanager-backend-api\",\n            \"appPort\": 7088,\n            \"httpPort\": 3500,\n            \"grpcPort\": 50001,\n            \"appSsl\": true,\n            \"label\": \"backend-api-dapr-debug\",\n            \"type\": \"dapr\",\n            \"dependsOn\": \"build-backend-api\",\n            \"componentsPath\": \"./components\"\n        },\n        {\n            \"appId\": \"tasksmanager-backend-api\",\n            \"label\": \"daprd-down-backend-api\",\n            \"type\": \"daprd-down\"\n        },\n        {\n            \"appId\": \"tasksmanager-frontend-webapp\",\n            \"appPort\": 7208,\n            \"httpPort\": 3501,\n            \"grpcPort\": 50002,\n            \"appSsl\": true,\n            \"label\": \"webapp-ui-dapr-debug\",\n            \"type\": \"dapr\",\n            \"dependsOn\": \"build-webapp-ui\"\n        },\n        {\n            \"appId\": \"tasksmanager-frontend-webapp\",\n            \"label\": \"webapp-ui-daprd-down\",\n            \"type\": \"daprd-down\"\n        },\n        {\n            \"appId\": \"tasksmanager-backend-processor\",\n            \"appPort\": 7263,\n            \"httpPort\": 3502,\n            \"grpcPort\": 50003,\n            \"appSsl\": true,\n            \"label\": \"processor-svc-dapr-debug\",\n            \"type\": \"dapr\",\n            \"dependsOn\": \"build-processor-svc\",\n            \"componentsPath\": \"./components\"\n        },\n        {\n            \"appId\": \"tasksmanager-backend-processor\",\n            \"label\": \"processor-svc-daprd-down\",\n            \"type\": \"daprd-down\"\n        }\n    ]\n}\n</code></pre> <pre><code>{\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \"Launch (web app)\",\n            \"type\": \"coreclr\",\n            \"request\": \"launch\",\n            \"preLaunchTask\": \"build-backend-api\",\n            \"program\": \"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui/bin/Debug/net6.0/TasksTracker.WebPortal.Frontend.Ui.dll\",\n            \"args\": [],\n            \"cwd\": \"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui\",\n            \"stopAtEntry\": false,\n            \"serverReadyAction\": {\n                \"action\": \"openExternally\",\n                \"pattern\": \"\\\\bNow listening on:\\\\s+(https?://\\\\S+)\"\n            },\n            \"env\": {\n                \"ASPNETCORE_ENVIRONMENT\": \"Development\"\n            },\n            \"sourceFileMap\": {\n                \"/Views\": \"${workspaceFolder}/Views\"\n            }\n        },\n        {\n            \"name\": \"Launch (backend api)\",\n            \"type\": \"coreclr\",\n            \"request\": \"launch\",\n            \"preLaunchTask\": \"build-webapp-ui\",\n            \"program\": \"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api/bin/Debug/net6.0/TasksTracker.TasksManager.Backend.Api.dll\",\n            \"args\": [],\n            \"cwd\": \"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api\",\n            \"stopAtEntry\": false,\n            \"serverReadyAction\": {\n                \"action\": \"openExternally\",\n                \"pattern\": \"\\\\bNow listening on:\\\\s+(https?://\\\\S+)\"\n            },\n            \"env\": {\n                \"ASPNETCORE_ENVIRONMENT\": \"Development\"\n            },\n            \"sourceFileMap\": {\n                \"/Views\": \"${workspaceFolder}/Views\"\n            }\n        },\n        {\n            \"name\": \"Launch (background processor)\",\n            \"type\": \"coreclr\",\n            \"request\": \"launch\",\n            \"preLaunchTask\": \"build-processor-svc\",\n            \"program\": \"${workspaceFolder}/TasksTracker.Processor.Backend.Svc/bin/Debug/net6.0/TasksTracker.Processor.Backend.Svc.dll\",\n            \"args\": [],\n            \"cwd\": \"${workspaceFolder}/TasksTracker.Processor.Backend.Svc\",\n            \"stopAtEntry\": false,\n            \"serverReadyAction\": {\n                \"action\": \"openExternally\",\n                \"pattern\": \"\\\\bNow listening on:\\\\s+(https?://\\\\S+)\"\n            },\n            \"env\": {\n                \"ASPNETCORE_ENVIRONMENT\": \"Development\"\n            },\n            \"sourceFileMap\": {\n                \"/Views\": \"${workspaceFolder}/Views\"\n            }\n        },\n        {\n            \"name\": \".NET Core Attach\",\n            \"type\": \"coreclr\",\n            \"request\": \"attach\"\n        },\n        {\n            \"name\": \"Launch (backend api) with Dapr\",\n            \"type\": \"coreclr\",\n            \"request\": \"launch\",\n            \"preLaunchTask\": \"backend-api-dapr-debug\",\n            \"program\": \"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api/bin/Debug/net6.0/TasksTracker.TasksManager.Backend.Api.dll\",\n            \"args\": [],\n            \"cwd\": \"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api\",\n            \"stopAtEntry\": false,\n            \"serverReadyAction\": {\n                \"action\": \"openExternally\",\n                \"pattern\": \"\\\\bNow listening on:\\\\s+(https?://\\\\S+)\"\n            },\n            \"env\": {\n                \"ASPNETCORE_ENVIRONMENT\": \"Development\"\n            },\n            \"sourceFileMap\": {\n                \"/Views\": \"${workspaceFolder}/Views\"\n            },\n            \"postDebugTask\": \"daprd-down-backend-api\"\n        },\n        {\n            \"name\": \"Launch (web app) with Dapr\",\n            \"type\": \"coreclr\",\n            \"request\": \"launch\",\n            \"preLaunchTask\": \"webapp-ui-dapr-debug\",\n            \"program\": \"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui/bin/Debug/net6.0/TasksTracker.WebPortal.Frontend.Ui.dll\",\n            \"args\": [],\n            \"cwd\": \"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui\",\n            \"stopAtEntry\": false,\n            \"serverReadyAction\": {\n                \"action\": \"openExternally\",\n                \"pattern\": \"\\\\bNow listening on:\\\\s+(https?://\\\\S+)\"\n            },\n            \"env\": {\n                \"ASPNETCORE_ENVIRONMENT\": \"Development\"\n            },\n            \"sourceFileMap\": {\n                \"/Views\": \"${workspaceFolder}/Views\"\n            },\n            \"postDebugTask\": \"webapp-ui-daprd-down\"\n        },\n        {\n            \"name\": \"Launch (background processor) with Dapr\",\n            \"type\": \"coreclr\",\n            \"request\": \"launch\",\n            \"preLaunchTask\": \"processor-svc-dapr-debug\",\n            \"program\": \"${workspaceFolder}/TasksTracker.Processor.Backend.Svc/bin/Debug/net6.0/TasksTracker.Processor.Backend.Svc.dll\",\n            \"args\": [],\n            \"cwd\": \"${workspaceFolder}/TasksTracker.Processor.Backend.Svc\",\n            \"stopAtEntry\": false,\n            \"serverReadyAction\": {\n                \"action\": \"openExternally\",\n                \"pattern\": \"\\\\bNow listening on:\\\\s+(https?://\\\\S+)\"\n            },\n            \"env\": {\n                \"ASPNETCORE_ENVIRONMENT\": \"Development\"\n            },\n            \"sourceFileMap\": {\n                \"/Views\": \"${workspaceFolder}/Views\"\n            },\n            \"postDebugTask\": \"processor-svc-daprd-down\"\n        }\n    ],\n    \"compounds\": [\n        {\n            \"name\": \"RunAll\",\n            \"configurations\": [\"Launch (web app)\", \"Launch (backend api)\", \"Launch (background processor)\",],\n            \"stopAll\": true\n        },\n        {\n            \"name\": \"RunAll with Dapr\",\n            \"configurations\": [ \"Launch (backend api) with Dapr\", \"Launch (web app) with Dapr\", \"Launch (background processor) with Dapr\", ],\n            \"stopAll\": true\n        }\n    ]\n}\n</code></pre>"},{"location":"aca/05-aca-dapr-pubsubapi/#27-update-backend-api-to-publish-a-message-when-a-task-is-saved","title":"2.7 Update Backend API to Publish a Message When a Task Is Saved","text":"<p>Now we need to update our Backend API to publish a message to the message broker when a task is saved (either due to a new task being added or an existing task assignee being updated).</p> <p>To do this, update below file under the project TasksTracker.TasksManager.Backend.Api and update the file in the Services folder as highlighted below:</p> TasksStoreManager.cs <pre><code>using Dapr.Client;\nusing TasksTracker.TasksManager.Backend.Api.Models;\n\nnamespace TasksTracker.TasksManager.Backend.Api.Services\n{\n    public class TasksStoreManager : ITasksManager\n    {\n        private static string STORE_NAME = \"statestore\";\n        private readonly DaprClient _daprClient;\n        private readonly IConfiguration _config;\n        private readonly ILogger&lt;TasksStoreManager&gt; _logger;\n\n        public TasksStoreManager(DaprClient daprClient, IConfiguration config, ILogger&lt;TasksStoreManager&gt; logger)\n        {\n            _daprClient = daprClient;\n            _config = config;\n            _logger = logger;\n        }\n        public async Task&lt;Guid&gt; CreateNewTask(string taskName, string createdBy, string assignedTo, DateTime dueDate)\n        {\n            var taskModel = new TaskModel()\n            {\n                TaskId = Guid.NewGuid(),\n                TaskName = taskName,\n                TaskCreatedBy = createdBy,\n                TaskCreatedOn = DateTime.UtcNow,\n                TaskDueDate = dueDate,\n                TaskAssignedTo = assignedTo,\n            };\n\n            _logger.LogInformation(\"Save a new task with name: '{0}' to state store\", taskModel.TaskName);\n            await _daprClient.SaveStateAsync&lt;TaskModel&gt;(STORE_NAME, taskModel.TaskId.ToString(), taskModel);\n            await PublishTaskSavedEvent(taskModel);\n            return taskModel.TaskId;\n        }\n\n        public async Task&lt;bool&gt; DeleteTask(Guid taskId)\n        {\n            _logger.LogInformation(\"Delete task with Id: '{0}'\", taskId);\n            await _daprClient.DeleteStateAsync(STORE_NAME, taskId.ToString());\n            return true;\n        }\n\n        public async Task&lt;TaskModel?&gt; GetTaskById(Guid taskId)\n        {\n            _logger.LogInformation(\"Getting task with Id: '{0}'\", taskId);\n            var taskModel = await _daprClient.GetStateAsync&lt;TaskModel&gt;(STORE_NAME, taskId.ToString());\n            return taskModel;\n        }\n\n        public async Task&lt;List&lt;TaskModel&gt;&gt; GetTasksByCreator(string createdBy)\n        {\n            var query = \"{\" +\n                    \"\\\"filter\\\": {\" +\n                        \"\\\"EQ\\\": { \\\"taskCreatedBy\\\": \\\"\" + createdBy + \"\\\" }\" +\n                    \"}}\";\n\n            var queryResponse = await _daprClient.QueryStateAsync&lt;TaskModel&gt;(STORE_NAME, query);\n\n            var tasksList = queryResponse.Results.Select(q =&gt; q.Data).OrderByDescending(o=&gt;o.TaskCreatedOn);\n            return tasksList.ToList();\n        }\n\n        public async Task&lt;bool&gt; MarkTaskCompleted(Guid taskId)\n        {\n            _logger.LogInformation(\"Mark task with Id: '{0}' as completed\", taskId);\n            var taskModel = await _daprClient.GetStateAsync&lt;TaskModel&gt;(STORE_NAME, taskId.ToString());\n            if (taskModel != null)\n            {\n                taskModel.IsCompleted = true;\n                await _daprClient.SaveStateAsync&lt;TaskModel&gt;(STORE_NAME, taskModel.TaskId.ToString(), taskModel);\n                return true;\n            }\n            return false;\n        }\n\n        public async Task&lt;bool&gt; UpdateTask(Guid taskId, string taskName, string assignedTo, DateTime dueDate)\n        {\n            _logger.LogInformation(\"Update task with Id: '{0}'\", taskId);\n            var taskModel = await _daprClient.GetStateAsync&lt;TaskModel&gt;(STORE_NAME, taskId.ToString());\n            var currentAssignee = taskModel.TaskAssignedTo;\n            if (taskModel != null)\n            {\n                taskModel.TaskName = taskName;\n                taskModel.TaskAssignedTo = assignedTo;\n                taskModel.TaskDueDate = dueDate;\n                await _daprClient.SaveStateAsync&lt;TaskModel&gt;(STORE_NAME, taskModel.TaskId.ToString(), taskModel);\n                if (!taskModel.TaskAssignedTo.Equals(currentAssignee, StringComparison.OrdinalIgnoreCase))\n                {\n                    await PublishTaskSavedEvent(taskModel);\n                }\n                return true;\n            }\n            return false;\n        }\n\n        private async Task PublishTaskSavedEvent(TaskModel taskModel)\n        {\n            _logger.LogInformation(\"Publish Task Saved event for task with Id: '{0}' and Name: '{1}' for Assignee: '{2}'\",\n            taskModel.TaskId, taskModel.TaskName, taskModel.TaskAssignedTo);\n            await _daprClient.PublishEventAsync(\"dapr-pubsub-servicebus\", \"tasksavedtopic\", taskModel);\n        }\n    }\n}\n</code></pre> <p>Tip</p> <p>Notice the new method <code>PublishTaskSavedEvent</code> added to the class. All we have to do is to call the method <code>PublishTaskSavedEvent</code> and pass the Pub/Sub name. In our case we named it <code>dapr-pubsub-servicebus</code> as we are going to use Azure Service Bus as a message broker in the next step.</p> <p>The second parameter <code>tasksavedtopic</code> is the topic name the publisher going to send the task model to. That's all the changes required to start publishing async messages from the Backend API.</p> <p>This is a good opportunity to save intermediately:</p> <ul> <li> <p>From the root, persist a list of all current variables.</p> <pre><code>git add .\\Variables.ps1\ngit commit -m \"Update Variables.ps1\"\n</code></pre> </li> <li> <p>Navigate to the root and persist the module to Git.</p> <pre><code>git add .\ngit commit -m \"Add Module 5.1\"\n</code></pre> </li> </ul>"},{"location":"aca/05-aca-dapr-pubsubapi/#3-use-azure-service-bus-as-a-service-broker-for-dapr-pubsub-api","title":"3. Use Azure Service Bus as a Service Broker for Dapr Pub/Sub API","text":"<p>Now we will switch our implementation to use Azure Service Bus as a message broker. Redis worked perfectly for local development and testing, but we need to prepare ourselves for the cloud deployment. To do so we need to create Service Bus Namespace followed by a Topic. A namespace provides a scoping container for Service Bus resources within your application.</p>"},{"location":"aca/05-aca-dapr-pubsubapi/#31-create-azure-service-bus-namespace-and-a-topic","title":"3.1 Create Azure Service Bus Namespace and a Topic","text":"<p>You can do this from Azure portal or use the below PowerShell command to create the services. We will assume you are using the same PowerShell session from the previous module so variables still hold the right values. You need to change the namespace variable as this one should be unique globally across all Azure subscriptions. Also, you will notice that we are opting for standard sku (default if not passed) as topics only available on the standard tier not and not on the basic tier. More details can be found here.</p> <pre><code>$SERVICE_BUS_NAMESPACE_NAME=\"sbns-taskstracker-$RANDOM_STRING\"\n$SERVICE_BUS_TOPIC_NAME=\"tasksavedtopic\"\n$SERVICE_BUS_TOPIC_SUBSCRIPTION=\"sbts-tasks-processor\"\n\n# Create servicebus namespace\naz servicebus namespace create --resource-group $RESOURCE_GROUP --name $SERVICE_BUS_NAMESPACE_NAME --location $LOCATION --sku Standard\n\n# Create a topic under the namespace\naz servicebus topic create --resource-group $RESOURCE_GROUP --namespace-name $SERVICE_BUS_NAMESPACE_NAME --name $SERVICE_BUS_TOPIC_NAME\n\n# Create a topic subscription\naz servicebus topic subscription create `\n--resource-group $RESOURCE_GROUP `\n--namespace-name $SERVICE_BUS_NAMESPACE_NAME `\n--topic-name $SERVICE_BUS_TOPIC_NAME `\n--name $SERVICE_BUS_TOPIC_SUBSCRIPTION\n\n# List connection string\naz servicebus namespace authorization-rule keys list `\n--resource-group $RESOURCE_GROUP `\n--namespace-name $SERVICE_BUS_NAMESPACE_NAME `\n--name RootManageSharedAccessKey `\n--query primaryConnectionString `\n--output tsv\n</code></pre> <p>Note</p> <p>Primary connection string is only needed for local dev testing. We will be using Managed Identities when publishing container apps to ACA.</p>"},{"location":"aca/05-aca-dapr-pubsubapi/#32-create-a-local-dapr-component-file-for-pubsub-api-using-azure-service-bus","title":"3.2 Create a local Dapr Component file for Pub/Sub API Using Azure Service Bus","text":"<p>We need to add a new Dapr Azure Service Bus Topic component. Add a new file in the components folder as shown below:</p> dapr-pubsub-svcbus.yaml<pre><code>apiVersion: dapr.io/v1alpha1\nkind: Component\nmetadata:\n  name: dapr-pubsub-servicebus\nspec:\n  type: pubsub.azure.servicebus.topics\n  version: v1\n  metadata:\n    - name: connectionString # Used for local dev testing.\n      value: \"&lt;connection string from step 1 starting with Endpoint=sb://...&gt;\"\n    - name: consumerID\n      value: \"sbts-tasks-processor\"\nscopes:\n  - tasksmanager-backend-api\n  - tasksmanager-backend-processor\n</code></pre> <p>Note</p> <p>We used the name <code>dapr-pubsub-servicebus</code> which should match the name of Pub/Sub component we've used earlier in the <code>TasksNotifierController.cs</code> controller on the action method with the attribute <code>Topic</code>.</p> <p>We set the metadata (key/value) to allow us to connect to Azure Service Bus topic. The metadata <code>consumerID</code> value should match the topic subscription name <code>sbts-tasks-processor</code>. </p> <p>We have set the scopes section to include the <code>tasksmanager-backend-api</code> and <code>tasksmanager-backend-processor</code> app ids, as those will be the Dapr apps that need access to Azure Service Bus for publishing and  consuming the messages.</p>"},{"location":"aca/05-aca-dapr-pubsubapi/#33-create-an-aca-dapr-component-file-for-pubsub-api-using-azure-service-bus","title":"3.3 Create an ACA Dapr Component file for Pub/Sub API Using Azure Service Bus","text":"<p>Add a new files aca-components as shown below:</p> <p>Note</p> <p>Remember to replace the namespace placeholder with the unique global name you chose earlier</p> containerapps-pubsub-svcbus.yaml<pre><code># pubsub.yaml for Azure Service Bus component\ncomponentType: pubsub.azure.servicebus.topics\nversion: v1\nmetadata:\n  - name: namespaceName\n    value: \"sbns-taskstracker-&lt;$RANDOM_STRING&gt;.servicebus.windows.net\"\n  - name: consumerID\n    value: \"sbts-tasks-processor\"\n# Application scopes\nscopes:\n  - tasksmanager-backend-api\n  - tasksmanager-backend-processor\n</code></pre> Things to note here <ul> <li>We didn't specify the component name <code>dapr-pubsub-servicebus</code> when we created this component file. We are going to specify it once we add this dapr component to Azure Container Apps Environment via CLI.</li> <li>We are not referencing any service bus connection strings as the authentication between Dapr and Azure Service Bus will be configured using Managed Identities.</li> <li>The metadata <code>namespaceName</code> value is set to the address of the Service Bus namespace as a fully qualified domain name. The <code>namespaceName</code> key is mandatory when using Managed Identities for authentication.</li> <li>We are setting the metadata <code>consumerID</code> value to match the topic subscription name <code>sbts-tasks-processor</code>. If you didn't set this metadata, dapr runtime will try to create a subscription using the dapr application ID.</li> </ul> <p>With all those bits in place, we are ready to run the publisher service <code>Backend API</code> and the consumer service <code>Backend Background Service</code> and test Pub/Sub pattern end to end.</p> <p>Note</p> <p>Ensure you are on the right root folder of each respective project.</p> .NET 6 or below.NET 7 or above <p><pre><code>cd ~\\TasksTracker.ContainerApps\\TasksTracker.TasksManager.Backend.Api\n\ndapr run `\n--app-id tasksmanager-backend-api `\n--app-port $API_APP_PORT `\n--dapr-http-port 3500 `\n--app-ssl `\n--resources-path \"../components\" `\n-- dotnet run\n</code></pre> <pre><code>cd ~\\TasksTracker.ContainerApps\\TasksTracker.Processor.Backend.Svc\n\ndapr run `\n--app-id tasksmanager-backend-processor `\n--app-port $BACKEND_SERVICE_APP_PORT `\n--dapr-http-port 3502 `\n--app-ssl `\n--resources-path \"../components\" `\n-- dotnet run\n</code></pre></p> <p><pre><code>cd ~\\TasksTracker.ContainerApps\\TasksTracker.TasksManager.Backend.Api\n\ndapr run `\n--app-id tasksmanager-backend-api `\n--app-port $API_APP_PORT `\n--dapr-http-port 3500 `\n--app-ssl `\n--resources-path \"../components\" `\n-- dotnet run --launch-profile https\n</code></pre> <pre><code>cd ~\\TasksTracker.ContainerApps\\TasksTracker.Processor.Backend.Svc\n\ndapr run `\n--app-id tasksmanager-backend-processor `\n--app-port $BACKEND_SERVICE_APP_PORT `\n--dapr-http-port 3502 `\n--app-ssl `\n--resources-path \"../components\" `\n-- dotnet run --launch-profile https\n</code></pre></p> <p>Note</p> <p>We gave the new Backend background service a Dapr App Id with the name <code>tasksmanager-backend-processor</code> and a Dapr HTTP port with the value 3502.</p> <p>Now let's try to publish a message by sending a POST request to http://localhost:3500/v1.0/publish/dapr-pubsub-servicebus/tasksavedtopic with the below request body, don't forget to set the <code>Content-Type</code> header to <code>application/json</code></p> <pre><code>POST /v1.0/publish/dapr-pubsub-servicebus/tasksavedtopic HTTP/1.1\nHost: localhost:3500\nContent-Type: application/json\n{\n    \"taskId\": \"fbc55b2c-d9fa-405e-aec8-22e53f4306dd\",\n    \"taskName\": \"Testing Pub Sub Publisher\",\n    \"taskCreatedBy\": \"user@mail.net\",\n    \"taskCreatedOn\": \"2023-02-12T00:24:37.7361348Z\",\n    \"taskDueDate\": \"2023-02-20T00:00:00\",\n    \"taskAssignedTo\": \"user2@mail.com\"\n}\n</code></pre> <p>You should see console messages from APP in the backend service console as you send requests.</p>"},{"location":"aca/05-aca-dapr-pubsubapi/#4-deploy-the-backend-background-processor-and-the-backend-api-projects-to-azure-container-apps","title":"4. Deploy the Backend Background Processor and the Backend API Projects to Azure Container Apps","text":""},{"location":"aca/05-aca-dapr-pubsubapi/#41-build-the-backend-background-processor-and-the-backend-api-app-images-and-push-them-to-acr","title":"4.1 Build the Backend Background Processor and the Backend API App Images and Push Them to ACR","text":"<p>As we have done previously we need to build and deploy both app images to ACR, so they are ready to be deployed to Azure Container Apps.</p> <p>Note</p> <p>Make sure you are in root directory of the project, i.e. TasksTracker.ContainerApps</p> <pre><code>$BACKEND_SERVICE_NAME=\"tasksmanager-backend-processor\"\n\naz acr build `\n--registry $AZURE_CONTAINER_REGISTRY_NAME `\n--image \"tasksmanager/$BACKEND_API_NAME\" `\n--file 'TasksTracker.TasksManager.Backend.Api/Dockerfile' . \n\naz acr build `\n--registry $AZURE_CONTAINER_REGISTRY_NAME `\n--image \"tasksmanager/$BACKEND_SERVICE_NAME\" `\n--file 'TasksTracker.Processor.Backend.Svc/Dockerfile' .\n</code></pre>"},{"location":"aca/05-aca-dapr-pubsubapi/#42-create-a-new-azure-container-app-to-host-the-new-backend-background-processor","title":"4.2 Create a new Azure Container App to host the new Backend Background Processor","text":"<p>Now we need to create a new Azure Container App. We need to have this new container app with those capabilities in place:</p> <ul> <li>Ingress for this container app should be disabled (no access via HTTP at all as this is a background processor responsible to process published messages).</li> <li>Dapr needs to be enabled.</li> </ul> <p>To achieve the above, run the PowerShell script below.</p> <p>Note</p> <p>Notice how we removed the Ingress property totally which disables the Ingress for this Container App.</p> <pre><code>az containerapp create `\n--name \"$BACKEND_SERVICE_NAME\"  `\n--resource-group $RESOURCE_GROUP `\n--environment $ENVIRONMENT `\n--image \"$AZURE_CONTAINER_REGISTRY_NAME.azurecr.io/tasksmanager/$BACKEND_SERVICE_NAME\" `\n--registry-server \"$AZURE_CONTAINER_REGISTRY_NAME.azurecr.io\" `\n--min-replicas 1 `\n--max-replicas 1 `\n--cpu 0.25 `\n--memory 0.5Gi `\n--enable-dapr `\n--dapr-app-id $BACKEND_SERVICE_NAME `\n--dapr-app-port $TARGET_PORT\n</code></pre>"},{"location":"aca/05-aca-dapr-pubsubapi/#43-deploy-new-revisions-of-the-backend-api-to-azure-container-apps","title":"4.3 Deploy New Revisions of the Backend API to Azure Container Apps","text":"<p>We need to update the Azure Container App hosting the Backend API with a new revision so our code changes for publishing messages after a task is saved is available for users.</p> <pre><code># Update Backend API App container app and create a new revision \naz containerapp update `\n--name $BACKEND_API_NAME `\n--resource-group $RESOURCE_GROUP `\n--revision-suffix v$TODAY-2\n</code></pre>"},{"location":"aca/05-aca-dapr-pubsubapi/#44-add-azure-service-bus-dapr-pubsub-component-to-azure-container-apps-environment","title":"4.4 Add Azure Service Bus Dapr Pub/Sub Component to Azure Container Apps Environment","text":"<p>Deploy the Dapr Pub/Sub Component to the Azure Container Apps Environment using the following command:</p> <pre><code>az containerapp env dapr-component set `\n--name $ENVIRONMENT `\n--resource-group $RESOURCE_GROUP `\n--dapr-component-name dapr-pubsub-servicebus `\n--yaml '.\\aca-components\\containerapps-pubsub-svcbus.yaml'\n</code></pre> <p>Note</p> <p>Notice that we set the component name <code>dapr-pubsub-servicebus</code> when we added it to the Container Apps Environment.</p>"},{"location":"aca/05-aca-dapr-pubsubapi/#5-configure-managed-identities-for-both-container-apps","title":"5. Configure Managed Identities for Both Container Apps","text":"<p>In the previous module we have already configured and used system-assigned identity for the Backend API container app. We follow the same steps here to create an association between the backend processor container app and Azure Service Bus.</p>"},{"location":"aca/05-aca-dapr-pubsubapi/#51-create-system-assigned-identity-for-backend-processor-app","title":"5.1 Create system-assigned identity for Backend Processor App","text":"<p>Run the command below to create <code>system-assigned</code> identity for our Backend Processor App:</p> <pre><code>az containerapp identity assign `\n--resource-group $RESOURCE_GROUP `\n--name $BACKEND_SERVICE_NAME `\n--system-assigned\n\n$BACKEND_SVC_PRINCIPAL_ID=(az containerapp identity show `\n--name $BACKEND_SERVICE_NAME `\n--resource-group $RESOURCE_GROUP `\n--query principalId `\n--output tsv)\n</code></pre> <p>This command will create an Enterprise Application (basically a Service Principal) within Azure AD, which is linked to our container app. The output of this command will be as the below, keep a note of the property <code>principalId</code> as we are going to use it in the next step.</p> <pre><code>{\n    \"principalId\": \"&lt;your principal id will be displayed here&gt;\",\n    \"tenantId\": \"&lt;your tenant id will be displayed here&gt;\",\n    \"type\": \"SystemAssigned\"\n}\n</code></pre>"},{"location":"aca/05-aca-dapr-pubsubapi/#52-grant-backend-processor-app-the-azure-service-bus-data-receiver-role","title":"5.2 Grant Backend Processor App the Azure Service Bus Data Receiver Role","text":"<p>We will be using a <code>system-assigned</code> managed identity with a role assignments to grant our Backend Processor App the <code>Azure Service Bus Data Receiver</code> role which will allow it to receive messages from Service Bus queues and subscriptions.</p> <p>You can read more about <code>Azure built-in roles for Azure Service Bus</code> here.</p> <p>Run the command below to associate the <code>system-assigned</code> identity with the access-control role <code>Azure Service Bus Data Receiver</code>:</p> <pre><code>$SVC_BUS_DATA_RECEIVER_ROLE = \"Azure Service Bus Data Receiver\" # Built in role name\n\naz role assignment create `\n--assignee $BACKEND_SVC_PRINCIPAL_ID `\n--role $SVC_BUS_DATA_RECEIVER_ROLE `\n--scope /subscriptions/$AZURE_SUBSCRIPTION_ID/resourcegroups/$RESOURCE_GROUP/providers/Microsoft.ServiceBus/namespaces/$SERVICE_BUS_NAMESPACE_NAME/topics/$SERVICE_BUS_TOPIC_NAME\n</code></pre>"},{"location":"aca/05-aca-dapr-pubsubapi/#53-grant-backend-api-app-the-azure-service-bus-data-sender-role","title":"5.3 Grant Backend API App the Azure Service Bus Data Sender Role","text":"<p>We'll do the same with Backend API container app, but we will use a different Azure built-in roles for Azure Service Bus which is the role <code>Azure Service Bus Data Sender</code> as the Backend API is a publisher of the messages. Run the command below to associate the <code>system-assigned</code> with access-control role <code>Azure Service Bus Data Sender</code>:</p> <pre><code>$SVC_BUS_DATA_SENDER_ROLE = \"Azure Service Bus Data Sender\" # Built in role name\n\naz role assignment create `\n--assignee $BACKEND_API_PRINCIPAL_ID `\n--role $SVC_BUS_DATA_SENDER_ROLE `\n--scope /subscriptions/$AZURE_SUBSCRIPTION_ID/resourcegroups/$RESOURCE_GROUP/providers/Microsoft.ServiceBus/namespaces/$SERVICE_BUS_NAMESPACE_NAME/topics/$SERVICE_BUS_TOPIC_NAME\n</code></pre> <p>Limiting Managed Identity Scope in Azure Service Bus</p> <p>Take note of the AZ CLI commands in 5.2 and 5.3. We are setting the scope of access for the system-assigned managed identity very narrowly to just the topic(s) that the container app should be able to access, not the entire Azure Service Bus namespace.</p>"},{"location":"aca/05-aca-dapr-pubsubapi/#54-restart-container-apps","title":"5.4 Restart Container Apps","text":"<p>Lastly, we need to restart both container apps revisions to pick up the role assignment.</p> <pre><code># Get revision name and assign it to a variable\n$REVISION_NAME = (az containerapp revision list `\n        --name $BACKEND_SERVICE_NAME  `\n        --resource-group $RESOURCE_GROUP `\n        --query [0].name)\n\n# Restart revision by name\naz containerapp revision restart `\n--resource-group $RESOURCE_GROUP `\n--name $BACKEND_SERVICE_NAME  `\n--revision $REVISION_NAME\n\n$REVISION_NAME = (az containerapp revision list `\n        --name $BACKEND_API_NAME  `\n        --resource-group $RESOURCE_GROUP `\n        --query [0].name)\n\n# Restart revision by name\naz containerapp revision restart `\n--resource-group $RESOURCE_GROUP `\n--name $BACKEND_API_NAME  `\n--revision $REVISION_NAME\n</code></pre> <p>Success</p> <p>With this in place, you should be able to test the 3 services end to end.</p> <p>Start by running the command below and then launch the application and start creating new tasks. You should start seeing logs similar to the ones shown in the image below. The command will stop executing after 60 seconds of inactivity.</p> <pre><code>az containerapp logs show --follow `\n-n $BACKEND_SERVICE_NAME `\n-g $RESOURCE_GROUP\n</code></pre> <p></p> What to do if you do not see messages? <p>Sometimes, the revision creation right after creating the managed identity results in the identity not yet being picked up properly. This becomes evident when we look at the Backend Service's Container App's <code>Log stream</code> blade in the Azure portal. Specifically, the <code>daprd</code> sidecar container will show HTTP 401 errors.</p> <p>Should this be the case, you can navigate to the <code>Revisions</code> blade, click on the active revision, then press <code>Restart</code>. Going back to the <code>daprd</code> sidecar in the <code>Log Stream</code> should now reveal processing of messages.</p> <ul> <li> <p>Execute the <code>Set-Variables.ps1</code> in the root to update the <code>variables.ps1</code> file with all current variables. The output of the script will inform you how many variables are written out.</p> <pre><code>.\\Set-Variables.ps1\n</code></pre> </li> <li> <p>From the root, persist a list of all current variables.</p> <pre><code>git add .\\Variables.ps1\ngit commit -m \"Update Variables.ps1\"\n</code></pre> </li> <li> <p>Navigate to the root and persist the module to Git.</p> <pre><code>git add .\ngit commit -m \"Add Module 5.2\"\n</code></pre> </li> </ul>"},{"location":"aca/05-aca-dapr-pubsubapi/#review","title":"Review","text":"<p>In this module, we have accomplished five objectives:</p> <ol> <li>Learned how Azure Container Apps uses the Publisher-Subscriber (Pub/Sub) pattern with Dapr.</li> <li>Introduced a new background service, <code>ACA Processor - Backend</code> configured for Dapr.</li> <li>Used Azure Service Bus as a Service Broker for Dapr Pub/Sub API.</li> <li>Deployed the Backend Background Processor and the updated Backend API Projects to Azure Container Apps.</li> <li>Configured Managed Identities for the Backend Background Processor and the Backend API Azure Container Apps.</li> </ol> <p>The next module will delve into the implementation of Dapr bindings with ACA.</p>"},{"location":"aca/06-aca-dapr-bindingsapi/","title":"Module 6 - ACA with Dapr Bindings Building Block","text":"<p>Module Duration</p> <p>90 minutes</p>"},{"location":"aca/06-aca-dapr-bindingsapi/#objective","title":"Objective","text":"<p>In this module, we will accomplish four objectives:</p> <ol> <li>Learn how to interface with external systems.</li> <li>Extend the backend background processor service (<code>ACA-Processor Backend</code>) to interface with an external system.</li> <li>Use Azure Key Vault via a Dapr Secret Store Component to externalize secrets.</li> <li>Deploy updated revisions for Backend Background Processor App.</li> </ol>"},{"location":"aca/06-aca-dapr-bindingsapi/#module-sections","title":"Module Sections","text":"<ul> <li> <p>From the VS Code Terminal tab, open developer command prompt or PowerShell terminal in the project folder <code>TasksTracker.ContainerApps</code> (root):</p> <pre><code>cd ~\\TasksTracker.ContainerApps\n</code></pre> </li> <li> <p>Restore the previously-stored variables by executing the local script. The output informs you how many variables have been set.</p> <pre><code>.\\Variables.ps1\n</code></pre> </li> </ul>"},{"location":"aca/06-aca-dapr-bindingsapi/#1-interfacing-with-an-external-system","title":"1. Interfacing with an External System","text":"<p>To achieve interfacing with an external system in a simple way, we will utilize Dapr Input and Output Bindings.</p> <p>The external system owns an Azure Storage Queue which the Tasks Tracker microservice application reacts to through an event handler (aka Input Binding). This event handler receives and processes the message coming to the storage queue. Once the processing of the message completes and stores the task into Cosmos DB, the system will trigger an event (aka Output binding) that invokes the external service. This service, in turn, stores the content of the message into an Azure Blob Storage container. It is important to emphasize that both the Azure Storage Queue and the Azure Storage Blob belong to the external system.</p> <p>The rest of this module will implement the three scenarios mentioned below:</p> <ul> <li>Trigger a process on the <code>ACA-Processor Backend</code> based on a message sent to a specific Azure Storage Queue. This scenario will assume that the Azure Storage Queue is an external system to which external clients can submit tasks.</li> <li>From the service <code>ACA-Processor Backend</code> we will invoke an external resource that stores the content of the incoming task from the external queue as a JSON blob file on Azure Storage Blobs.</li> <li>Remove the SendGrid SDK as well as the custom code created in the previous module to send emails and replace it with Dapr SendGrid output binding.</li> </ul> <p>Take a look at the high-level architecture diagram below to understand the flow of input and output bindings in Dapr:</p> <p></p> <p>Note</p> <p>Those 3rd party external services could be services hosted on another cloud provider, different Azure subscription, or even on premise. Dapr bindings are usually used to trigger an application with events coming in from external systems as well as interface with external systems.</p> <p>For simplicity of the workshop we are going to host those two supposedly external services in the same subscription of our Tasks Tracker microservice application.</p> <p>If you look at Dapr Bindings Building Block, you will notice a lot of similarities with the Pub/Sub Building Block that we covered in the previous module. But remember that Pub/Sub Building Block is meant to be used for async communication between services within your solution. The Binding Building Block has a wider scope and it mainly focuses on connectivity and interoperability across different systems, disparate applications, and services outside the boundaries of your own application. For a full list of supported bindings visit this link.</p>"},{"location":"aca/06-aca-dapr-bindingsapi/#11-overview-of-dapr-bindings-building-block","title":"1.1 Overview of Dapr Bindings Building Block","text":"<p>Let's take a look at the detailed Dapr Bindings Building Block architecture diagram that we are going to implement in this module to fulfill the use case we discussed earlier: </p> <p>Looking at the diagram we notice the following:</p> <ul> <li>In order to receive events and data from the external resource (Azure Storage Queue) our <code>ACA-Processor Backend</code> service needs to register a public endpoint that will become an event handler.</li> <li>This binding configuration between the external resource and our service will be configured by using the <code>Input Binding Configuration Yaml</code> file. The Dapr sidecar of the background service will read the configuration and subscribe to the endpoint defined for the external resource. In our case, it will be a specific Azure Storage Queue.</li> <li>When a message is published to the storage queue, the input binding component running in the Dapr sidecar picks it up and triggers the event.</li> <li>The Dapr sidecar invokes the endpoint (event handler defined in the <code>ACA-Processor Backend</code> Service) configured for the binding. In our case, it will be an endpoint that can be reached by invoking a <code>POST</code> operation <code>http://localhost:3502/ExternalTasksProcessor/Process</code> and the request body content will be the JSON payload of the published message to the Azure Storage Queue.</li> <li>When the event is handled in our <code>ACA-Processor Backend</code> and the business logic is completed, this endpoint needs to return an HTTP response with a <code>200 OK</code> status to acknowledge that processing is complete. If the event handling is not completed or there is an error, this endpoint should return an HTTP 4xx or 5xx status code.</li> <li>In order to enable the service <code>ACA-Processor Backend</code> to trigger an event that invokes an external resource, we need to use the <code>Output Binding Configuration Yaml</code> file to configure the binding between our service and the external resource (Azure Blob Storage) and how to connect to it.</li> <li>Once the Dapr sidecar reads the binding configuration file, our service can trigger an event that invokes the output binding API on the Dapr sidecar. In our case, the event will be creating a new blob file containing the content of the message we read earlier from the Azure Storage Queue.</li> <li> <p>With this in place, our service <code>ACA-Processor Backend</code> will be ready to invoke the external resource by sending a POST operation to the endpoint <code>http://localhost:3502/v1.0/bindings/ExternalTasksBlobstore</code> and the JSON payload will contain the content below. Alternatively, we can use the Dapr client SDK to invoke this output biding to invoke the external service and store the file in Azure Blob Storage.</p> <pre><code>{\n    \"data\": \"{\n        \"taskName\": \"Task Coming from External System\",\n        \"taskAssignedTo\": \"user1@hotmail.com\",\n        \"taskCreatedBy\": \"tjoudeh@bitoftech.net\",\n        \"taskDueDate\": \"2022-08-19T12:45:22.0983978Z\"\n    }\",\n    \"operation\": \"create\"\n}\n</code></pre> </li> </ul> <p>Let's start by updating our Backend Background Processor project and define the input and output bindings configuration files and event handlers.</p> <p>To proceed with this workshop, we need to provision the Azure Storage Account to start responding to messages published to a queue and then later use the same storage account to store blob files as an external event. Run the PowerShell script below to create Azure Storage Account and get the master key.</p> <p>Tip</p> <p>We will be retrieving the storage account key for local dev testing purposes. Note that the command below will return two keys. You will only need one of them for this exercise. When deploying the changes to ACA, we are going to store the storage key securely into Azure Key Vault using Dapr Secrets Store Building Block with AKV.</p> <p>We didn't use Azure Manged Identity here because the assumption is that those services are not part of our solution and thus they could theoretically be a non AD compliant services or hosted on another cloud.  If these services where part of your application's ecosystem it is always recommended that you use Azure Managed Identity.</p> <pre><code>$STORAGE_ACCOUNT_NAME = \"sttaskstracker$RANDOM_STRING\"\n\naz storage account create `\n--name $STORAGE_ACCOUNT_NAME `\n--resource-group $RESOURCE_GROUP `\n--location $LOCATION `\n--sku Standard_LRS `\n--kind StorageV2\n\n# List Azure storage keys\naz storage account keys list `\n--resource-group $RESOURCE_GROUP `\n--account-name $STORAGE_ACCOUNT_NAME\n\n# Get the primary storage account key\n$STORAGE_ACCOUNT_KEY=($(az storage account keys list `\n--resource-group $RESOURCE_GROUP `\n--account-name $STORAGE_ACCOUNT_NAME ) | ConvertFrom-Json)[0].value\n\necho \"Storage Account Name : $STORAGE_ACCOUNT_NAME\"\necho \"Storage Account Key  : $STORAGE_ACCOUNT_KEY\"\n</code></pre>"},{"location":"aca/06-aca-dapr-bindingsapi/#2-updating-the-backend-background-processor-project","title":"2. Updating the Backend Background Processor Project","text":""},{"location":"aca/06-aca-dapr-bindingsapi/#21-create-an-event-handler-api-endpoint-to-respond-to-messages-published-to-azure-storage-queue","title":"2.1 Create an event handler (API endpoint) to respond to messages published to Azure Storage Queue","text":"<p>Let's add an endpoint that will be responsible to handle the event when a message is published to Azure Storage Queue. This endpoint will start receiving the message published from the external service.</p> <p>Start by adding a new controller Controllers folder under the TasksTracker.Processor.Backend.Svc project:</p> ExternalTasksProcessorController.cs <pre><code>using Dapr.Client;\nusing Microsoft.AspNetCore.Mvc;\nusing TasksTracker.Processor.Backend.Svc.Models;\n\nnamespace TasksTracker.Processor.Backend.Svc.Controllers\n{\n    [Route(\"ExternalTasksProcessor\")]\n    [ApiController]\n    public class ExternalTasksProcessorController : ControllerBase\n    {\n        private readonly ILogger&lt;ExternalTasksProcessorController&gt; _logger;\n        private readonly DaprClient _daprClient;\n\n        public ExternalTasksProcessorController(ILogger&lt;ExternalTasksProcessorController&gt; logger, DaprClient daprClient)\n        {\n            _logger = logger;\n            _daprClient = daprClient;\n        }\n\n        [HttpPost(\"process\")]\n        public async Task&lt;IActionResult&gt; ProcessTaskAndStore([FromBody] TaskModel taskModel)\n        {\n            try\n            {\n                _logger.LogInformation(\"Started processing external task message from storage queue. Task Name: '{0}'\", taskModel.TaskName);\n\n                taskModel.TaskId = Guid.NewGuid();\n                taskModel.TaskCreatedOn = DateTime.UtcNow;\n\n                //Dapr SideCar Invocation (save task to a state store)\n                await _daprClient.InvokeMethodAsync(HttpMethod.Post, \"tasksmanager-backend-api\", $\"api/tasks\", taskModel);\n\n                _logger.LogInformation(\"Saved external task to the state store successfully. Task name: '{0}', Task Id: '{1}'\", taskModel.TaskName, taskModel.TaskId);\n\n                //ToDo: code to invoke external binding and store queue message content into blob file in Azure storage\n\n                return Ok();\n            }\n            catch (Exception)\n            {\n                throw;\n            }\n        }\n    }\n}\n</code></pre> Curious to know more about the code? <ul> <li> <p>We defined an action method named <code>ProcessTaskAndStore</code> which can be accessed by sending HTTP POST operation on the  endpoint <code>ExternalTasksProcessor/Process</code>. </p> </li> <li> <p>This action method accepts the TaskModel in the request body as JSON payload.This is what will be received from the external service (Azure Storage Queue). </p> </li> <li> <p>Within this action method, we are going to store the received task by sending a POST request to <code>/api/tasks</code> which is part of the backend api named <code>tasksmanager-backend-api</code>.</p> </li> <li> <p>Then we return <code>200 OK</code> to acknowledge that message received is processed successfully and should be removed from the external service queue.</p> </li> </ul>"},{"location":"aca/06-aca-dapr-bindingsapi/#22-create-dapr-input-binding-component-file","title":"2.2 Create Dapr Input Binding Component File","text":"<p>Now we need to create the component configuration file which will describe the configuration as well as how our backend background processor will start handling events coming from the external service (Azure Storage Queues). To do so, add a new file under components folder.</p> dapr-bindings-in-storagequeue.yaml <pre><code>apiVersion: dapr.io/v1alpha1\nkind: Component\nmetadata:\n  name: externaltasksmanager\nspec:\n  type: bindings.azure.storagequeues\n  version: v1\n  metadata:\n    - name: storageAccount\n      value: \"&lt;Your Storage Account Name&gt;\"\n    - name: storageAccessKey\n      value: \"&lt;Your Storage Account Key&gt;\"\n    - name: queue\n      value: \"external-tasks-queue\"\n    - name: decodeBase64\n      value: \"true\"\n    - name: route\n      value: /externaltasksprocessor/process\n</code></pre> Curious to learn more about the specification of yaml file? <p>The full specifications of yaml file with Azure Storage Queues can be found on this link, but let's go over the configuration we have added here:</p> <ul> <li>The type of binding is <code>bindings.azure.storagequeues</code>.</li> <li>The name of this input binding is <code>externaltasksmanager</code>.</li> <li>We are setting the <code>storageAccount</code> name, <code>storageAccessKey</code> value, and the <code>queue</code> name. Those properties will describe how the event handler we added can connect to the external service. You can create any queue you prefer on the Azure Storage Account we created to simulate an external system.</li> <li>We are setting the <code>route</code> property to the value <code>/externaltasksprocessor/process</code> which is the address of the endpoint we have just added so POST requests are sent to this endpoint.</li> <li>We are setting the property <code>decodeBase64</code> to <code>true</code> as the message queued in the Azure Storage Queue is Base64 encoded.</li> </ul> <p>Note</p> <p>The value of the Metadata <code>storageAccessKey</code> is used as plain text here for local dev scenario. We will see how we are going to store this key securely in Azure Key Vault and use Dapr Secrets Store API to read the access key.</p>"},{"location":"aca/06-aca-dapr-bindingsapi/#23-create-dapr-output-binding-component-file","title":"2.3 Create Dapr Output Binding Component File","text":"<p>Now we need to create the component configuration file which will describe the configuration and how our service <code>ACA-Processor Backend</code> will be able to invoke the external service (Azure Blob Storage) and be able to create and store a JSON blob file that contains the content of the message received from Azure Storage Queues.</p> <p>To do so, add a new file folder components.</p> dapr-bindings-out-blobstorage.yaml <pre><code>apiVersion: dapr.io/v1alpha1\nkind: Component\nmetadata:\n  name: externaltasksblobstore\nspec:\n  type: bindings.azure.blobstorage\n  version: v1\n  metadata:\n    - name: storageAccount\n      value: \"&lt;Your Storage Account Name&gt;\"\n    - name: storageAccessKey\n      value: \"&lt;Your Storage Account Key&gt;\"\n    - name: container\n      value: \"externaltaskscontainer\"\n    - name: decodeBase64\n      value: false\n</code></pre> Curious to learn more about the specification of yaml file? <p>The full specifications of yaml file with Azure blob storage can be found on this link,  but let's go over the configuration we have added here:</p> <ul> <li>The type of binding is <code>bindings.azure.blobstorage</code>.</li> <li>The name of this output binding is <code>externaltasksblobstore</code>. We will use this name when we use the Dapr SDK to trigger the output binding.</li> <li>We are setting the <code>storageAccount</code> name, <code>storageAccessKey</code> value, and the <code>container</code> name. Those properties will describe how our backend background service will be able to connect to the external service and create a blob file. We will assume that there is a container already created on the external service and named <code>externaltaskscontainer</code> as shown in the image below</li> </ul> <p></p> <ul> <li>We are setting the property <code>decodeBase64</code>  to <code>false</code> as we don't want to encode file content to base64 images, we need to store the file content as is.</li> </ul>"},{"location":"aca/06-aca-dapr-bindingsapi/#24-use-dapr-client-sdk-to-invoke-the-output-binding","title":"2.4 Use Dapr client SDK to Invoke the Output Binding","text":"<p>Now we need to invoke the output binding by using the .NET SDK.</p> <p>Update and replace the code in the file with the code below. Pay close attention to the updated ProcessTaskAndStore action method:</p> ExternalTasksProcessorController.cs <pre><code>using Dapr.Client;\nusing Microsoft.AspNetCore.Mvc;\nusing TasksTracker.Processor.Backend.Svc.Models;\n\nnamespace TasksTracker.Processor.Backend.Svc.Controllers\n{\n    [Route(\"ExternalTasksProcessor\")]\n    [ApiController]\n    public class ExternalTasksProcessorController : ControllerBase\n    {\n        private readonly ILogger&lt;ExternalTasksProcessorController&gt; _logger;\n        private readonly DaprClient _daprClient;\n        private const string OUTPUT_BINDING_NAME = \"externaltasksblobstore\";\n        private const string OUTPUT_BINDING_OPERATION = \"create\";\n\n        public ExternalTasksProcessorController(ILogger&lt;ExternalTasksProcessorController&gt; logger, DaprClient daprClient)\n        {\n            _logger = logger;\n            _daprClient = daprClient;\n        }\n\n        [HttpPost(\"process\")]\n        public async Task&lt;IActionResult&gt; ProcessTaskAndStore([FromBody] TaskModel taskModel)\n        {\n            try\n            {\n                _logger.LogInformation(\"Started processing external task message from storage queue. Task Name: '{0}'\", taskModel.TaskName);\n\n                taskModel.TaskId = Guid.NewGuid();\n                taskModel.TaskCreatedOn = DateTime.UtcNow;\n\n                //Dapr SideCar Invocation (save task to a state store)\n                await _daprClient.InvokeMethodAsync(HttpMethod.Post, \"tasksmanager-backend-api\", $\"api/tasks\", taskModel);\n\n                _logger.LogInformation(\"Saved external task to the state store successfully. Task name: '{0}', Task Id: '{1}'\", taskModel.TaskName, taskModel.TaskId);\n\n                //code to invoke external binding and store queue message content into blob file in Azure storage\n                IReadOnlyDictionary&lt;string,string&gt; metaData = new Dictionary&lt;string, string&gt;()\n                    {\n                        { \"blobName\", $\"{taskModel.TaskId}.json\" },\n                    };\n\n                await _daprClient.InvokeBindingAsync(OUTPUT_BINDING_NAME, OUTPUT_BINDING_OPERATION, taskModel, metaData);\n\n                _logger.LogInformation(\"Invoked output binding '{0}' for external task. Task name: '{1}', Task Id: '{2}'\", OUTPUT_BINDING_NAME, taskModel.TaskName, taskModel.TaskId);\n\n                return Ok();\n            }\n            catch (Exception)\n            {\n                throw;\n            }\n        }\n    }\n}\n</code></pre> Curious to know more about the code? <p>Looking at the <code>ProcessTaskAndStore</code> action method above, you will see that we are calling the method <code>InvokeBindingAsync</code> and we are passing the binding name <code>externaltasksblobstore</code>  defined in the configuration file, as well the second parameter <code>create</code> which is the action we need to carry against the external blob storage. </p> <p>You can for example delete or get a content of a certain file. For a full list of supported actions on Azure Blob Storage, visit this link.</p> <p>Notice how are setting the file name we are storing at the external service. We need the file names to be created using the same Task Identifier, so we will pass the key <code>blobName</code> with the file name values  into the <code>metaData</code> dictionary.</p>"},{"location":"aca/06-aca-dapr-bindingsapi/#25-test-dapr-bindings-locally","title":"2.5 Test Dapr Bindings Locally","text":"<ul> <li> <p>Execute the <code>Set-Variables.ps1</code> in the root to update the <code>variables.ps1</code> file with all current variables. The output of the script will inform you how many variables are written out.</p> <pre><code>.\\Set-Variables.ps1\n</code></pre> </li> </ul> <p>Now we are ready to give it an end-to-end test on our dev machines. To do so, run the below commands in three separate PowerShell console, ensure you are on the right root folder of each respective project.</p> <ul> <li> <p>Restore the previously-stored variables by executing the local script. The output informs you how many variables have been set.</p> <pre><code>.\\Variables.ps1\n</code></pre> </li> </ul> .NET 6 or below.NET 7 or above <p><pre><code>cd ~\\TasksTracker.ContainerApps\\TasksTracker.WebPortal.Frontend.Ui \n\ndapr run `\n--app-id tasksmanager-frontend-webapp `\n--app-port $UI_APP_PORT `\n--dapr-http-port 3501 `\n--app-ssl `\n-- dotnet run \n</code></pre> <pre><code>cd ~\\TasksTracker.ContainerApps\\TasksTracker.TasksManager.Backend.Api\n\ndapr run `\n--app-id tasksmanager-backend-api `\n--app-port $API_APP_PORT `\n--dapr-http-port 3500 `\n--app-ssl `\n--resources-path \"../components\" `\n-- dotnet run\n</code></pre> <pre><code>cd ~\\TasksTracker.ContainerApps\\TasksTracker.Processor.Backend.Svc\n\ndapr run `\n--app-id tasksmanager-backend-processor `\n--app-port $BACKEND_SERVICE_APP_PORT `\n--dapr-http-port 3502 `\n--app-ssl `\n--resources-path \"../components\" `\n-- dotnet run\n</code></pre></p> <p><pre><code>cd ~\\TasksTracker.ContainerApps\\TasksTracker.WebPortal.Frontend.Ui\n\ndapr run `\n--app-id tasksmanager-frontend-webapp `\n--app-port $UI_APP_PORT `\n--dapr-http-port 3501 `\n--app-ssl `\n-- dotnet run --launch-profile https\n</code></pre> <pre><code>cd ~\\TasksTracker.ContainerApps\\TasksTracker.TasksManager.Backend.Api\n\ndapr run `\n--app-id tasksmanager-backend-api `\n--app-port $API_APP_PORT `\n--dapr-http-port 3500 `\n--app-ssl `\n--resources-path \"../components\" `\n-- dotnet run --launch-profile https\n</code></pre> <pre><code>cd ~\\TasksTracker.ContainerApps\\TasksTracker.Processor.Backend.Svc\n\ndapr run `\n--app-id tasksmanager-backend-processor `\n--app-port $BACKEND_SERVICE_APP_PORT `\n--dapr-http-port 3502 `\n--app-ssl `\n--resources-path \"../components\" `\n-- dotnet run --launch-profile https\n</code></pre></p> <p>Open Azure Storage Explorer on your local machine. If you don't have it installed you can install it from here. Login to your Azure Subscription and navigate to the storage account already created, create a queue, and use the same name you already used in the Dapr Input configuration file. In our case the name of the queue in the configuration file is <code>external-tasks-queue</code>.</p> <p></p> <p>The content of the message that Azure Storage Queue excepts should be as below, so try to queue a new message using the tool as the image below:</p> <pre><code>{\n    \"taskName\": \"Task from External System\",\n    \"taskAssignedTo\": \"user1@hotmail.com\",\n    \"taskCreatedBy\": \"tjoudeh@bitoftech.net\",\n    \"taskDueDate\": \"2022-08-19T12:45:22.0983978Z\"\n}\n</code></pre> <p></p> <p>If all is configured successfully you should be able to see a JSON file created as a blob in the Azure Storage Container named <code>externaltaskscontainer</code> based on your configuration.</p> <p></p>"},{"location":"aca/06-aca-dapr-bindingsapi/#3-configure-dapr-secret-store-component-with-azure-key-vault","title":"3. Configure Dapr Secret Store Component with Azure Key Vault","text":"<p>Currently, we have three Dapr components which are not Microsoft Entra ID enabled services. As you may have noticed so far, the different component files are storing sensitive keys to access the different external services. The recommended approach for retrieving these secrets is to reference an existing Dapr secret store component that securely accesses the secrets.</p> <p>We need Create a Dapr secret store component using the Container Apps schema. The Dapr secret store will be configured with Azure Key Vault secret store.</p>"},{"location":"aca/06-aca-dapr-bindingsapi/#31-create-an-azure-key-vault-resource","title":"3.1 Create an Azure Key Vault resource","text":"<p>Create an Azure Key Vault which will be used to store securely any secret or key used in our application.</p> <pre><code>$KEYVAULT_NAME = \"kv-tasks-tracker-$RANDOM_STRING\"\n\naz keyvault create `\n--name $KEYVAULT_NAME `\n--resource-group $RESOURCE_GROUP `\n--location $LOCATION `\n--enable-rbac-authorization true\n</code></pre> <p>Note</p> <p>It is important to create the Azure Key Vault with Azure RBAC for authorization by setting <code>--enable-rbac-authorization true</code> because the role we are going to assign to the Microsoft Entra ID application will work only when RBAC authorization is enabled.</p>"},{"location":"aca/06-aca-dapr-bindingsapi/#32-grant-backend-processor-app-a-role-to-read-secrets-from-azure-key-vault","title":"3.2 Grant Backend Processor App a Role To Read Secrets from Azure Key Vault","text":"<p>In the previous module we have configured the <code>system-assigned</code> identity for the service <code>ACA-Processor Backend</code>. Now we need to assign a role named <code>Key Vault Secrets User</code> to it, so it access and read secrets from Azure Key Vault.</p> <p>You can read more about Azure built-in roles for Key Vault data plane operations.</p> <pre><code>$KEYVAULT_SECRETS_USER_ROLE_ID = \"4633458b-17de-408a-b874-0445c86b69e6\" # ID for 'Key Vault Secrets User' Role\n\n# Get PRINCIPAL ID of BACKEND Processor Service\n$BACKEND_SERVICE_PRINCIPAL_ID = az containerapp show `\n--name $BACKEND_SERVICE_NAME `\n--resource-group $RESOURCE_GROUP `\n--query identity.principalId\n\naz role assignment create `\n--role $KEYVAULT_SECRETS_USER_ROLE_ID `\n--assignee $BACKEND_SERVICE_PRINCIPAL_ID `\n--scope \"/subscriptions/$AZURE_SUBSCRIPTION_ID/resourcegroups/$RESOURCE_GROUP/providers/Microsoft.KeyVault/vaults/$KEYVAULT_NAME\"\n</code></pre>"},{"location":"aca/06-aca-dapr-bindingsapi/#33-create-secrets-in-the-azure-key-vault","title":"3.3 Create Secrets in the Azure Key Vault","text":"<p>To create a secret in Azure Key Vault you need to have a role which allows you to create secrets. From the Azure CLI we will assign the role <code>Key Vault Secrets Officer</code> to the user signed in to AZ CLI to be able to create secrets. To do so use the script below:</p> <pre><code>$SIGNEDIN_USERID = az ad signed-in-user show --query id\n$KEYVAULT_SECRETS_OFFICER_ROLE_ID = \"b86a8fe4-44ce-4948-aee5-eccb2c155cd7\" # ID for 'Key Vault Secrets Office' Role \n\naz role assignment create `\n--role $KEYVAULT_SECRETS_OFFICER_ROLE_ID `\n--assignee $SIGNEDIN_USERID `\n--scope \"/subscriptions/$AZURE_SUBSCRIPTION_ID/resourcegroups/$RESOURCE_GROUP/providers/Microsoft.KeyVault/vaults/$KEYVAULT_NAME\"\n</code></pre> <p>Now we will create the secrets in the Azure Key Vault using the commands below:</p> <pre><code># Set External Azure Storage Access Key as a secret named 'external-azure-storage-key'\naz keyvault secret set `\n--vault-name $KEYVAULT_NAME `\n--name \"external-azure-storage-key\" `\n--value $STORAGE_ACCOUNT_KEY\n</code></pre>"},{"location":"aca/06-aca-dapr-bindingsapi/#34-create-a-aca-dapr-secrets-store-component-file","title":"3.4 Create a ACA Dapr Secrets Store Component file","text":"<p>Obtain the name of the Key Vault.</p> <pre><code>$KEYVAULT_NAME\n</code></pre> <p>Create a new yaml file under the aca-components folder.</p> containerapps-secretstore-kv.yaml <pre><code>componentType: secretstores.azure.keyvault\nversion: v1\nmetadata:\n  - name: vaultName\n    value: &lt;Your keyvault name from $KEYVAULT_NAME goes here&gt;\nscopes:\n  - tasksmanager-backend-processor\n</code></pre> Curious to learn more about the yaml file? <ul> <li>We didn't specify the component name <code>secretstoreakv</code> in the metadata of the this component yaml file. We are going to specify it once we add this dapr component to Azure Container Apps Environment  via CLI similar to what we did in earlier modules.</li> <li>We are not referencing any service bus connection strings as the authentication between Dapr and Azure Service Bus will be configured using Managed Identities. </li> <li>The metadata <code>vaultName</code> value is set to the name of the Azure Key Vault we've just created. </li> <li>We are allowing this component only to be accessed by the dapr with application id <code>tasksmanager-backend-processor</code>. This means that our Backend API or Frontend Web App services will not be able to access the Dapr secret store. If we want to allow them to access the secrets we need to update this component file and grant the system-identity of those services a <code>Key Vault Secrets User</code> role.</li> </ul>"},{"location":"aca/06-aca-dapr-bindingsapi/#35-create-input-and-output-binding-component-files-matching-azure-container-apps-specs","title":"3.5 Create Input and Output Binding Component Files Matching Azure Container Apps Specs","text":"<p>Add new files under the aca-components use the yaml below:</p> containerapps-bindings-in-storagequeue.yamlcontainerapps-bindings-out-blobstorage.yaml <pre><code>componentType: bindings.azure.storagequeues\nversion: v1\nsecretStoreComponent: \"secretstoreakv\"\nmetadata:\n  - name: storageAccount\n    value: \"&lt;Your Storage Account Name&gt;\"\n  - name: storageAccessKey\n    secretRef: external-azure-storage-key\n  - name: queue\n    value: \"external-tasks-queue\"\n  - name: decodeBase64\n    value: \"true\"\n  - name: route\n    value: /externaltasksprocessor/process\nscopes:\n  - tasksmanager-backend-processor\n</code></pre> Curious to learn more about the yaml file? <p>The properties of this file are matching the ones used in Dapr component-specific file. It is a component of type <code>bindings.azure.storagequeues</code>.  The only differences are the following: </p> <ul> <li>We are setting the property <code>secretStoreComponent</code> value to <code>secretstoreakv</code> which is the name of Dapr secret store component.</li> <li>We are using <code>secretRef</code> when setting the metadata <code>storageAccessKey</code>. The value <code>external-azure-storage-key</code> represents the AKV secret created earlier.</li> </ul> <pre><code>componentType: bindings.azure.blobstorage\nversion: v1\nsecretStoreComponent: \"secretstoreakv\"\nmetadata:\n  - name: storageAccount\n    value: \"&lt;Your Storage Account Name&gt;\"\n  - name: storageAccessKey\n    secretRef: external-azure-storage-key\n  - name: container\n    value: \"externaltaskscontainer\"\n  - name: decodeBase64\n    value: \"false\"\n  - name: publicAccessLevel\n    value: \"none\"\nscopes:\n  - tasksmanager-backend-processor\n</code></pre> Curious to learn more about the yaml file? <p>The properties of this file are matching the ones used in Dapr component-specific file. It is a component of type <code>bindings.azure.blobstorage</code>.  The only differences are the following:</p> <ul> <li>We are setting the property <code>secretStoreComponent</code> value to <code>secretstoreakv</code> which is the name of Dapr secret store component.</li> <li>We are using <code>secretRef</code> when setting the metadata <code>storageAccessKey</code>. The value <code>external-azure-storage-key</code> represents the AKV secret created earlier</li> </ul> <p>With those changes in place, we are ready to rebuild the backend background processor container image, update Azure Container Apps Env, and redeploy a new revision.</p>"},{"location":"aca/06-aca-dapr-bindingsapi/#4-deploy-a-new-revision-of-the-backend-background-processor-app-to-aca","title":"4. Deploy a New Revision of the Backend Background Processor App to ACA","text":""},{"location":"aca/06-aca-dapr-bindingsapi/#41-build-the-backend-background-processor-image-and-push-it-to-acr","title":"4.1 Build the Backend Background Processor Image and Push it To ACR","text":"<p>As we have done previously we need to build and deploy the Backend Background Processor image to ACR, so it is ready to be deployed to ACA. Continue using the same PowerShell console and paste the code below (make sure you are under the  TasksTracker.ContainerApps directory):</p> <pre><code>az acr build `\n--registry $AZURE_CONTAINER_REGISTRY_NAME `\n--image \"tasksmanager/$BACKEND_SERVICE_NAME\" `\n--file 'TasksTracker.Processor.Backend.Svc/Dockerfile' .\n</code></pre>"},{"location":"aca/06-aca-dapr-bindingsapi/#42-add-dapr-secret-store-component-to-aca-environment","title":"4.2 Add Dapr Secret Store Component to ACA Environment","text":"<p>We need to run the command below from the root to create the Dapr secret store component:</p> <pre><code>az containerapp env dapr-component set `\n--name $ENVIRONMENT `\n--resource-group $RESOURCE_GROUP `\n--dapr-component-name secretstoreakv `\n--yaml '.\\aca-components\\containerapps-secretstore-kv.yaml'\n</code></pre>"},{"location":"aca/06-aca-dapr-bindingsapi/#43-add-the-bindings-dapr-components-to-aca-environment","title":"4.3 Add the Bindings Dapr Components to ACA Environment","text":"<p>Next, we will add the Dapr bindings components using the component files created.</p> <pre><code># Input binding component for Azure Storage Queue\naz containerapp env dapr-component set `\n--name $ENVIRONMENT `\n--resource-group $RESOURCE_GROUP `\n--dapr-component-name externaltasksmanager `\n--yaml '.\\aca-components\\containerapps-bindings-in-storagequeue.yaml'\n\n# Output binding component for Azure Blob Storage\naz containerapp env dapr-component set `\n--name $ENVIRONMENT `\n--resource-group $RESOURCE_GROUP `\n--dapr-component-name externaltasksblobstore `\n--yaml '.\\aca-components\\containerapps-bindings-out-blobstorage.yaml'\n</code></pre>"},{"location":"aca/06-aca-dapr-bindingsapi/#44-deploy-new-revisions-of-the-backend-background-processor-to-aca","title":"4.4 Deploy new revisions of the Backend Background Processor to ACA","text":"<p>Update the Azure Container App hosting the Backend Background Processor with a new revision so our code changes are available for end users.</p> <pre><code># Update Backend Background Processor container app and create a new revision \naz containerapp update `\n--name $BACKEND_SERVICE_NAME `\n--resource-group $RESOURCE_GROUP `\n--revision-suffix v$TODAY-3 `\n</code></pre> <p>Success</p> <p>With those changes in place and deployed, from the Azure portal you can open the log streams section of the container app hosting the <code>ACA-Processor-Backend</code> and check the logs generated after queuing a message into Azure Storage Queue (using Azure Storage Explorer tool used earlier) as an external system.</p> <pre><code>{\n  \"taskName\": \"Task from External System\",\n  \"taskAssignedTo\": \"user42@hotmail.com\",\n  \"taskCreatedBy\": \"tjoudeh@bitoftech.net\",\n  \"taskDueDate\": \"2022-08-19T12:45:22.0983978Z\"\n}\n</code></pre> <p>You should receive logs similar to the below:</p> <p></p> <ul> <li> <p>Execute the <code>Set-Variables.ps1</code> in the root to update the <code>variables.ps1</code> file with all current variables. The output of the script will inform you how many variables are written out.</p> <pre><code>.\\Set-Variables.ps1\n</code></pre> </li> <li> <p>From the root, persist a list of all current variables.</p> <pre><code>git add .\\Variables.ps1\ngit commit -m \"Update Variables.ps1\"\n</code></pre> </li> <li> <p>Navigate to the root and persist the module to Git.</p> <pre><code>git add .\ngit commit -m \"Add Module 6\"\n</code></pre> </li> </ul>"},{"location":"aca/06-aca-dapr-bindingsapi/#review","title":"Review","text":"<p>In this module, we have accomplished four objectives:</p> <ol> <li>Learned how to interface with external systems.</li> <li>Extended the backend background processor service (<code>ACA-Processor Backend</code>) to interface with an external system.</li> <li>Used Azure Key Vault via a Dapr Secret Store Component to externalize secrets.</li> <li>Deployed updated revisions for Backend Background Processor App.</li> </ol> <p>In the next module, we will cover a special type of Dapr input binding named Cron Binding.</p>"},{"location":"aca/07-aca-cron-bindings/","title":"Module 7 - ACA Scheduled Jobs with Dapr Cron Binding","text":"<p>Module Duration</p> <p>60 minutes</p> Curious about Azure Container Apps jobs? <p>There is a new kid on the block. Azure Container Apps jobs became generally available in late August 2023. This workshop is not yet updated to account for this new type of container app. Stay tuned for updates!</p>"},{"location":"aca/07-aca-cron-bindings/#objective","title":"Objective","text":"<p>In this module, we will accomplish three objectives:</p> <ol> <li>Learn how the Cron binding can trigger actions.</li> <li>Add a Cron binding to the Backend Background Processor.</li> <li>Deploy updated Background Processor and API projects to Azure.</li> </ol>"},{"location":"aca/07-aca-cron-bindings/#module-sections","title":"Module Sections","text":"<ul> <li> <p>From the VS Code Terminal tab, open developer command prompt or PowerShell terminal in the project folder <code>TasksTracker.ContainerApps</code> (root):</p> <pre><code>cd ~\\TasksTracker.ContainerApps\n</code></pre> </li> <li> <p>Restore the previously-stored variables by executing the local script. The output informs you how many variables have been set.</p> <pre><code>.\\Variables.ps1\n</code></pre> </li> </ul>"},{"location":"aca/07-aca-cron-bindings/#1-the-cron-binding","title":"1. The Cron Binding","text":"<p>In the preceding module, we discussed how Dapr bindings can simplify the integration process with external systems by facilitating the handling of events and the invocation of external resources.  </p> <p>In this module we will focus on a special type of Dapr input binding named Cron Binding.</p> <p>The Cron binding doesn't subscribe to events coming from an external system. Instead, this binding can be used to trigger application code in our service periodically based on a configurable interval. The binding provides a simple way to implement a background worker to wake up and do some work at a regular interval, without the need to implement an endless loop with a configurable delay. We intend to utilize this binding for a specific use case, wherein it will be triggered once daily at a particular time (12:05 am), and search for tasks that have a due date matching the previous day of its execution and are still pending. Once the service identifies tasks that meet these criteria, it will designate them as overdue tasks and save the revised status on Azure Cosmos DB.</p> <p>Contrasting the binding to Azure Container Apps jobs, we do not need a separate container app and can integrate this binding into our existing backend service.</p>"},{"location":"aca/07-aca-cron-bindings/#2-updating-the-backend-background-processor-project","title":"2. Updating the Backend Background Processor Project","text":""},{"location":"aca/07-aca-cron-bindings/#21-add-cron-binding-configuration","title":"2.1 Add Cron Binding Configuration","text":"<p>To set up the Cron binding, we add a component file that specifies the code that requires triggering and the intervals at which it should occur.  </p> <p>To accomplish this, create a new file called dapr-scheduled-cron.yaml within the components folder and insert the following code:</p> dapr-scheduled-cron.yaml <pre><code>apiVersion: dapr.io/v1alpha1\nkind: Component\nmetadata:\n  name: ScheduledTasksManager\n  namespace: default\nspec:\n  type: bindings.cron\n  version: v1\n  metadata:\n    - name: schedule\n      value: \"5 0 * * *\" # Everyday at 12:05am\nscopes:\n  - tasksmanager-backend-processor\n</code></pre> Curious to learn more about above yaml file configuration? <p>The actions performed above are as follows:</p> <ul> <li>Added a new input binding of type <code>bindings.cron</code>.</li> <li>Provided the name <code>ScheduledTasksManager</code> for this binding. This means that an HTTP POST endpoint on the URL <code>/ScheduledTasksManager</code> should be added as it will be invoked when the job is triggered based on  the Cron interval.</li> <li>Setting the interval for this Cron job to be triggered once a day at 12:05am. For full details and available options on how to set this value,  visit the Cron binding specs..</li> </ul>"},{"location":"aca/07-aca-cron-bindings/#22-add-the-endpoint-which-will-be-invoked-by-cron-binding","title":"2.2 Add the Endpoint Which Will be Invoked by Cron Binding","text":"<p>Let's add an endpoint which will be triggered when the Cron configuration is met. This endpoint will contain the routine needed to run at a regular interval.</p> <p>Add a new file under the Controllers folder in the project TasksTracker.Processor.Backend.Svc as shown below:</p> ScheduledTasksManagerController.cs <pre><code>using Dapr.Client;\nusing Microsoft.AspNetCore.Mvc;\nusing TasksTracker.Processor.Backend.Svc.Models;\n\nnamespace TasksTracker.Processor.Backend.Svc.Controllers\n{\n    [Route(\"ScheduledTasksManager\")]\n    [ApiController]\n    public class ScheduledTasksManagerController : ControllerBase\n    {\n        private readonly ILogger&lt;ScheduledTasksManagerController&gt; _logger;\n        private readonly DaprClient _daprClient;\n        public ScheduledTasksManagerController(ILogger&lt;ScheduledTasksManagerController&gt; logger, DaprClient daprClient)\n        {\n            _logger = logger;\n            _daprClient = daprClient;\n        }\n\n        [HttpPost]\n        public async Task CheckOverDueTasksJob()\n        {\n            var runAt = DateTime.UtcNow;\n\n            _logger.LogInformation($\"ScheduledTasksManager::Timer Services triggered at: {runAt}\");\n\n            var overdueTasksList = new List&lt;TaskModel&gt;();\n\n            var tasksList = await _daprClient.InvokeMethodAsync&lt;List&lt;TaskModel&gt;&gt;(HttpMethod.Get, \"tasksmanager-backend-api\", $\"api/overduetasks\");\n\n            _logger.LogInformation($\"ScheduledTasksManager::completed query state store for tasks, retrieved tasks count: {tasksList?.Count()}\");\n\n            tasksList?.ForEach(taskModel =&gt;\n            {\n                if (runAt.Date&gt; taskModel.TaskDueDate.Date)\n                {\n                    overdueTasksList.Add(taskModel);\n                }\n            });\n\n            if (overdueTasksList.Count&gt; 0)\n            {\n                _logger.LogInformation($\"ScheduledTasksManager::marking {overdueTasksList.Count()} as overdue tasks\");\n\n                await _daprClient.InvokeMethodAsync(HttpMethod.Post, \"tasksmanager-backend-api\", $\"api/overduetasks/markoverdue\", overdueTasksList);\n            }\n        }\n    }\n}\n</code></pre> <p>Here, we have added a new action method called <code>CheckOverDueTasksJob</code>, which includes the relevant business logic that will be executed by the Cron job configuration at specified intervals. This action method must be of the <code>POST</code> type, allowing it to be invoked when the job is triggered in accordance with the Cron interval.</p>"},{"location":"aca/07-aca-cron-bindings/#23-update-the-backend-web-api-project","title":"2.3 Update the Backend Web API Project","text":"<p>Now we need to add two new methods which are used by the scheduled job.</p> <p>Update these files under the Services folder in the project TasksTracker.TasksManager.Backend.Api as highlighted below:</p> ITasksManager.csTasksStoreManager.cs <pre><code>using TasksTracker.TasksManager.Backend.Api.Models;\n\nnamespace TasksTracker.TasksManager.Backend.Api.Services\n{\n    public interface ITasksManager\n    {\n        Task&lt;List&lt;TaskModel&gt;&gt; GetTasksByCreator(string createdBy);\n        Task&lt;TaskModel?&gt; GetTaskById(Guid taskId);\n        Task&lt;Guid&gt; CreateNewTask(string taskName, string createdBy, string assignedTo, DateTime dueDate);\n        Task&lt;bool&gt; UpdateTask(Guid taskId, string taskName, string assignedTo, DateTime dueDate);\n        Task&lt;bool&gt; MarkTaskCompleted(Guid taskId);\n        Task&lt;bool&gt; DeleteTask(Guid taskId);\n        Task MarkOverdueTasks(List&lt;TaskModel&gt; overdueTasksList);\n        Task&lt;List&lt;TaskModel&gt;&gt; GetYesterdaysDueTasks();\n    }\n}\n</code></pre> <pre><code>using Dapr.Client;\nusing System.Text.Json;\nusing System.Text.Encodings.Web;\nusing System.Text.Json.Serialization;\nusing TasksTracker.TasksManager.Backend.Api.Models;\n\nnamespace TasksTracker.TasksManager.Backend.Api.Services\n{\n    public class TasksStoreManager : ITasksManager\n    {\n        private static string STORE_NAME = \"statestore\";\n        private readonly DaprClient _daprClient;\n        private readonly IConfiguration _config;\n        private readonly ILogger&lt;TasksStoreManager&gt; _logger;\n\n        public TasksStoreManager(DaprClient daprClient, IConfiguration config, ILogger&lt;TasksStoreManager&gt; logger)\n        {\n            _daprClient = daprClient;\n            _config = config;\n            _logger = logger;\n        }\n        public async Task&lt;Guid&gt; CreateNewTask(string taskName, string createdBy, string assignedTo, DateTime dueDate)\n        {\n            var taskModel = new TaskModel()\n            {\n                TaskId = Guid.NewGuid(),\n                TaskName = taskName,\n                TaskCreatedBy = createdBy,\n                TaskCreatedOn = DateTime.UtcNow,\n                TaskDueDate = dueDate,\n                TaskAssignedTo = assignedTo,\n            };\n\n            _logger.LogInformation(\"Save a new task with name: '{0}' to state store\", taskModel.TaskName);\n            await _daprClient.SaveStateAsync&lt;TaskModel&gt;(STORE_NAME, taskModel.TaskId.ToString(), taskModel);\n            return taskModel.TaskId;\n        }\n\n        public async Task&lt;bool&gt; DeleteTask(Guid taskId)\n        {\n            _logger.LogInformation(\"Delete task with Id: '{0}'\", taskId);\n            await _daprClient.DeleteStateAsync(STORE_NAME, taskId.ToString());\n            return true;\n        }\n\n        public async Task&lt;TaskModel?&gt; GetTaskById(Guid taskId)\n        {\n            _logger.LogInformation(\"Getting task with Id: '{0}'\", taskId);\n            var taskModel = await _daprClient.GetStateAsync&lt;TaskModel&gt;(STORE_NAME, taskId.ToString());\n            return taskModel;\n        }\n\n        public async Task&lt;List&lt;TaskModel&gt;&gt; GetTasksByCreator(string createdBy)\n        {\n            var query = \"{\" +\n                    \"\\\"filter\\\": {\" +\n                        \"\\\"EQ\\\": { \\\"taskCreatedBy\\\": \\\"\" + createdBy + \"\\\" }\" +\n                    \"}}\";\n\n            var queryResponse = await _daprClient.QueryStateAsync&lt;TaskModel&gt;(STORE_NAME, query);\n\n            var tasksList = queryResponse.Results.Select(q =&gt; q.Data).OrderByDescending(o=&gt;o.TaskCreatedOn);\n            return tasksList.ToList();\n        }\n\n        public async Task&lt;bool&gt; MarkTaskCompleted(Guid taskId)\n        {\n            _logger.LogInformation(\"Mark task with Id: '{0}' as completed\", taskId);\n            var taskModel = await _daprClient.GetStateAsync&lt;TaskModel&gt;(STORE_NAME, taskId.ToString());\n            if (taskModel != null)\n            {\n                taskModel.IsCompleted = true;\n                await _daprClient.SaveStateAsync&lt;TaskModel&gt;(STORE_NAME, taskModel.TaskId.ToString(), taskModel);\n                return true;\n            }\n            return false;\n        }\n\n        public async Task&lt;bool&gt; UpdateTask(Guid taskId, string taskName, string assignedTo, DateTime dueDate)\n        {\n            _logger.LogInformation(\"Update task with Id: '{0}'\", taskId);\n            var taskModel = await _daprClient.GetStateAsync&lt;TaskModel&gt;(STORE_NAME, taskId.ToString());\n            var currentAssignee = taskModel.TaskAssignedTo;\n            if (taskModel != null)\n            {\n                taskModel.TaskName = taskName;\n                taskModel.TaskAssignedTo = assignedTo;\n                taskModel.TaskDueDate = dueDate;\n                await _daprClient.SaveStateAsync&lt;TaskModel&gt;(STORE_NAME, taskModel.TaskId.ToString(), taskModel);\n                return true;\n            }\n            return false;\n        }\n\n        public async Task&lt;List&lt;TaskModel&gt;&gt; GetYesterdaysDueTasks()\n        {\n            var options = new JsonSerializerOptions\n            {\n                PropertyNamingPolicy = JsonNamingPolicy.CamelCase,\n                WriteIndented = true,\n                Converters =\n                {\n                    new JsonStringEnumConverter(),\n                    new DateTimeConverter(\"yyyy-MM-ddTHH:mm:ss\")\n                },\n                PropertyNameCaseInsensitive = true,\n                DefaultIgnoreCondition = JsonIgnoreCondition.WhenWritingNull,\n                Encoder = JavaScriptEncoder.UnsafeRelaxedJsonEscaping\n            };\n            var yesterday = DateTime.Today.AddDays(-1);\n\n            var jsonDate = JsonSerializer.Serialize(yesterday, options);\n\n            _logger.LogInformation(\"Getting overdue tasks for yesterday date: '{0}'\", jsonDate);\n\n            var query = \"{\" +\n                    \"\\\"filter\\\": {\" +\n                        \"\\\"EQ\\\": { \\\"taskDueDate\\\": \" + jsonDate + \" }\" +\n                    \"}}\";\n\n            var queryResponse = await _daprClient.QueryStateAsync&lt;TaskModel&gt;(STORE_NAME, query);\n            var tasksList = queryResponse.Results.Select(q =&gt; q.Data).Where(q=&gt;q.IsCompleted==false &amp;&amp; q.IsOverDue==false).OrderBy(o=&gt;o.TaskCreatedOn);\n            return tasksList.ToList();\n        }\n\n        public async Task MarkOverdueTasks(List&lt;TaskModel&gt; overDueTasksList)\n        {\n            foreach (var taskModel in overDueTasksList)\n            {\n                _logger.LogInformation(\"Mark task with Id: '{0}' as OverDue task\", taskModel.TaskId);\n                taskModel.IsOverDue = true;\n                await _daprClient.SaveStateAsync&lt;TaskModel&gt;(STORE_NAME, taskModel.TaskId.ToString(), taskModel);\n            }\n        }\n    }\n}\n</code></pre> <p>Add a new file in a new Utilities folder in the project TasksTracker.TasksManager.Backend.Api as shown below:</p> DateTimeConverter.cs <pre><code>using System.Text.Json;\nusing System.Text.Json.Serialization;\n\nnamespace TasksTracker.TasksManager.Backend.Api.Services\n{\n    public class DateTimeConverter : JsonConverter&lt;DateTime&gt;\n    {\n        private readonly string _dateFormatString;\n\n        public DateTimeConverter(string dateFormatString)\n        {\n            _dateFormatString = dateFormatString;\n        }\n\n        public override DateTime Read(ref Utf8JsonReader reader, Type typeToConvert, JsonSerializerOptions options)\n        {\n            var dateString = reader.GetString();\n\n            if (dateString != null) {\n                return DateTime.ParseExact(dateString, _dateFormatString, System.Globalization.CultureInfo.InvariantCulture);\n            } else {\n                throw new(\"Date string from reader is null.\");\n            }\n        }\n\n        public override void Write(Utf8JsonWriter writer, DateTime value, JsonSerializerOptions options)\n        {\n            writer.WriteStringValue(value.ToString(_dateFormatString));\n        }\n    }\n}\n</code></pre> Curious to learn more about above code? <p>What we've implemented here is the following:</p> <ul> <li>Method <code>GetYesterdaysDueTasks</code> will query the Cosmos DB state store using Dapr State API to lookup all the yesterday's task which are not completed yet. Remember that Cron job is configured to run each day  at 12:05am so we are interested to check only the day before when the service runs. We initially made this implementation simple. There might be some edge cases not handled with the current implementation.</li> <li>Method <code>MarkOverdueTasks</code> will take list of all tasks which passed the due date and set the flag <code>IsOverDue</code> to <code>true</code>.</li> </ul> <p>Add the new methods to the fake implementation for class <code>FakeTasksManager.cs</code> so the project TasksTracker.TasksManager.Backend.Api builds successfully.</p> FakeTasksManager.cs <pre><code>using TasksTracker.TasksManager.Backend.Api.Models;\n\nnamespace TasksTracker.TasksManager.Backend.Api.Services\n{\n    public class FakeTasksManager : ITasksManager\n    {\n        List&lt;TaskModel&gt; _tasksList = new List&lt;TaskModel&gt;();\n        Random rnd = new Random();\n\n        private void GenerateRandomTasks()\n        {\n            for (int i = 0; i &lt; 10; i++)\n            {\n                var task = new TaskModel()\n                {\n                    TaskId = Guid.NewGuid(),\n                    TaskName = $\"Task number: {i}\",\n                    TaskCreatedBy = \"tjoudeh@bitoftech.net\",\n                    TaskCreatedOn = DateTime.UtcNow.AddMinutes(i),\n                    TaskDueDate = DateTime.UtcNow.AddDays(i),\n                    TaskAssignedTo = $\"assignee{rnd.Next(50)}@mail.com\",\n                };\n                _tasksList.Add(task);\n            }\n        }\n\n        public FakeTasksManager()\n        {\n            GenerateRandomTasks();\n        }\n\n        public Task&lt;Guid&gt; CreateNewTask(string taskName, string createdBy, string assignedTo, DateTime dueDate)\n        {\n            var task = new TaskModel()\n            {\n                TaskId = Guid.NewGuid(),\n                TaskName = taskName,\n                TaskCreatedBy = createdBy,\n                TaskCreatedOn = DateTime.UtcNow,\n                TaskDueDate = dueDate,\n                TaskAssignedTo = assignedTo,\n            };\n\n            _tasksList.Add(task);\n\n            return Task.FromResult(task.TaskId);\n        }\n\n        public Task&lt;bool&gt; DeleteTask(Guid taskId)\n        {\n            var task = _tasksList.FirstOrDefault(t =&gt; t.TaskId.Equals(taskId));\n\n            if (task != null)\n            {\n                _tasksList.Remove(task);\n                return Task.FromResult(true);\n            }\n\n            return Task.FromResult(false);\n        }\n\n        public Task&lt;TaskModel?&gt; GetTaskById(Guid taskId)\n        {\n            var taskModel = _tasksList.FirstOrDefault(t =&gt; t.TaskId.Equals(taskId));\n            return Task.FromResult(taskModel);\n        }\n\n        public Task&lt;List&lt;TaskModel&gt;&gt; GetTasksByCreator(string createdBy)\n        {\n            var tasksList = _tasksList.Where(t =&gt; t.TaskCreatedBy.Equals(createdBy)).OrderByDescending(o =&gt; o.TaskCreatedOn).ToList();\n            return Task.FromResult(tasksList);\n        }\n\n        public Task&lt;bool&gt; MarkTaskCompleted(Guid taskId)\n        {\n            var task = _tasksList.FirstOrDefault(t =&gt; t.TaskId.Equals(taskId));\n\n            if (task != null)\n            {\n                task.IsCompleted = true;\n                return Task.FromResult(true);\n            }\n\n            return Task.FromResult(false);\n        }\n\n        public Task&lt;bool&gt; UpdateTask(Guid taskId, string taskName, string assignedTo, DateTime dueDate)\n        {\n            var task = _tasksList.FirstOrDefault(t =&gt; t.TaskId.Equals(taskId));\n\n            if (task != null)\n            {\n                task.TaskName = taskName;\n                task.TaskAssignedTo = assignedTo;\n                task.TaskDueDate = dueDate;\n                return Task.FromResult(true);\n            }\n\n            return Task.FromResult(false);\n        }\n\n        public Task MarkOverdueTasks(List&lt;TaskModel&gt; overDueTasksList)\n        {\n            throw new NotImplementedException();\n        }\n\n        public Task&lt;List&lt;TaskModel&gt;&gt; GetYesterdaysDueTasks()\n        {\n            var tasksList = _tasksList.Where(t =&gt; t.TaskDueDate.Equals(DateTime.Today.AddDays(-1))).ToList();\n\n            return Task.FromResult(tasksList);\n        }  \n    }\n}\n</code></pre>"},{"location":"aca/07-aca-cron-bindings/#24-add-action-methods-to-backend-web-api-project","title":"2.4 Add Action Methods to Backend Web API project","text":"<p>As you've seen previously, we are using a Dapr Service-to-Service invocation API to call methods <code>api/overduetasks</code> and <code>api/overduetasks/markoverdue</code> in the Backend Web API from the Backend Background Processor.</p> <p>Add a new file under the Controllers folder in the project TasksTracker.TasksManager.Backend.Api as shown below:</p> OverdueTasksController.cs <pre><code>using Microsoft.AspNetCore.Mvc;\nusing TasksTracker.TasksManager.Backend.Api.Models;\nusing TasksTracker.TasksManager.Backend.Api.Services;\n\nnamespace TasksTracker.TasksManager.Backend.Api.Controllers\n{\n    [Route(\"api/overduetasks\")]\n    [ApiController]\n    public class OverdueTasksController : ControllerBase\n    {\n        private readonly ILogger&lt;TasksController&gt; _logger;\n        private readonly ITasksManager _tasksManager;\n\n        public OverdueTasksController(ILogger&lt;TasksController&gt; logger, ITasksManager tasksManager)\n        {\n            _logger = logger;\n            _tasksManager = tasksManager;\n        }\n\n        [HttpGet]\n        public async Task&lt;IEnumerable&lt;TaskModel&gt;&gt; Get()\n        {\n            return await _tasksManager.GetYesterdaysDueTasks();\n        }\n\n        [HttpPost(\"markoverdue\")]\n        public async Task&lt;IActionResult&gt; Post([FromBody] List&lt;TaskModel&gt; overdueTasksList)\n        {\n            await _tasksManager.MarkOverdueTasks(overdueTasksList);\n\n            return Ok();\n        }\n    }\n}\n</code></pre>"},{"location":"aca/07-aca-cron-bindings/#25-add-cron-binding-configuration-matching-aca-specs","title":"2.5 Add Cron Binding Configuration Matching ACA Specs","text":"<p>Add a new file folder aca-components. This file will be used when updating the Azure Container App Env and enable this binding.</p> containerapps-scheduled-cron.yaml <pre><code>componentType: bindings.cron\nversion: v1\nmetadata:\n  - name: schedule\n    value: \"5 0 * * *\" # Everyday at 12:05am\nscopes:\n  - tasksmanager-backend-processor\n</code></pre> <p>Note</p> <p>The name of the binding is not part of the file metadata. We are going to set the name of the binding to the value <code>ScheduledTasksManager</code> when we update the Azure Container Apps Env.</p>"},{"location":"aca/07-aca-cron-bindings/#3-deploy-the-backend-background-processor-and-the-backend-api-projects-to-azure-container-apps","title":"3. Deploy the Backend Background Processor and the Backend API Projects to Azure Container Apps","text":""},{"location":"aca/07-aca-cron-bindings/#31-build-the-backend-background-processor-and-the-backend-api-app-images-and-push-them-to-acr","title":"3.1 Build the Backend Background Processor and the Backend API App Images and Push them to ACR","text":"<p>To prepare for deployment to Azure Container Apps, we must build and deploy both application images to ACR, just as we did before. We can use the same PowerShell console use the following code (make sure you are on directory TasksTracker.ContainerApps):</p> <pre><code>az acr build `\n--registry $AZURE_CONTAINER_REGISTRY_NAME `\n--image \"tasksmanager/$BACKEND_API_NAME\" `\n--file 'TasksTracker.TasksManager.Backend.Api/Dockerfile' . \n\naz acr build `\n--registry $AZURE_CONTAINER_REGISTRY_NAME `\n--image \"tasksmanager/$BACKEND_SERVICE_NAME\" `\n--file 'TasksTracker.Processor.Backend.Svc/Dockerfile' .\n</code></pre>"},{"location":"aca/07-aca-cron-bindings/#32-add-the-cron-dapr-component-to-aca-environment","title":"3.2 Add the Cron Dapr Component to ACA Environment","text":"<pre><code># Cron binding component\naz containerapp env dapr-component set `\n--name $ENVIRONMENT --resource-group $RESOURCE_GROUP `\n--dapr-component-name scheduledtasksmanager `\n--yaml '.\\aca-components\\containerapps-scheduled-cron.yaml'\n</code></pre>"},{"location":"aca/07-aca-cron-bindings/#33-deploy-new-revisions-of-the-backend-api-and-backend-background-processor-to-aca","title":"3.3 Deploy New Revisions of the Backend API and Backend Background Processor to ACA","text":"<p>As we did before, we need to update the Azure Container App hosting the Backend API &amp; Backend Background Processor with a new revision so our code changes are available for the end users. To accomplish this run the PowerShell script below:</p> <pre><code># Update Backend API App container app and create a new revision \naz containerapp update `\n--name $BACKEND_API_NAME `\n--resource-group $RESOURCE_GROUP `\n--revision-suffix v$TODAY-4\n\n# Update Backend Background Processor container app and create a new revision \naz containerapp update `\n--name $BACKEND_SERVICE_NAME `\n--resource-group $RESOURCE_GROUP `\n--revision-suffix v$TODAY-4\n</code></pre> <p>Note</p> <p>The service <code>ScheduledTasksManager</code> which will be triggered by the Cron job on certain intervals is hosted in the ACA service <code>ACA-Processor Backend</code>. In the future module we are going to scale this ACA <code>ACA-Processor Backend</code> to multiple replicas/instances.</p> <p>It is highly recommended that background periodic jobs are hosted in a container app with one single replica, you don't want your background periodic job to run on multiple replicas trying to do the same thing. This, in fact, would be a limitation that could call for a separate Azure Container App jobs implementation as we typically want or app/API/service to scale.</p> <p>Success</p> <p>With those changes in place and deployed, from the Azure portal, you can open the log streams of the container app hosting the <code>ACA-Processor-Backend</code> and check the logs generated when the Cron job is triggered, you should see logs similar to the below image</p> <p></p> <p>Note</p> <p>Keep in mind though that you won't be able to see the results instantaneously as the cron job searches for tasks that have a due date matching the previous day of its execution and are still pending.</p> <ul> <li> <p>Navigate to the root and persist the module to Git.</p> <pre><code>git add .\ngit commit -m \"Add Module 7\"\n</code></pre> </li> </ul>"},{"location":"aca/07-aca-cron-bindings/#review","title":"Review","text":"<p>In this module, we have accomplished three objectives:</p> <ol> <li>Learned how the Cron binding can trigger actions.</li> <li>Added a Cron binding to the Backend Background Processor.</li> <li>Deployed updated Background Processor and API projects to Azure.</li> </ol>"},{"location":"aca/08-aca-monitoring/","title":"Module 8 - ACA Monitoring and Observability with Application Insights","text":"<p>Module Duration</p> <p>60 minutes</p>"},{"location":"aca/08-aca-monitoring/#objective","title":"Objective","text":"<p>In this module, we will accomplish four objectives:</p> <ol> <li>Learn how Azure Container Apps integrate with Application Insights to examine application telemetry.</li> <li>Configure Application Insights for the microservices.</li> <li>Deploy updated Background Processor, API, and UI projects to Azure.</li> <li>Understand how telemetry data is visualized.</li> </ol>"},{"location":"aca/08-aca-monitoring/#module-sections","title":"Module Sections","text":"<ul> <li> <p>From the VS Code Terminal tab, open developer command prompt or PowerShell terminal in the project folder <code>TasksTracker.ContainerApps</code> (root):</p> <pre><code>cd ~\\TasksTracker.ContainerApps\n</code></pre> </li> <li> <p>Restore the previously-stored variables by executing the local script. The output informs you how many variables have been set.</p> <pre><code>.\\Variables.ps1\n</code></pre> </li> </ul>"},{"location":"aca/08-aca-monitoring/#1-azure-container-apps-application-insights","title":"1. Azure Container Apps &amp; Application Insights","text":"<p>In this module, we will explore how we can configure ACA and ACA Environment with Application Insights which will provide a holistic view of our container apps health, performance metrics, logs data, various telemetries and traces. ACA does not support Auto-Instrumentation for Application Insights, so in this module, we will be focusing on how we can integrate Application Insights into our microservice application.</p>"},{"location":"aca/08-aca-monitoring/#11-application-insights-overview","title":"1.1 Application Insights Overview","text":"<p>Application Insights is an offering from Azure Monitor that empowers us to monitor all ACAs under the same Container App Environment and collect telemetry about the workload services. Furthermore, it supports us in understanding the usage of the services and users' engagement via integrated analytics tools.</p> <p>The term Telemetry refers to the information gathered to monitor our application, which can be classified into three distinct groups:</p> <ol> <li> <p>Distributed Tracing: Distributed Tracing allows for visibility into the communication between services participating in distributed transactions. For instance, when the Frontend Web Application interacts with the Backend API Application to add or retrieve information. An application map of how calls are flowing between services is very important for any distributed application.</p> </li> <li> <p>Metrics: This offers a view of a service's performance and its use of resources. For instance, it helps in monitoring the CPU and memory usage of the Backend Background Processor, and identifying when it is necessary to scale up the number of replicas.</p> </li> <li> <p>Logging: provides insights into how code is executing and if errors have occurred.</p> </li> </ol> <p>In module 1 we have already provisioned a Workspace-based Application Insights Instance and configured it for the ACA environment by setting the property <code>--dapr-instrumentation-key</code>. We presume that you have already set up an instance of Application Insights that is available for use across the three container apps.</p>"},{"location":"aca/08-aca-monitoring/#2-installing-application-insights-sdk-into-the-three-microservices-apps","title":"2. Installing Application Insights SDK Into the Three Microservices Apps","text":""},{"location":"aca/08-aca-monitoring/#21-install-the-application-insights-sdk-using-nuget","title":"2.1 Install the Application Insights SDK Using NuGet","text":"<p>Our next step is to incorporate the Application Insights SDK into the three microservices, which is a uniform procedure.</p> <p>Note</p> <p>While we will outline the process of configuring Application Insights for the Backend API service, the identical steps must be followed for the other two services.</p> <p>To incorporate the SDK, use the NuGet reference below in the <code>csproj</code> file of the Backend API project. You may locate the csproj file in the project directory TasksTracker.TasksManager.Backend.Api:</p> .NET 6.NET 7.NET 8 TasksTracker.TasksManager.Backend.Api.csprojTasksTracker.TasksManager.Backend.Svc.csprojTasksTracker.TasksManager.Frontend.Ui.csproj <pre><code>&lt;ItemGroup&gt;\n    &lt;!--Other packages are removed for brevity--&gt;\n    &lt;PackageReference Include=\"Microsoft.ApplicationInsights.AspNetCore\" Version=\"2.21.0\" /&gt;\n&lt;/ItemGroup&gt;\n</code></pre> <pre><code>&lt;ItemGroup&gt;\n    &lt;!--Other packages are removed for brevity--&gt;\n    &lt;PackageReference Include=\"Microsoft.ApplicationInsights.AspNetCore\" Version=\"2.21.0\" /&gt;\n&lt;/ItemGroup&gt;\n</code></pre> <pre><code>&lt;ItemGroup&gt;\n    &lt;!--Other packages are removed for brevity--&gt;\n    &lt;PackageReference Include=\"Microsoft.ApplicationInsights.AspNetCore\" Version=\"2.21.0\" /&gt;\n&lt;/ItemGroup&gt;\n</code></pre> TasksTracker.TasksManager.Backend.Api.csprojTasksTracker.TasksManager.Backend.Svc.csprojTasksTracker.TasksManager.Frontend.Ui.csproj <pre><code>&lt;Project Sdk=\"Microsoft.NET.Sdk.Web\"&gt;\n\n  &lt;PropertyGroup&gt;\n    &lt;TargetFramework&gt;net7.0&lt;/TargetFramework&gt;\n    &lt;Nullable&gt;enable&lt;/Nullable&gt;\n    &lt;ImplicitUsings&gt;enable&lt;/ImplicitUsings&gt;\n  &lt;/PropertyGroup&gt;\n\n  &lt;ItemGroup&gt;\n    &lt;PackageReference Include=\"Dapr.AspNetCore\" Version=\"1.12.0\" /&gt;\n    &lt;PackageReference Include=\"Microsoft.ApplicationInsights.AspNetCore\" Version=\"2.21.0\" /&gt;\n    &lt;PackageReference Include=\"Microsoft.AspNetCore.OpenApi\" Version=\"7.0.13\" /&gt;\n    &lt;PackageReference Include=\"Swashbuckle.AspNetCore\" Version=\"6.5.0\" /&gt;\n  &lt;/ItemGroup&gt;\n\n&lt;/Project&gt;\n</code></pre> <pre><code>&lt;Project Sdk=\"Microsoft.NET.Sdk.Web\"&gt;\n\n  &lt;PropertyGroup&gt;\n    &lt;TargetFramework&gt;net7.0&lt;/TargetFramework&gt;\n    &lt;Nullable&gt;enable&lt;/Nullable&gt;\n    &lt;ImplicitUsings&gt;enable&lt;/ImplicitUsings&gt;\n  &lt;/PropertyGroup&gt;\n\n  &lt;ItemGroup&gt;\n    &lt;PackageReference Include=\"Dapr.AspNetCore\" Version=\"1.12.0\" /&gt;\n    &lt;PackageReference Include=\"Microsoft.ApplicationInsights.AspNetCore\" Version=\"2.21.0\" /&gt;\n    &lt;PackageReference Include=\"Microsoft.AspNetCore.OpenApi\" Version=\"7.0.13\" /&gt;\n    &lt;PackageReference Include=\"Swashbuckle.AspNetCore\" Version=\"6.5.0\" /&gt;\n  &lt;/ItemGroup&gt;\n\n&lt;/Project&gt;\n</code></pre> <pre><code>&lt;Project Sdk=\"Microsoft.NET.Sdk.Web\"&gt;\n\n  &lt;PropertyGroup&gt;\n    &lt;TargetFramework&gt;net7.0&lt;/TargetFramework&gt;\n    &lt;Nullable&gt;enable&lt;/Nullable&gt;\n    &lt;ImplicitUsings&gt;enable&lt;/ImplicitUsings&gt;\n  &lt;/PropertyGroup&gt;\n\n  &lt;ItemGroup&gt;\n    &lt;PackageReference Include=\"Dapr.AspNetCore\" Version=\"1.12.0\" /&gt;\n    &lt;PackageReference Include=\"Microsoft.ApplicationInsights.AspNetCore\" Version=\"2.21.0\" /&gt;\n  &lt;/ItemGroup&gt;\n\n&lt;/Project&gt;\n</code></pre> TasksTracker.TasksManager.Backend.Api.csprojTasksTracker.TasksManager.Backend.Svc.csprojTasksTracker.TasksManager.Frontend.Ui.csproj <pre><code>&lt;Project Sdk=\"Microsoft.NET.Sdk.Web\"&gt;\n\n  &lt;PropertyGroup&gt;\n    &lt;TargetFramework&gt;net8.0&lt;/TargetFramework&gt;\n    &lt;Nullable&gt;enable&lt;/Nullable&gt;\n    &lt;ImplicitUsings&gt;enable&lt;/ImplicitUsings&gt;\n    &lt;InvariantGlobalization&gt;true&lt;/InvariantGlobalization&gt;\n  &lt;/PropertyGroup&gt;\n\n  &lt;ItemGroup&gt;\n    &lt;PackageReference Include=\"Dapr.AspNetCore\" Version=\"1.12.0\" /&gt;\n    &lt;PackageReference Include=\"Microsoft.ApplicationInsights.AspNetCore\" Version=\"2.21.0\" /&gt;\n    &lt;PackageReference Include=\"Microsoft.AspNetCore.OpenApi\" Version=\"7.0.13\" /&gt;\n    &lt;PackageReference Include=\"Swashbuckle.AspNetCore\" Version=\"6.5.0\" /&gt;\n  &lt;/ItemGroup&gt;\n\n&lt;/Project&gt;\n</code></pre> <pre><code>&lt;Project Sdk=\"Microsoft.NET.Sdk.Web\"&gt;\n\n  &lt;PropertyGroup&gt;\n    &lt;TargetFramework&gt;net8.0&lt;/TargetFramework&gt;\n    &lt;Nullable&gt;enable&lt;/Nullable&gt;\n    &lt;ImplicitUsings&gt;enable&lt;/ImplicitUsings&gt;\n    &lt;InvariantGlobalization&gt;true&lt;/InvariantGlobalization&gt;\n  &lt;/PropertyGroup&gt;\n\n  &lt;ItemGroup&gt;\n    &lt;PackageReference Include=\"Dapr.AspNetCore\" Version=\"1.12.0\" /&gt;\n    &lt;PackageReference Include=\"Microsoft.ApplicationInsights.AspNetCore\" Version=\"2.21.0\" /&gt;\n    &lt;PackageReference Include=\"Microsoft.AspNetCore.OpenApi\" Version=\"7.0.13\" /&gt;\n    &lt;PackageReference Include=\"Swashbuckle.AspNetCore\" Version=\"6.5.0\" /&gt;\n  &lt;/ItemGroup&gt;\n\n&lt;/Project&gt;\n</code></pre> <pre><code>&lt;Project Sdk=\"Microsoft.NET.Sdk.Web\"&gt;\n\n  &lt;PropertyGroup&gt;\n    &lt;TargetFramework&gt;net8.0&lt;/TargetFramework&gt;\n    &lt;Nullable&gt;enable&lt;/Nullable&gt;\n    &lt;ImplicitUsings&gt;enable&lt;/ImplicitUsings&gt;\n  &lt;/PropertyGroup&gt;\n\n  &lt;ItemGroup&gt;\n    &lt;PackageReference Include=\"Dapr.AspNetCore\" Version=\"1.12.0\" /&gt;\n    &lt;PackageReference Include=\"Microsoft.ApplicationInsights.AspNetCore\" Version=\"2.21.0\" /&gt;\n  &lt;/ItemGroup&gt;\n\n&lt;/Project&gt;\n</code></pre>"},{"location":"aca/08-aca-monitoring/#22-set-rolename-property-in-all-the-services","title":"2.2 Set RoleName Property in All the Services","text":"<p>For each of the three projects, we will add a new file to each project's root directory.</p> Backend.ApiBackend.SvcFrontend.Ui AppInsightsTelemetryInitializer.cs <pre><code>using Microsoft.ApplicationInsights.Channel;\nusing Microsoft.ApplicationInsights.Extensibility;\n\nnamespace TasksTracker.TasksManager.Backend.Api\n{\n    public class AppInsightsTelemetryInitializer : ITelemetryInitializer\n    {\n        public void Initialize(ITelemetry telemetry)\n        {\n            if (string.IsNullOrEmpty(telemetry.Context.Cloud.RoleName))\n            {\n                //set custom role name here\n                telemetry.Context.Cloud.RoleName = \"tasksmanager-backend-api\";\n            }\n        }\n    }\n}\n</code></pre> AppInsightsTelemetryInitializer.cs <pre><code>using Microsoft.ApplicationInsights.Channel;\nusing Microsoft.ApplicationInsights.Extensibility;\n\nnamespace TasksTracker.TasksManager.Backend.Svc\n{\n    public class AppInsightsTelemetryInitializer : ITelemetryInitializer\n    {\n        public void Initialize(ITelemetry telemetry)\n        {\n            if (string.IsNullOrEmpty(telemetry.Context.Cloud.RoleName))\n            {\n                //set custom role name here\n                telemetry.Context.Cloud.RoleName = \"tasksmanager-backend-processor\";\n            }\n        }\n    }\n}\n</code></pre> AppInsightsTelemetryInitializer.cs <pre><code>using Microsoft.ApplicationInsights.Channel;\nusing Microsoft.ApplicationInsights.Extensibility;\n\nnamespace TasksTracker.TasksManager.Frontend.Ui\n{\n    public class AppInsightsTelemetryInitializer : ITelemetryInitializer\n    {\n        public void Initialize(ITelemetry telemetry)\n        {\n            if (string.IsNullOrEmpty(telemetry.Context.Cloud.RoleName))\n            {\n                //set custom role name here\n                telemetry.Context.Cloud.RoleName = \"tasksmanager-frontend-webapp\";\n            }\n        }\n    }\n}\n</code></pre> <p>RoleName property for three services</p> <p>The only difference between each file on the 3 projects is the RoleName property value. </p> <p>Application Insights will utilize this property to recognize the elements on the application map. Additionally, it will prove beneficial for us in case we want to filter through all the warning logs produced by the Backend API service. Therefore, we will apply the tasksmanager-backend-api value for filtering purposes.</p> <p>Next, we need to register this <code>AppInsightsTelemetryInitializer</code> class in Program.cs in each of the three projects.</p> Backend.ApiBackend.SvcFrontend.Ui Program.cs <pre><code>using Microsoft.ApplicationInsights.Extensibility;\nusing TasksTracker.TasksManager.Backend.Api.Services;\nusing TasksTracker.TasksManager.Backend.Api;\n\nvar builder = WebApplication.CreateBuilder(args);\n\n// Add services to the container.\n\nbuilder.Services.AddApplicationInsightsTelemetry();\nbuilder.Services.Configure&lt;TelemetryConfiguration&gt;((o) =&gt; {\n    o.TelemetryInitializers.Add(new AppInsightsTelemetryInitializer());\n});\nbuilder.Services.AddDaprClient();\nbuilder.Services.AddSingleton&lt;ITasksManager, TasksStoreManager&gt;();\n//builder.Services.AddSingleton&lt;ITasksManager, FakeTasksManager&gt;();\nbuilder.Services.AddControllers();\n// Learn more about configuring Swagger/OpenAPI at https://aka.ms/aspnetcore/swashbuckle\nbuilder.Services.AddEndpointsApiExplorer();\nbuilder.Services.AddSwaggerGen();\n\nvar app = builder.Build();\n\n// Configure the HTTP request pipeline.\nif (app.Environment.IsDevelopment())\n{\n    app.UseSwagger();\n    app.UseSwaggerUI();\n}\n\napp.UseHttpsRedirection();\n\napp.UseAuthorization();\n\napp.MapControllers();\n\napp.Run();\n</code></pre> Program.cs <pre><code>using Microsoft.ApplicationInsights.Extensibility;\nusing TasksTracker.TasksManager.Backend.Svc;\n\nvar builder = WebApplication.CreateBuilder(args);\n\n// Add services to the container.\n\nbuilder.Services.AddApplicationInsightsTelemetry();\nbuilder.Services.Configure&lt;TelemetryConfiguration&gt;((o) =&gt; {\n    o.TelemetryInitializers.Add(new AppInsightsTelemetryInitializer());\n});\nbuilder.Services.AddControllers().AddDapr();\n// Learn more about configuring Swagger/OpenAPI at https://aka.ms/aspnetcore/swashbuckle\nbuilder.Services.AddEndpointsApiExplorer();\nbuilder.Services.AddSwaggerGen();\n\nvar app = builder.Build();\n\n// Configure the HTTP request pipeline.\nif (app.Environment.IsDevelopment())\n{\n    app.UseSwagger();\n    app.UseSwaggerUI();\n}\n\napp.UseHttpsRedirection();\n\napp.UseAuthorization();\n\napp.UseCloudEvents();\n\napp.MapControllers();\n\napp.MapSubscribeHandler();\n\napp.Run();\n</code></pre> Program.cs <pre><code>using Microsoft.ApplicationInsights.Extensibility;\nusing TasksTracker.TasksManager.Frontend.Ui;\n\nvar builder = WebApplication.CreateBuilder(args);\n\n// Add services to the container.\n\nbuilder.Services.AddApplicationInsightsTelemetry();\nbuilder.Services.Configure&lt;TelemetryConfiguration&gt;((o) =&gt; {\n    o.TelemetryInitializers.Add(new AppInsightsTelemetryInitializer());\n});\n\nbuilder.Services.AddRazorPages();\n\nbuilder.Services.AddDaprClient();\n\nbuilder.Services.AddHttpClient(\"BackEndApiExternal\", httpClient =&gt;\n{\n    var backendApiBaseUrlExternalHttp = builder.Configuration.GetValue&lt;string&gt;(\"BackendApiConfig:BaseUrlExternalHttp\");\n\n    if (!string.IsNullOrEmpty(backendApiBaseUrlExternalHttp)) {\n        httpClient.BaseAddress = new Uri(backendApiBaseUrlExternalHttp);\n    } else {\n        throw new(\"BackendApiConfig:BaseUrlExternalHttp is not defined in App Settings.\");\n    }\n});\n\nvar app = builder.Build();\n\n// Configure the HTTP request pipeline.\nif (!app.Environment.IsDevelopment())\n{\n    app.UseExceptionHandler(\"/Error\");\n    // The default HSTS value is 30 days. You may want to change this for production scenarios, see https://aka.ms/aspnetcore-hsts.\n    app.UseHsts();\n}\n\napp.UseHttpsRedirection();\n\napp.UseStaticFiles();\n\napp.UseRouting();\n\napp.UseAuthorization();\n\napp.MapRazorPages();\n\napp.Run();\n</code></pre>"},{"location":"aca/08-aca-monitoring/#23-set-the-application-insights-instrumentation-key","title":"2.3 Set the Application Insights Instrumentation Key","text":"<p>In the previous module, we've used Dapr Secret Store to store connection strings and keys. In this module we will demonstrate how we can use another approach to secrets in Container Apps.</p> <p>We need to set the Application Insights Instrumentation Key so that the projects are able to send telemetry data to the Application Insights instance. We are going to set this via secrets and environment variables once we redeploy the Container Apps and create new revisions.</p> appsettings.json <pre><code>{\n  // Configuration removed for brevity      \n  \"ApplicationInsights\": {\n    \"InstrumentationKey\": \"&lt;Application Insights Key here for local development&gt;\"\n  } \n}\n</code></pre> <p>With this step completed, we have done all the changes needed. Let's now deploy the changes and create new ACA revisions.</p>"},{"location":"aca/08-aca-monitoring/#3-deploy-services-to-aca-and-create-new-revisions","title":"3. Deploy Services to ACA and Create New Revisions","text":""},{"location":"aca/08-aca-monitoring/#31-add-application-insights-instrumentation-key-as-a-secret","title":"3.1 Add Application Insights Instrumentation Key As a Secret","text":"<p>Let's create a secret named <code>appinsights-key</code> on each Container App which contains the value of the Application Insights instrumentation key:</p> <pre><code>az containerapp secret set `\n--name $BACKEND_API_NAME `\n--resource-group $RESOURCE_GROUP `\n--secrets \"appinsights-key=$APPINSIGHTS_INSTRUMENTATIONKEY \"\n\naz containerapp secret set `\n--name $FRONTEND_WEBAPP_NAME `\n--resource-group $RESOURCE_GROUP `\n--secrets \"appinsights-key=$APPINSIGHTS_INSTRUMENTATIONKEY \"\n\naz containerapp secret set `\n--name $BACKEND_SERVICE_NAME `\n--resource-group $RESOURCE_GROUP `\n--secrets \"appinsights-key=$APPINSIGHTS_INSTRUMENTATIONKEY \"\n</code></pre>"},{"location":"aca/08-aca-monitoring/#32-build-new-images-and-push-them-to-acr","title":"3.2 Build New Images and Push Them to ACR","text":"<p>As we did before, we are required to build and push the images of the three applications to ACR. By doing so, they will be prepared to be deployed in ACA.</p> <p>To accomplish this, continue using the same PowerShell console and paste the code below (make sure you are on the following directory TasksTracker.ContainerApps):</p> <pre><code># Build Backend API on ACR and Push to ACR\naz acr build `\n--registry $AZURE_CONTAINER_REGISTRY_NAME `\n--image \"tasksmanager/$BACKEND_API_NAME\" `\n--file 'TasksTracker.TasksManager.Backend.Api/Dockerfile' . \n\n# Build Backend Service on ACR and Push to ACR\naz acr build `\n--registry $AZURE_CONTAINER_REGISTRY_NAME `\n--image \"tasksmanager/$BACKEND_SERVICE_NAME\" `\n--file 'TasksTracker.Processor.Backend.Svc/Dockerfile' .\n\n# Build Frontend Web App on ACR and Push to ACR\naz acr build `\n--registry $AZURE_CONTAINER_REGISTRY_NAME `\n--image \"tasksmanager/$FRONTEND_WEBAPP_NAME\" `\n--file 'TasksTracker.WebPortal.Frontend.Ui/Dockerfile' .\n</code></pre>"},{"location":"aca/08-aca-monitoring/#33-deploy-new-revisions-of-the-services-to-aca-and-set-a-new-environment-variable","title":"3.3 Deploy New Revisions of the Services to ACA and Set a New Environment Variable","text":"<p>We need to update all three container apps with new revisions so that our code changes are available for end users.</p> <p>Tip</p> <p>Notice how we used the property <code>--set-env-vars</code> to set new environment variable named <code>ApplicationInsights__InstrumentationKey</code>. Its value is a secret reference obtained from the secret <code>appinsights-key</code> we added in step 1.</p> <pre><code># Update Backend API App container app and create a new revision \naz containerapp update `\n--name $BACKEND_API_NAME  `\n--resource-group $RESOURCE_GROUP `\n--revision-suffix v$TODAY-5 `\n--set-env-vars \"ApplicationInsights__InstrumentationKey=secretref:appinsights-key\"\n\n# Update Frontend Web App container app and create a new revision \naz containerapp update `\n--name $FRONTEND_WEBAPP_NAME  `\n--resource-group $RESOURCE_GROUP `\n--revision-suffix v$TODAY-5 `\n--set-env-vars \"ApplicationInsights__InstrumentationKey=secretref:appinsights-key\"\n\n# Update Backend Background Service container app and create a new revision \naz containerapp update `\n--name $BACKEND_SERVICE_NAME `\n--resource-group $RESOURCE_GROUP `\n--revision-suffix v$TODAY-5 `\n--set-env-vars \"ApplicationInsights__InstrumentationKey=secretref:appinsights-key\"\n</code></pre> <p>Success</p> <p>With those changes in place, you should start seeing telemetry coming to the Application Insights instance provisioned. Let's review Application Insights' key dashboards and panels in Azure portal.</p>"},{"location":"aca/08-aca-monitoring/#4-visualizating-telemetry-data","title":"4. Visualizating Telemetry Data","text":""},{"location":"aca/08-aca-monitoring/#41-distributed-tracing-via-application-map","title":"4.1 Distributed Tracing Via Application Map","text":"<p>Application Map will help us spot any performance bottlenecks or failure hotspots across all our services of our distributed microservice application. Each node on the map represents an application component (service) or its dependencies and has a health KPI and alerts status.</p> <p></p> <p>Looking at the image above, you will see for example how the Backend Api with could RoleName <code>tasksmanager-backend-api</code> is depending on the Cosmos DB instance, showing the number of calls and average time to service these calls. The application map is interactive so you can select a service/component and drill down into details.</p> <p>For example, when we drill down into the Dapr State node to understand how many times the backend API invoked the Dapr Sidecar state service to Save/Delete state, you will see results similar to the  image below:</p> <p></p> <p>Note</p> <p>It will take some time for the application map to fully populate.</p>"},{"location":"aca/08-aca-monitoring/#42-monitor-production-application-using-live-metrics","title":"4.2 Monitor Production Application Using Live Metrics","text":"<p>This is one of the key monitoring panels. It provides you with near real-time (1-second latency) status of your entire distributed application. We have the ability to observe both the successes and failures of our system, monitor any occurring exceptions and trace them in real-time. Additionally, we can monitor the live servers (including replicas) and track their CPU and memory usage, as well as the number of requests they are currently handling.</p> <p>These live metrics provide very powerful diagnostics for our production microservice application. Check the image below and see the server names and some of the incoming requests to the system.</p> <p></p>"},{"location":"aca/08-aca-monitoring/#43-logs-search-using-transaction-search","title":"4.3 Logs Search Using Transaction Search","text":"<p>Transaction search in Application Insights will help us find and explore individual telemetry items, such as exceptions, web requests, or dependencies as well as any log traces and events that we've added to the application.</p> <p>For example, if we want to see all the event types of type <code>Request</code> for the cloud RoleName <code>tasksmanager-backend-api</code> in the past 24 hours, we can use the transaction search dashboard to do this. See how the filters are set and the results are displayed nicely. We can drill down on each result to have more details and what telemetry was captured before and after. A very useful feature when troubleshooting exceptions and reading logs.</p> <p></p>"},{"location":"aca/08-aca-monitoring/#44-failures-and-performance-panels","title":"4.4 Failures and Performance Panels","text":"<p>The failure panel enables us to assess the frequency of failures across various operations, which assists us in prioritizing our efforts towards the ones that have the most significant impact.</p> <p></p> <p>The Performance panel displays performance details for the different operations in our system. By identifying those operations with the longest duration, we can diagnose potential problems or best target our ongoing development to improve the overall performance of the system.</p> <p></p> <ul> <li> <p>Navigate to the root and persist the module to Git.</p> <pre><code>git add .\ngit commit -m \"Add Module 8\"\n</code></pre> </li> </ul>"},{"location":"aca/08-aca-monitoring/#review","title":"Review","text":"<p>In this module, we have accomplished four objectives:</p> <ol> <li>Learned how Azure Container Apps integrate with Application Insights to examine application telemetry.</li> <li>Configured Application Insights for the microservices.</li> <li>Deployed updated Background Processor, API, and UI projects to Azure.</li> <li>Understood how telemetry data is visualized.</li> </ol>"},{"location":"aca/09-aca-autoscale-keda/","title":"Module 9 - ACA Auto Scaling with KEDA","text":"<p>Module Duration</p> <p>30 minutes</p>"},{"location":"aca/09-aca-autoscale-keda/#objective","title":"Objective","text":"<p>In this module, we will accomplish four objectives:</p> <ol> <li>Understand Azure Container Apps Scaling Behaviors.</li> <li>Learn about the Kubernetes Event-Driven Autoscaler (KEDA).</li> <li>Create a scaling rule for the Backend Background Processor project.</li> <li>Test scaling of the Backend Background Processor.</li> </ol>"},{"location":"aca/09-aca-autoscale-keda/#module-sections","title":"Module Sections","text":"<ul> <li> <p>From the VS Code Terminal tab, open developer command prompt or PowerShell terminal in the project folder <code>TasksTracker.ContainerApps</code> (root):</p> <pre><code>cd ~\\TasksTracker.ContainerApps\n</code></pre> </li> <li> <p>Restore the previously-stored variables by executing the local script. The output informs you how many variables have been set.</p> <pre><code>.\\Variables.ps1\n</code></pre> </li> </ul>"},{"location":"aca/09-aca-autoscale-keda/#1-azure-container-apps-scaling-behaviors","title":"1. Azure Container Apps Scaling Behaviors","text":"<p>In this module, we will explore how we can configure auto scaling rules in container apps. The Auto Scaling feature is one of the key features of any Serverless hosting platform because it empowers your application to adjust dynamically. This means your application can automatically handle higher (or lower) workloads, ensuring your system maintains its availability and performance.</p> <p>Azure Container Apps support horizontal scaling, also known as scaling out and scaling in. Respectively, when demand increases, Azure Container Apps can add (scale out) replicas (new instances of the container app), thus splitting the workload across multiple replicas to process the work in parallel. Ideally, this keeps the workload per instance somewhat consistent with that instance's capacity. Conversely, when demand decreases, Azure Container Apps will remove (scale In) un- or under-utilized replicas according to your configured scaling rule. With this consumption-oriented approach, you pay only for the replicas provisioned at any time. You can also configure the scaling rule to scale to zero replicas, resulting in no costs being incurred when your Container App scales down to zero. However, be aware that scaling to zero for critical workloads is advised against.</p>"},{"location":"aca/09-aca-autoscale-keda/#11-scaling-triggers","title":"1.1 Scaling Triggers","text":"<p>Azure Container Apps supports different scaling triggers including:</p> <ul> <li>HTTP traffic: Scaling based on the number of concurrent HTTP requests to your revision.</li> <li>CPU or Memory usage: Scaling based on the amount of CPU utilized or memory consumed by a replica.</li> <li>Azure Storage Queues: Scaling based on the number of messages in Azure Storage Queue.</li> <li>Event-driven using KEDA: Scaling based on events triggers, such as the number of messages in Azure Service Bus Topic or the number of blobs in Azure Blob Storage container.</li> </ul> <p>As we covered in the introductory module, Azure Container Apps utilize different open source technologies, including KEDA, which facilitate tasks such as event-driven autoscaling. KEDA is installed by default when you provision your Container App; there is no need to worry about installing it. All we need to focus on is enabling and configuring our container app scaling rules.</p>"},{"location":"aca/09-aca-autoscale-keda/#2-an-overview-of-kubernetes-event-driven-autoscaler-keda","title":"2. An Overview of Kubernetes Event-Driven Autoscaler (KEDA)","text":"<p>KEDA stands for Kubernetes Event-Driven Autoscaler. It is an open-source project initially started by Microsoft and Red Hat to allow any Kubernetes workload to benefit from the event-driven architecture model. Prior to KEDA, horizontally scaling a Kubernetes deployment was achieved through the Horizontal Pod Autoscaler (HPA). The HPA relies on resource metrics such as Memory and CPU to determine when additional replicas should be deployed. In an enterprise application, there may be additional external metrics that we want to use to scale our application, such as the length of a Kafka topic log, an Azure Service Bus Queue, or metrics obtained from a Prometheus query. In short, scaling considerations are likely to be increasingly complex as your applications and ecosystem grow. KEDA offers more than 50 scalers to pick from based on your business need. KEDA exists to fill this gap and provides a framework for scaling based on events in conjunction with HPA scaling based on CPU and Memory.</p>"},{"location":"aca/09-aca-autoscale-keda/#3-configure-scaling-rule-in-backend-background-processor-project","title":"3. Configure Scaling Rule in Backend Background Processor Project","text":""},{"location":"aca/09-aca-autoscale-keda/#31-keda-azure-service-bus-scaler","title":"3.1 KEDA Azure Service Bus Scaler","text":"<p>We want to configure our Backend Background Processor, <code>tasksmanager-backend-processor</code>, service to scale out to increase the number of replicas. We do that based on the number of messages in the Azure Service Bus Topic named <code>tasksavedtopic</code>. When our service is under heavy load, and a single replica is insufficient to handle the number of messages on the topic, we require the container app to create additional replicas to distribute the processing of messages on this topic.</p> <p>Our requirements for scaling the backend processor are as follows:</p> <ul> <li>For every ten messages on the Azure Service Bus Topic, scale-out by one replica.</li> <li>When there are no messages on the topic, scale-in to a single replica.</li> <li>The maximum number of replicas should not exceed five.</li> </ul> <p>To achieve this, we look to the KEDA Azure Service Bus scaler. This specification describes the <code>azure-servicebus</code> trigger for Azure Service Bus Queue or Topic. Let's take a look at the yaml file below which contains a generic template for the KEDA specification:</p> <pre><code>triggers:\n- type: azure-servicebus\n  metadata:\n    # Required: queueName OR topicName and subscriptionName\n    queueName: queueName\n    # or\n    topicName: topicName\n    subscriptionName: subscriptionName\n    # Optional, required when pod identity is used\n    namespace: service-bus-namespace\n    # Optional, can use TriggerAuthentication as well\n    connectionFromEnv: SERVICEBUS_CONNECTIONSTRING_ENV_NAME # This must be a connection string for a queue itself, and not a namespace level (e.g. RootAccessPolicy) connection string \n    # Optional\n    messageCount: \"5\" # Optional. Count of messages to trigger scaling on. Default: 5 messages\n    cloud: Private # Optional. Default: AzurePublicCloud\n    endpointSuffix: servicebus.airgap.example # Required when cloud=Private\n</code></pre> Curious to learn more about the contents of the yaml file? <ul> <li>The property <code>type</code> is set to <code>azure-servicebus</code>. Each KEDA scaler specification file has a unique type.</li> <li>One of the properties <code>queueName</code> or <code>topicName</code> should be provided. In our case, it will be <code>topicName</code> and we will use the value <code>tasksavedtopic</code>.</li> <li>The property <code>subscriptionName</code> will be set to use <code>tasksmanager-backend-processor</code>. This represents the subscription associated with the topic. Not needed if we are using queues.</li> <li>The property <code>connectionFromEnv</code> will be set to reference a secret stored in our Container App. We will not use the Azure Service Bus shared access policy (connection string) directly. The shared access policy will be stored in the Container App secrets, and the secret will be referenced here. Please note that the Service Bus Shared Access Policy needs to be of type <code>Manage</code>. It is required for KEDA to be able to get metrics from Service Bus and read the length of messages in the queue or topic.</li> <li>The property <code>messageCount</code> is used to decide when scaling out should be triggered. In our case, it will be set to <code>10</code>.</li> <li>The property <code>cloud</code> represents the name of the cloud environment that the service bus belongs to.</li> </ul> <p>Note</p> <p>Note about authentication: KEDA scaler for Azure Service Bus supports different authentication mechanisms such as Pod Managed Identity, Azure AD Workload Identity, and shared access policy (connection string). At the time of writing this workshop, when using KEDA with Azure Container Apps the only supported authentication mechanism is Connection Strings. There is a work item in the ACA product backlog that involves enabling KEDA Scale with Managed Identity.</p> <p>Azure Container Apps has its own proprietary schema to map a KEDA Scaler template to its own when defining a custom scale rule. You can define this scaling rule via Container Apps ARM templates, yaml manifest, Azure CLI, or from the Azure portal. In this module, we will cover how to do it from the Azure CLI.</p>"},{"location":"aca/09-aca-autoscale-keda/#32-create-a-new-secret-in-the-container-app","title":"3.2 Create a New Secret In The Container App","text":"<p>Let's now create a secret named <code>svcbus-connstring</code> in our <code>tasksmanager-backend-processor</code> Container App. This secret will contain the value of Azure Service Bus shared access policy (connection string) with <code>Manage</code> policy. To accomplish this, run the following commands in the Azure CLI to get the connection string, and then add this secret using the second command:</p> <pre><code># List Service Bus Access Policy RootManageSharedAccessKey\n$SERVICE_BUS_CONNECTION_STRING = az servicebus namespace authorization-rule keys list `\n--name RootManageSharedAccessKey `\n--resource-group $RESOURCE_GROUP `\n--namespace-name $SERVICE_BUS_NAMESPACE_NAME `\n--query primaryConnectionString `\n--output tsv\n\n# Create a new secret named 'svcbus-connstring' in backend processer container app\naz containerapp secret set `\n--name $BACKEND_SERVICE_NAME `\n--resource-group $RESOURCE_GROUP `\n--secrets \"svcbus-connstring=$SERVICE_BUS_CONNECTION_STRING\"\n</code></pre>"},{"location":"aca/09-aca-autoscale-keda/#2-create-a-custom-scaling-rule-from-azure-cli","title":"2. Create a Custom Scaling Rule from Azure CLI","text":"<p>Now we are ready to add a new custom scaling rule to match the business requirements. To accomplish this, we need to run the Azure CLI command below:</p> <p>Note</p> <p>You might need to upgrade the extension if you are on an older version of <code>az containerapp</code> which didn't allow you to create a scaling rule from CLI. To update the extension you can run the following command <code>az extension update --name containerapp</code> inside your PowerShell terminal.</p> <pre><code>az containerapp update `\n--name $BACKEND_SERVICE_NAME `\n--resource-group $RESOURCE_GROUP `\n--min-replicas 1 `\n--max-replicas 5 `\n--revision-suffix v$TODAY-6 `\n--scale-rule-name \"topic-msgs-length\" `\n--scale-rule-type \"azure-servicebus\" `\n--scale-rule-auth \"connection=svcbus-connstring\" `\n--scale-rule-metadata \"topicName=$SERVICE_BUS_TOPIC_NAME\" `\n                        \"subscriptionName=$SERVICE_BUS_TOPIC_SUBSCRIPTION\" `\n                        \"namespace=$SERVICE_BUS_NAMESPACE_NAME\" `\n                        \"messageCount=10\" `\n                        \"connectionFromEnv=svcbus-connstring\"\n</code></pre> Curious to learn more about the different parameters passed to the <code>az containerapp update</code> command? <ul> <li>Setting the minimum number of replicas to <code>1</code>. This means that this Container App could be scaled-in to a single replica if there are no new messages on the topic.</li> <li>Setting the maximum number of replicas to <code>5</code>. This means that this Container App will not exceed more than 5 replicas regardless of the number of messages on the topic.</li> <li>Setting a friendly name for the scale rule <code>topic-msgs-length</code> which will be visible in the Azure portal.</li> <li>Setting the scale rule type to <code>azure-servicebus</code>. This is important to tell KEDA which type of scalers our Container App is configuring.</li> <li>Setting the authentication mechanism to type <code>connection</code> and indicating which secret reference will be used. In our case <code>svcbus-connstring</code>.</li> <li>Setting the <code>metadata</code> dictionary of the scale rule. Those match the metadata properties in KEDA template we discussed earlier.</li> <li>Disabled the integration with SendGrid as we are going to send several messages to test the scale out rule.</li> </ul> <p>Note</p> <p>Note About Setting Minimum Replicas To 0: * We can set the minimum number of replicas to <code>zero</code> to avoid any charges when the backend processor is not processing any message from Azure Service Bus Topic, but this will impact running the other features within this backend processor such as the periodic cron job as well as the external input bidding and output bindings. We are configuring the minimum number of replicas to one, ensuring that a backend processor instance is always running and capable of handling tasks, even if there are no messages being received by the Azure Service Bus Topic.</p> <ul> <li>When the single replica of the backend processor is not doing anything, it will be running in an <code>idle mode</code>. When the replica is in idle mode usage is charged at a reduced idle rate. A replica enters an active mode and is charged at the active rate when it is starting up, and when it is processing requests. For more details about the ACA pricing visit this link.</li> </ul>"},{"location":"aca/09-aca-autoscale-keda/#4-scaling-testing","title":"4. Scaling Testing","text":""},{"location":"aca/09-aca-autoscale-keda/#41-run-an-end-to-end-test-and-generate-several-messages","title":"4.1 Run an End-to-End Test and Generate Several Messages","text":"<p>Now we are ready to test out our Azure Service Bus Scaling Rule. To produce a high volume of messages, you can utilize the Service Bus Explorer located within your Azure Service Bus namespace. Navigate to Azure Service Bus, choose your topic/subscription, and then select the Service Bus Explorer option.</p> <p>To get the number of current replicas of service <code>tasksmanager-backend-processor</code> we could run the command below, this should run single replica as we didn't load the service bus topic yet.</p> <pre><code>az containerapp replica list `\n--name $BACKEND_SERVICE_NAME `\n--resource-group $RESOURCE_GROUP `\n--query [].name\n</code></pre> <p>The message structure our backend processor expects is similar to the JSON shown below. So copy this message and click on <code>Send messages</code> button, paste the message content, set the content type to <code>application/json</code>, check the <code>Repeat Send</code> check box, select <code>10000</code> messages and put an interval of <code>1ms</code> between them. This ensures that we are sending high volume at short intervals, so that the single replica container app cannot absorb and process quickly enough and will consequently need to scale out. Finally click <code>Send</code> when you are ready.</p> <pre><code>{\n    \"data\": {\n        \"isCompleted\": false,\n        \"isOverDue\": true,\n        \"taskAssignedTo\": \"temp@mail.com\",\n        \"taskCreatedBy\": \"someone@mail.com\",\n        \"taskCreatedOn\": \"2022-08-18T12:45:22.0984036Z\",\n        \"taskDueDate\": \"2023-02-24T12:45:22.0983978Z\",\n        \"taskId\": \"6a051aeb-f567-40dd-a434-39927f2b93c5\",\n        \"taskName\": \"Auto scale Task\"\n    }\n}\n</code></pre> <p></p>"},{"location":"aca/09-aca-autoscale-keda/#42-verify-that-multiple-replicas-are-created","title":"4.2 Verify that Multiple Replicas Are Created","text":"<p>Success</p> <p>If all is setup correctly, five replicas will be created based on the number of messages we generated into the topic. There are various ways to verify this:</p> <ul> <li>You can run the Azure CLI command used in previous step to list the names of replicas.</li> <li>You can verify this from Container Apps <code>Console</code> tab where you will see those replicas in the drop-down list </li> </ul> <p>Note</p> <p>Note About KEDA Scale In: Container Apps implements the KEDA ScaledObject with the following default settings:</p> <ul> <li>pollingInterval: 30 seconds. This is the interval to check each trigger on. By default, KEDA will check each trigger source on every ScaledObject every 30 seconds.</li> <li>cooldownPeriod: 300 seconds. The period to wait after the last trigger is reported active before scaling in the resource back to 0. By default, it's 5 minutes (300 seconds). Currently, there is no way to override this value, yet there is an open issue on the Container Apps repo and the PG is tracking it as 5 minutes might be a long period to wait for instances to be scaled in after they finish processing messages.</li> </ul> <ul> <li> <p>Execute the <code>Set-Variables.ps1</code> in the root to update the <code>variables.ps1</code> file with all current variables. The output of the script will inform you how many variables are written out.</p> <pre><code>.\\Set-Variables.ps1\n</code></pre> </li> <li> <p>From the root, persist a list of all current variables.</p> <pre><code>git add .\\Variables.ps1\ngit commit -m \"Update Variables.ps1\"\n</code></pre> </li> </ul>"},{"location":"aca/09-aca-autoscale-keda/#review","title":"Review","text":"<p>In this module, we accomplished four objectives:</p> <ol> <li>Understood Azure Container Apps Scaling Behaviors.</li> <li>Learned about the Kubernetes Event-Driven Autoscaler (KEDA).</li> <li>Created a scaling rule for the Backend Background Processor project.</li> <li>Tested scaling of the Backend Background Processor.</li> </ol>"},{"location":"aca/10-aca-iac-bicep/","title":"Module 10 - Deployment Via Bicep and DevOps","text":"<p>Throughout the various modules, we have utilized various Azure CLI commands to provision different resources. While this approach is suitable for this workshop, in a production environment, you will likely require a more automated process to deploy the same resources. In this module, we will be working on defining the proper process to automate the infrastructure provisioning by creating the scripts/templates to provision the resources. This process is known as IaC (Infrastructure as Code).</p> <p>Once we have this in place, IaC deployments will benefit us in key ways such as:</p> <ol> <li>By ensuring consistency and reducing human errors in resource provisioning, deployments can be made with greater confidence and consistency.</li> <li>Avoid configuration drifts as IaC is an idempotent operation, which means it provides the same result each time it's run.</li> <li>With Infrastructure as Code (IaC) in place, recreating an identical environment to the production one becomes a simple task of executing the scripts. This can be particularly useful during the application's lifecycle when short-term isolation is needed for tasks such as penetration testing or load testing.</li> <li>The Azure portal abstracts several processes when you provision resources. For instance, when you create an Azure Container Apps Environment from the portal, it automatically creates a Log Analytics workspace and associates it with the environment without your direct involvement. However, using Infrastructure as Code (IaC) can provide you with a deeper understanding of Azure and help you troubleshoot any issues that may arise more effectively.</li> </ol>"},{"location":"aca/10-aca-iac-bicep/#arm-templates-in-azure","title":"ARM Templates in Azure","text":"<p>ARM templates are files that define the infrastructure and configuration for your deployment. The templates use declarative syntax, which lets you state what you intend to deploy without having to write the sequence of programming commands to create it.</p> <p>Within Azure there are two ways to create IaC. We can either use the JSON ARM templates or Bicep (domain-specific language). As a project grows and the number of components and dependencies increases, working with JSON ARM templates in real-world scenarios can become increasingly complex and difficult to manage and maintain. Bicep provides a more user-friendly and straightforward experience when compared to ARM templates, resulting in increased productivity. However, it's worth noting that Bicep code is eventually compiled into ARM templates through a process called \"transpilation.\"</p> <p></p> <p>Tip</p> <p>For those interested in learning more about Bicep, it is recommended to visit the Microsoft Learn website Fundamentals of Bicep.</p>"},{"location":"aca/10-aca-iac-bicep/ci-cd-azdo/","title":"Deploy Infrastructure Using Azure DevOps","text":"<p>Module Duration</p> <p>30 minutes</p> <p>In the previous section, we demonstrated how Bicep scripts can be used to automate the deployment of infrastructure components. However, creating the container registry and deploying the Bicep scripts using the Azure CLI still required manual effort. For a more efficient and streamlined process, it's preferable to use automation. Azure DevOps is a great solution for automating workflows, and in this section, we'll explain how to create a Azure DevOps pipeline for deploying the infrastructure components of our application.</p> <p>The workshop repository contains a Azure Devops Pipeline yaml file that will be used to deploy the infrastructure components of our application. Follow the steps below to create a devops pipeline to deploy the infrastructure components of our application.</p> <p>Note</p> <pre><code>The following instructions assume that you will utilize the forked Github repository both as the host for your YAML pipeline and the source code. However, it is possible to host the same assets in your Azure DevOps repository instead, if that is your preference. It is important to remember that if you choose to store your assets in your Azure DevOps repository, you will have to direct your Azure DevOps pipeline towards the Azure DevOps repository instead of the Github repository.\n</code></pre>"},{"location":"aca/10-aca-iac-bicep/ci-cd-azdo/#fork-the-github-repository","title":"Fork the GitHub repository","text":"<p>Start by forking the workshop repository to your GitHub account. Follow the steps below to fork the workshop:</p> <ol> <li>Navigate to the workshop repository at  Azure/aca-dotnet-workshop</li> <li>Click the Fork button in the top-right corner of the page.</li> <li>Select your GitHub account to fork the repository to.</li> <li>Wait for the repository to be forked.</li> </ol>"},{"location":"aca/10-aca-iac-bicep/ci-cd-azdo/#configure-a-service-connection-for-github-and-azure-subscription","title":"Configure a Service Connection for GitHub and Azure Subscription","text":"<p>Before we start with creating pipeline, we need to configure service connection for GitHub and Azure Subscription. You can do this in either existing or new project.</p>"},{"location":"aca/10-aca-iac-bicep/ci-cd-azdo/#create-a-service-connection-for-github","title":"Create a Service Connection for GitHub","text":"<p>Provide access to the repository forked above by creating a service connection to GitHub. You create a new pipeline by first selecting a GitHub repository and then a YAML file in repository at path .ado/infra-deploy.yml.</p> <p>The repository in which the YAML file is present is called self repository. By default, this is the repository that your pipeline builds.</p> <p>There are three authentication types for granting Azure Pipelines access to your GitHub repositories while creating a pipeline. Follow guide at this link to create service connection for GitHub.</p> <p></p>"},{"location":"aca/10-aca-iac-bicep/ci-cd-azdo/#create-service-connection-for-azure-subscription","title":"Create Service Connection for Azure Subscription","text":"<p>Create a new service connection to your Azure subscription by following the steps at this link.</p> <p>Note</p> <p>Update the created service connection role to have User Access Administrator role. This is required for pipeline to be able to perform role assignments in the infrastructure components deployed. To update the role of a service connection in Azure DevOps to have the User Access Administrator role, you can follow these steps:</p> <ul> <li> <p>Navigate to the Azure portal and select the subscription where the service connection is created.</p> </li> <li> <p>Click on Access control (IAM) in the left-hand menu.</p> </li> <li> <p>Click on Add role assignment.</p> </li> <li> <p>For the Assignment type choose Privileged administrator roles.</p> </li> <li> <p>In the Role section choose User Access Administrator.</p> </li> <li> <p>In the Members section, search for the name of the service connection that you want to update and select it.</p> </li> <li> <p>Click Save to apply the changes.</p> </li> </ul>"},{"location":"aca/10-aca-iac-bicep/ci-cd-azdo/#configure-variable-group-under-azure-devops-library-section","title":"Configure Variable Group under Azure DevOps Library Section","text":"<p>Create a variable group named AcaApp under Library in your Azure Devops project. Make sure the pipeline has permissions to access the created variable group under Pipeline permissions.</p> <p>This variable group will be used to store below details:</p> <pre><code># AZURE_SUBSCRIPTION: Name of the service connection created for Azure Subscription\nAZURE_SUBSCRIPTION=&lt;service connection name&gt;\n\n# LOCATION: Azure region where resources will be deployed\nLOCATION=&lt;location&gt;\n\n# RESOURCE_GROUP: Name of the resource group which will be created and where the resources will be deployed\nRESOURCE_GROUP=&lt;resource group name&gt;\n\n# (OPTIONAL)CONTAINER_REGISTRY_NAME: Unique name of the container registry which will be created and where images will be imported\nCONTAINER_REGISTRY_NAME=&lt;container registry name&gt;\n</code></pre> <p>Note</p> <p>Repository variable <code>CONTAINER_REGISTRY_NAME</code> is only needed by pipeline if you intend to deploy images from a private Azure Container Registry (ACR). You may chose to skip defining this variable and the pipeline will use the public github container registry images to deploy the images.</p>"},{"location":"aca/10-aca-iac-bicep/ci-cd-azdo/#trigger-azure-devops-pipeline","title":"Trigger Azure Devops Pipeline","text":"<p>With these steps completed, you are now ready to trigger the Pipeline.</p> <p>Success</p> <p>Your Pipeline should be triggered and the infrastructure components of our application should be deployed successfully.</p> <p></p> Want to delete the resources deployed by the pipeline? <p>Trigger the pipeline again select checkbox option named Should teardown infrastructure?.</p> <p></p>"},{"location":"aca/10-aca-iac-bicep/ci-cd-git-action/","title":"Deploy Infrastructure Using GitHub Actions","text":"<p>Module Duration</p> <p>30 minutes</p> <p>In the previous section, we demonstrated how Bicep scripts can be used to automate the deployment of infrastructure components. However, creating the container registry and deploying the Bicep scripts using the Azure CLI still required manual effort. For a more efficient and streamlined process, it's preferable to use automation. GitHub Actions is a great solution for automating workflows, and in this section, we'll explain how to create a GitHub Action workflow for deploying the infrastructure components of our application.</p> <p>The workshop repository contains a GitHub Action workflow file that will be used to deploy the infrastructure components of our application. Follow the steps below to create a GitHub Action workflow to deploy the infrastructure components of our application.</p>"},{"location":"aca/10-aca-iac-bicep/ci-cd-git-action/#fork-the-github-repository","title":"Fork the GitHub repository","text":"<p>Start by forking the workshop repository to your GitHub account. Follow the steps below to fork the workshop:</p> <ol> <li>Navigate to the workshop repository at  Azure/aca-dotnet-workshop</li> <li>Click the Fork button in the top-right corner of the page.</li> <li>Select your GitHub account to fork the repository to.</li> <li>Wait for the repository to be forked.</li> </ol>"},{"location":"aca/10-aca-iac-bicep/ci-cd-git-action/#configure-repository-for-oidc-authentication-with-azure-ad","title":"Configure Repository for OIDC Authentication with Azure AD","text":"<p>In order to use the GitHub Actions workflow to deploy the infrastructure components of our application, we need to log in to Azure using the Azure CLI with Azure login action.</p> <p>The Azure login action supports two different ways of authenticating with Azure:</p> <ul> <li>Service principal with secrets</li> <li>OpenID Connect (OIDC) with a Azure service principal using a Federated Identity Credential</li> </ul> <p>In this workshop, we will use the OIDC authentication method. Assuming you are already logged in using Azure cli locally, follow the steps below to configure the repository for OIDC authentication with Azure AD either using powershell or bash/wsl:</p> PowerShellBash/WSL <ul> <li>Execute the following commands in PowerShell to create an Azure AD application and service principal.</li> </ul> <pre><code>$AZURE_TENANT = az account show -o tsv --query tenantId\n$SUBSCRIPTION_ID = az account show -o tsv --query id\n\n$APP_ID = az ad app create --display-name aca-dotnet-workshop-oidc --query appId -otsv\n\naz ad sp create --id $APP_ID --query appId -otsv\n\n$OBJECT_ID = az ad app show --id $APP_ID --query id -otsv\n</code></pre> <ul> <li>Execute below command to create a federated identity credential for the Azure AD application.</li> </ul> <p>Note</p> <p>Replace <code>&lt;Repo owner&gt;</code> in below json with your GitHub username where you forked the workshop repository.</p> <pre><code>az rest --method POST --uri \"https://graph.microsoft.com/beta/applications/$OBJECT_ID/federatedIdentityCredentials\" --body '{\\\"name\\\":\\\"aca-dotnet-workshop-federated-identity\\\",\\\"issuer\\\":\\\"https://token.actions.githubusercontent.com\\\",\\\"subject\\\":\\\"repo:&lt;Repo owner&gt;/aca-dotnet-workshop:ref:refs/heads/main\\\",\\\"description\\\":\\\"GitHub\\\",\\\"audiences\\\":[\\\"api://AzureADTokenExchange\\\"]}' --headers \"Content-Type=application/json\"\n</code></pre> <ul> <li>Perform role assignment for the Azure AD application to access the subscription.</li> </ul> <pre><code>az role assignment create --assignee $APP_ID --role contributor --scope /subscriptions/$SUBSCRIPTION_ID\naz role assignment create --assignee $APP_ID --role 'User Access Administrator' --scope /subscriptions/$SUBSCRIPTION_ID\n</code></pre> <ul> <li>Execute the following commands in PowerShell to create an Azure AD application and service principal.</li> </ul> <pre><code>AZURE_TENANT=$(az account show -o tsv --query tenantId)\nSUBSCRIPTION_ID=$(az account show -o tsv --query id)\n\nAPP_ID=$(az ad app create --display-name aca-dotnet-workshop-oidc --query appId -otsv)\n\naz ad sp create --id $APP_ID --query appId -otsv\n\nOBJECT_ID=$(az ad app show --id $APP_ID --query id -otsv)\n</code></pre> <ul> <li>Execute below command to create a federated identity credential for the Azure AD application.</li> </ul> <p>Note</p> <p>Replace <code>&lt;Repo owner&gt;</code> in below json with your GitHub username where you forked the workshop repository.</p> <pre><code>cat &lt;&lt;EOF &gt; body.json\n{\n    \"name\": \"aca-dotnet-workshop-federated-identity\",\n    \"issuer\": \"https://token.actions.githubusercontent.com\",\n    \"subject\": \"repo:&lt;Repo owner&gt;/aca-dotnet-workshop:ref:refs/heads/main\",\n    \"description\": \"GitHub\",\n    \"audiences\": [\n        \"api://AzureADTokenExchange\"\n    ]\n}\nEOF\n\naz rest --method POST --uri \"https://graph.microsoft.com/beta/applications/$OBJECT_ID/federatedIdentityCredentials\" --body @body.json\n</code></pre> <ul> <li>Perform role assignment for the Azure AD application to access the subscription.</li> </ul> <pre><code>az role assignment create --assignee $APP_ID --role contributor --scope /subscriptions/$SUBSCRIPTION_ID\naz role assignment create --assignee $APP_ID --role 'User Access Administrator' --scope /subscriptions/$SUBSCRIPTION_ID\n</code></pre>"},{"location":"aca/10-aca-iac-bicep/ci-cd-git-action/#configure-github-repository-secrets","title":"Configure GitHub Repository Secrets","text":"<p>Configure secrets details in GitHub repo as described here in create GitHub secrets. Use below values mapped to relevant secrets in GitHub.</p> <pre><code># AZURE_SUBSCRIPTION_ID\necho $SUBSCRIPTION_ID\n# AZURE_TENANT_ID\necho $AZURE_TENANT\n# AZURE_CLIENT_ID\necho $APP_ID\n</code></pre>"},{"location":"aca/10-aca-iac-bicep/ci-cd-git-action/#configure-github-repository-variables","title":"Configure GitHub Repository Variables","text":"<p>Configure repository variables in GitHub repo as described here in create GitHub variables. Use below values mapped to relevant variables in GitHub.</p> <pre><code># LOCATION: Azure region where resources will be deployed\nLOCATION=&lt;location. e.g. eastus&gt;\n\n# RESOURCE_GROUP: Name of the resource group which will be created and resources will be deployed\nRESOURCE_GROUP=&lt;resource group name&gt;\n\n# (OPTIONAL)CONTAINER_REGISTRY_NAME: Unique name of the container registry which will be created and where images will be imported\nCONTAINER_REGISTRY_NAME=&lt;container registry name&gt;\n</code></pre> <p>Note</p> <p>Repository variables <code>CONTAINER_REGISTRY_NAME</code> is only needed by workflow, if you wish the images to be deployed from private ACR.</p> <p>You may chose to skip defining this variable and the workflow will use the public github container registry images to deploy the images.</p>"},{"location":"aca/10-aca-iac-bicep/ci-cd-git-action/#trigger-github-actions-workflow","title":"Trigger GitHub Actions Workflow","text":"<p>With these steps completed, you are now ready to trigger the GitHub Actions workflow named Build and deploy infrastructure as code to Azure using workflow dispatch to deploy the infrastructure components of the application.</p> <p>Success</p> <p>Your GitHub Actions workflow should be triggered and the infrastructure components of our application should be deployed successfully.</p> <p></p> Want to delete the resources deployed by the workflow? <p>Trigger the workflow again using workflow dispatch and select checkbox option.</p> <p></p>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/","title":"Build the Infrastructure as Code Using Bicep","text":"<p>Module Duration</p> <p>30 minutes</p> <p>Note</p> <p>If you're not interested in manually deploying the Bicep files or creating the container registry yourself, and prefer not to delve into the details of how they work, then you can skip this section and head directly to either Deploy Infrastructure Using Github Actions or Deploy Infrastructure Using Azure DevOps depending on your DevOps tool of choice.</p> <p>To begin, we need to define the Bicep modules that will be required to generate the Infrastructure code. Our goal for this module is to have a freshly created resource group that encompasses all the necessary resources and configurations - such as connection strings, secrets, environment variables, and Dapr components - which we utilized to construct our solution. By the end, we will have a new resource group that includes the following resources.</p> <p></p> <p>Note</p> <p>To simplify the execution of the module, we will assume that you have already created latest images of three services and pushed them to a container registry. This section below guides you through different options of getting images pushed to either Azure Container Registry (ACR) or GitHub Container Registry (GHCR).</p>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/#1-add-the-needed-extension-to-vs-code","title":"1. Add the Needed Extension to VS Code","text":"<p>To proceed, you must install an extension called Bicep. This extension will simplify building Bicep files as it offers IntelliSense, Validation, listing all available resource types, etc..</p>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/#2-define-an-azure-container-apps-environment","title":"2. Define an Azure Container Apps Environment","text":"<p>Add a new folder named <code>bicep</code> on the root project directory, then add another folder named <code>modules</code>. Add file as shown below:</p> container-apps-environment.bicep <pre><code>targetScope = 'resourceGroup'\n\n// ------------------\n//    PARAMETERS\n// ------------------\n@description('The location where the resources will be created.')\nparam location string = resourceGroup().location\n\n@description('Optional. The tags to be assigned to the created resources.')\nparam tags object = {}\n\n@description('The name of the container apps environment. If set, it overrides the name generated by the template.')\nparam containerAppsEnvironmentName string \n\n@description('The name of the log analytics workspace. If set, it overrides the name generated by the template.')\nparam logAnalyticsWorkspaceName string \n\n@description(' The name of the application insights. If set, it overrides the name generated by the template.')\nparam applicationInsightName string \n\n\n// ------------------\n// RESOURCES\n// ------------------\nresource logAnalyticsWorkspace 'Microsoft.OperationalInsights/workspaces@2021-06-01' = {\n  name: logAnalyticsWorkspaceName\n  location: location\n  tags: tags\n  properties: any({\n    features: {\n      searchVersion: 1\n    }\n    sku: {\n      name: 'PerGB2018'\n    }\n    retentionInDays: 30\n  })\n}\n\nresource applicationInsights 'Microsoft.Insights/components@2020-02-02' = {\n  name: applicationInsightName\n  location: location\n  tags: tags\n  kind: 'web'\n  properties: {\n    Application_Type: 'web'\n    WorkspaceResourceId: logAnalyticsWorkspace.id\n  }\n}\n\nresource containerAppsEnvironment 'Microsoft.App/managedEnvironments@2022-10-01' = {\n  name: containerAppsEnvironmentName\n  location: location\n  tags: tags\n  sku: {\n    name: 'Consumption'\n  }\n  properties: {\n    daprAIInstrumentationKey: applicationInsights.properties.InstrumentationKey\n    appLogsConfiguration: {\n      destination: 'log-analytics'\n      logAnalyticsConfiguration: {\n        customerId: logAnalyticsWorkspace.properties.customerId\n        sharedKey:  logAnalyticsWorkspace.listKeys().primarySharedKey\n      }\n    }\n  }\n}\n\n// ------------------\n// OUTPUTS\n// ------------------\n\n@description('The name of the application insights.')\noutput applicationInsightsName string  = applicationInsights.name\n</code></pre> What we've added in the Bicep file above <ul> <li>The module takes multiple parameters, all of which are set to default values. This indicates that if no value is specified, the default value will be utilized.</li> <li>The <code>location</code> parameter defaults to the location of the container resource group. Bicep has a function called <code>resourceGroup()</code>, which can be used to retrieve the location.</li> <li>The parameters <code>prefix</code> and <code>suffix</code> could be used if you want to add a prefix or suffix to the resource names.</li> <li>The parameter <code>tag</code> is used to tag the created resources. Tags are key-value pairs that help you identify resources based on settings that are relevant to your organization and deployment.</li> <li>The parameters <code>containerAppsEnvironmentName</code>, <code>logAnalyticsWorkspaceName</code>, and <code>applicationInsightName</code> have default values of resource names using the helper function named <code>uniqueString</code>. This function performs a 64-bit hash of the provided strings to create a unique string. This function is helpful when you need to create a unique name for a resource. We are passing the <code>resourceGroup().id</code> to this function to ensure that if we executed this module on two different resource groups, the generated string will be a global unique name.</li> <li>This module will create two resources. It will start by creating a <code>logAnalyticsWorkspace</code>, then an <code>applicationInsights</code> resource. Notice how we are setting the <code>logAnalyticsWorkspace.id</code> as an Application Insights <code>WorkspaceResourceId</code>.</li> <li>Lastly we are creating the <code>containerAppsEnvironment</code>. Notice how we are setting the <code>daprAIInstrumentationKey</code> by using the Application Insights <code>InstrumentationKey</code> and then setting <code>logAnalyticsConfiguration.customerId</code> and <code>logAnalyticsConfiguration.sharedKey</code>.</li> <li>The output of this module are a is parameter named <code>applicationInsightsName</code>. This output is needed as an input for a subsequent module.</li> </ul>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/#3-define-an-azure-key-vault-resource","title":"3. Define an Azure Key Vault Resource","text":"<p>Add file as shown below under the folder <code>bicep\\modules</code>:</p> key-vault.bicep <pre><code>targetScope = 'resourceGroup'\n\n// ------------------\n//    PARAMETERS\n// ------------------\n\n@description('The location where the resources will be created.')\nparam location string = resourceGroup().location\n\n@description('The name of the Key Vault. If set, it overrides the name generated by the template.')\nparam KEYVAULT_NAME string\n\n@description('Optional. The tags to be assigned to the created resources.')\nparam tags object = {}\n\n// ------------------\n// RESOURCES\n// ------------------\n\nresource keyVault 'Microsoft.KeyVault/vaults@2022-07-01' = {\n  name: KEYVAULT_NAME\n  location: location  \n  tags: tags\n  properties: {\n    tenantId: subscription().tenantId\n    sku: {\n      family: 'A'\n      name: 'standard'\n    }\n    enableSoftDelete: false\n    softDeleteRetentionInDays: 7\n    enablePurgeProtection: null  // It seems that you cannot set it to False even the first time. workaround is not to set it at all: https://github.com/Azure/bicep/issues/5223\n    enableRbacAuthorization: true\n    enabledForTemplateDeployment: true\n  }\n}\n\n// ------------------\n// OUTPUTS\n// ------------------\n\n@description('The resource ID of the key vault.')\noutput keyVaultId string = keyVault.id\n</code></pre> What we've added in the Bicep file above <ul> <li>This module will create the Azure Key Vault resource which will be used to store secrets.</li> <li>The output of this module is a single parameter named <code>keyVaultId</code>. This output is needed as an input for a subsequent module.</li> </ul>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/#4-define-a-azure-service-bus-resource","title":"4. Define a Azure Service Bus Resource","text":"<p>Add file as shown below under the folder <code>bicep\\modules</code>:</p> service-bus.bicep <pre><code>targetScope = 'resourceGroup'\n\n// ------------------\n//    PARAMETERS\n// ------------------\n\n@description('The location where the resources will be created.')\nparam location string = resourceGroup().location\n\n@description('Optional. The name of the service bus namespace. If set, it overrides the name generated by the template.')\nparam serviceBusName string\n\n@description('Optional. The tags to be assigned to the created resources.')\nparam tags object = {}\n\n@description('The name of the service bus topic.')\nparam serviceBusTopicName string\n\n@description('The name of the service bus topic\\'s authorization rule.')\nparam serviceBusTopicAuthorizationRuleName string\n\n@description('The name of the service for the backend processor service. The name is used as Dapr App ID and as the name of service bus topic subscription.')\nparam backendProcessorServiceName string\n\n// ------------------\n// RESOURCES\n// ------------------\n\nresource serviceBusNamespace 'Microsoft.ServiceBus/namespaces@2021-11-01' = {\n  name: serviceBusName\n  location: location\n  tags: tags\n  sku: {\n    name: 'Standard'\n  }\n}\n\nresource serviceBusTopic 'Microsoft.ServiceBus/namespaces/topics@2021-11-01' = {\n  name: serviceBusTopicName\n  parent: serviceBusNamespace\n}\n\nresource serviceBusTopicAuthRule 'Microsoft.ServiceBus/namespaces/topics/authorizationRules@2021-11-01' = {\n  name: serviceBusTopicAuthorizationRuleName\n  parent: serviceBusTopic\n  properties: {\n    rights: [\n      'Manage'\n      'Send'\n      'Listen'\n    ]\n  }\n}\n\nresource serviceBusTopicSubscription 'Microsoft.ServiceBus/namespaces/topics/subscriptions@2022-10-01-preview' = {\n  name: backendProcessorServiceName\n  parent: serviceBusTopic\n}\n\n// ------------------\n// OUTPUTS\n// ------------------\n\n@description('The name of the service bus namespace.')\noutput serviceBusName string = serviceBusNamespace.name\n\n@description('The name of the service bus topic.')\noutput serviceBusTopicName string = serviceBusTopic.name\n\n@description('The name of the service bus topic\\'s authorization rule.')\noutput serviceBusTopicAuthorizationRuleName string = serviceBusTopicAuthRule.name\n</code></pre> What we've added in the Bicep file above <ul> <li>This module will create the Azure Service resource, a topic, a subscription for the consumer, and an authorization rule with <code>Manage</code> permissions.</li> <li>The output of this module will return three output parameters which will be used as an input for a subsequent module.</li> </ul>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/#5-define-an-azure-cosmosdb-resource","title":"5. Define an Azure CosmosDb Resource","text":"<p>Add file as shown below under the folder <code>bicep\\modules</code>:</p> cosmos-db.bicep <pre><code>targetScope = 'resourceGroup'\n\n// ------------------\n//    PARAMETERS\n// ------------------\n\n@description('The location where the resources will be created.')\nparam location string = resourceGroup().location\n\n@description('Optional. The tags to be assigned to the created resources.')\nparam tags object = {}\n\n@description('The name of Cosmos DB resource.')\nparam cosmosDbName string\n\n@description('The name of Cosmos DB\\'s database.')\nparam cosmosDbDatabaseName string\n\n@description('The name of Cosmos DB\\'s collection.')\nparam cosmosDbCollectionName string\n\n// ------------------\n// RESOURCES\n// ------------------\nresource cosmosDbAccount 'Microsoft.DocumentDB/databaseAccounts@2022-08-15' = {\n  name: cosmosDbName\n  location: location\n  tags: tags\n  kind: 'GlobalDocumentDB'\n  properties: {\n    locations: [\n      {\n        locationName: location\n        failoverPriority: 0\n        isZoneRedundant: false\n      }\n    ]\n    databaseAccountOfferType: 'Standard'\n    publicNetworkAccess:'Enabled'\n  }\n}\n\nresource cosmosDbDatabase 'Microsoft.DocumentDB/databaseAccounts/sqlDatabases@2021-04-15' = {\n  name: cosmosDbDatabaseName\n  parent: cosmosDbAccount\n  tags: tags\n  properties: {\n    resource: {\n      id: cosmosDbDatabaseName\n    }\n  }\n}\n\nresource cosmosDbDatabaseCollection 'Microsoft.DocumentDB/databaseAccounts/sqlDatabases/containers@2021-05-15' = {\n  name: cosmosDbCollectionName\n  parent: cosmosDbDatabase\n  tags: tags\n  properties: {\n    resource: {\n      id: cosmosDbCollectionName\n      partitionKey: {\n        paths: [\n          '/partitionKey'\n        ]\n        kind: 'Hash'\n      }\n    }\n    options: {\n      autoscaleSettings: {\n        maxThroughput: 4000\n      }\n    }\n  }\n}\n\n// ------------------\n// OUTPUTS\n// ------------------\n\n@description('The name of Cosmos DB resource.')\noutput cosmosDbName string = cosmosDbAccount.name\n@description('The name of Cosmos DB\\'s database.')\noutput cosmosDbDatabaseName string = cosmosDbDatabase.name\n@description('The name of Cosmos DB\\'s collection.')\noutput cosmosDbCollectionName string = cosmosDbDatabaseCollection.name\n</code></pre> What we've added in the Bicep file above <ul> <li>This module will create the Azure Cosmos DB account, a Cosmos DB database, and a Cosmos DB collection.</li> <li>The output of this module will return three output parameters which will be used as an input for a subsequent module.</li> </ul>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/#6-define-an-azure-storage-resource","title":"6. Define an Azure Storage Resource","text":"<p>Add file as shown below under the folder <code>bicep\\modules</code>:</p> storage-account.bicep <pre><code>targetScope = 'resourceGroup'\n\n// ------------------\n//    PARAMETERS\n// ------------------\n\n@description('The location where the resources will be created.')\nparam location string = resourceGroup().location\n\n@description('Optional. The tags to be assigned to the created resources.')\nparam tags object = {}\n\n@description('The name of the external Azure Storage Account.')\nparam storageAccountName string\n\n@description('The name of the external Queue in Azure Storage.')\nparam externalTasksQueueName string\n\n// ------------------\n// RESOURCES\n// ------------------\n\nresource storageAccount 'Microsoft.Storage/storageAccounts@2021-09-01' = {\n  name: storageAccountName\n  tags: tags\n  location: location\n  sku: {\n    name: 'Standard_LRS'\n  }\n  kind: 'StorageV2'\n}\n\nresource storageQueuesService 'Microsoft.Storage/storageAccounts/queueServices@2021-09-01' = {\n  name: 'default'\n  parent: storageAccount\n}\n\nresource externalQueue 'Microsoft.Storage/storageAccounts/queueServices/queues@2021-09-01' = {\n  name: externalTasksQueueName\n  parent: storageQueuesService\n}\n\n// ------------------\n// OUTPUTS\n// ------------------\n\n@description('The external storage account name.')\noutput storageAccountName string = storageAccount.name\n</code></pre> What we've added in the Bicep file above <ul> <li>This module will create the Azure Storage account, a storage queue service, and a queue.</li> <li>The output of this module will be a single output parameter which will be used as an input for a subsequent module.</li> </ul>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/#7-define-dapr-components","title":"7. Define Dapr Components","text":"<p>Next we will define all dapr components used in the solution in a single bicep module. To accomplish this, add a new file under the folder <code>bicep\\modules</code> as shown below:</p> dapr-components.bicep <pre><code>targetScope = 'resourceGroup'\n\n// ------------------\n//    PARAMETERS\n// ------------------\n\n@description('The name of the container apps environment.')\nparam containerAppsEnvironmentName string\n\n@description('The name of Dapr component for the secret store building block.')\n// We disable lint of this line as it is not a secret but the name of the Dapr component\n#disable-next-line secure-secrets-in-params\nparam secretStoreComponentName string\n\n@description('The name of the key vault resource.')\nparam KEYVAULT_NAME string\n\n@description('The name of the service bus namespace.')\nparam serviceBusName string\n\n@description('The name of Cosmos DB resource.')\nparam cosmosDbName string\n\n@description('The name of Cosmos DB\\'s database.')\nparam cosmosDbDatabaseName string\n\n@description('The name of Cosmos DB\\'s collection.')\nparam cosmosDbCollectionName string\n\n@description('The name of the external Azure Storage Account.')\nparam storageAccountName string\n\n@description('The name of the external Queue in Azure Storage.')\nparam externalTasksQueueName string\n\n@description('The name of the external blob container in Azure Storage.')\nparam externalTasksContainerBlobName string\n\n@description('The name of the secret containing the External Azure Storage Access key.')\nparam externalStorageKeySecretName string\n\n@description('The name of the Send Grid Email From.')\nparam sendGridEmailFrom string\n\n@description('The name of the Send Grid Email From Name.')\nparam sendGridEmailFromName string\n\n@description('The name of the secret containing the SendGrid API key value.')\nparam sendGridKeySecretName string\n\n@description('The cron settings for scheduled job.')\nparam scheduledJobCron string \n\n@description('The name of the service for the backend api service. The name is used as Dapr App ID.')\nparam backendApiServiceName string\n\n@description('The name of the service for the backend processor service. The name is used as Dapr App ID and as the name of service bus topic subscription.')\nparam backendProcessorServiceName string\n\n// ------------------\n// RESOURCES\n// ------------------\n\nresource containerAppsEnvironment 'Microsoft.App/managedEnvironments@2022-03-01' existing = {\n  name: containerAppsEnvironmentName\n}\n\nresource cosmosDbAccount 'Microsoft.DocumentDB/databaseAccounts@2022-08-15' existing = {\n  name: cosmosDbName\n}\n\n//Secret Store Component\nresource secretstoreComponent 'Microsoft.App/managedEnvironments/daprComponents@2022-03-01' = {\n  name: secretStoreComponentName\n  parent: containerAppsEnvironment\n  properties: {\n    componentType: 'secretstores.azure.keyvault'\n    version: 'v1'\n    metadata: [\n      {\n        name: 'vaultName'\n        value: KEYVAULT_NAME\n      }\n    ]\n    scopes: [\n      backendApiServiceName\n      backendProcessorServiceName\n    ]\n  }\n}\n\n//Cosmos DB State Store Component\nresource statestoreComponent 'Microsoft.App/managedEnvironments/daprComponents@2022-06-01-preview' = {\n  name: 'statestore'\n  parent: containerAppsEnvironment\n  properties: {\n    componentType: 'state.azure.cosmosdb'\n    version: 'v1'\n    secrets: [\n    ]\n    metadata: [\n      {\n        name: 'url'\n        value: cosmosDbAccount.properties.documentEndpoint\n      }\n      {\n        name: 'database'\n        value: cosmosDbDatabaseName\n      }\n      {\n        name: 'collection'\n        value: cosmosDbCollectionName\n      }\n    ]\n    scopes: [\n      backendApiServiceName\n    ]\n  }\n}\n\n//PubSub service bus Component\nresource pubsubComponent 'Microsoft.App/managedEnvironments/daprComponents@2022-06-01-preview' = {\n  name: 'dapr-pubsub-servicebus'\n  parent: containerAppsEnvironment\n  properties: {\n    componentType: 'pubsub.azure.servicebus'\n    version: 'v1'\n    secrets: [\n    ]\n    metadata: [\n      {\n        name: 'namespaceName'\n        value: '${serviceBusName}.servicebus.windows.net'\n      }\n      {\n        name: 'consumerID'\n        value: backendProcessorServiceName\n      }\n    ]\n    scopes: [\n      backendApiServiceName\n      backendProcessorServiceName\n    ]\n  }\n}\n\n//Scheduled Tasks Manager Component\nresource scheduledtasksmanagerDaprComponent 'Microsoft.App/managedEnvironments/daprComponents@2022-06-01-preview' = {\n  name: 'scheduledtasksmanager'\n  parent: containerAppsEnvironment\n  properties: {\n    componentType: 'bindings.cron'\n    version: 'v1'\n    metadata: [\n      {\n        name: 'schedule'\n        value: scheduledJobCron\n      }\n    ]\n    scopes: [\n      backendProcessorServiceName\n    ]\n  }\n}\n\n//External tasks manager Component (Storage Queue)\nresource externaltasksmanagerDaprComponent 'Microsoft.App/managedEnvironments/daprComponents@2022-06-01-preview' = {\n  name: 'externaltasksmanager'\n  parent: containerAppsEnvironment\n  properties: {\n    componentType: 'bindings.azure.storagequeues'\n    version: 'v1'\n    secretStoreComponent: secretStoreComponentName\n    metadata: [\n      {\n        name: 'storageAccount'\n        value: storageAccountName\n      }\n      {\n        name: 'queue'\n        value: externalTasksQueueName\n      }\n      {\n        name: 'decodeBase64'\n        value: 'true'\n      }\n      {\n        name: 'route'\n        value: '/externaltasksprocessor/process'\n      }\n      {\n        name: 'storageAccessKey'\n        secretRef: externalStorageKeySecretName\n      }\n    ]\n    scopes: [\n      backendProcessorServiceName\n    ]\n  }\n  dependsOn: [\n    secretstoreComponent\n  ]\n}\n\n//External tasks blob store Component (Blob Store)\nresource externaltasksblobstoreDaprComponent 'Microsoft.App/managedEnvironments/daprComponents@2022-06-01-preview' = {\n  name: 'externaltasksblobstore'\n  parent: containerAppsEnvironment\n  properties: {\n    componentType: 'bindings.azure.blobstorage'\n    version: 'v1'\n    secretStoreComponent: secretStoreComponentName\n    metadata: [\n      {\n        name: 'storageAccount'\n        value: storageAccountName\n      }\n      {\n        name: 'container'\n        value: externalTasksContainerBlobName\n      }\n      {\n        name: 'decodeBase64'\n        value: 'false'\n      }\n      {\n        name: 'publicAccessLevel'\n        value: 'none'\n      }\n      {\n        name: 'storageAccessKey'\n        secretRef: externalStorageKeySecretName\n      }\n    ]\n    scopes: [\n      backendProcessorServiceName\n    ]\n  }\n  dependsOn: [\n    secretstoreComponent\n  ]\n}\n\n//SendGrid outbound Component\nresource sendgridDaprComponent 'Microsoft.App/managedEnvironments/daprComponents@2022-06-01-preview' = {\n  name: 'sendgrid'\n  parent: containerAppsEnvironment\n  properties: {\n    componentType: 'bindings.twilio.sendgrid'\n    version: 'v1'\n    secretStoreComponent: secretStoreComponentName\n    metadata: [\n      {\n        name: 'emailFrom'\n        value: sendGridEmailFrom\n      }\n      {\n        name: 'emailFromName'\n        value: sendGridEmailFromName\n      }\n      {\n        name: 'apiKey'\n        secretRef: sendGridKeySecretName\n      }\n    ]\n    scopes: [\n      backendProcessorServiceName\n    ]\n  }\n  dependsOn:[\n    secretstoreComponent\n  ]\n}\n</code></pre> What we've added in the Bicep file above <ul> <li>This module will be responsible for creating all dapr components used in the solution. It accepts various input parameters needed by the dapr components.</li> <li> <p>Notice how we are using the keyword <code>existing</code> to obtain a strongly typed reference to the pre-created resource</p> <pre><code>resource containerAppsEnvironment 'Microsoft.App/managedEnvironments@2022-03-01' existing = {\nname: containerAppsEnvironmentName\n}\n\nresource cosmosDbAccount 'Microsoft.DocumentDB/databaseAccounts@2022-08-15' existing = {\nname: cosmosDbName\n}\n</code></pre> </li> </ul>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/#8-create-secrets-into-azure-key-vault","title":"8. Create Secrets Into Azure Key Vault","text":"<p>This module will have the responsibility of generating the secrets and saving them in Azure Key Vault. Additionally, it will establish a role assignment for the backend processor service, specifically of type <code>Azure Role Key Vault Secrets User</code>, which will allow the service to access the Key Vault and retrieve the secrets.</p> <p>To achieve this, create a new directory called <code>container-apps\\secrets</code> within the <code>modules</code> folder. Add new file as shown below under the folder <code>bicep\\modules\\container-apps\\secrets</code>:</p> processor-backend-service-secrets.bicep <pre><code>targetScope = 'resourceGroup'\n\n// ------------------\n//    PARAMETERS\n// ------------------\n\n@description('Optional. The tags to be assigned to the created resources.')\nparam tags object = {}\n\n@description('The name of the Key Vault.')\nparam KEYVAULT_NAME string\n\n@description('The name of the secret containing the SendGrid API key value for the Backend Background Processor Service.')\nparam sendGridKeySecretName string\n\n@secure()\n@description('The SendGrid API key for for Backend Background Processor Service.')\nparam sendGridKeySecretValue string\n\n@description('The name of the secret containing the External Azure Sorage Access key for the Backend Background Processor Service.')\nparam externalAzureStorageKeySecretName string\n\n@secure()\n@description('The External Azure Stroage Access key for the Backend Background Processor Service.')\nparam externalAzureStorageKeySecretValue string\n\n@description('The principal ID of the Backend Processor Service.')\nparam backendProcessorServicePrincipalId string\n\n// ------------------\n// VARIABLES\n// ------------------\n\nvar keyVaultSecretUserRoleGuid = '4633458b-17de-408a-b874-0445c86b69e6'\n\nvar sendGridKey = empty(sendGridKeySecretValue) ? 'dummy' : sendGridKeySecretValue\n\n// ------------------\n// RESOURCES\n// ------------------\n\nresource keyVault 'Microsoft.KeyVault/vaults@2021-04-01-preview' existing = {\n  name: KEYVAULT_NAME\n}\n\n// Send Grid API key secret used by Backend Background Processor Service.\nresource sendGridKeySecret 'Microsoft.KeyVault/vaults/secrets@2022-07-01' = {\n  parent: keyVault\n  tags: tags\n  name: sendGridKeySecretName\n  properties: {\n    value: sendGridKey\n  }\n}\n\n// External Azure storage key secret used by Backend Background Processor Service.\nresource externalAzureStorageKeySecret 'Microsoft.KeyVault/vaults/secrets@2022-07-01' = {\n  parent: keyVault\n  tags: tags\n  name: externalAzureStorageKeySecretName\n  properties: {\n    value: externalAzureStorageKeySecretValue\n  }\n}\n\nresource keyVaultSecretUserRoleAssignment 'Microsoft.Authorization/roleAssignments@2022-04-01' = {\n  name: guid(subscription().id, keyVault.id, backendProcessorServicePrincipalId, keyVaultSecretUserRoleGuid) \n  scope: keyVault\n  properties: {\n    principalId: backendProcessorServicePrincipalId\n    roleDefinitionId: resourceId('Microsoft.Authorization/roleDefinitions', keyVaultSecretUserRoleGuid)\n    principalType: 'ServicePrincipal'\n  }\n}\n</code></pre>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/#9-define-the-frontend-service-azure-container-app","title":"9. Define the Frontend Service Azure Container App","text":"<p>We will now begin defining the modules that are necessary for producing the container apps, starting with the Frontend App. To initiate this process, add a new file under the folder <code>bicep\\modules\\container-apps</code> as shown below:</p> webapp-frontend-service.bicep <pre><code>targetScope = 'resourceGroup'\n\n// ------------------\n//    PARAMETERS\n// ------------------\n\n@description('The location where the resources will be created.')\nparam location string = resourceGroup().location\n\n@description('Optional. The tags to be assigned to the created resources.')\nparam tags object = {}\n\n@description('The resource Id of the container apps environment.')\nparam containerAppsEnvironmentId string\n\n@description('The name of the service for the frontend web app service. The name is use as Dapr App ID.')\nparam frontendWebAppServiceName string\n\n// Container Registry &amp; Image\n@description('The name of the container registry.')\nparam containerRegistryName string\n\n@description('The resource ID of the user assigned managed identity for the container registry to be able to pull images from it.')\nparam containerRegistryUserAssignedIdentityId string\n\n@description('The image for the frontend web app service.')\nparam frontendWebAppServiceImage string\n\n@secure()\n@description('The Application Insights Instrumentation.')\nparam appInsightsInstrumentationKey string\n\n@description('The target and dapr port for the frontend web app service.')\nparam frontendWebAppPortNumber int\n\n// ------------------\n// RESOURCES\n// ------------------\n\nresource frontendWebAppService 'Microsoft.App/containerApps@2022-06-01-preview' = {\n  name: frontendWebAppServiceName\n  location: location\n  tags: tags\n  identity: {\n    type: 'UserAssigned'\n    userAssignedIdentities: {\n        '${containerRegistryUserAssignedIdentityId}': {}\n    }\n  }\n  properties: {\n    managedEnvironmentId: containerAppsEnvironmentId\n    configuration: {\n      activeRevisionsMode: 'single'\n      ingress: {\n        external: true\n        targetPort: frontendWebAppPortNumber\n      }\n      dapr: {\n        enabled: true\n        appId: frontendWebAppServiceName\n        appProtocol: 'http'\n        appPort: frontendWebAppPortNumber\n        logLevel: 'info'\n        enableApiLogging: true\n      }\n      secrets: [\n        {\n          name: 'appinsights-key'\n          value: appInsightsInstrumentationKey\n        }\n      ]\n      registries: !empty(containerRegistryName) ? [\n        {\n          server: '${containerRegistryName}.azurecr.io'\n          identity: containerRegistryUserAssignedIdentityId\n        }\n      ] : []\n    }\n    template: {\n      containers: [\n        {\n          name: frontendWebAppServiceName\n          image: frontendWebAppServiceImage\n          resources: {\n            cpu: json('0.25')\n            memory: '0.5Gi'\n          }\n          env: [\n            {\n              name: 'ApplicationInsights__InstrumentationKey'\n              secretRef: 'appinsights-key'\n            }\n          ]\n        }\n      ]\n      scale: {\n        minReplicas: 1\n        maxReplicas: 1\n      }\n    }\n  }\n}\n\n// ------------------\n// OUTPUTS\n// ------------------\n\n@description('The name of the container app for the frontend web app service.')\noutput frontendWebAppServiceContainerAppName string = frontendWebAppService.name\n\n@description('The FQDN of the frontend web app service.')\noutput frontendWebAppServiceFQDN string = frontendWebAppService.properties.configuration.ingress.fqdn\n</code></pre> What we've added in the Bicep file above <ul> <li>Observe the usage of the <code>@secure</code> attribute on input parameters that contain confidential information or keys. This attribute may be applied to both string and object parameters that encompass secretive values. By implementing this attribute, Azure will abstain from presenting the parameter values within the deployment logs or on the terminal if you happen to be utilizing Azure CLI.</li> <li>The output parameters of this module will provide the fully qualified domain name (FQDN) for the frontend container application.</li> </ul>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/#10-define-the-backend-api-service-azure-container-app","title":"10. Define the Backend Api Service Azure Container App","text":"<p>Add a new file under the folder <code>bicep\\modules\\container-apps</code> as shown below:</p> webapi-backend-service.bicep <pre><code>targetScope = 'resourceGroup'\n\n// ------------------\n//    PARAMETERS\n// ------------------\n\n@description('The location where the resources will be created.')\nparam location string = resourceGroup().location\n\n@description('Optional. The tags to be assigned to the created resources.')\nparam tags object = {}\n\n@description('The resource Id of the container apps environment.')\nparam containerAppsEnvironmentId string\n\n@description('The name of the service for the backend api service. The name is use as Dapr App ID.')\nparam backendApiServiceName string\n\n// Service Bus\n@description('The name of the service bus namespace.')\nparam serviceBusName string\n\n@description('The name of the service bus topic.')\nparam serviceBusTopicName string\n\n// Cosmos DB\n@description('The name of the provisioned Cosmos DB resource.')\nparam cosmosDbName string \n\n@description('The name of the provisioned Cosmos DB\\'s database.')\nparam cosmosDbDatabaseName string\n\n@description('The name of Cosmos DB\\'s collection.')\nparam cosmosDbCollectionName string\n\n// Container Registry &amp; Image\n@description('The name of the container registry.')\nparam containerRegistryName string\n\n@description('The resource ID of the user assigned managed identity for the container registry to be able to pull images from it.')\nparam containerRegistryUserAssignedIdentityId string\n\n@description('The image for the backend api service.')\nparam backendApiServiceImage string\n\n@secure()\n@description('The Application Insights Instrumentation.')\nparam appInsightsInstrumentationKey string\n\n@description('The target and dapr port for the backend api service.')\nparam backendApiPortNumber int\n\n// ------------------\n// RESOURCES\n// ------------------\n\nresource serviceBusNamespace 'Microsoft.ServiceBus/namespaces@2021-11-01' existing = {\n  name: serviceBusName\n}\n\nresource serviceBusTopic 'Microsoft.ServiceBus/namespaces/topics@2021-11-01' existing = {\n  name: serviceBusTopicName\n  parent: serviceBusNamespace\n}\n\nresource cosmosDbAccount 'Microsoft.DocumentDB/databaseAccounts@2022-08-15' existing = {\n  name: cosmosDbName\n}\n\nresource cosmosDbDatabase 'Microsoft.DocumentDB/databaseAccounts/sqlDatabases@2021-04-15' existing = {\n  name: cosmosDbDatabaseName\n  parent: cosmosDbAccount\n}\n\nresource cosmosDbDatabaseCollection 'Microsoft.DocumentDB/databaseAccounts/sqlDatabases/containers@2021-05-15' existing = {\n  name: cosmosDbCollectionName\n  parent: cosmosDbDatabase\n}\n\nresource backendApiService 'Microsoft.App/containerApps@2022-06-01-preview' = {\n  name: backendApiServiceName\n  location: location\n  tags: tags\n  identity: {\n    type: 'SystemAssigned,UserAssigned'\n    userAssignedIdentities: {\n        '${containerRegistryUserAssignedIdentityId}': {}\n    }\n  }\n  properties: {\n    managedEnvironmentId: containerAppsEnvironmentId\n    configuration: {\n      activeRevisionsMode: 'single'\n      ingress: {\n        external: false\n        targetPort: backendApiPortNumber\n      }\n      dapr: {\n        enabled: true\n        appId: backendApiServiceName\n        appProtocol: 'http'\n        appPort: backendApiPortNumber\n        logLevel: 'info'\n        enableApiLogging: true\n      }\n      registries: !empty(containerRegistryName) ? [\n        {\n          server: '${containerRegistryName}.azurecr.io'\n          identity: containerRegistryUserAssignedIdentityId\n        }\n      ] : []\n      secrets: [\n        {\n          name: 'appinsights-key'\n          value: appInsightsInstrumentationKey\n        }\n      ]\n    }\n    template: {\n      containers: [\n        {\n          name: backendApiServiceName\n          image: backendApiServiceImage\n          resources: {\n            cpu: json('0.25')\n            memory: '0.5Gi'\n          }\n          env: [\n            {\n              name: 'ApplicationInsights__InstrumentationKey'\n              secretRef: 'appinsights-key'\n            }\n          ]\n        }\n      ]\n      scale: {\n        minReplicas: 1\n        maxReplicas: 1\n      }\n    }\n  }\n}\n\n// Assign cosmosdb account read/write access to aca system assigned identity\n// To know more: https://learn.microsoft.com/en-us/azure/cosmos-db/how-to-setup-rbac\nresource backendApiService_cosmosdb_role_assignment 'Microsoft.DocumentDB/databaseAccounts/sqlRoleAssignments@2022-08-15' = {\n  name: guid(subscription().id, backendApiService.name, '00000000-0000-0000-0000-000000000002')\n  parent: cosmosDbAccount\n  properties: {\n    principalId: backendApiService.identity.principalId\n    roleDefinitionId:  resourceId('Microsoft.DocumentDB/databaseAccounts/sqlRoleDefinitions', cosmosDbAccount.name, '00000000-0000-0000-0000-000000000002')//DocumentDB Data Contributor\n    scope: '${cosmosDbAccount.id}/dbs/${cosmosDbDatabase.name}/colls/${cosmosDbDatabaseCollection.name}'\n  }\n}\n\n// Enable publish message to Service Bus using app managed identity.\nresource backendApiService_sb_role_assignment 'Microsoft.Authorization/roleAssignments@2020-04-01-preview' = {\n  name: guid(resourceGroup().id, backendApiService.name, '69a216fc-b8fb-44d8-bc22-1f3c2cd27a39')\n  properties: {\n    principalId: backendApiService.identity.principalId\n    roleDefinitionId: resourceId('Microsoft.Authorization/roleDefinitions', '69a216fc-b8fb-44d8-bc22-1f3c2cd27a39')//Azure Service Bus Data Sender\n    principalType: 'ServicePrincipal'\n  }\n  scope: serviceBusTopic\n}\n\n// ------------------\n// OUTPUTS\n// ------------------\n\n@description('The name of the container app for the backend api service.')\noutput backendApiServiceContainerAppName string = backendApiService.name\n\n@description('The FQDN of the backend api service.')\noutput backendApiServiceFQDN string = backendApiService.properties.configuration.ingress.fqdn\n</code></pre> What we've added in the Bicep file above <ul> <li> <p>Notice how we are assigning the Cosmosdb account a read/write access using the <code>Cosmos DB Built-in Data Contributor</code> role to the Backend API system assigned identity, by using the code below:</p> <pre><code>resource backendApiService_cosmosdb_role_assignment 'Microsoft.DocumentDB/databaseAccounts/sqlRoleAssignments@2022-08-15' = {\nname: guid(subscription().id, backendApiService.name, '00000000-0000-0000-0000-000000000002')\nparent: cosmosDbAccount\nproperties: {\n    principalId: backendApiService.identity.principalId\n    roleDefinitionId:  resourceId('Microsoft.DocumentDB/databaseAccounts/sqlRoleDefinitions', cosmosDbAccount.name, '00000000-0000-0000-0000-000000000002')//DocumentDB Data Contributor\n    scope: '${cosmosDbAccount.id}/dbs/${cosmosDbDatabase.name}/colls/${cosmosDbDatabaseCollection.name}'\n}\n</code></pre> </li> <li> <p>A similar technique was applied when assigning the Azure Service Bus Data Sender role to the Backend API, enabling it to publish messages to Azure Service Bus utilizing the Backend API system-assigned identity. This was accomplished utilizing the following code:     <pre><code>resource backendApiService_sb_role_assignment 'Microsoft.Authorization/roleAssignments@2020-04-01-preview' = {\nname: guid(resourceGroup().id, backendApiService.name, '69a216fc-b8fb-44d8-bc22-1f3c2cd27a39')\nproperties: {\n    principalId: backendApiService.identity.principalId\n    roleDefinitionId: resourceId('Microsoft.Authorization/roleDefinitions', '69a216fc-b8fb-44d8-bc22-1f3c2cd27a39')//Azure Service Bus Data Sender\n    principalType: 'ServicePrincipal'\n}\nscope: serviceBusTopic\n}\n</code></pre></p> </li> </ul>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/#11-define-the-backend-processor-service-azure-container-app","title":"11. Define the Backend Processor Service Azure Container App","text":"<p>Add a new file under the folder <code>bicep\\modules\\container-apps</code> as shown below:</p> processor-backend-service.bicep <pre><code>targetScope = 'resourceGroup'\n\n// ------------------\n//    PARAMETERS\n// ------------------\n\n@description('The location where the resources will be created.')\nparam location string = resourceGroup().location\n\n@description('Optional. The tags to be assigned to the created resources.')\nparam tags object = {}\n\n@description('The resource Id of the container apps environment.')\nparam containerAppsEnvironmentId string\n\n@description('The name of the service for the backend processor service. The name is use as Dapr App ID and as the name of service bus topic subscription.')\nparam backendProcessorServiceName string\n\n// Key Vault\n@description('The resource ID of the key vault to store the license key for the backend processor service.')\nparam keyVaultId string\n\n@description('The name of the secret containing the SendGrid API key value for the Backend Background Processor Service.')\nparam sendGridKeySecretName string\n\n@secure()\n@description('The SendGrid API key for for Backend Background Processor Service.')\nparam sendGridKeySecretValue string\n\n@description('The name of the secret containing the External Azure Storage Access key for the Backend Background Processor Service.')\nparam externalStorageKeySecretName string\n\n@secure()\n@description('The Application Insights Instrumentation.')\nparam appInsightsInstrumentationKey string\n\n// Service Bus\n@description('The name of the service bus namespace.')\nparam serviceBusName string\n\n@description('The name of the service bus topic.')\nparam serviceBusTopicName string\n\n@description('The name of the service bus topic\\'s authorization rule.')\nparam serviceBusTopicAuthorizationRuleName string\n\n// External Storage\n@description('The name of the external Azure Storage Account.')\nparam externalStorageAccountName string\n\n// Container Registry &amp; Image\n@description('The name of the container registry.')\nparam containerRegistryName string\n\n@description('The resource ID of the user assigned managed identity for the container registry to be able to pull images from it.')\nparam containerRegistryUserAssignedIdentityId string\n\n@description('The image for the backend processor service.')\nparam backendProcessorServiceImage string\n\n@description('The dapr port for the backend processor service.')\nparam backendProcessorPortNumber int\n\n\n// ------------------\n// VARIABLES\n// ------------------\n\nvar keyVaultIdTokens = split(keyVaultId, '/')\nvar keyVaultSubscriptionId = keyVaultIdTokens[2]\nvar keyVaultResourceGroupName = keyVaultIdTokens[4]\nvar KEYVAULT_NAME = keyVaultIdTokens[8]\n\n// ------------------\n// RESOURCES\n// ------------------\n\nresource serviceBusNamespace 'Microsoft.ServiceBus/namespaces@2021-11-01' existing = {\n  name: serviceBusName\n}\n\nresource serviceBusTopic 'Microsoft.ServiceBus/namespaces/topics@2021-11-01' existing = {\n  name: serviceBusTopicName\n  parent: serviceBusNamespace\n}\n\nresource serviceBusTopicAuthorizationRule 'Microsoft.ServiceBus/namespaces/topics/authorizationRules@2021-11-01' existing = {\n  name: serviceBusTopicAuthorizationRuleName\n  parent: serviceBusTopic\n}\n\n\nresource storageAccount 'Microsoft.Storage/storageAccounts@2021-09-01' existing = {\n  name: externalStorageAccountName\n}\n\nresource backendProcessorService 'Microsoft.App/containerApps@2022-06-01-preview' = {\n  name: backendProcessorServiceName\n  location: location\n  tags: tags\n  identity: {\n    type: 'SystemAssigned,UserAssigned'\n    userAssignedIdentities: {\n        '${containerRegistryUserAssignedIdentityId}': {}\n    }\n  }\n  properties: {\n    managedEnvironmentId: containerAppsEnvironmentId\n    configuration: {\n      activeRevisionsMode: 'single'\n      dapr: {\n        enabled: true\n        appId: backendProcessorServiceName\n        appProtocol: 'http'\n        appPort: backendProcessorPortNumber\n        logLevel: 'info'\n        enableApiLogging: true\n      }\n      secrets: [\n        {\n          name: 'svcbus-connstring'\n          value: serviceBusTopicAuthorizationRule.listKeys().primaryConnectionString\n        }\n        {\n          name: 'appinsights-key'\n          value: appInsightsInstrumentationKey\n        }\n      ]\n      registries: !empty(containerRegistryName) ? [\n        {\n          server: '${containerRegistryName}.azurecr.io'\n          identity: containerRegistryUserAssignedIdentityId\n        }\n      ] : []\n    }\n    template: {\n      containers: [\n        {\n          name: backendProcessorServiceName\n          image: backendProcessorServiceImage\n          resources: {\n            cpu: json('0.25')\n            memory: '0.5Gi'\n          }\n          env: [\n            {\n              name: 'SendGrid__IntegrationEnabled'\n              value: empty(sendGridKeySecretValue) ? 'false' : 'true'\n            }\n            {\n              name: 'ApplicationInsights__InstrumentationKey'\n              secretRef: 'appinsights-key'\n            }\n          ]\n        }\n      ]\n      scale: {\n        minReplicas: 1\n        maxReplicas: 5\n        rules: [\n          {\n            name: 'topic-msgs-length'\n            custom: {\n              type: 'azure-servicebus'\n              auth: [\n                {\n                  secretRef: 'svcbus-connstring'\n                  triggerParameter: 'connection'\n                }\n              ]\n              metadata: {\n                namespace: serviceBusName\n                subscriptionName: backendProcessorServiceName\n                topicName: serviceBusTopicName\n                messageCount: '10'\n                connectionFromEnv: 'svcbus-connstring'\n              }\n            }\n          }\n        ]\n      }\n    }\n  }\n}\n\n\n// Enable consume from servicebus using system managed identity.\nresource backendProcessorService_sb_role_assignment 'Microsoft.Authorization/roleAssignments@2020-04-01-preview' = {\n  name: guid(resourceGroup().id, backendProcessorServiceName, '4f6d3b9b-027b-4f4c-9142-0e5a2a2247e0')\n  properties: {\n    principalId: backendProcessorService.identity.principalId\n    roleDefinitionId: resourceId('Microsoft.Authorization/roleDefinitions', '4f6d3b9b-027b-4f4c-9142-0e5a2a2247e0') // Azure Service Bus Data Receiver.\n    principalType: 'ServicePrincipal'\n  } \n  scope: serviceBusNamespace\n}\n\n// Invoke create secrets and assign role 'Azure Role Key Vault Secrets User' to the backend processor service\nmodule backendProcessorKeySecret 'secrets/processor-backend-service-secrets.bicep' = {\n  name: 'backendProcessorKeySecret-${uniqueString(resourceGroup().id)}'\n  params: {\n    KEYVAULT_NAME: KEYVAULT_NAME\n    sendGridKeySecretName: sendGridKeySecretName\n    sendGridKeySecretValue: sendGridKeySecretValue\n    externalAzureStorageKeySecretName: externalStorageKeySecretName\n    externalAzureStorageKeySecretValue: storageAccount.listKeys().keys[0].value\n    backendProcessorServicePrincipalId: backendProcessorService.identity.principalId\n  }\n  scope: resourceGroup(keyVaultSubscriptionId, keyVaultResourceGroupName)\n}\n\n// ------------------\n// OUTPUTS\n// ------------------\n\n@description('The name of the container app for the backend processor service.')\noutput backendProcessorServiceContainerAppName string = backendProcessorService.name\n</code></pre> What we've added in the Bicep file above <ul> <li>Notice how we are assigning the role <code>Azure Service Bus Data Receiver</code> to the Backend Processor to be able to consume/read messages from Azure Service Bus Topic using Backend Processor system assigned identity, by using the code below:     <pre><code>resource backendProcessorService_sb_role_assignment 'Microsoft.Authorization/roleAssignments@2020-04-01-preview' = {\nname: guid(resourceGroup().id, backendProcessorServiceName, '4f6d3b9b-027b-4f4c-9142-0e5a2a2247e0')\nproperties: {\n    principalId: backendProcessorService.identity.principalId\n    roleDefinitionId: resourceId('Microsoft.Authorization/roleDefinitions', '4f6d3b9b-027b-4f4c-9142-0e5a2a2247e0') // Azure Service Bus Data Receiver.\n    principalType: 'ServicePrincipal'\n} \nscope: serviceBusNamespace\n}\n</code></pre></li> <li>Within this module, we've invoked the module defined in step 8 which is responsible to create the secrets in Azure Key Vault and assign the role <code>Azure Role Key Vault Secrets User</code> to the Backend Processor Service, by using the code below:     <pre><code>module backendProcessorKeySecret 'secrets/processor-backend-service-secrets.bicep' = {\nname: 'backendProcessorKeySecret-${uniqueString(resourceGroup().id)}'\nparams: {\n    KEYVAULT_NAME: KEYVAULT_NAME\n    sendGridKeySecretName: sendGridKeySecretName\n    sendGridKeySecretValue: sendGridKeySecretValue\n    externalAzureStorageKeySecretName: externalStorageKeySecretName\n    externalAzureStorageKeySecretValue: storageAccount.listKeys().keys[0].value\n    backendProcessorServicePrincipalId: backendProcessorService.identity.principalId\n}\nscope: resourceGroup(keyVaultSubscriptionId, keyVaultResourceGroupName)\n}\n</code></pre></li> </ul>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/#12-define-a-container-module-for-the-three-container-apps","title":"12. Define a Container Module For the Three Container Apps","text":"<p>This module will act as a container for the three Container Apps modules defined in the previous three steps. It is optional to create it, but it makes it easier when we invoke all the created modules as you will see in the next step.</p> <p>Add a new file under the folder <code>bicep\\modules</code> as shown below:</p> container-apps.bicep <pre><code>targetScope = 'resourceGroup'\n\n// ------------------\n//    PARAMETERS\n// ------------------\n\n@description('The location where the resources will be created.')\nparam location string = resourceGroup().location\n\n@description('The tags to be assigned to the created resources.')\nparam tags object = {}\n\n@description('The name of the container apps environment.')\nparam containerAppsEnvironmentName string\n\n// Services\n@description('The name of the service for the backend api service. The name is use as Dapr App ID.')\nparam backendApiServiceName string\n\n@description('The name of the service for the backend processor service. The name is use as Dapr App ID and as the name of service bus topic subscription.')\nparam backendProcessorServiceName string\n\n@description('The name of the service for the frontend web app service. The name is use as Dapr App ID.')\nparam frontendWebAppServiceName string\n\n// Service Bus\n@description('The name of the service bus namespace.')\nparam serviceBusName string\n\n@description('The name of the service bus topic.')\nparam serviceBusTopicName string\n\n@description('The name of the service bus topic\\'s authorization rule.')\nparam serviceBusTopicAuthorizationRuleName string\n\n// Cosmos DB\n@description('The name of the provisioned Cosmos DB resource.')\nparam cosmosDbName string \n\n@description('The name of the provisioned Cosmos DB\\'s database.')\nparam cosmosDbDatabaseName string\n\n@description('The name of Cosmos DB\\'s collection.')\nparam cosmosDbCollectionName string\n\n// Key Vault\n@description('The resource ID of the key vault.')\nparam keyVaultId string\n\n@description('The name of the secret containing the SendGrid API key value for the Backend Background Processor Service.')\nparam sendGridKeySecretName string\n\n@secure()\n@description('The SendGrid API key for for Backend Background Processor Service.')\nparam sendGridKeySecretValue string\n\n@description('The name of the secret containing the External Azure Storage Access key for the Backend Background Processor Service.')\nparam externalStorageKeySecretName string\n\n// External Storage\n@description('The name of the external Azure Storage Account.')\nparam externalStorageAccountName string\n\n// Container Registry &amp; Images\n@description('The name of the container registry.')\nparam containerRegistryName string\n\n@description('The image for the backend api service.')\nparam backendApiServiceImage string\n\n@description('The image for the backend processor service.')\nparam backendProcessorServiceImage string\n\n@description('The image for the frontend web app service.')\nparam frontendWebAppServiceImage string\n\n@description('The name of the application insights.')\nparam applicationInsightsName string\n\n// App Ports\n@description('The target and dapr port for the frontend web app service.')\nparam frontendWebAppPortNumber int\n\n@description('The target and dapr port for the backend api service.')\nparam backendApiPortNumber int\n\n@description('The dapr port for the backend processor service.')\nparam backendProcessorPortNumber int\n\n// ------------------\n// VARIABLES\n// ------------------\n\nvar containerRegistryPullRoleGuid='7f951dda-4ed3-4680-a7ca-43fe172d538d'\n\n// ------------------\n// RESOURCES\n// ------------------\n\nresource containerAppsEnvironment 'Microsoft.App/managedEnvironments@2022-03-01' existing = {\n  name: containerAppsEnvironmentName\n}\n\n//Reference to AppInsights resource\nresource applicationInsights 'Microsoft.Insights/components@2020-02-02' existing = {\n  name: applicationInsightsName\n}\n\nresource containerRegistry 'Microsoft.ContainerRegistry/registries@2023-01-01-preview' existing = {\n  name: containerRegistryName\n}\n\nresource containerRegistryUserAssignedIdentity 'Microsoft.ManagedIdentity/userAssignedIdentities@2023-01-31' = {\n  name: 'aca-user-identity-${uniqueString(resourceGroup().id)}'\n  location: location\n  tags: tags\n}\n\nresource containerRegistryPullRoleAssignment 'Microsoft.Authorization/roleAssignments@2022-04-01' = if(!empty(containerRegistryName)) {\n  name: guid(subscription().id, containerRegistry.id, containerRegistryUserAssignedIdentity.id) \n  scope: containerRegistry\n  properties: {\n    principalId: containerRegistryUserAssignedIdentity.properties.principalId\n    roleDefinitionId: resourceId('Microsoft.Authorization/roleDefinitions', containerRegistryPullRoleGuid)\n    principalType: 'ServicePrincipal'\n  }\n}\n\nmodule frontendWebAppService 'container-apps/webapp-frontend-service.bicep' = {\n  name: 'frontendWebAppService-${uniqueString(resourceGroup().id)}'\n  params: {\n    frontendWebAppServiceName: frontendWebAppServiceName\n    location: location\n    tags: tags\n    containerAppsEnvironmentId: containerAppsEnvironment.id\n    containerRegistryName: containerRegistryName\n    containerRegistryUserAssignedIdentityId: containerRegistryUserAssignedIdentity.id\n    frontendWebAppServiceImage: frontendWebAppServiceImage\n    appInsightsInstrumentationKey: applicationInsights.properties.InstrumentationKey\n    frontendWebAppPortNumber: frontendWebAppPortNumber\n\n  }\n}\n\nmodule backendApiService 'container-apps/webapi-backend-service.bicep' = {\n  name: 'backendApiService-${uniqueString(resourceGroup().id)}'\n  params: {\n    backendApiServiceName: backendApiServiceName\n    location: location\n    tags: tags\n    containerAppsEnvironmentId: containerAppsEnvironment.id\n    serviceBusName: serviceBusName\n    serviceBusTopicName: serviceBusTopicName\n    containerRegistryName: containerRegistryName\n    containerRegistryUserAssignedIdentityId: containerRegistryUserAssignedIdentity.id\n    backendApiServiceImage: backendApiServiceImage\n    cosmosDbName: cosmosDbName\n    cosmosDbDatabaseName: cosmosDbDatabaseName\n    cosmosDbCollectionName: cosmosDbCollectionName\n    appInsightsInstrumentationKey: applicationInsights.properties.InstrumentationKey\n    backendApiPortNumber: backendApiPortNumber\n  }\n}\n\nmodule backendProcessorService 'container-apps/processor-backend-service.bicep' = {\n  name: 'backendProcessorService-${uniqueString(resourceGroup().id)}'\n  params: {\n    backendProcessorServiceName: backendProcessorServiceName\n    location: location\n    tags: tags\n    containerAppsEnvironmentId: containerAppsEnvironment.id\n    keyVaultId: keyVaultId\n    serviceBusName: serviceBusName\n    serviceBusTopicName: serviceBusTopicName\n    serviceBusTopicAuthorizationRuleName: serviceBusTopicAuthorizationRuleName\n    containerRegistryName: containerRegistryName\n    containerRegistryUserAssignedIdentityId: containerRegistryUserAssignedIdentity.id\n    sendGridKeySecretName: sendGridKeySecretName\n    sendGridKeySecretValue: sendGridKeySecretValue\n    externalStorageAccountName: externalStorageAccountName\n    externalStorageKeySecretName:externalStorageKeySecretName\n    backendProcessorServiceImage: backendProcessorServiceImage\n    appInsightsInstrumentationKey: applicationInsights.properties.InstrumentationKey\n    backendProcessorPortNumber: backendProcessorPortNumber\n  }\n}\n\n// ------------------\n// OUTPUTS\n// ------------------\n\n@description('The name of the container app for the backend processor service.')\noutput backendProcessorServiceContainerAppName string = backendProcessorService.outputs.backendProcessorServiceContainerAppName\n\n@description('The name of the container app for the backend api service.')\noutput backendApiServiceContainerAppName string = backendApiService.outputs.backendApiServiceContainerAppName\n\n@description('The name of the container app for the front end web app service.')\noutput frontendWebAppServiceContainerAppName string = frontendWebAppService.outputs.frontendWebAppServiceContainerAppName\n\n@description('The FQDN of the front end web app.')\noutput frontendWebAppServiceFQDN string = frontendWebAppService.outputs.frontendWebAppServiceFQDN\n\n@description('The FQDN of the backend web app')\noutput backendApiServiceFQDN string  = backendApiService.outputs.backendApiServiceFQDN\n</code></pre>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/#13-define-the-main-module-for-the-solution","title":"13. Define the Main Module For the Solution","text":"<p>Finally, we must specify the Main Bicep module that will connect all other modules together. This file will be referenced by the AZ CLI command when producing all resources.</p> <p>To achieve this, add a new file under the <code>bicep</code> directory as shown below:</p> main.bicep <pre><code>targetScope = 'resourceGroup'\n\n// ------------------\n//    PARAMETERS\n// ------------------\n\n@description('The location where the resources will be created.')\nparam location string = resourceGroup().location\n\n@description('Optional. The prefix to be used for all resources created by this template.')\nparam prefix string = ''\n\n@description('Optional. The suffix to be used for all resources created by this template.')\nparam suffix string = ''\n\n@description('Optional. The tags to be assigned to the created resources.')\nparam tags object = {}\n\n// Container Apps Env / Log Analytics Workspace / Application Insights\n@description('Optional. The name of the container apps environment. If set, it overrides the name generated by the template.')\nparam containerAppsEnvironmentName string = '${prefix}cae-${uniqueString(resourceGroup().id)}${suffix}'\n\n@description('Optional. The name of the log analytics workspace. If set, it overrides the name generated by the template.')\nparam logAnalyticsWorkspaceName string = '${prefix}log-${uniqueString(resourceGroup().id)}${suffix}'\n\n@description('Optional. The name of the application insights. If set, it overrides the name generated by the template.')\nparam applicationInsightName string = '${prefix}appi-${uniqueString(resourceGroup().id)}${suffix}'\n\n// Servivces\n@description('The name of the service for the backend processor service. The name is use as Dapr App ID and as the name of service bus topic subscription.')\nparam backendProcessorServiceName string\n\n@description('The name of the service for the backend api service. The name is use as Dapr App ID.')\nparam backendApiServiceName string\n\n@description('The name of the service for the frontend web app service. The name is use as Dapr App ID.')\nparam frontendWebAppServiceName string\n\n// Service Bus\n@description('Optional. The name of the service bus namespace. If set, it overrides the name generated by the template.')\nparam serviceBusName string = '${prefix}sb-${uniqueString(resourceGroup().id)}${suffix}'\n\n@description('The name of the service bus topic.')\nparam serviceBusTopicName string\n\n@description('The name of the service bus topic\\'s authorization rule.')\nparam serviceBusTopicAuthorizationRuleName string\n\n// Cosmos DB\n@description('Optional. The name of Cosmos DB resource. If set, it overrides the name generated by the template.')\nparam cosmosDbName string ='${prefix}cosno-${uniqueString(resourceGroup().id)}${suffix}'\n\n@description('The name of Cosmos DB\\'s database.')\nparam cosmosDbDatabaseName string\n\n@description('The name of Cosmos DB\\'s collection.')\nparam cosmosDbCollectionName string\n\n// Azure Stroage\n@description('The name of the external Azure Storage Account.')\nparam storageAccountName string = '${prefix}storage${uniqueString(resourceGroup().id)}${suffix}'\n\n@description('The name of the external Queue in Azure Storage.')\nparam externalTasksQueueName string\n\n@description('The name of the external blob container in Azure Storage.')\nparam externalTasksContainerBlobName string\n\n@description('The name of the secret containing the External Azure Storage Access key for the backend processor service.')\nparam externalStorageKeySecretName string \n\n//SendGrid\n@description('The name of the secret containing the SendGrid API key value for the backend processor service.')\nparam sendGridKeySecretName string = 'sendgrid-api-key'\n\n@description('The name of the SendGrid Email From.')\nparam sendGridEmailFrom string\n\n@description('The name of the SendGrid Email From Name.')\nparam sendGridEmailFromName string\n\n@secure()\n@description('The SendGrid API key for the backend processor service. If not provided, SendGrid integration will be disabled.')\nparam sendGridKeySecretValue string\n\n//Cron Shedule Jon\n@description('The cron settings for scheduled job.')\nparam scheduledJobCron string\n\n// Dapr components\n@description('The name of Dapr component for the secret store building block.')\n// We disable lint of this line as it is not a secret but the name of the Dapr component\n#disable-next-line secure-secrets-in-params\nparam secretStoreComponentName string\n\n@description('The key vault name store secrets')\nparam KEYVAULT_NAME string = '${prefix}kv-${uniqueString(resourceGroup().id)}${suffix}'\n\n// Container Registry &amp; Images\n@description('The name of the container registry.')\nparam containerRegistryName string\n\n@description('The image for the backend processor service.')\nparam backendProcessorServiceImage string\n\n@description('The image for the backend api service.')\nparam backendApiServiceImage string\n\n@description('The image for the frontend web app service.')\nparam frontendWebAppServiceImage string\n\n// App Ports\n@description('The target and dapr port for the frontend web app service.')\nparam frontendWebAppPortNumber int = 80\n\n@description('The target and dapr port for the backend api service.')\nparam backendApiPortNumber int = 80\n\n@description('The dapr port for the backend processor service.')\nparam backendProcessorPortNumber int = 80\n\n// ------------------\n// RESOURCES\n// ------------------\n\nmodule containerAppsEnvironment 'modules/container-apps-environment.bicep' ={\n  name: 'containerAppsEnv-${uniqueString(resourceGroup().id)}'\n  params: {\n   containerAppsEnvironmentName: containerAppsEnvironmentName\n   logAnalyticsWorkspaceName: logAnalyticsWorkspaceName\n   applicationInsightName: applicationInsightName\n    location: location\n    tags: tags\n  }\n}\n\nmodule keyVault 'modules/key-vault.bicep' = {\n  name: 'keyVault-${uniqueString(resourceGroup().id)}'\n  params: {\n    KEYVAULT_NAME: KEYVAULT_NAME\n    location: location\n    tags: tags\n  }\n}\n\nmodule serviceBus 'modules/service-bus.bicep' = {\n  name: 'serviceBus-${uniqueString(resourceGroup().id)}'\n  params: {\n    serviceBusName: serviceBusName\n    location: location\n    tags: tags\n    serviceBusTopicName: serviceBusTopicName\n    serviceBusTopicAuthorizationRuleName: serviceBusTopicAuthorizationRuleName\n    backendProcessorServiceName: backendProcessorServiceName\n  }\n}\n\nmodule cosmosDb 'modules/cosmos-db.bicep' = {\n  name: 'cosmosDb-${uniqueString(resourceGroup().id)}'\n  params: {\n    cosmosDbName: cosmosDbName\n    location: location\n    tags: tags\n    cosmosDbDatabaseName: cosmosDbDatabaseName\n    cosmosDbCollectionName: cosmosDbCollectionName \n  }\n}\n\nmodule externalStorageAccount 'modules/storage-account.bicep' = {\n  name: 'storageAccount-${uniqueString(resourceGroup().id)}'\n  params: {\n    storageAccountName: storageAccountName\n    externalTasksQueueName: externalTasksQueueName\n    location: location\n    tags: tags\n  }\n}\n\nmodule daprComponents 'modules/dapr-components.bicep' = {\n  name: 'daprComponents-${uniqueString(resourceGroup().id)}'\n  params: {\n    secretStoreComponentName: secretStoreComponentName \n    containerAppsEnvironmentName: containerAppsEnvironmentName    \n    KEYVAULT_NAME: KEYVAULT_NAME    \n    serviceBusName: serviceBus.outputs.serviceBusName\n    cosmosDbName: cosmosDb.outputs.cosmosDbName\n    cosmosDbDatabaseName: cosmosDb.outputs.cosmosDbDatabaseName\n    cosmosDbCollectionName: cosmosDb.outputs.cosmosDbCollectionName    \n    backendApiServiceName: backendApiServiceName\n    backendProcessorServiceName: backendProcessorServiceName\n    storageAccountName: storageAccountName\n    sendGridKeySecretName: sendGridKeySecretName\n    sendGridEmailFrom: sendGridEmailFrom\n    sendGridEmailFromName: sendGridEmailFromName\n    scheduledJobCron: scheduledJobCron\n    externalTasksQueueName: externalTasksQueueName\n    externalTasksContainerBlobName: externalTasksContainerBlobName\n    externalStorageKeySecretName: externalStorageKeySecretName\n  }\n  dependsOn: [\n    containerAppsEnvironment\n  ]\n}\n\nmodule containerApps 'modules/container-apps.bicep' = {\n  name: 'containerApps-${uniqueString(resourceGroup().id)}'\n  params: {\n    location: location\n    tags: tags\n    backendProcessorServiceName: backendProcessorServiceName\n    backendApiServiceName: backendApiServiceName\n    frontendWebAppServiceName: frontendWebAppServiceName    \n    containerAppsEnvironmentName: containerAppsEnvironmentName\n    keyVaultId: keyVault.outputs.keyVaultId\n    serviceBusName: serviceBus.outputs.serviceBusName\n    serviceBusTopicName: serviceBus.outputs.serviceBusTopicName\n    serviceBusTopicAuthorizationRuleName: serviceBus.outputs.serviceBusTopicAuthorizationRuleName    \n    cosmosDbName: cosmosDb.outputs.cosmosDbName\n    cosmosDbDatabaseName: cosmosDb.outputs.cosmosDbDatabaseName\n    cosmosDbCollectionName: cosmosDb.outputs.cosmosDbCollectionName    \n    containerRegistryName: containerRegistryName\n    backendProcessorServiceImage: backendProcessorServiceImage\n    backendApiServiceImage: backendApiServiceImage\n    frontendWebAppServiceImage: frontendWebAppServiceImage\n    sendGridKeySecretName: sendGridKeySecretName\n    sendGridKeySecretValue: sendGridKeySecretValue\n    applicationInsightsName: containerAppsEnvironment.outputs.applicationInsightsName\n    externalStorageAccountName: externalStorageAccount.outputs.storageAccountName\n    externalStorageKeySecretName: externalStorageKeySecretName\n    frontendWebAppPortNumber: frontendWebAppPortNumber\n    backendApiPortNumber: backendApiPortNumber\n    backendProcessorPortNumber: backendProcessorPortNumber\n  }\n  dependsOn: [\n    daprComponents\n  ]\n}\n\n// ------------------\n// OUTPUTS\n// ------------------\n\n@description('The name of the container app for the backend processor service.')\noutput backendProcessorServiceContainerAppName string = containerApps.outputs.backendProcessorServiceContainerAppName\n\n@description('The name of the container app for the backend api service.')\noutput backendApiServiceContainerAppName string = containerApps.outputs.backendApiServiceContainerAppName\n\n@description('The name of the container app for the front end web app service.')\noutput frontendWebAppServiceContainerAppName string = containerApps.outputs.frontendWebAppServiceContainerAppName\n\n@description('The FQDN of the front end web app.')\noutput frontendWebAppServiceFQDN string = containerApps.outputs.frontendWebAppServiceFQDN\n\n@description('The FQDN of the backend web app')\noutput backendApiServiceFQDN string  = containerApps.outputs.backendApiServiceFQDN\n</code></pre> What we've added in the Bicep file above <ul> <li> <p>When calling the module <code>dapr-components.bicep</code> we are setting the value of the array <code>dependsOn</code> to the Container Apps Environment. This is called explicit dependency which aids the Bicep interpreter in comprehending the relationships between components. In this instance, the Container Apps Environment must be provisioned before the Dapr Components to guarantee a successful deployment.</p> </li> <li> <p>When calling the module <code>container-apps.bicep</code>, some of the input params are expecting are referencing another resource, for example consider the input param named <code>cosmosDbName</code> and the value used is <code>cosmosDb.outputs.cosmosDbName</code>. This means that the module <code>cosmos-db.bicep</code> should be created successfully before creating the container apps module, this called Implicit dependency.</p> </li> </ul>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/#deploy-the-infrastructure-and-create-the-components","title":"Deploy the Infrastructure and Create the Components","text":"<p>Start by creating a new resource group which will contain all the resources to be created by the Bicep scripts.</p> <pre><code>$RESOURCE_GROUP=\"&lt;your RG name&gt;\"\n$LOCATION=\"&lt;your location&gt;\"\n\naz group create `\n--name $RESOURCE_GROUP `\n--location $LOCATION\n</code></pre> <p>Create a parameters file which will simplify the invocation of the main bicep file. To achieve this, right click on file <code>main.bicep</code> and select Generate Parameter File. This will result in creating a file named <code>main.parameters.json</code> similar to the file below:</p> Example main.parameters.json <pre><code>{\n  \"$schema\": \"https://schema.management.azure.com/schemas/2015-01-01/deploymentParameters.json#\",\n  \"contentVersion\": \"1.0.0.0\",\n  \"parameters\": {\n    \"prefix\": {\n      \"value\": \"\"\n    },\n    \"suffix\": {\n        \"value\": \"\"\n    },\n    \"tags\": {\n        \"value\": {}\n    },\n    \"backendProcessorServiceName\": {\n      \"value\": \"tasksmanager-backend-processor\"\n    },\n    \"backendApiServiceName\": {\n      \"value\": \"tasksmanager-backend-api\"\n    },\n    \"frontendWebAppServiceName\": {\n      \"value\": \"tasksmanager-frontend-webapp\"\n    },\n    \"serviceBusTopicName\": {\n      \"value\": \"tasksavedtopic\"\n    },\n    \"serviceBusTopicAuthorizationRuleName\": {\n      \"value\": \"tasksavedtopic-manage-policy\"\n    },\n    \"cosmosDbDatabaseName\": {\n      \"value\": \"tasksmanagerdb\"\n    },\n    \"cosmosDbCollectionName\": {\n      \"value\": \"taskscollection\"\n    },\n    \"sendGridKeySecretValue\": {\n      \"value\": \"\"\n    },\n    \"sendGridEmailFrom\": {\n      \"value\": \"&lt;SEND_GRID_FROM_EMAIL&gt;\"\n    },\n    \"sendGridEmailFromName\": {\n      \"value\": \"Tasks Tracker Notification\"\n    },\n    \"externalTasksQueueName\": {\n      \"value\": \"external-tasks-queue\"\n    },\n    \"externalTasksContainerBlobName\": {\n      \"value\": \"externaltasksblob\"\n    },\n    \"externalStorageKeySecretName\": {\n      \"value\": \"external-azure-storage-key\"\n    },\n    \"scheduledJobCron\": {\n      \"value\": \"5 0 * * *\"\n    },\n    \"secretStoreComponentName\": {\n      \"value\": \"secretstoreakv\"\n    },\n    \"containerRegistryName\": {\n      \"value\": \"&lt;CONTAINER_REGISTRY_NAME&gt;\"\n    },\n    \"backendProcessorServiceImage\": {\n      \"value\": \"&lt;CONTAINER_REGISTRY_NAME&gt;.azurecr.io/tasksmanager/tasksmanager-backend-processor:latest\"\n    },\n    \"backendApiServiceImage\": {\n      \"value\": \"&lt;CONTAINER_REGISTRY_NAME&gt;.azurecr.io/tasksmanager/tasksmanager-backend-api:latest\"\n    },\n    \"frontendWebAppServiceImage\": {\n      \"value\": \"&lt;CONTAINER_REGISTRY_NAME&gt;.azurecr.io/tasksmanager/tasksmanager-frontend-webapp:latest\"\n    },\n    \"frontendWebAppPortNumber\": {\n      \"value\": 80\n    },\n    \"backendApiPortNumber\": {\n      \"value\": 80\n    },\n    \"backendProcessorPortNumber\": {\n      \"value\": 80\n    }\n  }\n}\n</code></pre> <p>Note</p> <p>To use this file, you need to edit this generated file and provide values for the parameters. You can use the same values shown above in sample file. </p> <p>You only need to replace parameter values between the angle brackets <code>&lt;&gt;</code> with values related to your container registry and SendGrid. Values for container registry and container images can be derived by following one of the three options in next step.</p> <p>In case you followed along with the whole workshop and would like to use your own sourcecode, make sure to replace the port numbers (80) by the port numbers that were generated when you created your docker files in vs code for your three applications (e.g., 5225). Make sure that the port numbers match the numbers in the respective docker files. If port numbers aren't matching, your deployment will work without errors, but the portal will report issues with the apps and calling one of the apps will result in a session timeout.</p> <p>Next, we will prepare container images for the three container apps and update the values in <code>main.parameters.json</code> file. You can do so by any of the three options below:</p> Option 1: Build and Push the Images to Azure Container Registry (ACR)Option 2: Import pre-built public images to your private Azure Container RegistryOption 3: Use the pre-built images from the public repository <ol> <li> <p>Create an Azure Container Registry (ACR) inside the newly created Resource Group:</p> <pre><code>$CONTAINER_REGISTRY_NAME=\"&lt;your ACR name&gt;\"\n\naz acr create `\n    --resource-group $RESOURCE_GROUP `\n    --name $CONTAINER_REGISTRY_NAME `\n    --sku Basic\n</code></pre> </li> <li> <p>Build and push the images to ACR. Make sure you are at the root project directory when executing the following commands:</p> <pre><code>## Build Backend API on ACR and Push to ACR\n\naz acr build --registry $CONTAINER_REGISTRY_NAME `\n    --image \"tasksmanager/tasksmanager-backend-api\" `\n    --file 'TasksTracker.TasksManager.Backend.Api/Dockerfile' .\n\n## Build Backend Service on ACR and Push to ACR\n\naz acr build --registry $CONTAINER_REGISTRY_NAME `\n    --image \"tasksmanager/tasksmanager-backend-processor\" `\n    --file 'TasksTracker.Processor.Backend.Svc/Dockerfile' .\n\n## Build Frontend Web App on ACR and Push to ACR\n\naz acr build --registry $CONTAINER_REGISTRY_NAME `\n    --image \"tasksmanager/tasksmanager-frontend-webapp\" `\n    --file 'TasksTracker.WebPortal.Frontend.Ui/Dockerfile' .\n</code></pre> </li> <li> <p>Update the <code>main.parameters.json</code> file with the container registry name and the container images names as shown below:</p> <pre><code>{\n    \"containerRegistryName\": {\n        \"value\": \"&lt;CONTAINER_REGISTRY_NAME&gt;\"\n    },\n    \"backendProcessorServiceImage\": {\n        \"value\": \"&lt;CONTAINER_REGISTRY_NAME&gt;.azurecr.io/tasksmanager/tasksmanager-backend-processor:latest\"\n    },\n    \"backendApiServiceImage\": {\n        \"value\": \"&lt;CONTAINER_REGISTRY_NAME&gt;.azurecr.io/tasksmanager/tasksmanager-backend-api:latest\"\n    },\n    \"frontendWebAppServiceImage\": {\n        \"value\": \"&lt;CONTAINER_REGISTRY_NAME&gt;.azurecr.io/tasksmanager/tasksmanager-frontend-webapp:latest\"\n    }\n}\n</code></pre> </li> </ol> <p>All the container image are available in a public image repository. If you do not wish to build the container images from code directly, you can import it directly into  your private container instance as shown below.</p> <ol> <li> <p>Create an Azure Container Registry (ACR) inside the newly created Resource Group:</p> <pre><code>$CONTAINER_REGISTRY_NAME=\"&lt;your ACR name&gt;\"\n\naz acr create `\n    --resource-group $RESOURCE_GROUP `\n    --name $CONTAINER_REGISTRY_NAME `\n    --sku Basic\n</code></pre> </li> <li> <p>Import the images to your private ACR as shown below:</p> <pre><code>    az acr import `\n    --name $CONTAINER_REGISTRY_NAME `\n    --image tasksmanager/tasksmanager-backend-api `\n    --source ghcr.io/azure/tasksmanager-backend-api:latest\n\n    az acr import  `\n    --name $CONTAINER_REGISTRY_NAME `\n    --image tasksmanager/tasksmanager-frontend-webapp `\n    --source ghcr.io/azure/tasksmanager-frontend-webapp:latest\n\n    az acr import  `\n    --name $CONTAINER_REGISTRY_NAME `\n    --image tasksmanager/tasksmanager-backend-processor `\n    --source ghcr.io/azure/tasksmanager-backend-processor:latest\n</code></pre> </li> <li> <p>Update the <code>main.parameters.json</code> file with the container registry name and the container images names as shown below:</p> <pre><code>{\n    \"containerRegistryName\": {\n        \"value\": \"&lt;CONTAINER_REGISTRY_NAME&gt;\"\n    },\n    \"backendProcessorServiceImage\": {\n        \"value\": \"&lt;CONTAINER_REGISTRY_NAME&gt;.azurecr.io/tasksmanager/tasksmanager-backend-processor:latest\"\n    },\n    \"backendApiServiceImage\": {\n        \"value\": \"&lt;CONTAINER_REGISTRY_NAME&gt;.azurecr.io/tasksmanager/tasksmanager-backend-api:latest\"\n    },\n    \"frontendWebAppServiceImage\": {\n        \"value\": \"&lt;CONTAINER_REGISTRY_NAME&gt;.azurecr.io/tasksmanager/tasksmanager-frontend-webapp:latest\"\n    }\n}\n</code></pre> </li> </ol> <p>All the container image are available in a public image repository. If you do not wish to build the container images from code directly, you can use the pre-built images from the public repository as shown below.</p> <p>The public images can be set directly in the <code>main.parameters.json</code> file:</p> <pre><code>{\n    \"containerRegistryName\": {\n        \"value\": \"\"\n    },\n    \"backendProcessorServiceImage\": {\n      \"value\": \"ghcr.io/azure/tasksmanager-backend-processor:latest\"\n    },\n    \"backendApiServiceImage\": {\n      \"value\": \"ghcr.io/azure/tasksmanager-backend-api:latest\"\n    },\n    \"frontendWebAppServiceImage\": {\n      \"value\": \"ghcr.io/azure/tasksmanager-frontend-webapp:latest\"\n    },\n}   \n</code></pre> <p>Start the deployment by calling <code>az deployment group create</code>. To accomplish this, open the PowerShell console and use the content below.</p> <pre><code>az deployment group create `\n--resource-group $RESOURCE_GROUP `\n--template-file \"./bicep/main.bicep\" `\n--parameters \"./bicep/main.parameters.json\"\n</code></pre> <p>The Azure CLI will take the Bicep module and start creating the deployment in the resource group.</p>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/#verify-the-final-results","title":"Verify the Final Results","text":"<p>Success</p> <p>Upon successful deployment, you should observe all resources generated within the designated resource group. Additionally, you may navigate to the <code>Deployments</code> section to confirm that the ARM templates have been deployed, which should resemble the image provided below:</p> <p></p>"},{"location":"aca/11-aca-landing-zone/","title":"Module 11 - Integration with Azure Container Apps landing zone accelerator","text":"<p>Azure landing zone accelerators provide architectural guidance, reference architectures, reference implementations, and automation to deploy workload platforms on Azure at scale. They are aligned with industry proven practices, such as those presented in Azure landing zones guidance in the Cloud Adoption Framework.</p> <p>This Azure Container Apps landing zone accelerator represents the strategic design path and target technical state for an Azure Container Apps deployment, owned and operated by a workload team.</p> <p>The application created as part of the workshop is integrated with the Azure Container Apps landing zone accelerator.</p>"},{"location":"aca/11-aca-landing-zone/#deploy-the-landing-zone","title":"Deploy the landing zone","text":"<p>To deploy the landing zone, you can follow the complete guide in Azure Container Apps - Internal environment secure baseline [Bicep].</p> <p>The deployment of the sample app deploys also an application gateway with the same name as the one of the landing zone. It is recommended to deploy only the first four building blocks of the landing zone and then deploy this sample app, i.e. do not deploy hello world sample app and application gateway. To do so, you can set the attribute <code>deployHelloWorldSampleApp</code> to <code>false</code> in the parameters file of the landing zone.</p> <p>To have Dapr observability in Application Insights, you need to set the attributes <code>enableApplicationInsights</code> and <code>enableDaprInstrumentation</code> to <code>true</code> in the parameters file of the landing zone. To know more about monitoring and observability, you can follow this documentation Operations management considerations for Azure Container Apps.</p>"},{"location":"aca/11-aca-landing-zone/#deploy-the-container-apps","title":"Deploy the Container Apps","text":"<p>Once the landing zone is deployed, the container apps and their dependencies can be deployed. </p>"},{"location":"aca/11-aca-landing-zone/#build-the-container-images","title":"Build the container images","text":"<p>There are 2 options to build the container images:</p> <ol> <li>Import pre-built public images to your private Azure Container Registry</li> <li>Use the pre-built public images from Azure Container Registry</li> </ol> <p>For the first options, you need the name of the container registry. You can get this name from the landing zone deployment:</p> <pre><code>LZA_DEPLOYMENT_NAME=&lt;LZA_DEPLOYMENT_NAME&gt;\nCONTAINER_REGISTRY_NAME=$(az deployment sub show -n \"$LZA_DEPLOYMENT_NAME\" --query properties.outputs.containerRegistryName.value -o tsv)\n</code></pre> <p>Where <code>LZA_DEPLOYMENT_NAME</code> is the name of the deployment of the landing zone.</p> <p>The latest images can be found here</p>"},{"location":"aca/11-aca-landing-zone/#option-1-import-pre-built-public-images-to-your-private-azure-container-registry","title":"Option 1 - Import pre-built public images to your private Azure Container Registry","text":"<p>All the container image are available in a public image repository. If you do not wish to build the container images from code directly, you can import it directly into your private container instance as shown below. Note - you might need to execute this from a jump box or workstation which can reach your private container registry instance.</p> <pre><code>TAG=&lt;TAG&gt;\nBACKEND_PROCESSOR_IMAGE=$CONTAINER_REGISTRY_NAME.azurecr.io/tasksmanager-backend-processor:$TAG\nFRONTEND_IMAGE=$CONTAINER_REGISTRY_NAME.azurecr.io/tasksmanager-frontend-webapp:$TAG\nTASKS_API_IMAGE=$CONTAINER_REGISTRY_NAME.azurecr.io/tasksmanager-backend-api:$TAG\n\naz login\n\naz acr login -n $CONTAINER_REGISTRY_NAME\n\naz acr import \\\n  --name $CONTAINER_REGISTRY_NAME \\\n  --image tasksmanager-backend-processor:$TAG \\\n  --source ghcr.io/azure/tasksmanager-backend-processor:latest\n\naz acr import \\\n  --name $CONTAINER_REGISTRY_NAME \\\n  --image tasksmanager-frontend-webapp:$TAG \\\n  --source ghcr.io/azure/tasksmanager-frontend-webapp:latest\n\naz acr import \\\n  --name $CONTAINER_REGISTRY_NAME \\\n  --image tasksmanager-backend-api:$TAG \\\n  --source ghcr.io/azure/tasksmanager-backend-api:latest\n</code></pre> <p>Where <code>TAG</code> is the tag of the container images. </p> <p>You can set the Bicep parameters for the image in the <code>main.parameters.jsonc</code> or use the environment variables defined above.</p> <p>NOTE</p> <p>To be able to import the images from the public repository, you need to be logged in to the private Container Registry. To do so you'll need to install Docker in the jump box VM or workstation. The script jumpbox-setup.sh can be used as an example on how to install Docker. </p> <p> Deploy the sample app</p>"},{"location":"aca/11-aca-landing-zone/#option-2-use-the-public-container-images-and-deploy-them-directly-in-azure-container-apps","title":"Option 2 - Use the public container images and deploy them directly in Azure Container Apps","text":"<p>The public images can be set directly in the <code>main.parameters.jsonc</code> file:</p> <pre><code>{\n    \"containerRegistryName\": {\n        \"value\": \"\"\n    },\n    \"backendProcessorServiceImage\": {\n      \"value\": \"ghcr.io/azure/tasksmanager-backend-processor:latest\"\n    },\n    \"backendApiServiceImage\": {\n      \"value\": \"ghcr.io/azure/tasksmanager-backend-api:latest\"\n    },\n    \"frontendWebAppServiceImage\": {\n      \"value\": \"ghcr.io/azure/tasksmanager-frontend-webapp:latest\"\n    }\n}  \n</code></pre> <p>or in the environment variables:</p> <pre><code>CONTAINER_REGISTRY_NAME=\nBACKEND_PROCESSOR_IMAGE=ghcr.io/azure/tasksmanager-backend-processor:latest\nFRONTEND_IMAGE=ghcr.io/azure/tasksmanager-frontend-webapp:latest\nTASKS_API_IMAGE=ghcr.io/azure/tasksmanager-backend-api:latest\n</code></pre>"},{"location":"aca/11-aca-landing-zone/#deploy-the-sample-app","title":"Deploy the sample app","text":"<p>The sample app can be deployed using the main.bicep template.</p> <p>To set the parameters for the deployment, you can either use the <code>main.parameters.jsonc</code> file or set environment variables.</p>"},{"location":"aca/11-aca-landing-zone/#deploy-the-sample-app-using-environment-variables","title":"Deploy the sample app using environment variables","text":"<p>You can override the parameters in the <code>main.parameters.jsonc</code> when creating the deployment using:</p> <pre><code>  --parameters &lt;parameter-name&gt;=&lt;parameter-value&gt;\n</code></pre> <p>Where <code>&lt;parameter-name&gt;</code> is the name of the parameter and <code>&lt;parameter-value&gt;</code> is the value of the parameter.</p> <p>You can get the parameters from the landing zone deployment:</p> <pre><code># Set a parameter with the Subscription Deployment name you used for the ACA LZA. This is required to query and get several names of resources\nLZA_DEPLOYMENT_NAME=&lt;LZA_DEPLOYMENT_NAME&gt;\n\n# Get the name of the Spoke Resoure Group\nSPOKE_RESOURCE_GROUP_NAME=$(az deployment sub show -n \"$LZA_DEPLOYMENT_NAME\" --query properties.outputs.spokeResourceGroupName.value -o tsv)\n\n# Get the name of the Container Apps Environment that has been deployed by the ACA LZA\nCONTAINER_APPS_ENVIRONMENT_NAME=$(az deployment sub show -n \"$LZA_DEPLOYMENT_NAME\" --query properties.outputs.containerAppsEnvironmentName.value -o tsv)\n\n# Get the Resource ID of the Hub's Virtual Network\nHUB_VNET_ID=$(az deployment sub show -n \"$LZA_DEPLOYMENT_NAME\" --query properties.outputs.hubVNetId.value -o tsv)\n\n# Get the name of the spoke's Virtual Network\nSPOKE_VNET_NAME=$(az deployment sub show -n \"$LZA_DEPLOYMENT_NAME\" --query properties.outputs.spokeVnetName.value -o tsv)\n\n# Get the name of the subnet that holds the private endpoints (their NICs)\nSPOKE_PRIVATE_ENDPOINTS_SUBNET_NAME=$(az deployment sub show -n \"$LZA_DEPLOYMENT_NAME\" --query properties.outputs.spokePrivateEndpointsSubnetName.value -o tsv)\n\n# Get the Resource ID of the the KeyVault\nKEY_VAULT_ID=$(az deployment sub show -n \"$LZA_DEPLOYMENT_NAME\" --query properties.outputs.keyVaultId.value -o tsv)\n\n# Get the name of the ACR\nCONTAINER_REGISTRY_NAME=$(az deployment sub show -n \"$LZA_DEPLOYMENT_NAME\" --query properties.outputs.containerRegistryName.value -o tsv)\n\n# Get the ID of the ACR IDentity\nCONTAINER_REGISTRY_USER_ASSIGNED_IDENTITY_ID=$(az deployment sub show -n \"$LZA_DEPLOYMENT_NAME\" --query properties.outputs.containerRegistryUserAssignedIdentityId.value -o tsv)\n\n# Get the name of the application gateway subnet\nSPOKE_APPLICATION_GATEWAY_SUBNET_NAME=$(az deployment sub show -n \"$LZA_DEPLOYMENT_NAME\" --query properties.outputs.spokeApplicationGatewaySubnetName.value -o tsv)\n\n\n# Set app insights name to empty if workload name is same as that of used when deploying the landing zone. If not, Set with the name of the app insights created for the workload\nAPPLICATION_INSIGHTS_NAME=&lt;APPLICATION_INSIGHTS_NAME&gt;\n</code></pre> <p>Where <code>&lt;LZA_DEPLOYMENT_NAME&gt;</code> is the name of the landing zone deployment.</p> <p>To deploy the sample app using environment variables, run the following command in the <code>bicep</code> folder:</p> <pre><code>LZA_DEPLOYMENT_SAMPLE_DOTNET=bicepLzaDeploymentSampleDotNet  # or any other value that suits your needs\n\naz deployment group create -g \"$SPOKE_RESOURCE_GROUP_NAME\" -f main.bicep -p main.parameters.jsonc \\\n  --name $LZA_DEPLOYMENT_SAMPLE_DOTNET \\\n  --parameters containerAppsEnvironmentName=$CONTAINER_APPS_ENVIRONMENT_NAME \\\n  --parameters hubVNetId=$HUB_VNET_ID \\\n  --parameters spokeVNetName=$SPOKE_VNET_NAME \\\n  --parameters spokePrivateEndpointsSubnetName=$SPOKE_PRIVATE_ENDPOINTS_SUBNET_NAME \\\n  --parameters keyVaultId=$KEY_VAULT_ID \\\n  --parameters containerRegistryName=$CONTAINER_REGISTRY_NAME \\\n  --parameters backendProcessorServiceImage=$BACKEND_PROCESSOR_IMAGE\\\n  --parameters frontendWebAppServiceImage=$FRONTEND_IMAGE \\\n  --parameters backendApiServiceImage=$TASKS_API_IMAGE \\\n  --parameters spokeApplicationGatewaySubnetName=$SPOKE_APPLICATION_GATEWAY_SUBNET_NAME \\\n  --parameters applicationInsightsName=$APPLICATION_INSIGHTS_NAME\n</code></pre>"},{"location":"aca/11-aca-landing-zone/#test-the-sample-app","title":"Test the sample app","text":"<p>Navigate to the spoke resource group and get the public IP address of the application gateway</p> <pre><code>APP_GATEWAY_IP=$(az deployment group show -g \"$SPOKE_RESOURCE_GROUP_NAME\" -n \"$LZA_DEPLOYMENT_SAMPLE_DOTNET\" --query properties.outputs.applicationGatewayPublicIp.value -o tsv)\n\ncurl -k https://$APP_GATEWAY_IP # or open https://$APP_GATEWAY_IP in a browser\n</code></pre>"},{"location":"aca/12-optimize-containers/","title":"Module 12 - Container Optimization","text":"<p>Module Duration</p> <p>45-60 minutes</p>"},{"location":"aca/12-optimize-containers/#objective","title":"Objective","text":"<p>In this module, we will accomplish two objectives:</p> <ol> <li>Learn how to reduce container footprints.</li> <li>Build &amp; deploy updated, optimized images to Azure.</li> </ol>"},{"location":"aca/12-optimize-containers/#module-sections","title":"Module Sections","text":"<ul> <li> <p>From the VS Code Terminal tab, open developer command prompt or PowerShell terminal in the project folder <code>TasksTracker.ContainerApps</code> (root):</p> <pre><code>cd ~\\TasksTracker.ContainerApps\n</code></pre> </li> <li> <p>Restore the previously-stored variables by executing the local script. The output informs you how many variables have been set.</p> <pre><code>.\\Variables.ps1\n</code></pre> </li> </ul>"},{"location":"aca/12-optimize-containers/#1-optimizing-containers","title":"1. Optimizing Containers","text":"<p>Azure Container Apps makes it simple to quickly become effective with containers. But even a managed container platform requires hygiene and can benefit greatly from smaller containers.  </p> <p>In this module, we will look into the benefits of optimized containers such as:</p> <ul> <li>Smaller images to store and transfer to and from the container registry.</li> <li>Potentially less Common Vulnerabilities and Exposures (CVEs).</li> <li>No bloat and unnecessary components such as shells, package managers, etc.</li> </ul> <p>While available prior to .NET 8, the general availability introduction of .NET 8 in November 2023 came with an expanded focus on container optimization and a move away from general-purpose containers.</p> <p>Please ensure you have the Docker daemon ready. Running Docker Desktop does it.</p>"},{"location":"aca/12-optimize-containers/#11-the-status-quo","title":"1.1 The Status Quo","text":"<p>Let's focus on our first project, the Backend API. This is an ASP.NET Core application.</p> <p>Our original <code>Dockerfile</code> looks like this:</p> Backend.Api Dockerfile <pre><code>FROM mcr.microsoft.com/dotnet/aspnet:8.0 AS base\nWORKDIR /app\nEXPOSE 5000\n\nENV ASPNETCORE_URLS=http://+:5000\n\nUSER app\nFROM mcr.microsoft.com/dotnet/sdk:8.0 AS build\nARG configuration=Release\nWORKDIR /src\nCOPY [\"TasksTracker.TasksManager.Backend.Api/TasksTracker.TasksManager.Backend.Api.csproj\", \"TasksTracker.TasksManager.Backend.Api/\"]\nRUN dotnet restore \"TasksTracker.TasksManager.Backend.Api/TasksTracker.TasksManager.Backend.Api.csproj\"\nCOPY . .\nWORKDIR \"/src/TasksTracker.TasksManager.Backend.Api\"\nRUN dotnet build \"TasksTracker.TasksManager.Backend.Api.csproj\" -c $configuration -o /app/build\n\nFROM build AS publish\nARG configuration=Release\nRUN dotnet publish \"TasksTracker.TasksManager.Backend.Api.csproj\" -c $configuration -o /app/publish /p:UseAppHost=false\n\nFROM base AS final\nWORKDIR /app\nCOPY --from=publish /app/publish .\nENTRYPOINT [\"dotnet\", \"TasksTracker.TasksManager.Backend.Api.dll\"]\n</code></pre> <pre><code>cd ~\\TasksTracker.ContainerApps\n</code></pre> <pre><code>docker build -t backend-api-status-quo -f .\\TasksTracker.TasksManager.Backend.Api\\Dockerfile .\n\ndocker image list\n</code></pre> <p>This yields a sizable image at 222 MB!</p> <p></p> <p>This image is comprised of two images, 452 packages, and has 19 vulnerabilities.</p> <p></p>"},{"location":"aca/12-optimize-containers/#12-chiseled-images","title":"1.2. Chiseled Images","text":"<p>Microsoft and Ubuntu's creator, Canonical, collaborated on the concept of a chiseled image for .NET. Take a general-purpose base image and start chiseling away until you are left with an image that contains nothing more than the bare necessities to run your workload. No shell, no package manager, no bloat.</p> Backend.Api Dockerfile.chiseled <pre><code>FROM mcr.microsoft.com/dotnet/aspnet:8.0-jammy-chiseled AS base\nWORKDIR /app\nEXPOSE 5000\n\nENV ASPNETCORE_URLS=http://+:5000\n\nUSER app\nFROM mcr.microsoft.com/dotnet/sdk:8.0-jammy AS build\nARG configuration=Release\nWORKDIR /src\nCOPY [\"TasksTracker.TasksManager.Backend.Api/TasksTracker.TasksManager.Backend.Api.csproj\", \"TasksTracker.TasksManager.Backend.Api/\"]\nRUN dotnet restore \"TasksTracker.TasksManager.Backend.Api/TasksTracker.TasksManager.Backend.Api.csproj\"\nCOPY . .\nWORKDIR \"/src/TasksTracker.TasksManager.Backend.Api\"\nRUN dotnet build \"TasksTracker.TasksManager.Backend.Api.csproj\" -c $configuration -o /app/build\n\nFROM build AS publish\nARG configuration=Release\nRUN dotnet publish \"TasksTracker.TasksManager.Backend.Api.csproj\" -c $configuration -o /app/publish /p:UseAppHost=false\n\nFROM base AS final\nWORKDIR /app\nCOPY --from=publish /app/publish .\nENTRYPOINT [\"dotnet\", \"TasksTracker.TasksManager.Backend.Api.dll\"]\n</code></pre> <p>Create a new file, <code>Dockerfile.chiseled</code> in the Backend Api root directory, then build the image again:</p> <pre><code>docker build -t backend-api-chiseled -f .\\TasksTracker.TasksManager.Backend.Api\\Dockerfile.chiseled .\n\ndocker image list\n</code></pre> <p>Our image now stands at a much smaller 115 MB - a drop of 107 MB and a size just 51.8% of the status quo image!</p> <p></p> <p>This image is comprised of one image, 331 packages, and has five vulnerabilities.</p> <p></p>"},{"location":"aca/12-optimize-containers/#13-chiseled-ahead-of-time-aot-compilation","title":"1.3 Chiseled &amp; Ahead-of-time (AOT) Compilation","text":"<p>Ahead-of-time (AOT) compilation was first introduced with .NET 7. AOT compiles the application to native code instead of Intermediate Language (IL). This means that we must have foresight as to what platform will be hosting the application. Our process is simplified by the fact that containers in Azure Container Apps are only Linux-hosted. By using native code, we will bypass the just-in-time (JIT) compiler when the container executes, which means we will have faster startup and a smaller memory footprint. It also means these images can run in environments where JIT compilation may not be permitted.</p> Backend.Api Dockerfile.chiseled.aot <pre><code>FROM mcr.microsoft.com/dotnet/nightly/runtime-deps:8.0-jammy-chiseled-aot AS base\nWORKDIR /app\nEXPOSE 5000\n\nENV ASPNETCORE_URLS=http://+:5000\n\nUSER app\nFROM mcr.microsoft.com/dotnet/nightly/sdk:8.0-jammy-aot AS build\nARG configuration=Release\nWORKDIR /src\nCOPY [\"TasksTracker.TasksManager.Backend.Api/TasksTracker.TasksManager.Backend.Api.csproj\", \"TasksTracker.TasksManager.Backend.Api/\"]\nRUN dotnet restore \"TasksTracker.TasksManager.Backend.Api/TasksTracker.TasksManager.Backend.Api.csproj\"\nCOPY . .\nWORKDIR \"/src/TasksTracker.TasksManager.Backend.Api\"\nRUN dotnet build \"TasksTracker.TasksManager.Backend.Api.csproj\" -c $configuration -o /app/build\n\nFROM build AS publish\nARG configuration=Release\nRUN dotnet publish \"TasksTracker.TasksManager.Backend.Api.csproj\" -c $configuration -o /app/publish /p:UseAppHost=false\n\nFROM base AS final\nWORKDIR /app\nCOPY --from=publish /app/publish .\nENTRYPOINT [\"dotnet\", \"TasksTracker.TasksManager.Backend.Api.dll\"]\n</code></pre> <p>Create a new file, <code>Dockerfile.chiseled.aot</code> in the Backend Api root directory, then build the image again:</p> <pre><code>docker build -t backend-api-chiseled-aot -f .\\TasksTracker.TasksManager.Backend.Api\\Dockerfile.chiseled.aot .\n\ndocker image list\n</code></pre> <p>Nightly Images</p> <p>As the name implies, these images are produced nightly. They are not yet images that are versioned and stable in the registry. Your mileage may vary.</p> <p>Another massive reduction takes the image down to a mere 16 MB - a total drop of 206 MB and a size just 7.2% of the status quo image!</p> <p></p> <p>This image is comprised of one image, just 23 packages, and has nine vulnerabilities. Notably, the four additional vulnerabilities are in the <code>openssl 3.0.2</code> package in this image.</p> <p></p>"},{"location":"aca/12-optimize-containers/#14-deploying-the-new-status-quo","title":"1.4 Deploying the new Status Quo","text":"<p>While the image is vastly reduced, what hasn't changed is the functionality of the API. Whether you are executing it locally or deploying to Azure, the Backend API will continue to function as it always has. However, now it has less vulnerabilities, less time to transfer from the registry, less startup time, and less of a memory footprint. Furthermore, 16 MB is the uncompressed image. With compression, we are likely to continue dropping in size.</p> <p>Let's update our existing Backend API container app with a new build and revision:</p> <pre><code>## Build Backend Service on ACR and Push to ACR\n\naz acr build `\n--registry $AZURE_CONTAINER_REGISTRY_NAME `\n--image \"tasksmanager/$BACKEND_API_NAME\" `\n--file 'TasksTracker.TasksManager.Backend.Api/Dockerfile.chiseled.aot' . \n\n# Update Backend API App container app and create a new revision \naz containerapp update `\n--name $BACKEND_API_NAME  `\n--resource-group $RESOURCE_GROUP `\n--revision-suffix v$TODAY-6 `\n--set-env-vars \"ApplicationInsights__InstrumentationKey=secretref:appinsights-key\"\n</code></pre> <p>Verify that the application continues to work:</p> <pre><code>$FRONTEND_UI_BASE_URL\n</code></pre>"},{"location":"aca/12-optimize-containers/#2-optimizing-frontend-ui-backend-service-containers","title":"2. Optimizing Frontend UI &amp; Backend Service Containers","text":"<p>As all three projects use ASP.NET Core, we can follow the same approach with these two projects as well.how much you are able to reduce!</p>"},{"location":"aca/12-optimize-containers/#21-frontend-ui","title":"2.1 Frontend UI","text":""},{"location":"aca/12-optimize-containers/#211-the-status-quo","title":"2.1.1 The Status Quo","text":"<p>Our original <code>Dockerfile</code> looks like this:</p> Frontend.Ui Dockerfile <pre><code>FROM mcr.microsoft.com/dotnet/aspnet:8.0 AS base\nWORKDIR /app\nEXPOSE 5000\n\nENV ASPNETCORE_URLS=http://+:5000\n\nUSER app\nFROM mcr.microsoft.com/dotnet/sdk:8.0 AS build\nARG configuration=Release\nWORKDIR /src\nCOPY [\"TasksTracker.WebPortal.Frontend.Ui/TasksTracker.WebPortal.Frontend.Ui.csproj\", \"TasksTracker.WebPortal.Frontend.Ui/\"]\nRUN dotnet restore \"TasksTracker.WebPortal.Frontend.Ui/TasksTracker.WebPortal.Frontend.Ui.csproj\"\nCOPY . .\nWORKDIR \"/src/TasksTracker.WebPortal.Frontend.Ui\"\nRUN dotnet build \"TasksTracker.WebPortal.Frontend.Ui.csproj\" -c $configuration -o /app/build\n\nFROM build AS publish\nARG configuration=Release\nRUN dotnet publish \"TasksTracker.WebPortal.Frontend.Ui.csproj\" -c $configuration -o /app/publish /p:UseAppHost=false\n\nFROM base AS final\nWORKDIR /app\nCOPY --from=publish /app/publish .\nENTRYPOINT [\"dotnet\", \"TasksTracker.WebPortal.Frontend.Ui.dll\"]\n</code></pre> <pre><code>cd ~\\TasksTracker.ContainerApps\n</code></pre> <pre><code>docker build -t frontend-ui-status-quo -f .\\TasksTracker.WebPortal.Frontend.Ui\\Dockerfile .\n\ndocker image list\n</code></pre> <p>This yields an image size of 227 MB.</p>"},{"location":"aca/12-optimize-containers/#212-chiseled-ahead-of-time-aot-compilation","title":"2.1.2 Chiseled &amp; Ahead-of-time (AOT) Compilation","text":"<p>Skipping straight to AOT images:</p> Frontend.Ui Dockerfile.chiseled.aot <pre><code>FROM mcr.microsoft.com/dotnet/nightly/runtime-deps:8.0-jammy-chiseled-aot AS base\nWORKDIR /app\nEXPOSE 5000\n\nENV ASPNETCORE_URLS=http://+:5000\n\nUSER app\nFROM mcr.microsoft.com/dotnet/nightly/sdk:8.0-jammy-aot AS build\nARG configuration=Release\nWORKDIR /src\nCOPY [\"TasksTracker.WebPortal.Frontend.Ui/TasksTracker.WebPortal.Frontend.Ui.csproj\", \"TasksTracker.WebPortal.Frontend.Ui/\"]\nRUN dotnet restore \"TasksTracker.WebPortal.Frontend.Ui/TasksTracker.WebPortal.Frontend.Ui.csproj\"\nCOPY . .\nWORKDIR \"/src/TasksTracker.WebPortal.Frontend.Ui\"\nRUN dotnet build \"TasksTracker.WebPortal.Frontend.Ui.csproj\" -c $configuration -o /app/build\n\nFROM build AS publish\nARG configuration=Release\nRUN dotnet publish \"TasksTracker.WebPortal.Frontend.Ui.csproj\" -c $configuration -o /app/publish /p:UseAppHost=false\n\nFROM base AS final\nWORKDIR /app\nCOPY --from=publish /app/publish .\nENTRYPOINT [\"dotnet\", \"TasksTracker.WebPortal.Frontend.Ui.dll\"]\n</code></pre> <p>Create a new file, <code>Dockerfile.chiseled.aot</code> in the Frontend Ui root directory, then build the image again:</p> <pre><code>docker build -t frontend-ui-chiseled-aot -f .\\TasksTracker.WebPortal.Frontend.Ui\\Dockerfile.chiseled.aot .\n\ndocker image list\n</code></pre> <p>This much-improved image is now 20.6 MB.</p>"},{"location":"aca/12-optimize-containers/#22-backend-service","title":"2.2 Backend Service","text":""},{"location":"aca/12-optimize-containers/#221-the-status-quo","title":"2.2.1 The Status Quo","text":"<p>Our original <code>Dockerfile</code> looks like this:</p> Backend.Svc Dockerfile <pre><code>FROM mcr.microsoft.com/dotnet/aspnet:8.0 AS base\nWORKDIR /app\nEXPOSE 5000\n\nENV ASPNETCORE_URLS=http://+:5000\n\nUSER app\nFROM mcr.microsoft.com/dotnet/sdk:8.0 AS build\nARG configuration=Release\nWORKDIR /src\nCOPY [\"TasksTracker.Processor.Backend.Svc/TasksTracker.Processor.Backend.Svc.csproj\", \"TasksTracker.Processor.Backend.Svc/\"]\nRUN dotnet restore \"TasksTracker.Processor.Backend.Svc/TasksTracker.Processor.Backend.Svc.csproj\"\nCOPY . .\nWORKDIR \"/src/TasksTracker.Processor.Backend.Svc\"\nRUN dotnet build \"TasksTracker.Processor.Backend.Svc.csproj\" -c $configuration -o /app/build\n\nFROM build AS publish\nARG configuration=Release\nRUN dotnet publish \"TasksTracker.Processor.Backend.Svc.csproj\" -c $configuration -o /app/publish /p:UseAppHost=false\n\nFROM base AS final\nWORKDIR /app\nCOPY --from=publish /app/publish .\nENTRYPOINT [\"dotnet\", \"TasksTracker.Processor.Backend.Svc.dll\"]\n</code></pre> <pre><code>cd ~\\TasksTracker.ContainerApps\n</code></pre> <pre><code>docker build -t backend-svc-status-quo -f .\\TasksTracker.Processor.Backend.Svc\\Dockerfile .\n\ndocker image list\n</code></pre> <p>This yields an image size of 222 MB.</p>"},{"location":"aca/12-optimize-containers/#222-chiseled-ahead-of-time-aot-compilation","title":"2.2.2 Chiseled &amp; Ahead-of-time (AOT) Compilation","text":"<p>Skipping straight to AOT images:</p> Backend.Svc Dockerfile.chiseled.aot <pre><code>FROM mcr.microsoft.com/dotnet/nightly/runtime-deps:8.0-jammy-chiseled-aot AS base\nWORKDIR /app\nEXPOSE 5000\n\nENV ASPNETCORE_URLS=http://+:5000\n\nUSER app\nFROM mcr.microsoft.com/dotnet/nightly/sdk:8.0-jammy-aot AS build\nARG configuration=Release\nWORKDIR /src\nCOPY [\"TasksTracker.Processor.Backend.Svc/TasksTracker.Processor.Backend.Svc.csproj\", \"TasksTracker.Processor.Backend.Svc/\"]\nRUN dotnet restore \"TasksTracker.Processor.Backend.Svc/TasksTracker.Processor.Backend.Svc.csproj\"\nCOPY . .\nWORKDIR \"/src/TasksTracker.Processor.Backend.Svc\"\nRUN dotnet build \"TasksTracker.Processor.Backend.Svc.csproj\" -c $configuration -o /app/build\n\nFROM build AS publish\nARG configuration=Release\nRUN dotnet publish \"TasksTracker.Processor.Backend.Svc.csproj\" -c $configuration -o /app/publish /p:UseAppHost=false\n\nFROM base AS final\nWORKDIR /app\nCOPY --from=publish /app/publish .\nENTRYPOINT [\"dotnet\", \"TasksTracker.Processor.Backend.Svc.dll\"]\n</code></pre> <p>Create a new file, <code>Dockerfile.chiseled.aot</code> in the Backend Svc root directory, then build the image again:</p> <pre><code>docker build -t backend-svc-chiseled-aot -f .\\TasksTracker.Processor.Backend.Svc\\Dockerfile.chiseled.aot .\n\ndocker image list\n</code></pre> <p>This much-improved image is now 16 MB.</p>"},{"location":"aca/12-optimize-containers/#3-optimization-summary","title":"3. Optimization Summary","text":""},{"location":"aca/12-optimize-containers/#31-table-of-improvements","title":"3.1 Table of Improvements","text":"<p>The Backend API and the Backend Svc projects are all but identical while the Frontend UI project is just slightly larger. All three projects were cut down to less than 10% of their original size!</p> Image Size Size Reduction Size compared to Original Packages CVEs Backend API Original 222 MB 452 19 Backend API Chiseled &amp; AOT 16 MB 206 MB 7.2% 23 9 Frontend UI Original 226 MB 447 19 Frontend UI Chiseled &amp; AOT 21 MB 205 MB 9.3% 18 9 Backend Svc Original 222 MB 452 19 Backend Svc Chiseled &amp; AOT 16 MB 206 MB 7.2% 23 9"},{"location":"aca/12-optimize-containers/#32-build-deploy-all-services","title":"3.2 Build &amp; Deploy All Services","text":"<p>The last step is to build &amp; deploy updated images. For good measure, let's do the Backend API as well even though we did it earlier already.</p> <pre><code># Build Backend API on ACR and Push to ACR\naz acr build `\n--registry $AZURE_CONTAINER_REGISTRY_NAME `\n--image \"tasksmanager/$BACKEND_API_NAME\" `\n--file 'TasksTracker.TasksManager.Backend.Api/Dockerfile.chiseled.aot' . \n\n# Build Backend Service on ACR and Push to ACR\naz acr build `\n--registry $AZURE_CONTAINER_REGISTRY_NAME `\n--image \"tasksmanager/$BACKEND_SERVICE_NAME\" `\n--file 'TasksTracker.Processor.Backend.Svc/Dockerfile.chiseled.aot' .\n\n# Build Frontend Web App on ACR and Push to ACR\naz acr build `\n--registry $AZURE_CONTAINER_REGISTRY_NAME `\n--image \"tasksmanager/$FRONTEND_WEBAPP_NAME\" `\n--file 'TasksTracker.WebPortal.Frontend.Ui/Dockerfile.chiseled.aot' .\n</code></pre> <pre><code># Update Backend API App container app and create a new revision \naz containerapp update `\n--name $BACKEND_API_NAME  `\n--resource-group $RESOURCE_GROUP `\n--revision-suffix v$TODAY-7 `\n--set-env-vars \"ApplicationInsights__InstrumentationKey=secretref:appinsights-key\"\n\n# Update Frontend Web App container app and create a new revision \naz containerapp update `\n--name $FRONTEND_WEBAPP_NAME  `\n--resource-group $RESOURCE_GROUP `\n--revision-suffix v$TODAY-7 `\n--set-env-vars \"ApplicationInsights__InstrumentationKey=secretref:appinsights-key\"\n\n# Update Backend Background Service container app and create a new revision \naz containerapp update `\n--name $BACKEND_SERVICE_NAME `\n--resource-group $RESOURCE_GROUP `\n--revision-suffix v$TODAY-7 `\n--set-env-vars \"ApplicationInsights__InstrumentationKey=secretref:appinsights-key\"\n</code></pre> <p>Verify that the application continues to work with the three much smaller containers:</p> <pre><code>$FRONTEND_UI_BASE_URL\n</code></pre> <ul> <li> <p>Navigate to the root and persist the module to Git.</p> <pre><code>git add .\ngit commit -m \"Add Module 12\"\n</code></pre> </li> </ul>"},{"location":"aca/12-optimize-containers/#review","title":"Review","text":"<p>In this module, we have accomplished two objectives:</p> <ol> <li>Learned how to reduce container footprints.</li> <li>Built &amp; deployed updated, optimized images to Azure.</li> </ol>"},{"location":"aca/29-about-the-authors/","title":"Authors","text":""},{"location":"aca/29-about-the-authors/#taiseer-joudeh","title":"Taiseer Joudeh","text":"<p>Taiseer works for Microsoft Consultation Services as a Lead App Dev Consultant. He has more than 15 years of experience in developing and managing different software solutions for the finance, transportation, logistics, and e-commerce sectors.</p> <p>Taiseer has been deeply involved in .NET development since early framework versions with a deep knowledge of distributed systems, microservices architecture, cloud-native apps, and Microsoft Azure.</p> <p>He frequently publishes articles on his blog. Connect with Taiseer on  LinkedIn.</p>"},{"location":"aca/29-about-the-authors/#wael-kdouh","title":"Wael Kdouh","text":"<p>Wael is a Principal Cloud Solution Architect at Microsoft with over 20 years of experience developing innovative solutions for leading software companies. He has successfully led the completion of several mission-critical projects in multiple sectors such Airline Solutions and Retail to name a few.</p> <p>You will find him actively blogging on  Medium and occasionally posting on . Connect with Wael on  LinkedIn.</p>"},{"location":"aca/29-about-the-authors/#pankaj-agrawal","title":"Pankaj Agrawal","text":"<p>Pankaj is Developer at heart, currently working as Senior Cloud Solutions Architect at Microsoft and based out of Oslo, Norway. Pankaj works with several customers across Nordics, helping them to make best use of Cloud native technologies and accelerate their journey to cloud. In his spare time, Pankaj enjoys running into the woods and love to learn new technical skills. He is quite passionate about DevOps and Serverless technologies and truly believe in automating everything.</p> <p>Pankaj loves writing technical blogs and contributing to open source projects. He keeps a journal of his blog and projects here. Connect with Pankaj on  or on  LinkedIn.</p>"},{"location":"aca/29-about-the-authors/#simon-kurtz","title":"Simon Kurtz","text":"<p>Simon is a Senior Cloud Solutions Architect at Microsoft, focused primarily on App Innovation and Platform-as-a-Service (PaaS). He has been heavily involved in Azure API Management and Azure Container Apps. Simon has enjoyed working with diverse customers and empowering everyone and every organization to be successful with Azure. He is very passionate about teaching and community outreach, posting frequently on blogs and LinkedIn.</p> <p>Originally from Germany, he has lived in the United States for more than a quarter century and has called Columbia, MD his home for many years. When not working with technology, he is a Cub Scout den leader and soccer coach. Connect with Simon on  LinkedIn.</p>"},{"location":"aca/30-appendix/01-run-debug-dapr-app-vscode/","title":"Debug and Launch Dapr Applications in VSCode","text":"<p>This page shows you how to configure VSCode to run and debug multiple Dapr applications at same time.</p>"},{"location":"aca/30-appendix/01-run-debug-dapr-app-vscode/#debug-and-launch-dapr-applications-in-vscode","title":"Debug and launch Dapr applications in VSCode","text":"<p>We need to update VS code <code>tasks.json</code> and <code>launch.json</code> configuration files included in your workspace. Once completed you should be able to use the Run and Debug button on the activity bar within VS Code to launch all services to be able to debug them locally.</p> <p>First we need to add a new launch configuration for the Backend Web API and Frontend Web App projects. To accomplish this, open file <code>launch.json</code> and add the two configurations shown below.</p> <p>Note</p> <p>Make sure you append the configurations below to the existing array instead of replacing what you have. This way you will preserve your existing configuration and simply add two new ones.</p> Looking for complete launch.json? launch.json <pre><code>{\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \"Launch (web app)\",\n            \"type\": \"coreclr\",\n            \"request\": \"launch\",\n            \"preLaunchTask\": \"build-backend-api\",\n            \"program\": \"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui/bin/Debug/net6.0/TasksTracker.WebPortal.Frontend.Ui.dll\",\n            \"args\": [],\n            \"cwd\": \"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui\",\n            \"stopAtEntry\": false,\n            \"serverReadyAction\": {\n                \"action\": \"openExternally\",\n                \"pattern\": \"\\\\bNow listening on:\\\\s+(https?://\\\\S+)\"\n            },\n            \"env\": {\n                \"ASPNETCORE_ENVIRONMENT\": \"Development\"\n            },\n            \"sourceFileMap\": {\n                \"/Views\": \"${workspaceFolder}/Views\"\n            }\n        },\n        {\n            \"name\": \"Launch (backend api)\",\n            \"type\": \"coreclr\",\n            \"request\": \"launch\",\n            \"preLaunchTask\": \"build-webapp-ui\",\n            \"program\": \"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api/bin/Debug/net6.0/TasksTracker.TasksManager.Backend.Api.dll\",\n            \"args\": [],\n            \"cwd\": \"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api\",\n            \"stopAtEntry\": false,\n            \"serverReadyAction\": {\n                \"action\": \"openExternally\",\n                \"pattern\": \"\\\\bNow listening on:\\\\s+(https?://\\\\S+)\"\n            },\n            \"env\": {\n                \"ASPNETCORE_ENVIRONMENT\": \"Development\"\n            },\n            \"sourceFileMap\": {\n                \"/Views\": \"${workspaceFolder}/Views\"\n            }\n        },\n        {\n            \"name\": \"Launch (background processor)\",\n            \"type\": \"coreclr\",\n            \"request\": \"launch\",\n            \"preLaunchTask\": \"build-processor-svc\",\n            \"program\": \"${workspaceFolder}/TasksTracker.Processor.Backend.Svc/bin/Debug/net6.0/TasksTracker.Processor.Backend.Svc.dll\",\n            \"args\": [],\n            \"cwd\": \"${workspaceFolder}/TasksTracker.Processor.Backend.Svc\",\n            \"stopAtEntry\": false,\n            \"serverReadyAction\": {\n                \"action\": \"openExternally\",\n                \"pattern\": \"\\\\bNow listening on:\\\\s+(https?://\\\\S+)\"\n            },\n            \"env\": {\n                \"ASPNETCORE_ENVIRONMENT\": \"Development\"\n            },\n            \"sourceFileMap\": {\n                \"/Views\": \"${workspaceFolder}/Views\"\n            }\n        },\n        {\n            \"name\": \".NET Core Attach\",\n            \"type\": \"coreclr\",\n            \"request\": \"attach\"\n        },\n        {\n            \"name\": \"Launch (backend api) with Dapr\",\n            \"type\": \"coreclr\",\n            \"request\": \"launch\",\n            \"preLaunchTask\": \"backend-api-dapr-debug\",\n            \"program\": \"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api/bin/Debug/net6.0/TasksTracker.TasksManager.Backend.Api.dll\",\n            \"args\": [],\n            \"cwd\": \"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api\",\n            \"stopAtEntry\": false,\n            \"serverReadyAction\": {\n                \"action\": \"openExternally\",\n                \"pattern\": \"\\\\bNow listening on:\\\\s+(https?://\\\\S+)\"\n            },\n            \"env\": {\n                \"ASPNETCORE_ENVIRONMENT\": \"Development\"\n            },\n            \"sourceFileMap\": {\n                \"/Views\": \"${workspaceFolder}/Views\"\n            },\n            \"postDebugTask\": \"daprd-down-backend-api\"\n        },\n        {\n            \"name\": \"Launch (web app) with Dapr\",\n            \"type\": \"coreclr\",\n            \"request\": \"launch\",\n            \"preLaunchTask\": \"webapp-ui-dapr-debug\",\n            \"program\": \"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui/bin/Debug/net6.0/TasksTracker.WebPortal.Frontend.Ui.dll\",\n            \"args\": [],\n            \"cwd\": \"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui\",\n            \"stopAtEntry\": false,\n            \"serverReadyAction\": {\n                \"action\": \"openExternally\",\n                \"pattern\": \"\\\\bNow listening on:\\\\s+(https?://\\\\S+)\"\n            },\n            \"env\": {\n                \"ASPNETCORE_ENVIRONMENT\": \"Development\"\n            },\n            \"sourceFileMap\": {\n                \"/Views\": \"${workspaceFolder}/Views\"\n            },\n            \"postDebugTask\": \"webapp-ui-daprd-down\"\n        },\n        {\n            \"name\": \"Launch (background processor) with Dapr\",\n            \"type\": \"coreclr\",\n            \"request\": \"launch\",\n            \"preLaunchTask\": \"processor-svc-dapr-debug\",\n            \"program\": \"${workspaceFolder}/TasksTracker.Processor.Backend.Svc/bin/Debug/net6.0/TasksTracker.Processor.Backend.Svc.dll\",\n            \"args\": [],\n            \"cwd\": \"${workspaceFolder}/TasksTracker.Processor.Backend.Svc\",\n            \"stopAtEntry\": false,\n            \"serverReadyAction\": {\n                \"action\": \"openExternally\",\n                \"pattern\": \"\\\\bNow listening on:\\\\s+(https?://\\\\S+)\"\n            },\n            \"env\": {\n                \"ASPNETCORE_ENVIRONMENT\": \"Development\"\n            },\n            \"sourceFileMap\": {\n                \"/Views\": \"${workspaceFolder}/Views\"\n            },\n            \"postDebugTask\": \"processor-svc-daprd-down\"\n        }\n    ],\n    \"compounds\": [\n        {\n            \"name\": \"RunAll\",\n            \"configurations\": [\"Launch (web app)\", \"Launch (backend api)\", \"Launch (background processor)\",],\n            \"stopAll\": true\n        },\n        {\n            \"name\": \"RunAll with Dapr\",\n            \"configurations\": [ \"Launch (backend api) with Dapr\", \"Launch (web app) with Dapr\", \"Launch (background processor) with Dapr\", ],\n            \"stopAll\": true\n        }\n    ]\n}\n</code></pre> <p>Note</p> <p>The configuration below assumes that you are using .net 6. If you are using a different .net version make sure you update the paths to use the correct version. For example if using .net 7 then change the path to say net7.0 instead of net6.0.</p> launch.json <pre><code>{\"configurations\":\n[\n  {\n    \"name\": \"Launch (backend api) with Dapr\",\n    \"type\": \"coreclr\",\n    \"request\": \"launch\",\n    \"preLaunchTask\": \"backend-api-dapr-debug\",\n    \"program\": \"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api/bin/Debug/net6.0/TasksTracker.TasksManager.Backend.Api.dll\",\n    \"args\": [],\n    \"cwd\": \"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api\",\n    \"stopAtEntry\": false,\n    \"serverReadyAction\": {\n      \"action\": \"openExternally\",\n      \"pattern\": \"\\\\bNow listening on:\\\\s+(https?://\\\\S+)\"\n    },\n    \"env\": {\n      \"ASPNETCORE_ENVIRONMENT\": \"Development\"\n    },\n    \"sourceFileMap\": {\n      \"/Views\": \"${workspaceFolder}/Views\"\n    },\n    \"postDebugTask\": \"daprd-down-backend-api\"\n  },\n  {\n    \"name\": \"Launch (web app) with Dapr\",\n    \"type\": \"coreclr\",\n    \"request\": \"launch\",\n    \"preLaunchTask\": \"webapp-ui-dapr-debug\",\n    \"program\": \"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui/bin/Debug/net6.0/TasksTracker.WebPortal.Frontend.Ui.dll\",\n    \"args\": [],\n    \"cwd\": \"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui\",\n    \"stopAtEntry\": false,\n    \"serverReadyAction\": {\n      \"action\": \"openExternally\",\n      \"pattern\": \"\\\\bNow listening on:\\\\s+(https?://\\\\S+)\"\n    },\n    \"env\": {\n      \"ASPNETCORE_ENVIRONMENT\": \"Development\"\n    },\n    \"sourceFileMap\": {\n      \"/Views\": \"${workspaceFolder}/Views\"\n    },\n    \"postDebugTask\": \"webapp-ui-daprd-down\"\n  }\n]}\n</code></pre> <p>Note</p> <p>We have a <code>preLaunchTask</code> and a <code>postDebugTask</code> which we need to define right now. Those tasks are Dapr tasks.</p> <p>The Dapr VSCode extension we have previously installed helps us to define those pre- and post-debug tasks.</p> <p>To accomplish this, open the file tasks.json and click Ctrl+Shift+P, and type Dapr: Scaffold Dapr Tasks.</p> <p>The Dapr VS Code extension will allow us to manage Dapr application and test it out in an easier way, the below image shows a full list of helper commands.</p> <p></p> <p>Now we will add 4 tasks, for each application, there will be a task to support the <code>preLaunch</code> activity and the <code>postDebug</code> activity (Terminate/Exit Dapr Sidecar process), so open file tasks.json and add the tasks below:</p> tasks.json <pre><code>{\n  \"tasks\": [\n    {\n      \"appId\": \"tasksmanager-backend-api\",\n      \"appPort\": [web api application port number found under properties-&gt;launchSettings.json. e.g. 7112],\n      \"httpPort\": 3500,\n      \"grpcPort\": 50001,\n      \"appSsl\": true,\n      \"label\": \"backend-api-dapr-debug\",\n      \"type\": \"dapr\",\n      \"dependsOn\": \"build-backend-api\",\n      // Uncomment this line after adding Azure Cosmos DB in module 4\n      //\"componentsPath\": \"./components\"\n    },\n    {\n      \"appId\": \"tasksmanager-backend-api\",\n      \"label\": \"daprd-down-backend-api\",\n      \"type\": \"daprd-down\"\n    },\n    {\n      \"appId\": \"tasksmanager-frontend-webapp\",\n      \"appPort\": [frontend application port number found under properties-&gt;launchSettings.json. e.g. 7112],\n      \"httpPort\": 3501,\n      \"grpcPort\": 50002,\n      \"appSsl\": true,\n      \"label\": \"webapp-ui-dapr-debug\",\n      \"type\": \"dapr\",\n      \"dependsOn\": \"build-webapp-ui\"\n    },\n    {\n      \"appId\": \"tasksmanager-frontend-webapp\",\n      \"label\": \"webapp-ui-daprd-down\",\n      \"type\": \"daprd-down\"\n    }\n  ]}\n</code></pre> Curious to learn more about the tasks.json file above? <ul> <li>The tasks with the label <code>backend-api-dapr-debug</code> will invoke the <code>daprd</code> task. This task is similar to calling dapr run from CLI.</li> <li>We are setting the appPort, httpPort, and grpcPort properties (grpcPort is needed in future modules when we start using the state manager building block.  If you didn't set it, you might face a similar issue)</li> <li>We are setting the \u201ccomponentsPath\u201d property. This is needed when start working with the state manager, pub/sub, etc.</li> <li>We are setting the dependsOn property, so this means this task will fire after the dependsOn tasks complete successfully. We need to add those dependsOn tasks.</li> <li>The tasks with the label <code>daprd-down-backend-api</code> will terminate the Dapr Sidecar process. This will be used for the <code>postDebug</code> activity in configuration.json.</li> <li>For a complete list of available properties please check this link.</li> </ul> <p>Next let's add the dependsOn tasks. Open <code>tasks.json</code> and add the tasks below:</p> tasks.json<pre><code>{\n    \"label\": \"build-backend-api\",\n    \"command\": \"dotnet\",\n    \"type\": \"process\",\n    \"args\": [\n        \"build\",\n        \"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api/TasksTracker.TasksManager.Backend.Api.csproj\",\n        \"/property:GenerateFullPaths=true\",\n        \"/consoleloggerparameters:NoSummary\"\n    ],\n    \"problemMatcher\": \"$msCompile\"\n},\n{\n    \"label\": \"build-webapp-ui\",\n    \"command\": \"dotnet\",\n    \"type\": \"process\",\n    \"args\": [\n        \"build\",\n        \"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui/TasksTracker.WebPortal.Frontend.Ui.csproj\",\n        \"/property:GenerateFullPaths=true\",\n        \"/consoleloggerparameters:NoSummary\"\n    ],\n    \"problemMatcher\": \"$msCompile\"\n}\n</code></pre> Looking for complete tasks.json? tasks.json <pre><code>{\n    \"version\": \"2.0.0\",\n    \"tasks\": [\n        {\n            \"label\": \"build-backend-api\",\n            \"command\": \"dotnet\",\n            \"type\": \"process\",\n            \"args\": [\n                \"build\",\n                \"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api/TasksTracker.TasksManager.Backend.Api.csproj\",\n                \"/property:GenerateFullPaths=true\",\n                \"/consoleloggerparameters:NoSummary\"\n            ],\n            \"problemMatcher\": \"$msCompile\"\n        },\n        {\n            \"label\": \"publish-backend-api\",\n            \"command\": \"dotnet\",\n            \"type\": \"process\",\n            \"args\": [\n                \"publish\",\n                \"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api/TasksTracker.TasksManager.Backend.Api.csproj\",\n                \"/property:GenerateFullPaths=true\",\n                \"/consoleloggerparameters:NoSummary\"\n            ],\n            \"problemMatcher\": \"$msCompile\"\n        },\n        {\n            \"label\": \"watch-backend-api\",\n            \"command\": \"dotnet\",\n            \"type\": \"process\",\n            \"args\": [\n                \"watch\",\n                \"run\",\n                \"--project\",\n                \"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api/TasksTracker.TasksManager.Backend.Api.csproj\"\n            ],\n            \"problemMatcher\": \"$msCompile\"\n        },\n        {\n            \"label\": \"build-webapp-ui\",\n            \"command\": \"dotnet\",\n            \"type\": \"process\",\n            \"args\": [\n                \"build\",\n                \"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui/TasksTracker.WebPortal.Frontend.Ui.csproj\",\n                \"/property:GenerateFullPaths=true\",\n                \"/consoleloggerparameters:NoSummary\"\n            ],\n            \"problemMatcher\": \"$msCompile\"\n        },\n        {\n            \"label\": \"publish-webapp-ui\",\n            \"command\": \"dotnet\",\n            \"type\": \"process\",\n            \"args\": [\n                \"publish\",\n                \"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui/TasksTracker.WebPortal.Frontend.Ui.csproj\",\n                \"/property:GenerateFullPaths=true\",\n                \"/consoleloggerparameters:NoSummary\"\n            ],\n            \"problemMatcher\": \"$msCompile\"\n        },\n        {\n            \"label\": \"watch-webapp-ui\",\n            \"command\": \"dotnet\",\n            \"type\": \"process\",\n            \"args\": [\n                \"watch\",\n                \"run\",\n                \"--project\",\n                \"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui/TasksTracker.WebPortal.Frontend.Ui.csproj\"\n            ],\n            \"problemMatcher\": \"$msCompile\"\n        },\n        {\n            \"label\": \"build-processor-svc\",\n            \"command\": \"dotnet\",\n            \"type\": \"process\",\n            \"args\": [\n                \"build\",\n                \"${workspaceFolder}/TasksTracker.Processor.Backend.Svc/TasksTracker.Processor.Backend.Svc.csproj\",\n                \"/property:GenerateFullPaths=true\",\n                \"/consoleloggerparameters:NoSummary\"\n            ],\n            \"problemMatcher\": \"$msCompile\"\n        },\n        {\n            \"label\": \"publish-processor-svc\",\n            \"command\": \"dotnet\",\n            \"type\": \"process\",\n            \"args\": [\n                \"publish\",\n                \"${workspaceFolder}/TasksTracker.Processor.Backend.Svc/TasksTracker.Processor.Backend.Svc.csproj\",\n                \"/property:GenerateFullPaths=true\",\n                \"/consoleloggerparameters:NoSummary\"\n            ],\n            \"problemMatcher\": \"$msCompile\"\n        },\n        {\n            \"label\": \"watch-processor-svc\",\n            \"command\": \"dotnet\",\n            \"type\": \"process\",\n            \"args\": [\n                \"watch\",\n                \"run\",\n                \"--project\",\n                \"${workspaceFolder}/TasksTracker.Processor.Backend.Svc/TasksTracker.Processor.Backend.Svc.csproj\"\n            ],\n            \"problemMatcher\": \"$msCompile\"\n        },\n        {\n            \"label\": \"build-all\",\n            \"dependsOn\": [\n                \"build-backend-api\",\n                \"build-webapp-ui\",\n                \"build-processor-svc\"\n            ],\n            \"problemMatcher\": [],\n            \"group\": {\n                \"kind\": \"build\",\n                \"isDefault\": true\n            }\n        },\n        {\n            \"appId\": \"tasksmanager-backend-api\",\n            \"appPort\": 7088,\n            \"httpPort\": 3500,\n            \"grpcPort\": 50001,\n            \"appSsl\": true,\n            \"label\": \"backend-api-dapr-debug\",\n            \"type\": \"dapr\",\n            \"dependsOn\": \"build-backend-api\",\n            \"componentsPath\": \"./components\"\n        },\n        {\n            \"appId\": \"tasksmanager-backend-api\",\n            \"label\": \"daprd-down-backend-api\",\n            \"type\": \"daprd-down\"\n        },\n        {\n            \"appId\": \"tasksmanager-frontend-webapp\",\n            \"appPort\": 7208,\n            \"httpPort\": 3501,\n            \"grpcPort\": 50002,\n            \"appSsl\": true,\n            \"label\": \"webapp-ui-dapr-debug\",\n            \"type\": \"dapr\",\n            \"dependsOn\": \"build-webapp-ui\"\n        },\n        {\n            \"appId\": \"tasksmanager-frontend-webapp\",\n            \"label\": \"webapp-ui-daprd-down\",\n            \"type\": \"daprd-down\"\n        },\n        {\n            \"appId\": \"tasksmanager-backend-processor\",\n            \"appPort\": 7263,\n            \"httpPort\": 3502,\n            \"grpcPort\": 50003,\n            \"appSsl\": true,\n            \"label\": \"processor-svc-dapr-debug\",\n            \"type\": \"dapr\",\n            \"dependsOn\": \"build-processor-svc\",\n            \"componentsPath\": \"./components\"\n        },\n        {\n            \"appId\": \"tasksmanager-backend-processor\",\n            \"label\": \"processor-svc-daprd-down\",\n            \"type\": \"daprd-down\"\n        }\n    ]\n}\n</code></pre> <p>Lastly, we need to add a <code>compound launch</code> property, so we launch and debug both applications together.</p> <p>To accomplish this, open the file <code>launch.json</code> again and add the below array after the <code>configuration</code> array.</p> launch.json<pre><code>\"compounds\": [\n    {\n        \"name\": \"RunAll with Dapr\",\n        \"configurations\": [\n            \"Launch (backend api) with Dapr\",\n            \"Launch (web app) with Dapr\"\n        ],\n        \"stopAll\": true\n    }\n]\n</code></pre> <p>Success</p> <p>If all is done correctly, you should be able to see a debug configuration named <code>RunAll with Dapr</code> and you should be able to just hit ++F5++, sit breakpoints and debug both applications locally in VS Code.</p> <p></p>"},{"location":"aca/30-appendix/02-github-local-codespaces/","title":"Inner loop, testing your changes locally or using GitHub Codespaces","text":"<ul> <li><code>docs/aca</code> folder , contains all the mark-down documentation files for all the modules</li> <li><code>docs/assets</code> folder, contains all the images, slides, and files used in the lab</li> <li>This site uses, Material for MkDocs. Take some time to familiarize yourself with the theme and the features it provides.</li> </ul>"},{"location":"aca/30-appendix/02-github-local-codespaces/#locally","title":"Locally","text":"<p>Checkout the repo locally using below command:</p> <pre><code>git clone  https://github.com/Azure/aca-dotnet-workshop.git\n</code></pre> <p>Using bash terminal or wsl terminal, navigate to the repo root folder and run the below command to build and run the website locally:</p> <pre><code>make docs-local\n</code></pre>"},{"location":"aca/30-appendix/02-github-local-codespaces/#using-github-codespaces","title":"Using GitHub Codespaces","text":"<p>This repo has a github codespaces dev container defined. This container is based on ubuntu 20.04 and contains all the libraries and components to run github pages locally in Github Codespaces. To test your changes follow these steps:</p> <ul> <li>Enable GitHub codespaces for your account</li> <li>Fork this repo</li> <li>Open the repo in github codespaces</li> <li>Wait for the container to build and connect to it</li> <li>Run the website in github codespaces using below command</li> </ul> <pre><code>make docs-local\n</code></pre> <p></p>"},{"location":"aca/30-appendix/03-variables/","title":"Variables","text":"<p>We declare numerous variables throughout this workshop. As these modules are lengthy, you will likely complete them over multiple sessions. However, as sessions are additive, they require previously-set variables.</p> <p>Shell Support</p> <p>Presently, this supports PowerShell only, and we would like to see community contributions for shell scripts, please. Please see GitHub Issue #111.</p>"},{"location":"aca/30-appendix/03-variables/#setting-variables","title":"Setting Variables","text":""},{"location":"aca/30-appendix/03-variables/#powershell","title":"PowerShell","text":"<p>Execute this script to persist all variables in the current session at any time. We recommend you do this after you complete each module or any other time you are taking a break from the workshop. Execute it in the root (e.g. <code>~\\TasksTracker.ContainerApps</code>) to keep setting and updating the same <code>Variables.ps1</code> file.</p> Set-Variables.ps1 <pre><code>$file = \"./Variables.ps1\"\n$i = 0\n\n# Create a new or replace any existing file (note how we do not use -Append in the first line).\n\"# Execute with `\"$file`\" to restore previously-saved variables.\" | Out-File -FilePath $file\n\n$vars = @(\n    \"ACA_ENVIRONMENT_SUBNET_ID\",\n    \"API_APP_PORT\",\n    \"APPINSIGHTS_NAME\",\n    \"APPINSIGHTS_INSTRUMENTATIONKEY\",\n    \"AZURE_CONTAINER_REGISTRY_NAME\",\n    \"AZURE_SUBSCRIPTION_ID\",\n    \"BACKEND_API_EXTERNAL_BASE_URL\",\n    \"BACKEND_API_INTERNAL_BASE_URL\",\n    \"BACKEND_API_NAME\",\n    \"BACKEND_API_PRINCIPAL_ID\",\n    \"BACKEND_SERVICE_APP_PORT\",\n    \"BACKEND_SERVICE_NAME\",\n    \"BACKEND_SERVICE_PRINCIPAL_ID\",\n    \"COSMOS_DB_ACCOUNT\",\n    \"COSMOS_DB_CONTAINER\",\n    \"COSMOS_DB_DBNAME\",\n    \"COSMOS_DB_ENDPOINT\",\n    \"COSMOS_DB_PRIMARY_MASTER_KEY\",\n    \"ENVIRONMENT\",\n    \"FRONTEND_UI_BASE_URL\",\n    \"FRONTEND_UI_BASE_URL_LOCAL\",\n    \"FRONTEND_WEBAPP_NAME\",\n    \"KEYVAULT_NAME\",\n    \"KEYVAULT_SECRETS_OFFICER_ROLE_ID\",\n    \"KEYVAULT_SECRETS_USER_ROLE_ID\",\n    \"LOCATION\",\n    \"RANDOM_STRING\",\n    \"RESOURCE_GROUP\",\n    \"REVISION_NAME\",\n    \"ROLE_ID\",\n    \"SERVICE_BUS_CONNECTION_STRING\",\n    \"SERVICE_BUS_NAMESPACE_NAME\",\n    \"SERVICE_BUS_TOPIC_NAME\",\n    \"SERVICE_BUS_TOPIC_SUBSCRIPTION\",\n    \"SIGNEDIN_USERID\",\n    \"STORAGE_ACCOUNT_NAME\",\n    \"STORAGE_ACCOUNT_KEY\",\n    \"TARGET_PORT\",\n    \"UI_APP_PORT\",\n    \"VNET_NAME\",\n    \"WORKSPACE_ID\",\n    \"WORKSPACE_NAME\",\n    \"WORKSPACE_SECRET\"\n);\n\nforeach ($var in $vars) { \n    # Ensure the variable exists. If not, don't attempt to get it and don't write out a blank value.\n\n    if (Test-Path variable:$var) {\n        $val = Get-Variable -Name $var -ValueOnly\n\n        # Powershell 7.4.0 requires a bit more type safety by setting quotes around strings.\n        if ($val.GetType().Name -eq \"String\") {\n            $val = \"`\"$val`\"\"\n        }\n\n        \"Set-Variable -Scope Global -Name $var -Value $val\" | Out-File -FilePath $file -Append\n        $i++\n    }\n}\n\n# $TODAY is a special variable that simply, easily captures today's date.\n\"Set-Variable -Scope Global -Name TODAY -Value (Get-Date -Format 'yyyyMMdd')\" | Out-File -FilePath $file -Append\n$i++\n\n# When the Variables.ps1 script executes, the following line will inform how many variables were set in the current session.\n\"Write-Host `\"Set $i variable$($i -eq 1 ? '' : 's').`\"\" | Out-File -FilePath $file -Append\n\nWrite-Host \"`nWrote $i variable$($i -eq 1 ? '' : 's') to $file.`n\"\n</code></pre>"},{"location":"aca/30-appendix/03-variables/#restoring-variables","title":"Restoring Variables","text":""},{"location":"aca/30-appendix/03-variables/#powershell_1","title":"PowerShell","text":"<p>The output of the <code>Set-Variables.ps1</code> script is stored in the same directory where you execute that script. You can quickly apply those variables and get back to a working state by executing <code>.\\Variables.ps1</code> in your PowerShell console. This is useful after having taken a break from the workshop and losing the session or when you are asked to open a second session such as when you are running multiple microservices locally with dapr.</p>"}]}