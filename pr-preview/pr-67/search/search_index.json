{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Homepage","text":"<p>There is no doubt that building containerized applications and following a microservices architecture is one of the most common software architecture patterns observed in the past couple of years.</p> <p>Microsoft Azure offers different services to package, deploy and manage cloud-native applications, each of which serves a certain purpose and has its own pros and cons. This page provides a good comparison between the available services to host and manage cloud-native containerized applications in Azure. </p> <p>Whereas building cloud-native apps on Azure Kubernetes Service (AKS) is powerful,  there is a bit of a learning curve needed when it comes to creating and configuring the cluster, configuring networking between microservices, services discovery, certificates provisioning, and lastly managing the cluster over the lifetime of the application.</p> <p>In this workshop, we will be focusing on a containerization service offered by Microsoft Azure which is Azure Container Apps (ACA). Microsoft announced the public preview of Azure Container Apps back in Nov 2021 and in May 2022 it announced the General Availability of Azure Container Apps. In brief, Azure Container Apps is a fully managed serverless container runtime for building and running cloud-native applications which focuses on the business logic of the apps rather than on cloud infrastructure management.</p>"},{"location":"aca/00-workshop-intro/","title":"Introduction","text":""},{"location":"aca/00-workshop-intro/#description","title":"Description","text":"<p>The Building Microservice Applications with Azure Container Apps workshop will provide you with the practical knowledge to create, deploy and operate an enterprise level microservice application deployed on the latest serverless containers offering Azure Container Apps. We will demonstrate enabling different components like Dapr which will allow you to address common challenges when building an event driven distributed application while keeping your code platform agnostic. In addition to this you will get familiar with the built-in autoscaling capabilities in Azure Container Apps using KEDA and how to control spending by scaling down to zero replicas.</p>"},{"location":"aca/00-workshop-intro/#objectives-outcomes","title":"Objectives &amp; Outcomes","text":"<p>After completing the workshop, you should:</p> <ul> <li>Gain practical knowledge to create, deploy, and operate a distributed application with multiple microservices deployed to ACA.</li> <li>Setup up Dapr locally and configure VS code to support a complete local debugging experience for your distributed microservice application project.</li> <li>Use various building blocks of Dapr to simplify the building of Microservice applications, utilizing different building blocks like service-to-service Invocation using HTTP and gRPC, State management, Pub and Sub, and Input &amp; output bindings.</li> <li>Get familiar with Autoscaling feature in ACA using KEDA.</li> <li>Configure Monitoring, Observability, and distributed tracings of ACA using Application Insights.</li> <li>Setup Continuous Deployment for your microservice application using GitHub Actions.</li> <li>Recreate your entire microservice application components and generate IaC scripts using Bicep.</li> </ul>"},{"location":"aca/00-workshop-intro/1-aca-core-components/","title":"ACA Core Components Overview","text":""},{"location":"aca/00-workshop-intro/1-aca-core-components/#overview-of-azure-container-apps-core-components","title":"Overview of Azure Container Apps Core Components","text":"<p>The main components of Azure Container Apps are:</p> <p></p> <p>1. Environments The Environment is a secure boundary around several Container Apps. It contains one or more container apps. All container apps within an environment are deployed into a dedicated Azure Virtual Network, which makes it possible for these different container apps to communicate securely. In addition, all the logs produced from all container apps in the environment are sent to a dedicated Log Analytics workspace.</p> <p>2. Log Analytics Workspace Used to provide monitoring and observability functionality. Each environment will have its own Log Analytic workspace and will be shared among all container apps within the environment.</p> <p>3. Container Apps Each container App represents a single deployable unit that can contain one or more related containers. More than one container is an advanced use case. For this workshop we will deploy a single container in each container app. More about multiple containers in the same single Azure Container App can be found here.</p> <p>4. Revisions For each container app, you can create up to 100 revisions. Revisions are a way to deploy multiple versions of an app where you have the option to send the traffic to a certain revision. You can select if revision mode will support 1 active revision or multiple active revisions at the same time to support A/B testing scenarios or canary deployments. A container app running in single revision mode will have a single revision that is backed by zero-many Pods/replicas.</p> <p>5. Containers Containers in the Azure Container Apps are grouped together in pods/replicas inside revision snapshots. A Pod/replica is composed of the application container and any required sidecar containers. Containers can be deployed from any public or private container registry, and they support any Linux-based x86-64 (linux/amd64) images. At the time of creating this workshop Windows based images are not supported.</p>"},{"location":"aca/00-workshop-intro/2-scenario-architecture/","title":"Scenario and Solution Architecture","text":""},{"location":"aca/00-workshop-intro/2-scenario-architecture/#workshop-scenario","title":"Workshop Scenario","text":"<p>In this workshop we will build a tasks management application following the microservices architecture pattern. This application will consist of 3 microservices where each microservice has certain capabilities to demonstrate how ACA and Dapr can simplify the building of a microservices application. Below is the architecture diagram of the application we are going to build in this workshop.</p>"},{"location":"aca/00-workshop-intro/2-scenario-architecture/#solution-architecture","title":"Solution Architecture","text":"<ol> <li>ACA Web App-Frontend is a simple ASP.NET Razor pages web app that accepts requests from public users to manage their tasks. It invokes the component \"ACA WebAPI-Backend\" endpoints via HTTP or gRPC.</li> <li>ACA WebAPI-Backend is a backend Web API which contains the business logic of tasks management service, data storage, and publishing messages to Azure Service Bus Topic.</li> <li>ACA Processor-Backend is an event-driven backend processor which is responsible for sending emails to task owners based on messages coming from Azure Service Bus Topic. Here there is a continuously running background processor, which is based on Dapr Cron timer configuration, to flag overdue tasks.</li> <li>Autoscaling rules using KEDA are configured in the \"ACA Processor-Backend\" service to scale out/in replicas based on the the number of messages in the Azure Service Bus Topic. </li> <li>Azure Container Registry is used to build and host container images and deploy images from ACR to Azure Container Apps.</li> <li>Application Insights and Azure Log Analytics are used for Monitoring, Observability, and distributed tracings of ACA.</li> </ol>"},{"location":"aca/00-workshop-intro/3-dapr-integration/","title":"Dapr Integration in ACA","text":""},{"location":"aca/00-workshop-intro/3-dapr-integration/#dapr-overview","title":"Dapr Overview","text":"<p>As developers, we are often tasked with creating scalable, resilient, and distributed applications using microservices. But more often than not we face the same challenges: - Recovering state after failures - Services discovery and calling other microservices - Integration with external resources - Asynchronous communications between different services - Distributed tracing  - Measuring message calls and performance across components and networked services</p> <p>Dapr (Distributed Application Runtime) offers a solution for the common challenges that are faced in any distributed microservice application. Dapr can be used with any language (Go, .NET python, Node, Java, C++) and can run anywhere (On-premise, Kubernetes, and any public cloud (e.g. Azure)).</p> <p>Dapr's core component is the concept of a Building Block. So far Dapr supports 9 Building Blocks. Simply put, a Building Block is a modular component which encapsulates best practices and can be accessed over standard HTTP or gRPC APIs.</p> <p>Building Blocks address common challenges faced in building resilient microservices applications and implement best practices and patterns. Building Blocks provide consistent APIs and abstract away the implementation details to keep your code simple and portable.</p> <p>The diagram below shows the 9 Building Blocks which expose public APIs that can be called from your code, and can be configured using components to implement the building blocks\u2019 capability. Remember that you can pick whatever building block that suites your distributed microservice application and you can incorporate other building blocks as needed.</p> <p></p>"},{"location":"aca/00-workshop-intro/3-dapr-integration/#dapr-microservices","title":"Dapr &amp; Microservices","text":"<p>Dapr exposes its Building Blocks and components through a sidecar architecture. A sidecar enables Dapr to run in a separate memory process or separate container alongside your service. Sidecars provide isolation and encapsulation as they aren't part of the service, but connected to it. This separation enables each service to have its own runtime environment and be built upon different programming platforms.</p> <p></p> <p>This pattern is named Sidecar because it resembles a sidecar attached to a motorcycle. In the previous figure, note how the Dapr sidecar is attached to your service to provide distributed application capabilities.</p>"},{"location":"aca/00-workshop-intro/3-dapr-integration/#dapr-usage-in-the-workshop","title":"Dapr usage in the workshop","text":"<p>We are going to enable Dapr for all Azure Container Apps in the solution, the Dapr APIs/Building Blocks used in this workshop are:</p> <ul> <li>Service to Service invocation: \"ACA Web App-Frontend\" microservice invokes the \"ACA WebAPI-Backend\" microservice using Dapr sidecar via the Service-to-service invocation building block</li> <li>State Management: \"ACA WebAPI-Backend\" stores data on Azure Cosmos DB and stores email logs on Azure Table Storage using Dapr State Management building blocks.</li> <li>Pub/Sub: \"ACA WebAPI-Backend\" publishes messages to Azure Service Bus when a task is saved and the \"ACA Processor-Backend\" microservices consumes those messages and sends emails using SendGrid.</li> <li>Bindings: \"ACA Processor-Backend\" is triggered based on an incoming event such as a Cron job.</li> </ul>"},{"location":"aca/00-workshop-intro/4-prerequisites/","title":"Prerequisites","text":""},{"location":"aca/00-workshop-intro/4-prerequisites/#prerequisites","title":"Prerequisites","text":"<p>Make sure you have your development environment setup and configured.</p> <ol> <li>An Azure account with an active subscription - Create an account for free</li> <li>dotnet 6.0 or a higher version - Install</li> <li>Docker Desktop - Install </li> <li>Visual Studio Code - Install</li> <li>VS Code Docker extension - Install</li> <li>Dapr CLI - Install and Initialize</li> <li>VS Code Dapr extension. Depends on Dapr CLI - Install</li> <li>Azure CLI - Install</li> </ol>"},{"location":"aca/00-workshop-intro/4-prerequisites/#workshop-instructions","title":"Workshop Instructions","text":"<p>The workshop is divided into separate modules. Each module will guide you through building the solution code step-by-step. Ensure that you finish the modules in the right order as they have dependency on each other.</p> <p>If you don't want to build the solution code from scratch, you can clone the source code repository final version by utilizing below command, and you can use the modules to deploy Azure resources using the provided Azure CLI commands.</p> <pre><code>git clone https://github.com/Azure/aca-dotnet-workshop.git\n</code></pre>"},{"location":"aca/01-deploy-api-to-aca/","title":"Module 1 - Deploy Backend API to ACA","text":"<p>Module Duration</p> <p>60 minutes</p> <p>In this module, we will start by creating the first microservice named <code>ACA Web API \u2013 Backend</code> as illustrated in the architecture diagram. Followed by that we will provision the  Azure resources needed to deploy the service to Azure Container Apps using the Azure CLI.</p>"},{"location":"aca/01-deploy-api-to-aca/#1-create-the-backend-api-project-web-api","title":"1. Create the backend API project (Web API)","text":"<ul> <li> <p>Open a command-line terminal and create a folder for your project. Use the <code>code</code> command to launch Visual Studio Code from that directory as shown:     <pre><code>mkdir TasksTracker.ContainerApps\ncd TasksTracker.ContainerApps\ncode .\n</code></pre></p> </li> <li> <p>From VS Code Terminal tab, open developer command prompt or PowerShell terminal in the project folder <code>TasksTracker.ContainerApps</code> and initialize the project. This will create and ASP.NET Web API project scaffolded with a single controller.     <pre><code>dotnet new webapi -o TasksTracker.TasksManager.Backend.Api\n</code></pre></p> </li> <li> <p>Next we need to containerize this application, so we can push it to Azure Container Registry as a docker image then deploy it to Azure Container Apps. Start by opening the VS Code Command Palette (Ctrl+Shift+P) and select <code>Docker: Add Docker Files to Workspace...</code></p> <ul> <li>Use <code>.NET: ASP.NET Core</code> when prompted for application platform.</li> <li>Choose <code>Linux</code> when prompted to choose the operating system.</li> <li>You will be asked if you want to add Docker Compose files. Select <code>No</code>.</li> <li>Take a note of the provided application port as we will pass it later on as the --target-port for the <code>az containerapp create</code> command.</li> <li><code>Dockerfile</code> and <code>.dockerignore</code> files are added to the workspace.</li> </ul> </li> <li> <p>Add a new folder named <code>Models</code> and create a new file with name below. These are the DTOs that will be used across the projects.</p> </li> </ul> TaskModel.cs <pre><code>namespace TasksTracker.TasksManager.Backend.Api.Models\n{\npublic class TaskModel\n{\npublic Guid TaskId { get; set; }\npublic string TaskName { get; set; } = string.Empty;\npublic string TaskCreatedBy { get; set; } = string.Empty;\npublic DateTime TaskCreatedOn { get; set; }\npublic DateTime TaskDueDate { get; set; }\npublic string TaskAssignedTo { get; set; } = string.Empty;\npublic bool IsCompleted { get; set; }\npublic bool IsOverDue { get; set; }\n}\npublic class TaskAddModel\n{\npublic string TaskName { get; set; } = string.Empty;\npublic string TaskCreatedBy { get; set; } = string.Empty;\npublic DateTime TaskDueDate { get; set; }\npublic string TaskAssignedTo { get; set; } = string.Empty;\n}\npublic class TaskUpdateModel\n{\npublic Guid TaskId { get; set; }\npublic string TaskName { get; set; } = string.Empty;\npublic DateTime TaskDueDate { get; set; }\npublic string TaskAssignedTo { get; set; } = string.Empty;\n}\n}\n</code></pre> <ul> <li>Create new folder named Services (make sure it is created at the same level as the models folder and not inside the models folder itself) and add new files as shown below.     Add the Fake Tasks Manager service (In-memory),  this will be the interface of Tasks Manager service. We will work initially with data in memory to keep things simple with very limited dependency on any other components or data store and focus on the deployment of the backend API to ACA.     In the upcoming modules we will switch this implementation with a concrete data store where we are going to store data in Redis and Azure Cosmos DB using Dapr State Store building block</li> </ul> ITasksManager.csFakeTasksManager.cs <pre><code>using TasksTracker.TasksManager.Backend.Api.Models;\nnamespace TasksTracker.TasksManager.Backend.Api.Services\n{\npublic interface ITasksManager\n{\nTask&lt;List&lt;TaskModel&gt;&gt; GetTasksByCreator(string createdBy);\nTask&lt;TaskModel?&gt; GetTaskById(Guid taskId);\nTask&lt;Guid&gt; CreateNewTask(string taskName, string createdBy, string assignedTo, DateTime dueDate);\nTask&lt;bool&gt; UpdateTask(Guid taskId, string taskName, string assignedTo, DateTime dueDate);\nTask&lt;bool&gt; MarkTaskCompleted(Guid taskId);\nTask&lt;bool&gt; DeleteTask(Guid taskId);\n}\n}\n</code></pre> <p><pre><code>using TasksTracker.TasksManager.Backend.Api.Models;\nnamespace TasksTracker.TasksManager.Backend.Api.Services\n{\npublic class FakeTasksManager : ITasksManager\n{\nprivate List&lt;TaskModel&gt; _tasksList = new List&lt;TaskModel&gt;();\nRandom rnd = new Random();\nprivate void GenerateRandomTasks()\n{\nfor (int i = 0; i &lt; 10; i++)\n{\nvar task = new TaskModel()\n{\nTaskId = Guid.NewGuid(),\nTaskName = $\"Task number: {i}\",\nTaskCreatedBy = \"tjoudeh@bitoftech.net\",\nTaskCreatedOn = DateTime.UtcNow.AddMinutes(i),\nTaskDueDate = DateTime.UtcNow.AddDays(i),\nTaskAssignedTo = $\"assignee{rnd.Next(50)}@mail.com\",\n};\n_tasksList.Add(task);\n}\n}\npublic FakeTasksManager()\n{\nGenerateRandomTasks();\n}\npublic Task&lt;Guid&gt; CreateNewTask(string taskName, string createdBy, string assignedTo, DateTime dueDate)\n{\nvar task = new TaskModel()\n{\nTaskId = Guid.NewGuid(),\nTaskName = taskName,\nTaskCreatedBy = createdBy,\nTaskCreatedOn = DateTime.UtcNow,\nTaskDueDate = dueDate,\nTaskAssignedTo = assignedTo,\n};\n_tasksList.Add(task);\nreturn Task.FromResult(task.TaskId);\n}\npublic Task&lt;bool&gt; DeleteTask(Guid taskId)\n{\nvar task = _tasksList.FirstOrDefault(t =&gt; t.TaskId.Equals(taskId));\nif (task != null)\n{\n_tasksList.Remove(task);\nreturn Task.FromResult(true);\n}\nreturn Task.FromResult(false);\n}\npublic Task&lt;TaskModel?&gt; GetTaskById(Guid taskId)\n{\nvar taskModel = _tasksList.FirstOrDefault(t =&gt; t.TaskId.Equals(taskId));\nreturn Task.FromResult(taskModel);\n}\npublic Task&lt;List&lt;TaskModel&gt;&gt; GetTasksByCreator(string createdBy)\n{\nvar tasksList = _tasksList.Where(t =&gt; t.TaskCreatedBy.Equals(createdBy)).OrderByDescending(o =&gt; o.TaskCreatedOn).ToList();\nreturn Task.FromResult(tasksList);\n}\npublic Task&lt;bool&gt; MarkTaskCompleted(Guid taskId)\n{\nvar task = _tasksList.FirstOrDefault(t =&gt; t.TaskId.Equals(taskId));\nif (task != null)\n{\ntask.IsCompleted = true;\nreturn Task.FromResult(true);\n}\nreturn Task.FromResult(false);\n}\npublic Task&lt;bool&gt; UpdateTask(Guid taskId, string taskName, string assignedTo, DateTime dueDate)\n{\nvar task = _tasksList.FirstOrDefault(t =&gt; t.TaskId.Equals(taskId));\nif (task != null)\n{\ntask.TaskName = taskName;\ntask.TaskAssignedTo = assignedTo;\ntask.TaskDueDate = dueDate;\nreturn Task.FromResult(true);\n}\nreturn Task.FromResult(false);\n}\n}\n}\n</code></pre>   The code above is self-explanatory, it generates 10 tasks and stores them in a list in memory. It also has some operations to add/remove/update those tasks.</p> <ul> <li>Now we need to register FakeTasksManager on project startup. Open file <code>Program.cs</code> and register the newly created service by adding the highlighted lines from below snippet. Don't forget to include the required using statements for the task interface and class.</li> </ul> Program.cs <pre><code>using TasksTracker.TasksManager.Backend.Api.Services;\nvar builder = WebApplication.CreateBuilder(args);\n// Add services to the container.\nbuilder.Services.AddSingleton&lt;ITasksManager, FakeTasksManager&gt;();\n// Code removed for brevity\napp.Run();\n</code></pre> <ul> <li>Add a new controller under the <code>Controllers</code> folder with name below. We need to create API endpoints to manage tasks.</li> </ul> TasksController.cs <pre><code> using Microsoft.AspNetCore.Mvc;\nusing TasksTracker.TasksManager.Backend.Api.Models;\nusing TasksTracker.TasksManager.Backend.Api.Services;\nnamespace TasksTracker.TasksManager.Backend.Api.Controllers\n{\n[Route(\"api/tasks\")]\n[ApiController]\npublic class TasksController : ControllerBase\n{\nprivate readonly ILogger&lt;TasksController&gt; _logger;\nprivate readonly ITasksManager _tasksManager;\npublic TasksController(ILogger&lt;TasksController&gt; logger, ITasksManager tasksManager)\n{\n_logger = logger;\n_tasksManager = tasksManager;\n}\n[HttpGet]\npublic async Task&lt;IEnumerable&lt;TaskModel&gt;&gt; Get(string createdBy)\n{\nreturn await _tasksManager.GetTasksByCreator(createdBy);\n}\n[HttpGet(\"{taskId}\")]\npublic async Task&lt;IActionResult&gt; GetTask(Guid taskId)\n{\nvar task = await _tasksManager.GetTaskById(taskId);\nif (task != null)\n{\nreturn Ok(task);\n}\nreturn NotFound();\n}\n[HttpPost]\npublic async Task&lt;IActionResult&gt; Post([FromBody] TaskAddModel taskAddModel)\n{\nvar taskId = await _tasksManager.CreateNewTask(taskAddModel.TaskName,\ntaskAddModel.TaskCreatedBy,\ntaskAddModel.TaskAssignedTo,\ntaskAddModel.TaskDueDate);\nreturn Created($\"/api/tasks/{taskId}\", null);\n}\n[HttpPut(\"{taskId}\")]\npublic async Task&lt;IActionResult&gt; Put(Guid taskId, [FromBody] TaskUpdateModel taskUpdateModel)\n{\nvar updated = await _tasksManager.UpdateTask(taskId,\ntaskUpdateModel.TaskName,\ntaskUpdateModel.TaskAssignedTo,\ntaskUpdateModel.TaskDueDate);\nif (updated)\n{\nreturn Ok();\n}\nreturn BadRequest();\n}\n[HttpPut(\"{taskId}/markcomplete\")]\npublic async Task&lt;IActionResult&gt; MarkComplete(Guid taskId)\n{\nvar updated = await _tasksManager.MarkTaskCompleted(taskId);\nif (updated)\n{\nreturn Ok();\n}\nreturn BadRequest();\n}\n[HttpDelete(\"{taskId}\")]\npublic async Task&lt;IActionResult&gt; Delete(Guid taskId)\n{\nvar deleted = await _tasksManager.DeleteTask(taskId);\nif (deleted)\n{\nreturn Ok();\n}\nreturn NotFound();\n}\n}\n}\n</code></pre> <ul> <li>From VS Code Terminal tab, open developer command prompt or PowerShell terminal and navigate to the parent directory which hosts the <code>.csproj</code> project folder and build the project.      <pre><code>cd ~\\TasksTracker.ContainerApps\\TasksTracker.TasksManager.Backend.Api\ndotnet build\n</code></pre> Make sure that the build is successful and that there are no build errors. Usually you should see a \"Build succeeded\" message in the terminal upon a successful build.</li> </ul>"},{"location":"aca/01-deploy-api-to-aca/#2-deploy-web-api-backend-project-to-aca","title":"2. Deploy Web API Backend Project to ACA","text":"<p>We will be using Azure CLI to deploy the Web API Backend to ACA as shown in the following steps:</p> <ul> <li> <p>We will start with Installing/Upgrading the Azure Container Apps Extension.     <pre><code># Upgrade Azure CLI\naz upgrade\n# Login to Azure\naz login # Only required if you have multiple subscriptions\naz account set --subscription &lt;name or id&gt;\n# Install/Upgrade Azure Container Apps Extension\naz extension add --name containerapp --upgrade\n</code></pre></p> </li> <li> <p>Define the variables below in the PowerShell console to use them across the different modules in the workshop. You should change the values of those variables to be able to create the resources successfully. Some of those variables should be unique across all Azure subscriptions such as Azure Container Registry name. Remember to replace the place holders with your own values:     <pre><code>$RESOURCE_GROUP=\"tasks-tracker-rg\"\n$LOCATION=\"eastus\"\n$ENVIRONMENT=\"tasks-tracker-containerapps-env\"\n$WORKSPACE_NAME=\"&lt;replace this with your unique app log analytics workspace name&gt;\"\n$APPINSIGHTS_NAME=\"&lt;replace this with your unique app insights name&gt;\"\n$BACKEND_API_NAME=\"tasksmanager-backend-api\"\n$ACR_NAME=\"&lt;replace this with your unique acr name&gt;\"\n</code></pre></p> </li> <li> <p>Create a <code>resource group</code> to organize the services related to the application, run the below command:     <pre><code>az group create `\n--name $RESOURCE_GROUP `\n--location \"$LOCATION\"\n</code></pre></p> </li> <li> <p>Create an Azure Container Registry (ACR) instance in the resource group to store images of all Microservices we are going to build during this workshop. Make sure that you set the <code>admin-enabled</code> flag to true in order to seamlessly authenticate the Azure container app when trying to create the container app using the image stored in ACR</p> <pre><code>az acr create `\n--resource-group $RESOURCE_GROUP `\n--name $ACR_NAME `\n--sku Basic `\n--admin-enabled true\n</code></pre> </li> </ul> <p>Note</p> <p>Notice that we create the registry with admin rights <code>--admin-enabled</code> flag set to <code>true</code> which is not suited for real production, but good for our workshop.</p> <ul> <li>Create an Azure Log Analytics Workspace which will provide a common place to store the system and application log data from all container apps running in the environment. Each environment should have its own Log Analytics Workspace. To create it, run the command below:     <pre><code># create the log analytics workspace\naz monitor log-analytics workspace create `\n--resource-group $RESOURCE_GROUP `\n--workspace-name $WORKSPACE_NAME\n# retrieve workspace ID\n$WORKSPACE_ID=az monitor log-analytics workspace show --query customerId `\n-g $RESOURCE_GROUP `\n-n $WORKSPACE_NAME -o tsv\n\n# retrieve workspace secret\n$WORKSPACE_SECRET=az monitor log-analytics workspace get-shared-keys --query primarySharedKey `\n-g $RESOURCE_GROUP `\n-n $WORKSPACE_NAME -o tsv\n</code></pre></li> <li> <p>Create an Application Insights Instance which will be used mainly for distributed tracing between different container apps within the ACA environment to provide searching for and visualizing an end-to-end flow of a given execution or transaction. To create it, run the command below:     <pre><code># Install the application-insights extension for the CLI\naz extension add -n application-insights\n\n# Create application-insights instance\naz monitor app-insights component create `\n-g $RESOURCE_GROUP `\n-l $LOCATION `\n--app $APPINSIGHTS_NAME `\n--workspace $WORKSPACE_NAME\n# Get Application Insights Instrumentation Key\n$APPINSIGHTS_INSTRUMENTATIONKEY=($(az monitor app-insights component show `\n--app $APPINSIGHTS_NAME `\n-g $RESOURCE_GROUP)  | ConvertFrom-Json).instrumentationKey\n</code></pre></p> </li> <li> <p>Now we will create an Azure Container Apps Environment. As a reminder of the different ACA component check this link in the workshop introduction. The ACA environment acts as a secure boundary around a group of container apps that we are going to provision during this workshop. To create it, run the below command:     <pre><code># Create the ACA environment\naz containerapp env create `\n--name $ENVIRONMENT `\n--resource-group $RESOURCE_GROUP `\n--logs-workspace-id $WORKSPACE_ID `\n--logs-workspace-key $WORKSPACE_SECRET `\n--dapr-instrumentation-key $APPINSIGHTS_INSTRUMENTATIONKEY `\n--location $LOCATION\n</code></pre></p> </li> </ul> Want to learn what above command does? <ul> <li>It creates an ACA environment and associates it with the Log Analytics Workspace created in the previous step.</li> <li>We are setting the <code>--dapr-instrumentation-key</code> value to the instrumentation key of the Application Insights instance. This will come handy when we introduce Dapr in later modules and show how the distributed tracing between microservices/container apps are captured and visualized in Application Insights.   <p>NOTE: You can set the <code>--dapr-instrumentation-key</code> after you create the ACA environment but this is not possible via the AZ CLI right now. There is an open issue which is being tracked by the product group.</p> </li> </ul> <ul> <li> <p>Build the Web API project on ACR and push the docker image to ACR. Use the below command to initiate the image build and push process using ACR. The <code>.</code> at the end of the command represents the docker build context, in our case, we need to be on the parent directory which hosts the <code>.csproj</code>.</p> <p><pre><code>cd ~\\TasksTracker.ContainerApps\naz acr build --registry $ACR_NAME --image \"tasksmanager/$BACKEND_API_NAME\" --file 'TasksTracker.TasksManager.Backend.Api/Dockerfile' .\n</code></pre> Once this step is completed you can verify the results by going to the Azure portal and checking that a new repository named <code>tasksmanager/tasksmanager-backend-api</code> has been created and there is a new docker image with a <code>latest</code> tag is created.</p> </li> <li> <p>The last step here is to create and deploy the Web API to ACA following the below command. Remember to replace the place holders with your own values:</p> <pre><code>az containerapp create `\n--name $BACKEND_API_NAME  `\n--resource-group $RESOURCE_GROUP `\n--environment $ENVIRONMENT `\n--image \"$ACR_NAME.azurecr.io/tasksmanager/$BACKEND_API_NAME\" `\n--registry-server \"$ACR_NAME.azurecr.io\" `\n--target-port [port number that was generated when you created your docker file in vs code] `\n--ingress 'external' `\n--min-replicas 1 `\n--max-replicas 1 `\n--cpu 0.25 --memory 0.5Gi `\n--query configuration.ingress.fqdn\n</code></pre> </li> </ul> Want to learn what above command does? <ul> <li>Ingress param is set to <code>external</code> which means that this container app (Web API) project will be accessible from the public internet. When Ingress is set to <code>Internal</code> or <code>External</code> it will be assigned a fully qualified domain name (FQDN). Important notes about IP addresses and domain names can be found here.</li> <li>The target port param is set to 80, this is the port our Web API container listens to for incoming requests.</li> <li>We didn't specify the ACR registry username and password, <code>az containerapp create</code> command was able to look up ACR username and password and add them as a secret under the created Azure container app for future container updates.</li> <li>The minimum and the maximum number of replicas are set. More about this when we cover Autoscaling in later modules. For the time being, only a single instance of this container app will be provisioned as Auto scale is not configured.</li> <li>We set the size of the Container App. The total amount of CPUs and memory requested for the container app must add up to certain combinations, for full details check the link here.</li> <li>The <code>query</code> property will filter the response coming from the command and just return the FQDN. Take note of this FQDN as you will need it for the next step.</li> </ul> <p>For full details on all available parameters for this command, please visit this page.  </p> <ul> <li>You can now verify the deployment of the first ACA by navigating to the Azure Portal and selecting the resource group named <code>tasks-tracker-rg</code> that you created earlier. You should see the 5 recourses created below. </li> </ul> <p>Success</p> <p>To test the backend api service, copy the FQDN (Application URL) of the Azure container app named <code>tasksmanager-backend-api</code>.  Issue a <code>GET</code> request similar to this one: <code>https://tasksmanager-backend-api.&lt;your-aca-env-unique-id&gt;.eastus.azurecontainerapps.io/api/tasks/?createdby=tjoudeh@bitoftech.net</code> and you should receive an array of the 10 tasks similar to the below image.</p> <p>Tip</p> <p>You can find your azure container app application url on the azure portal overview tab.</p> <p></p> <p>In the next module, we will see how we will add a new Frontend Web App as a microservice and how it will communicate with the backend API.</p>"},{"location":"aca/02-aca-comm/","title":"Module 2 - Communication Between Microservices in ACA","text":"<p>Module Duration</p> <p>60 minutes</p> <p>In this module, we will add a service named <code>ACA Web API \u2013 Frontend</code> as illustrated in the architecture diagram. This service will host a simple ASP.NET Razor pages web app which allows the end users to manage their tasks. After that we will provision Azure resources needed to deploy the service to ACA using Azure CLI.</p>"},{"location":"aca/02-aca-comm/#1-create-the-frontend-web-app-project-web-app","title":"1. Create the Frontend Web App project (Web APP)","text":"<ul> <li> <p>Open a command-line terminal and navigate to root folder of your project. Create a new folder as shown below:     <pre><code>cd TasksTracker.ContainerApps\n</code></pre></p> </li> <li> <p>From VS Code Terminal tab, open developer command prompt or PowerShell terminal in the project folder <code>TasksTracker.ContainerApps</code> and initialize the project. This will create and ASP.NET Razor Pages web app project.     <pre><code>dotnet new webapp  -o TasksTracker.WebPortal.Frontend.Ui\n</code></pre></p> </li> <li> <p>We need to containerize this application, so we can push it to Azure Container Registry as a docker image then deploy it to ACA. Open the VS Code Command Palette (Ctrl+Shift+P) and select <code>Docker: Add Docker Files to Workspace...</code></p> <ul> <li>Use <code>.NET: ASP.NET Core</code> when prompted for application platform.</li> <li>Choose <code>Linux</code> when prompted to choose the operating system.</li> <li>You will be asked if you want to add Docker Compose files. Select <code>No</code>.</li> <li>Take a note of the provided application port as we will be using later on.</li> <li><code>Dockerfile</code> and <code>.dockerignore</code> files are added to the workspace.</li> </ul> </li> <li> <p>Add a new folder named Tasks under the Pages folder. Then add a new folder named Models under the Tasks folder and create file as shown below.</p> </li> </ul> TasksModel.cs <pre><code>using System.ComponentModel.DataAnnotations;\npublic class TaskModel\n{\npublic Guid TaskId { get; set; }\npublic string TaskName { get; set; } = string.Empty;\npublic string TaskCreatedBy { get; set; } = string.Empty;\npublic DateTime TaskCreatedOn { get; set; }\npublic DateTime TaskDueDate { get; set; }\npublic string TaskAssignedTo { get; set; } = string.Empty;\npublic bool IsCompleted { get; set; }\npublic bool IsOverDue { get; set; }\n}\npublic class TaskAddModel\n{\n[Display(Name = \"Task Name\")]\n[Required]\npublic string TaskName { get; set; } = string.Empty;\n[Display(Name = \"Task DueDate\")]\n[Required]\npublic DateTime TaskDueDate { get; set; }\n[Display(Name = \"Assigned To\")]\n[Required]\npublic string TaskAssignedTo { get; set; } = string.Empty;\npublic string TaskCreatedBy { get; set; } = string.Empty;\n}\npublic class TaskUpdateModel\n{\npublic Guid TaskId { get; set; }\n[Display(Name = \"Task Name\")]\n[Required]\npublic string TaskName { get; set; } = string.Empty;\n[Display(Name = \"Task DueDate\")]\n[Required]\npublic DateTime TaskDueDate { get; set; }\n[Display(Name = \"Assigned To\")]\n[Required]\npublic string TaskAssignedTo { get; set; } = string.Empty;\n}\n</code></pre> <ul> <li>Now we will add 3 Razor pages for CRUD operations which will be responsible for listing all the tasks, creating a new task, and updating existing tasks. By looking at the cshtml content notice that the page is expecting a query string named <code>createdBy</code> which will be used to group tasks for application users. </li> </ul> <p>Note</p> <p>We are following this approach here to keep the workshop simple, but for production applications authentication should be applied and the user email should be retrieved from the claims identity of the authenticated users.</p> Index.cshtmlIndex.cshtml.csCreate.cshtmlCreate.cshtml.csEdit.cshtmlEdit.cshtml.cs <pre><code>@page \n@model TasksTracker.WebPortal.Frontend.Ui.Pages.Tasks.IndexModel\n@{\n}\n\n&lt;h1&gt;Tasks Manager&lt;/h1&gt;\n&lt;h4&gt;Tasks for (@Model.TasksCreatedBy)&lt;/h4&gt;\n&lt;form method=\"post\"&gt;\n&lt;table class=\"table\"&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Name&lt;/th&gt;\n&lt;th&gt;Due Date&lt;/th&gt;\n&lt;th&gt;Assigned To&lt;/th&gt;\n&lt;th&gt;Completed&lt;/th&gt;\n&lt;th&gt;Overdue&lt;/th&gt;\n&lt;th&gt;&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n            @if (Model.TasksList != null)\n            {\n                foreach (var task in Model.TasksList)\n                {\n                    &lt;tr&gt;\n&lt;td&gt;&lt;a asp-page=\"./Edit\" asp-route-id=\"@task.TaskId\"&gt;@task.TaskName&lt;/a&gt;&lt;/td&gt;\n&lt;td&gt;@task.TaskDueDate.Date.ToString(\"dd-MM-yyyy\")&lt;/td&gt;\n&lt;td&gt;@task.TaskAssignedTo&lt;/td&gt;\n&lt;td&gt;@Html.CheckBox(\"IsCompleted\",@task.IsCompleted)&lt;/td&gt;\n&lt;td&gt;@Html.CheckBox(\"IsOverDue\",@task.IsOverDue)&lt;/td&gt;\n&lt;td&gt;\n&lt;button type=\"submit\" asp-page-handler=\"complete\" asp-route-id=\"@task.TaskId\"&gt;Complete&lt;/button&gt;\n&lt;button type=\"submit\" asp-page-handler=\"delete\" asp-route-id=\"@task.TaskId\"&gt;Delete&lt;/button&gt;\n&lt;/td&gt;\n&lt;/tr&gt;\n                }\n            }\n        &lt;/tbody&gt;\n&lt;/table&gt;\n&lt;a asp-page=\"Create\"&gt;Create New&lt;/a&gt;\n&lt;/form&gt;\n</code></pre> <pre><code> using Microsoft.AspNetCore.Mvc;\nusing Microsoft.AspNetCore.Mvc.RazorPages;\nnamespace TasksTracker.WebPortal.Frontend.Ui.Pages.Tasks\n{\npublic class IndexModel : PageModel\n{\nprivate readonly IHttpClientFactory _httpClientFactory;\npublic List&lt;TaskModel&gt;? TasksList { get; set; }\n[BindProperty]\npublic string? TasksCreatedBy { get; set; }\npublic IndexModel(IHttpClientFactory httpClientFactory)\n{\n_httpClientFactory = httpClientFactory;\n}\npublic async Task OnGetAsync()\n{\nTasksCreatedBy = Request.Cookies[\"TasksCreatedByCookie\"];\n// direct svc to svc http request\nvar httpClient = _httpClientFactory.CreateClient(\"BackEndApiExternal\");\nTasksList = await httpClient.GetFromJsonAsync&lt;List&lt;TaskModel&gt;&gt;($\"api/tasks?createdBy={TasksCreatedBy}\");\n}\npublic async Task&lt;IActionResult&gt; OnPostDeleteAsync(Guid id)\n{\n// direct svc to svc http request\nvar httpClient = _httpClientFactory.CreateClient(\"BackEndApiExternal\");\nvar result = await httpClient.DeleteAsync($\"api/tasks/{id}\");\nreturn RedirectToPage();\n}\npublic async Task&lt;IActionResult&gt; OnPostCompleteAsync(Guid id)\n{\n// direct svc to svc http request\nvar httpClient = _httpClientFactory.CreateClient(\"BackEndApiExternal\");\nvar result = await httpClient.PutAsync($\"api/tasks/{id}/markcomplete\", null);\nreturn RedirectToPage();\n}\n}\n}\n</code></pre> <p>What does this code do?</p> <p>In the code above we've injected named HttpClientFactory which is responsible to call the Backend API service as HTTP request. The index page supports deleting and marking tasks as completed along with listing tasks for certain users based on the <code>createdBy</code> property stored in a cookie named <code>TasksCreatedByCookie</code>.  More about populating this property later in the workshop.</p> <pre><code>@page\n@model TasksTracker.WebPortal.Frontend.Ui.Pages.Tasks.CreateModel\n@{\n}\n\n&lt;h1&gt;Create Task&lt;/h1&gt;\n&lt;h4&gt;Task&lt;/h4&gt;\n&lt;hr /&gt;\n&lt;div class=\"row\"&gt;\n&lt;div class=\"col-md-4\"&gt;\n&lt;form method=\"post\"&gt;\n&lt;div asp-validation-summary=\"ModelOnly\" class=\"text-danger\"&gt;&lt;/div&gt;\n&lt;div class=\"form-group\"&gt;\n&lt;label asp-for=\"TaskAdd!.TaskName\" class=\"control-label\"&gt;&lt;/label&gt;\n&lt;input asp-for=\"TaskAdd!.TaskName\" class=\"form-control\" /&gt;\n&lt;span asp-validation-for=\"TaskAdd!.TaskName\" class=\"text-danger\"&gt;&lt;/span&gt;\n&lt;/div&gt;\n&lt;div class=\"form-group\"&gt;\n&lt;label asp-for=\"TaskAdd!.TaskDueDate\" class=\"control-label\"&gt;&lt;/label&gt;\n&lt;input asp-for=\"TaskAdd!.TaskDueDate\" class=\"form-control\" type=\"date\" /&gt;\n&lt;span asp-validation-for=\"TaskAdd!.TaskDueDate\" class=\"text-danger\"&gt;&lt;/span&gt;\n&lt;/div&gt;\n&lt;div class=\"form-group\"&gt;\n&lt;label asp-for=\"TaskAdd!.TaskAssignedTo\" class=\"control-label\"&gt;&lt;/label&gt;\n&lt;input asp-for=\"TaskAdd!.TaskAssignedTo\" class=\"form-control\" type=\"email\"/&gt;\n&lt;span asp-validation-for=\"TaskAdd!.TaskAssignedTo\" class=\"text-danger\"&gt;&lt;/span&gt;\n&lt;/div&gt;\n&lt;div class=\"form-group\"&gt;\n&lt;input type=\"submit\" value=\"Save\" class=\"btn btn-primary\" /&gt;\n&lt;/div&gt;\n&lt;/form&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;div&gt;\n&lt;a asp-page=\"./Index\"&gt;Back to List&lt;/a&gt;\n&lt;/div&gt;\n@section Scripts {\n    @{\n        await Html.RenderPartialAsync(\"_ValidationScriptsPartial\");\n    }\n    }\n</code></pre> <pre><code>using Microsoft.AspNetCore.Mvc;\nusing Microsoft.AspNetCore.Mvc.RazorPages;\nnamespace TasksTracker.WebPortal.Frontend.Ui.Pages.Tasks\n{\npublic class CreateModel : PageModel\n{\nprivate readonly IHttpClientFactory _httpClientFactory;\npublic CreateModel(IHttpClientFactory httpClientFactory)\n{\n_httpClientFactory = httpClientFactory;\n}\npublic IActionResult OnGet()\n{\nreturn Page();\n}\n[BindProperty]\npublic TaskAddModel TaskAdd { get; set; }\npublic async Task&lt;IActionResult&gt; OnPostAsync()\n{\nif (!ModelState.IsValid)\n{\nreturn Page();\n}\nif (TaskAdd != null)\n{\nvar createdBy = Request.Cookies[\"TasksCreatedByCookie\"];\nTaskAdd.TaskCreatedBy = createdBy;\n// direct svc to svc http request\nvar httpClient = _httpClientFactory.CreateClient(\"BackEndApiExternal\");\nvar result = await httpClient.PostAsJsonAsync(\"api/tasks/\", TaskAdd);\n}\nreturn RedirectToPage(\"./Index\");\n}\n}\n}\n</code></pre> <p>What does this code do?</p> <p>The code is self-explanatory here. We just injected the type HttpClientFactory in order to issue a POST request and create a new task.</p> <pre><code>@page \"{id:guid}\"\n@model TasksTracker.WebPortal.Frontend.Ui.Pages.Tasks.EditModel\n@{\n    ViewData[\"Title\"] = \"Edit\";\n}\n\n&lt;h1&gt;Edit Task&lt;/h1&gt;\n&lt;h4&gt;Task&lt;/h4&gt;\n&lt;hr /&gt;\n&lt;div class=\"row\"&gt;\n&lt;div class=\"col-md-4\"&gt;\n&lt;form method=\"post\"&gt;\n&lt;div asp-validation-summary=\"ModelOnly\" class=\"text-danger\"&gt;&lt;/div&gt;\n&lt;input type=\"hidden\" asp-for=\"TaskUpdate!.TaskId\" /&gt;\n&lt;div class=\"form-group\"&gt;\n&lt;label asp-for=\"TaskUpdate!.TaskName\" class=\"control-label\"&gt;&lt;/label&gt;\n&lt;input asp-for=\"TaskUpdate!.TaskName\" class=\"form-control\" /&gt;\n&lt;span asp-validation-for=\"TaskUpdate!.TaskName\" class=\"text-danger\"&gt;&lt;/span&gt;\n&lt;/div&gt;\n&lt;div class=\"form-group\"&gt;\n&lt;label asp-for=\"TaskUpdate!.TaskDueDate\" class=\"control-label\"&gt;&lt;/label&gt;\n&lt;input asp-for=\"TaskUpdate!.TaskDueDate\" class=\"form-control\" type=\"date\" /&gt;\n&lt;span asp-validation-for=\"TaskUpdate!.TaskDueDate\" class=\"text-danger\"&gt;&lt;/span&gt;\n&lt;/div&gt;\n&lt;div class=\"form-group\"&gt;\n&lt;label asp-for=\"TaskUpdate!.TaskAssignedTo\" class=\"control-label\"&gt;&lt;/label&gt;\n&lt;input asp-for=\"TaskUpdate!.TaskAssignedTo\" class=\"form-control\"/&gt;\n&lt;span asp-validation-for=\"TaskUpdate!.TaskAssignedTo\" class=\"text-danger\"&gt;&lt;/span&gt;\n&lt;/div&gt;\n&lt;div class=\"form-group\"&gt;\n&lt;input type=\"submit\" value=\"Save\" class=\"btn btn-primary\" /&gt;\n&lt;/div&gt;\n&lt;/form&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;div&gt;\n&lt;a asp-page=\"./Index\"&gt;Back to List&lt;/a&gt;\n&lt;/div&gt;\n@section Scripts {\n    @{\n        await Html.RenderPartialAsync(\"_ValidationScriptsPartial\");\n    }\n    }\n</code></pre> <pre><code>using Microsoft.AspNetCore.Mvc;\nusing Microsoft.AspNetCore.Mvc.RazorPages;\nnamespace TasksTracker.WebPortal.Frontend.Ui.Pages.Tasks\n{\npublic class EditModel : PageModel\n{\nprivate readonly IHttpClientFactory _httpClientFactory;\n[BindProperty]\npublic TaskUpdateModel? TaskUpdate { get; set; }\npublic EditModel(IHttpClientFactory httpClientFactory)\n{\n_httpClientFactory = httpClientFactory;\n}\npublic async Task&lt;IActionResult&gt; OnGetAsync(Guid? id)\n{\nif (id == null)\n{\nreturn NotFound();\n}\n// direct svc to svc http request\nvar httpClient = _httpClientFactory.CreateClient(\"BackEndApiExternal\");\nvar Task = await httpClient.GetFromJsonAsync&lt;TaskModel&gt;($\"api/tasks/{id}\");\nif (Task == null)\n{\nreturn NotFound();\n}\nTaskUpdate = new TaskUpdateModel()\n{\nTaskId = Task.TaskId,\nTaskName = Task.TaskName,\nTaskAssignedTo = Task.TaskAssignedTo,\nTaskDueDate = Task.TaskDueDate,\n};\nreturn Page();\n}\npublic async Task&lt;IActionResult&gt; OnPostAsync()\n{\nif (!ModelState.IsValid)\n{\nreturn Page();\n}\nif (TaskUpdate != null)\n{\n// direct svc to svc http request\nvar httpClient = _httpClientFactory.CreateClient(\"BackEndApiExternal\");\nvar result = await httpClient.PutAsJsonAsync($\"api/tasks/{TaskUpdate.TaskId}\", TaskUpdate);\n}\nreturn RedirectToPage(\"./Index\");\n}\n}\n}\n</code></pre> <p>What does this code do?</p> <p>The code added is similar to the create operation. The Edit page accepts the TaskId as a Guid, loads the task, and then updates the task by sending an HTTP PUT operation.</p> <ul> <li>Now we will inject an HTTP client factory and define environment variables. To do so we will register the HttpClientFactory named <code>BackEndApiExternal</code> to make it available for injection in controllers. Open the <code>Program.cs</code> file and update it with highlighted code below:</li> </ul> Program.cs <pre><code>namespace TasksTracker.WebPortal.Frontend.Ui\n{\npublic class Program\n{\npublic static void Main(string[] args)\n{\nvar builder = WebApplication.CreateBuilder(args);\n// Add services to the container.\nbuilder.Services.AddRazorPages();\nbuilder.Services.AddHttpClient(\"BackEndApiExternal\", httpClient =&gt;\n{\nhttpClient.BaseAddress = new Uri(builder.Configuration.GetValue&lt;string&gt;(\"BackendApiConfig:BaseUrlExternalHttp\"));\n});\nvar app = builder.Build();\n// Code removed for brevity \n}\n}\n}\n</code></pre> <ul> <li>Next, we will add a new environment variable named <code>BackendApiConfig:BaseUrlExternalHttp</code> into <code>appsettings.json</code> file.  This variable will contain the Base URL for the backend API deployed in the previous module to ACA. Later on in the workshop, we will see how we can set the environment variable once we deploy it to ACA.</li> </ul> appsettings.json <pre><code>   {\n\"Logging\": {\n\"LogLevel\": {\n\"Default\": \"Information\",\n\"Microsoft.AspNetCore\": \"Warning\"\n}\n},\n\"AllowedHosts\": \"*\",\n\"BackendApiConfig\": {\n\"BaseUrlExternalHttp\": \"url to your backend api goes here. You can find this on the azure portal overview tab. Look for the Application url property there.\"\n}\n}\n</code></pre> <ul> <li>Lastly, we will update the web app landing page <code>Index.html</code> and <code>Index.cshtml.cs</code> inside Pages folder to capture the email of the tasks owner user and assign this email to a cookie named <code>TasksCreatedByCookie</code>. </li> </ul> Index.cshtmlIndex.cshtml.cs <pre><code>@page\n@model IndexModel\n@{\n    ViewData[\"Title\"] = \"Tasks Tracker\";\n}\n\n&lt;form method=\"post\"&gt;\n&lt;div class=\"container\"&gt;\n&lt;div class=\"row\"&gt;\n&lt;div class=\"col-sm-9 col-md-7 col-lg-5 mx-auto\"&gt;\n&lt;div class=\"card border-0 shadow rounded-3 my-5\"&gt;\n&lt;div class=\"card-body p-4 p-sm-5\"&gt;\n&lt;h5 class=\"card-title text-center mb-5 fw-light fs-5\"&gt;Welcome to Tasks Tracker!&lt;/h5&gt;\n&lt;form&gt;\n&lt;div class=\"form-floating mb-3\"&gt;\n&lt;input type=\"email\" class=\"form-control\" id=\"floatingInput\" placeholder=\"name@example.com\" asp-for=\"TasksCreatedBy\"&gt;\n&lt;label for=\"floatingInput\"&gt;Email address&lt;/label&gt;\n&lt;/div&gt;\n&lt;div class=\"d-grid\"&gt;\n&lt;input type=\"submit\" class=\"btn btn-primary btn-login text-uppercase fw-bold\" value=\"Load My Tasks\" /&gt;\n&lt;/div&gt;\n&lt;/form&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/div&gt;\n&lt;/form&gt;\n</code></pre> <pre><code> namespace TasksTracker.WebPortal.Frontend.Ui.Pages\n{\n[IgnoreAntiforgeryToken(Order = 1001)]\npublic class IndexModel : PageModel\n{\nprivate readonly ILogger&lt;IndexModel&gt; _logger;\n[BindProperty]\npublic string TasksCreatedBy { get; set; }\npublic IndexModel(ILogger&lt;IndexModel&gt; logger)\n{\n_logger = logger;\n}\npublic void OnGet()\n{\n}\npublic IActionResult OnPost()\n{\nif (!string.IsNullOrEmpty(TasksCreatedBy))\n{\nResponse.Cookies.Append(\"TasksCreatedByCookie\", TasksCreatedBy);\n}\nreturn RedirectToPage(\"./Tasks/Index\");\n}\n}\n}\n</code></pre> <ul> <li> <p>From VS Code Terminal tab, open developer command prompt or PowerShell terminal and navigate to the frontend directory which hosts the <code>.csproj</code> project folder and build the project. </p> <pre><code>cd {YourLocalPath}\\TasksTracker.WebPortal.Frontend.Ui\ndotnet build\n</code></pre> </li> </ul> <p>Note</p> <p>Make sure that the build is successful and that there are no build errors. Usually you should see a Build succeeded message in the terminal upon a successful build.</p>"},{"location":"aca/02-aca-comm/#2-deploy-razor-pages-web-app-frontend-project-to-aca","title":"2. Deploy Razor Pages Web App Frontend Project to ACA","text":"<p>We will assume that you still have the same PowerShell console session opened from the last module which has all the powershell variables defined from module 1. We need to add the below PS variables:</p> <p><pre><code>$FRONTEND_WEBAPP_NAME=\"tasksmanager-frontend-webapp\"\n</code></pre> - Now we will build and push the Web App project docker image to ACR. Use the below command to initiate the image build and push process using ACR. The <code>.</code> at the end of the command represents the docker build context. In our case, we need to be on the parent directory which hosts the .csproject.</p> <p><pre><code>cd {YourLocalPath}\\TasksTracker.ContainerApps \naz acr build --registry $ACR_NAME --image \"tasksmanager/$FRONTEND_WEBAPP_NAME\" --file 'TasksTracker.WebPortal.Frontend.Ui/Dockerfile' .\n</code></pre> Once this step is completed you can verify the results by going to the Azure portal and checking that a new repository named <code>tasksmanager/tasksmanager-frontend-webapp</code> has been created and there is a new docker image with a <code>latest</code> tag is created.</p> <ul> <li>Next, we will create and deploy the Web App to ACA using the following command. Remember to replace the placeholders with your own values:</li> </ul> <pre><code>az containerapp create `\n--name \"$FRONTEND_WEBAPP_NAME\"  `\n--resource-group $RESOURCE_GROUP `\n--environment $ENVIRONMENT `\n--image \"$ACR_NAME.azurecr.io/tasksmanager/$FRONTEND_WEBAPP_NAME\" `\n--registry-server \"$ACR_NAME.azurecr.io\" `\n--env-vars \"BackendApiConfig__BaseUrlExternalHttp=&lt;url to your backend api goes here. You can find this on the azure portal overview tab. Look for the Application url property there.&gt;/\" `\n--target-port &lt;port number that was generated when you created your docker file in vs code for your frontend application&gt; `\n--ingress 'external' `\n--min-replicas 1 `\n--max-replicas 1 `\n--cpu 0.25 --memory 0.5Gi `\n--query configuration.ingress.fqdn\n</code></pre> <p>Tip</p> <p>Notice how we used the property <code>env-vars</code> to set the value of the environment variable named <code>BackendApiConfig_BaseUrlExternalHttp</code> which we added in the AppSettings.json file. You can set multiple environment variables at the same time by using a space between each variable. The <code>ingress</code> property is set to <code>external</code> as the Web frontend App will be exposed to the public internet for users.</p> <p>After your run the command, copy the FQDN (Application URL) of the Azure container app named <code>tasksmanager-frontend-webapp</code> and open it in your browser, and you should be able to browse the frontend web app and manage your tasks.</p>"},{"location":"aca/02-aca-comm/#3-update-backend-web-api-container-app-ingress-property","title":"3. Update Backend Web API Container App Ingress property","text":"<p>So far the Frontend App is sending HTTP requests to publicly exposed Web API which means that any REST client can invoke this API. We need to change the Web API ingress settings and make it only accessible for applications deployed within our Azure Container Environment only. Any application outside the Azure Container Environment will not be able to access the Web API.</p> <ul> <li> <p>To change the settings of the Backend API, execute the following command:</p> <pre><code>az containerapp ingress enable `\n--name  $BACKEND_API_NAME  `\n--resource-group  $RESOURCE_GROUP `\n--target-port [port number that was generated when you created your docker file in vs code for your backend application] `\n--type \"internal\"\n</code></pre> </li> </ul> Want to know more about the command? <p>When you do this change, the FQDN (Application URL) will change, and it will be similar to the one shown below. Notice how there is an <code>Internal</code> part of the URL. <code>https://tasksmanager-backend-api.internal.[Environment unique identifier].eastus.azurecontainerapps.io/api/tasks/</code></p> <p>If you try to invoke the URL from the browser directly it will return 404 as this Internal Url can only be accessed from container apps within the container environment.</p> <p>The FQDN consists of multiple parts. For example, all our Container Apps will be under a specific Environment unique identifier (e.g. <code>agreeablestone-8c14c04c</code>) and the Container App will vary based on the name provided, check the image below for a better explanation. </p> <ul> <li> <p>Now we will need to update the Frontend Web App environment variable to point to the internal backend Web API FQDN. The last thing we need to do here is to update the Frontend WebApp environment variable named <code>BackendApiConfig_BaseUrlExternalHttp</code> with the new value of the internal Backend Web API base URL, to do so we need to update the Web App container app and it will create a new revision implicitly (more about revisions in the upcoming modules). The following command will update the container app with the changes:</p> <pre><code>az containerapp update `\n--name \"$FRONTEND_WEBAPP_NAME\"  `\n--resource-group $RESOURCE_GROUP `\n--set-env-vars \"BackendApiConfig__BaseUrlExternalHttp=https://tasksmanager-backend-api.internal.[Environment unique identifier].eastus.azurecontainerapps.io\"\n</code></pre> </li> </ul> <p>Success</p> <p>Browse the web app again, and you should be able to see the same results and access the backend API endpoints from the Web App.</p> <p>In the next module, we will start integrating Dapr and use the service to service Building block for services discovery and invocation.</p>"},{"location":"aca/03-aca-dapr-integration/","title":"Module 3 - Dapr Integration with ACA","text":"<p>Module Duration</p> <p>60 minutes</p> <p>In this module, we will start integrating Dapr into both services and see how Dapr with ACA will simplify complex microservices scenarios such as service discovery, service-to-service invocation, calling services asynchronously via pub/sub patterns, auto-scaling for overloaded services, etc..</p>"},{"location":"aca/03-aca-dapr-integration/#benefits-of-integrating-dapr-in-azure-container-apps","title":"Benefits of Integrating Dapr in Azure Container Apps","text":"<p>The Tasks Tracker microservice application is composed of multiple microservices (2 microservices so far), and function calls are spread across the network. To support the distributed nature of microservices,  we need to account for failures, retries, and timeouts. While Container Apps features the building blocks for running microservices, the use of Dapr provides an even richer microservices programming model. </p> <p>Dapr includes features like service discovery, pub/sub, service-to-service invocation with mutual TLS, retries, state store management, and more.  Here is a good link which touches on some benefits of the Dapr service invocation building block which we will be building upon in this module.  Because the calls will flow through sidecars, Dapr can inject some useful cross-cutting behaviors. </p> <p>Although we won't tap into all these benefits in this workshop its worth keeping in mind that you will most probably need to rely on these features in production.</p> <ul> <li>Automatically retry calls upon failure.</li> <li>Make calls between services secure with mutual (mTLS) authentication, including automatic certificate rollover.</li> <li>Control what operations clients can do using access control policies.</li> <li>Capture traces and metrics for all calls between services to provide insights and diagnostics. </li> </ul>"},{"location":"aca/03-aca-dapr-integration/#configure-dapr-on-a-local-development-machine","title":"Configure Dapr on a Local Development Machine","text":"<p>In order to run applications using Dapr, we need to install and initialize Dapr CLI locally. The official documentation is quite clear, and we can follow the steps needed to install Dapr and then Initialize it.</p>"},{"location":"aca/03-aca-dapr-integration/#run-backend-api-and-frontend-web-app-locally-using-dapr","title":"Run Backend API and Frontend Web App Locally Using Dapr","text":"<p>You are now ready to run the applications locally using Dapr sidecar in a self-hosted mode. There is a VS code extension called Dapr which will allow you to run, debug, and interact with Dapr-enabled applications in VS Code.</p> <ul> <li>Let's start by running the Backend Web API service using Dapr. From VS Code open a new PowerShell terminal, run the below commands in PS terminal based on your .NET version. </li> </ul> <p>Note</p> <p>Remember to replace the placeholders with your own values based on image below. Remember to use https port number for the Web API application.</p> .NET 6 or below.NET 7 or above <pre><code>cd TasksTracker.TasksManager.Backend.Api\ndapr run --app-id tasksmanager-backend-api --app-port &lt;web api application https port number found under properties-&gt;launchSettings.json. e.g. 7112&gt; --dapr-http-port 3500 --app-ssl -- dotnet run\n</code></pre> <pre><code>cd TasksTracker.TasksManager.Backend.Api\ndapr run --app-id tasksmanager-backend-api --app-port &lt;web api application https port number found under properties-&gt;launchSettings.json. e.g. 7112&gt; --dapr-http-port 3500 --app-ssl -- dotnet run --launch-profile https\n</code></pre> <p></p> Want to learn more about Dapr run command above? <p>When using Dapr run command you are running a dapr process as a sidecar next to the Web API application. The properties you have configured are as follows:</p> <ul> <li>app-id: The unique identifier of the application. Used for service discovery, state encapsulation, and the pub/sub consumer identifier.</li> <li>app-port: This parameter tells Dapr which port your application is listening on. You can get the app port from <code>properties-&gt;launchSettings.json</code> file in the Web API Project as shown in the image above. Make sure you use the https port listed within the <code>properties-&gt;launchSettings.json</code> as we are using the --app-ssl when running the dapr cli locally. Don't use the port inside the DockerFile. The DockerFile port will come in handy when you deploy to ACA at which point the application would be running inside a container.</li> <li>dapr-http-port: The HTTP port for Dapr to listen on.</li> <li>app-ssl: Sets the URI scheme of the app to https and attempts an SSL connection.</li> </ul> <p>For a full list of properties, you can check this link.</p> <p>If all is working as expected, you should receive an output similar to the one below where your app logs and dapr logs will appear on the same PowerShell terminal:</p> <p></p> <p>Now to test invoking the Web API using Dapr sidecar, you can issue HTTP GET request to the following URL: http://localhost:3500/v1.0/invoke/tasksmanager-backend-api/method/api/tasks?createdBy=tjoudeh@bitoftech.net</p> Want to learn more about what is happening here? <p>What happened here is that Dapr exposes its HTTP and gRPC APIs as a sidecar process which can access our Backend Web API. We didn't do any changes to the application code to include any Dapr runtime code. We also ensured separation of the application logic for improved supportability.</p> <p>Looking back at the HTTP GET request, we can break it as follows:</p> <ul> <li><code>/v1.0/invoke</code> Endpoint: is the Dapr feature identifier for the \"Service to Service invocation\" building block. This building block enables applications to communicate with each other through well-known endpoints in the form of http or gRPC messages. Dapr provides an endpoint that acts as a combination of a reverse proxy with built-in service discovery while leveraging built-in distributed tracing and error handling.</li> <li><code>3500</code>: the HTTP port that Dapr is listening on.</li> <li><code>tasksmanager-backend-api</code>: is the dapr application unique identifier.</li> <li><code>method</code>: reserved word when using invoke endpoint.</li> <li><code>api/tasks?createdBy=tjoudeh@bitoftech.net</code>: the path of the action method that needs to be invoked in the webapi service.</li> </ul> <p>Another example is that we want to create a new task by invoking the POST operation, we need to issue the below POST request:</p> <pre><code>POST /v1.0/invoke/tasksmanager-backend-api/method/api/tasks/ HTTP/1.1\nHost: localhost:3500\nContent-Type: application/json\n{\n\"taskName\": \"Task number: 51\",\n\"taskCreatedBy\": \"tjoudeh@bitoftech.net\",\n\"taskDueDate\": \"2022-08-31T09:33:35.9256429Z\",\n\"taskAssignedTo\": \"assignee51@mail.com\"\n}\n</code></pre> <ul> <li> <p>Next, we will be using Dapr SDK in the frontend Web App to invoke Backend API services, The Dapr .NET SDK provides .NET developers with an intuitive and language-specific way to interact with Dapr. The SDK offers developers three ways of making remote service invocation calls:</p> <ol> <li>Invoke HTTP services using HttpClient</li> <li>Invoke HTTP services using DaprClient</li> <li>Invoke gRPC services using DaprClient</li> </ol> <p>We will be using the second approach in this workshop (HTTP services using DaprClient), but it is worth spending some time explaining the first approach (Invoke HTTP services using HttpClient). We will go over the first approach briefly and then discuss the second in details.</p> <p>Install DAPR SDK for .NET Core in the Frontend Web APP, so we can use the service discovery and service invocation offered by Dapr Sidecar. To do so, add below nuget package to the project.</p> </li> </ul> TasksTracker.WebPortal.Frontend.Ui.csproj <pre><code>&lt;ItemGroup&gt;\n&lt;PackageReference Include=\"Dapr.AspNetCore\" Version=\"1.9.0\" /&gt;\n&lt;/ItemGroup&gt;\n</code></pre> <ul> <li>Next, open the file <code>Programs.cs</code> of the Frontend Web App and register the DaprClient as the highlighted below. </li> </ul> Program.cs <pre><code>namespace TasksTracker.WebPortal.Frontend.Ui\n{\npublic class Program\n{\npublic static void Main(string[] args)\n{\nvar builder = WebApplication.CreateBuilder(args);\n// Add services to the container.\nbuilder.Services.AddRazorPages();\n// Code removed for brevity     \nbuilder.Services.AddDaprClient();\nvar app = builder.Build();\n// Code removed for brevity \n}\n}\n}\n</code></pre> <ul> <li>Now, we will inject the DaprClient into the <code>.cshtml</code> pages to use the method <code>InvokeMethodAsync</code> (second approach). Update file under folder Pages\\Tasks and use the code below for different files.</li> </ul> Index.cshtml.csCreate.cshtml.csEdit.cshtml.cs <pre><code>using Dapr.Client;\nusing Microsoft.AspNetCore.Mvc;\nusing Microsoft.AspNetCore.Mvc.RazorPages;\nusing TasksTracker.WebPortal.Frontend.Ui.Pages.Tasks.Models;\nnamespace TasksTracker.WebPortal.Frontend.Ui.Pages.Tasks\n{\npublic class IndexModel : PageModel\n{\nprivate readonly IHttpClientFactory _httpClientFactory;\nprivate readonly DaprClient _daprClient;\npublic List&lt;TaskModel&gt;? TasksList { get; set; }\n[BindProperty]\npublic string? TasksCreatedBy { get; set; }\npublic IndexModel(IHttpClientFactory httpClientFactory, DaprClient daprClient)\n{\n_httpClientFactory = httpClientFactory;\n_daprClient = daprClient;\n}\npublic async Task OnGetAsync()\n{\nTasksCreatedBy = Request.Cookies[\"TasksCreatedByCookie\"];\n//Invoke via internal URL (Not Dapr)\n//var httpClient = _httpClientFactory.CreateClient(\"BackEndApiExternal\");\n//TasksList = await httpClient.GetFromJsonAsync&lt;List&lt;TaskModel&gt;&gt;($\"api/tasks?createdBy={TasksCreatedBy}\");\n// Invoke via Dapr SideCar URL\n//var port = 3500;//Environment.GetEnvironmentVariable(\"DAPR_HTTP_PORT\");\n//HttpClient client = new HttpClient();\n//var result = await client.GetFromJsonAsync&lt;List&lt;TaskModel&gt;&gt;($\"http://localhost:{port}/v1.0/invoke/tasksmanager-backend-api/method/api/tasks?createdBy={TasksCreatedBy}\");\n//TasksList = result;\n// Invoke via DaprSDK (Invoke HTTP services using HttpClient) --&gt; Use Dapr Appi ID (Option 1)\n//var daprHttpClient = DaprClient.CreateInvokeHttpClient(appId: \"tasksmanager-backend-api\"); \n//TasksList = await daprHttpClient.GetFromJsonAsync&lt;List&lt;TaskModel&gt;&gt;($\"api/tasks?createdBy={TasksCreatedBy}\");\n// Invoke via DaprSDK (Invoke HTTP services using HttpClient) --&gt; Specify Custom Port (Option 2)\n// var daprHttpClient = DaprClient.CreateInvokeHttpClient(daprEndpoint: \"http://localhost:3500\"); \n// TasksList = await daprHttpClient.GetFromJsonAsync&lt;List&lt;TaskModel&gt;&gt;($\"http://tasksmanager-backend-api/api/tasks?createdBy={TasksCreatedBy}\");\n// Invoke via DaprSDK (Invoke HTTP services using DaprClient)\nTasksList = await _daprClient.InvokeMethodAsync&lt;List&lt;TaskModel&gt;&gt;(HttpMethod.Get, \"tasksmanager-backend-api\", $\"api/tasks?createdBy={TasksCreatedBy}\");\n}\npublic async Task&lt;IActionResult&gt; OnPostDeleteAsync(Guid id)\n{\n// direct svc to svc http request\n// var httpClient = _httpClientFactory.CreateClient(\"BackEndApiExternal\");\n// var result = await httpClient.DeleteAsync($\"api/tasks/{id}\");\n//Dapr SideCar Invocation\nawait _daprClient.InvokeMethodAsync(HttpMethod.Delete, \"tasksmanager-backend-api\", $\"api/tasks/{id}\");\nreturn RedirectToPage();          }\npublic async Task&lt;IActionResult&gt; OnPostCompleteAsync(Guid id)\n{\n// direct svc to svc http request\n// var httpClient = _httpClientFactory.CreateClient(\"BackEndApiExternal\");\n// var result = await httpClient.PutAsync($\"api/tasks/{id}/markcomplete\", null);\n//Dapr SideCar Invocation\nawait _daprClient.InvokeMethodAsync(HttpMethod.Put, \"tasksmanager-backend-api\", $\"api/tasks/{id}/markcomplete\");\nreturn RedirectToPage();\n}\n}\n}\n</code></pre> <pre><code>using Dapr.Client;\nusing Microsoft.AspNetCore.Mvc;\nusing Microsoft.AspNetCore.Mvc.RazorPages;\nusing TasksTracker.WebPortal.Frontend.Ui.Pages.Tasks.Models;\nnamespace TasksTracker.WebPortal.Frontend.Ui.Pages.Tasks\n{\npublic class CreateModel : PageModel\n{\nprivate readonly IHttpClientFactory _httpClientFactory;\nprivate readonly DaprClient _daprClient;\npublic CreateModel(IHttpClientFactory httpClientFactory, DaprClient daprClient)\n{\n_httpClientFactory = httpClientFactory;\n_daprClient = daprClient;\n}\npublic IActionResult OnGet()\n{\nreturn Page();\n}\n[BindProperty]\npublic TaskAddModel TaskAdd { get; set; }\npublic async Task&lt;IActionResult&gt; OnPostAsync()\n{\nif (!ModelState.IsValid)\n{\nreturn Page();\n}\nif (TaskAdd != null)\n{\nvar createdBy = Request.Cookies[\"TasksCreatedByCookie\"];\nTaskAdd.TaskCreatedBy = createdBy;\n// direct svc to svc http request\n// var httpClient = _httpClientFactory.CreateClient(\"BackEndApiExternal\");\n// var result = await httpClient.PostAsJsonAsync(\"api/tasks/\", TaskAdd);\n//Dapr SideCar Invocation\nawait _daprClient.InvokeMethodAsync(HttpMethod.Post, \"tasksmanager-backend-api\", $\"api/tasks\", TaskAdd);\n}\nreturn RedirectToPage(\"./Index\");\n}\n}\n}\n</code></pre> <pre><code>using Dapr.Client;\nusing Microsoft.AspNetCore.Mvc;\nusing Microsoft.AspNetCore.Mvc.RazorPages;\nusing TasksTracker.WebPortal.Frontend.Ui.Pages.Tasks.Models;\nnamespace TasksTracker.WebPortal.Frontend.Ui.Pages.Tasks\n{\npublic class EditModel : PageModel\n{\nprivate readonly IHttpClientFactory _httpClientFactory;\nprivate readonly DaprClient _daprClient;\n[BindProperty]\npublic TaskUpdateModel? TaskUpdate { get; set; }\npublic EditModel(IHttpClientFactory httpClientFactory, DaprClient daprClient)\n{\n_httpClientFactory = httpClientFactory;\n_daprClient = daprClient;\n}\npublic async Task&lt;IActionResult&gt; OnGetAsync(Guid? id)\n{\nif (id == null)\n{\nreturn NotFound();\n}\n// direct svc to svc http request\n// var httpClient = _httpClientFactory.CreateClient(\"BackEndApiExternal\");\n// var Task = await httpClient.GetFromJsonAsync&lt;TaskModel&gt;($\"api/tasks/{id}\");\n//Dapr SideCar Invocation\nvar Task = await _daprClient.InvokeMethodAsync&lt;TaskModel&gt;(HttpMethod.Get, \"tasksmanager-backend-api\", $\"api/tasks/{id}\");\nif (Task == null)\n{\nreturn NotFound();\n}\nTaskUpdate = new TaskUpdateModel()\n{\nTaskId = Task.TaskId,\nTaskName = Task.TaskName,\nTaskAssignedTo = Task.TaskAssignedTo,\nTaskDueDate = Task.TaskDueDate,\n};\nreturn Page();\n}\npublic async Task&lt;IActionResult&gt; OnPostAsync()\n{\nif (!ModelState.IsValid)\n{\nreturn Page();\n}\nif (TaskUpdate != null)\n{\n// direct svc to svc http request\n// var httpClient = _httpClientFactory.CreateClient(\"BackEndApiExternal\");\n// var result = await httpClient.PutAsJsonAsync($\"api/tasks/{TaskUpdate.TaskId}\", TaskUpdate);\n//Dapr SideCar Invocation\nawait _daprClient.InvokeMethodAsync&lt;TaskUpdateModel&gt;(HttpMethod.Put, \"tasksmanager-backend-api\", $\"api/tasks/{TaskUpdate.TaskId}\", TaskUpdate);\n}\nreturn RedirectToPage(\"./Index\");\n}\n}\n}\n</code></pre> Tip <p>Notice how we are not using the <code>HttpClientFactory</code> anymore and how we were able from the Frontend Dapr Sidecar to invoke backend API Sidecar using the method <code>InvokeMethodAsync</code> which accepts the Dapr remote App ID for the Backend API <code>tasksmanager-backend-api</code> and it will be able to discover the URL and invoke the method based on the specified input params.</p> <p>In addition to this, notice how in POST and PUT operations, the third argument is a <code>TaskAdd</code> or <code>TaskUpdate</code> Model, those objects will be serialized internally (using System.Text.JsonSerializer) and sent as the request payload. The .NET SDK takes care of the call to the Sidecar. It also deserializes the response in case of the GET operations to a <code>List&lt;TaskModel&gt;</code> object.</p> <p>Looking at the first option of invoking the remote service \"Invoke HTTP services using HttpClient\", you can see that we can create an HttpClient by invoking <code>DaprClient.CreateInvokeHttpClient</code> and specify the remote service app id, custom port if needed and then use the HTTP methods such as <code>GetFromJsonAsync</code>, this is a good approach as well at it gives you full support of advanced scenarios, such as custom headers and full control over request and response messages.</p> <p>In both options, the final request will be rewritten by the Dapr .NET SDK before it gets executed. In our case and for the GET operation it will be written to this request: <code>http://127.0.0.1:3500/v1/invoke/tasksmanager-backend-api/method/api/tasks?createdBy=tjoudeh@bitoftech.net</code></p> <ul> <li>We are ready now to verify changes on Frontend Web App and test locally, we need to run the Frontend Web App along with the Backend Web API and test locally that changes using the .NET SDK and invoking services via Dapr Sidecar are working as expected. To do so run the two commands commands shown below (ensure that you are on the right project directory when running each command). Remember to replace the place holders with your own values:</li> </ul> <p>Note</p> <p>Remember to replace the placeholders. Remember to use https port number for the Web API application.</p> .NET 6 or below.NET 7 or above <pre><code>~\\TasksTracker.ContainerApps\\TasksTracker.WebPortal.Frontend.Ui&gt; dapr run --app-id tasksmanager-frontend-webapp --app-port &lt;web frontend application https port found under properties-&gt;launchSettings.json. e.g. 7000&gt; --dapr-http-port 3501 --app-ssl -- dotnet run \n~\\TasksTracker.ContainerApps\\TasksTracker.TasksManager.Backend.Api&gt; dapr run --app-id tasksmanager-backend-api --app-port &lt;web api application https port found under properties-&gt;launchSettings.json. e.g. 7112&gt; --dapr-http-port 3500 --app-ssl -- dotnet run\n</code></pre> <pre><code>~\\TasksTracker.ContainerApps\\TasksTracker.WebPortal.Frontend.Ui&gt; dapr run --app-id tasksmanager-frontend-webapp --app-port &lt;web frontend application https port found under properties-&gt;launchSettings.json. e.g. 7000&gt; --dapr-http-port 3501 --app-ssl -- dotnet run --launch-profile https\n~\\TasksTracker.ContainerApps\\TasksTracker.TasksManager.Backend.Api&gt; dapr run --app-id tasksmanager-backend-api --app-port &lt;web api application https port found under properties-&gt;launchSettings.json. e.g. 7112&gt; --dapr-http-port 3500 --app-ssl -- dotnet run --launch-profile https\n</code></pre> <p>Notice how we assigned the Dapr App Id \u201ctasksmanager-frontend-webapp\u201d to the Frontend WebApp.</p> <p>Note</p> <p>If you need to run both microservices together, you need to keep calling <code>dapr run</code> manually each time in the terminal. And when you have multiple microservices talking to each other you need to run at the same time to debug the solution. This can be a convoluted process. You can refer to the debug and launch Dapr applications in VSCode to see how to configure VScode for running and debugging Dapr applications.</p> <p>Success</p> <p>Now both Applications are running using Dapr sidecar. Open your browser and browse for <code>https://localhost:{localwebappport}</code>. E.g. <code>https://localhost:7000</code> and provide an email to load the tasks for the user (e.g. tjoudeh@bitoftech.net). If the application is working as expected you should see tasks list associated with the email you provided (e.g. tjoudeh@bitoftech.net).</p> <p>In the next module, we will integrate the Dapr state store building block by saving tasks to Azure Cosmos DB. We will also deploy the updated applications to Azure Container Apps.</p>"},{"location":"aca/04-aca-dapr-stateapi/","title":"Module 4 - ACA State Store With Dapr State Management API","text":"<p>Module Duration</p> <p>60 minutes</p> <p>In this module we will switch the in-memory store of tasks and use a key/value persistent store (Azure Cosmos DB). By using the Dapr State Management Building Block, we will see how we can store the data in Azure Cosmos DB without installing any Cosmos DB SDK or write specific code to integrate our Backend API with Azure Cosmos DB. Moreover, we will use Redis to store tasks when we are running the application locally. You will see that we can switch between different stores without any code changes, thanks to the Dapr pluggable state stores feature. It is a matter of adding new Dapr Component files and the underlying store will be changed. This page shows the supported state stores in Dapr.</p> <p></p>"},{"location":"aca/04-aca-dapr-stateapi/#overview-of-dapr-state-management-api","title":"Overview of Dapr State Management API","text":"<p>Dapr's state management API allows you to save, read, and query key/value pairs in the supported state stores. To try this out and without doing any code changes or installing any NuGet packages we can directly invoke the State Management API and store the data on Redis locally. When you initialized Dapr in your local development environment, it installed Redis container instance locally. So we can use Redis locally to store and retrieve state. If you navigate to the path <code>%USERPROFILE%\\.dapr\\components (assuming you are using windows)</code> you will find a file named <code>statestore.yaml</code>. Inside this file, you will see the properties needed to access the local Redis instance. The state store template component file structure can be found on this link.</p> <p>To try out the State Management APIs, run the Backend API from VS Code by running the following command. Remember to replace the place holders with your own values:</p> .NET 6 or below.NET 7 or above <pre><code>~\\TasksTracker.ContainerApps\\TasksTracker.TasksManager.Backend.Api&gt; dapr run --app-id tasksmanager-backend-api --app-port &lt;web api application https port number found under properties-&gt;launchSettings.json. e.g. 7112&gt; --dapr-http-port 3500 --app-ssl -- dotnet run\n</code></pre> <pre><code>~\\TasksTracker.ContainerApps\\TasksTracker.TasksManager.Backend.Api&gt; dapr run --app-id tasksmanager-backend-api --app-port &lt;web api application https port number found under properties-&gt;launchSettings.json. e.g. 7112&gt; --dapr-http-port 3500 --app-ssl -- dotnet run --launch-profile https\n</code></pre> <p>Now from any rest client, invoke the below POST request to the endpoint: http://localhost:3500/v1.0/state/statestore</p> <pre><code>POST /v1.0/state/statestore HTTP/1.1\nHost: localhost:3500\nContent-Type: application/json\n[\n{\n\"key\": \"Book1\",\n\"value\": {\n\"title\": \"Parallel and High Performance Computing\",\n\"author\": \"Robert Robey\",\n\"genre\": \"Technical\"\n}\n},\n{\n\"key\": \"Book2\",\n\"value\": {\n\"title\": \"Software Engineering Best Practices\",\n\"author\": \"Capers Jones\",\n\"genre\": \"Technical\"\n}\n},\n{\n\"key\": \"Book3\",\n\"value\": {\n\"title\": \"The Unstoppable Mindset\",\n\"author\": \"Jessica Marks\",\n\"genre\": \"Self Improvement\",\n\"formats\":[\"kindle\", \"audiobook\", \"papercover\"]\n}\n}\n]\n</code></pre> <p>What we've done here is the following:</p> <ul> <li>The value <code>statestore</code> in the endpoint should match the <code>name</code> value in the global component file <code>statestore.yaml</code></li> <li>We have sent a request to store 3 entries of books, you can put any JSON representation in the value property</li> </ul> <p>To see the results visually, you can install a VS Code extension to connect to Redis DB and see the results. There are several redis extensions available for VS Code. For this workshop we will use an extension named \"Redis Xplorer\". </p> <p>Once you install the extension it will add a tab under the explorer section of VS Code called \"REDIS XPLORER\". Next you will need to connect to the redis server locally by adding a new \"REDIS XPLORER\" profile. Click on the + sign in the \"REDIS XPLORER\" section in VS Code.  This will ask you to enter the nickname (e.g. dapr_redis) as well as the hostname and port. For the hostname and port you can get this information by executing the following command in your powershell terminal:</p> <pre><code>docker ps\n</code></pre> <p>Look under the Ports column and use the server and port specified there. In the image below the server is 0.0.0.0 and the port is 6379. Use the values that you see on your own terminal.</p> <p></p> <p>After you connect to Redis locally, you should see the 3 entries similar to the ones shown in the image below. Notice how each entry key is prefixed by the Dapr App Id. In our case it is <code>tasksmanager-backend-api</code>. More about key prefix strategy in later sections in this module.</p> <p></p> <p>To get the value of a key, you need to issue a GET request to the endpoint <code>http://localhost:3500/v1.0/state/statestore/{YourKey}</code>. This will return the value from the key store.  For example if you execute the following GET http://localhost:3500/v1.0/state/statestore/Book3 the results will be the below object:</p> <pre><code>{\n\"formats\": [\n\"kindle\",\n\"audiobook\",\n\"papercover\"\n],\n\"title\": \"The Unstoppable Mindset\",\n\"author\": \"Jessica Marks\",\n\"genre\": \"Self Improvement\"\n}\n</code></pre>"},{"location":"aca/04-aca-dapr-stateapi/#use-dapr-client-sdk-for-state-store-management","title":"Use Dapr Client SDK For State Store Management","text":"<p>Whereas in the previous section we demonstrated using Dapr State Store without code changes, we will now introduce a change on the Backend API and create a new service named <code>TasksStoreManager.cs</code> which will implement the interface <code>ITasksManager.cs</code> to start storing tasks data on the persist store. Locally we will start testing with Redis, then we are going to change the state store to use Azure Cosmos DB.</p>"},{"location":"aca/04-aca-dapr-stateapi/#1-add-dapr-client-sdk-to-the-backend-api","title":"1. Add Dapr Client SDK to The Backend API","text":"<p>Similar to what we have done in the Frontend Web App, we need to use Dapr Client SDK to manage the state store. Update below file with highlighted lines:</p> TasksTracker.TasksManager.Backend.Api.csproj <pre><code>&lt;ItemGroup&gt;\n&lt;PackageReference Include=\"Dapr.AspNetCore\" Version=\"1.9.0\" /&gt;\n&lt;!-- Other packages are removed for brevity --&gt;\n&lt;/ItemGroup&gt;\n</code></pre>"},{"location":"aca/04-aca-dapr-stateapi/#2-create-a-new-concrete-implementation-to-manage-tasks-persistence","title":"2. Create a New Concrete Implementation to Manage Tasks Persistence","text":"<p>As you recall from the previous module, we were storing the tasks in memory. Now we need to store them in Redis and later on Azure Cosmos DB.  The key thing to keep in mind here is that switching from redis to Azure Cosmos DB won't require changing the code below which is a huge advantage of using Dapr.</p> <p>Add below file under the folder named Services. This file will implement the interface <code>ITasksManager</code>.</p> TasksStoreManager.cs <pre><code>using Dapr.Client;\nusing TasksTracker.TasksManager.Backend.Api.Models;\nnamespace TasksTracker.TasksManager.Backend.Api.Services\n{\npublic class TasksStoreManager : ITasksManager\n{\nprivate static string STORE_NAME = \"statestore\";\nprivate readonly DaprClient _daprClient;\nprivate readonly IConfiguration _config;\nprivate readonly ILogger&lt;TasksStoreManager&gt; _logger;\npublic TasksStoreManager(DaprClient daprClient, IConfiguration config, ILogger&lt;TasksStoreManager&gt; logger)\n{\n_daprClient = daprClient;\n_config = config;\n_logger = logger;\n}\npublic async Task&lt;Guid&gt; CreateNewTask(string taskName, string createdBy, string assignedTo, DateTime dueDate)\n{\nvar taskModel = new TaskModel()\n{\nTaskId = Guid.NewGuid(),\nTaskName = taskName,\nTaskCreatedBy = createdBy,\nTaskCreatedOn = DateTime.UtcNow,\nTaskDueDate = dueDate,\nTaskAssignedTo = assignedTo,\n};\n_logger.LogInformation(\"Save a new task with name: '{0}' to state store\", taskModel.TaskName);\nawait _daprClient.SaveStateAsync&lt;TaskModel&gt;(STORE_NAME, taskModel.TaskId.ToString(), taskModel);\nreturn taskModel.TaskId;\n}\npublic async Task&lt;bool&gt; DeleteTask(Guid taskId)\n{\n_logger.LogInformation(\"Delete task with Id: '{0}'\", taskId);\nawait _daprClient.DeleteStateAsync(STORE_NAME, taskId.ToString());\nreturn true;\n}\npublic async Task&lt;TaskModel?&gt; GetTaskById(Guid taskId)\n{\n_logger.LogInformation(\"Getting task with Id: '{0}'\", taskId);\nvar taskModel = await _daprClient.GetStateAsync&lt;TaskModel&gt;(STORE_NAME, taskId.ToString());\nreturn taskModel;\n}\npublic async Task&lt;List&lt;TaskModel&gt;&gt; GetTasksByCreator(string createdBy)\n{\nvar query = \"{\" +\n\"\\\"filter\\\": {\" +\n\"\\\"EQ\\\": { \\\"taskCreatedBy\\\": \\\"\" + createdBy + \"\\\" }\" +\n\"}}\";\nvar queryResponse = await _daprClient.QueryStateAsync&lt;TaskModel&gt;(STORE_NAME, query);\nvar tasksList = queryResponse.Results.Select(q =&gt; q.Data).OrderByDescending(o=&gt;o.TaskCreatedOn);\nreturn tasksList.ToList();\n}\npublic async Task&lt;bool&gt; MarkTaskCompleted(Guid taskId)\n{\n_logger.LogInformation(\"Mark task with Id: '{0}' as completed\", taskId);\nvar taskModel = await _daprClient.GetStateAsync&lt;TaskModel&gt;(STORE_NAME, taskId.ToString());\nif (taskModel != null)\n{\ntaskModel.IsCompleted = true;\nawait _daprClient.SaveStateAsync&lt;TaskModel&gt;(STORE_NAME, taskModel.TaskId.ToString(), taskModel);\nreturn true;\n}\nreturn false;\n}\npublic async Task&lt;bool&gt; UpdateTask(Guid taskId, string taskName, string assignedTo, DateTime dueDate)\n{\n_logger.LogInformation(\"Update task with Id: '{0}'\", taskId);\nvar taskModel = await _daprClient.GetStateAsync&lt;TaskModel&gt;(STORE_NAME, taskId.ToString());\nvar currentAssignee = taskModel.TaskAssignedTo;\nif (taskModel != null)\n{\ntaskModel.TaskName = taskName;\ntaskModel.TaskAssignedTo = assignedTo;\ntaskModel.TaskDueDate = dueDate;\nawait _daprClient.SaveStateAsync&lt;TaskModel&gt;(STORE_NAME, taskModel.TaskId.ToString(), taskModel);\nreturn true;\n}\nreturn false;\n}\n}\n}\n</code></pre> Curious about the code? <p>Looking at the code above, we have injected the <code>DaprClient</code> into the new service and DaprClient has a set of methods to support CRUD operations. Notice how we are using the state store named <code>statestore</code>  which should match the name in the component file.</p> <p>Note</p> <p>The query API will not work against the local Redis store as you need to install RediSearch locally on your machine which is out of the scope for this workshop.  It will work locally once we switch to Azure Cosmos DB.</p>"},{"location":"aca/04-aca-dapr-stateapi/#3-register-the-tasksstoremanager-new-service-and-daprclient","title":"3. Register the TasksStoreManager New Service and DaprClient","text":"<p>Now we need to register the new service named <code>TasksStoreManager</code> and <code>DaprClient</code> when the Backend API app starts up. Update the below file with the highlighted text as shown below.</p> <p>Note</p> <p>Do not forget to comment out the registration of the <code>FakeTasksManager</code> service as we don\u2019t want to store tasks in memory anymore.</p> Program.cs <pre><code>var builder = WebApplication.CreateBuilder(args);\n// Add services to the container.\nbuilder.Services.AddDaprClient();\nbuilder.Services.AddSingleton&lt;ITasksManager, TasksStoreManager&gt;();\n//builder.Services.AddSingleton&lt;ITasksManager, FakeTasksManager&gt;();\n//Code removed for brevity\n</code></pre> <p>Now you are ready to run both applications and debug them. You can store new tasks, update them, delete existing tasks and mark them as completed. The data should be stored on your local Redis instance.</p> <p>Info</p> <p>For now don't try running the application as you will get an error running the query against the local redis. As mentioned earlier setting up the local redis store is out of scope for this workshop.  Instead, we will focus on wiring the Azure Cosmos DB as the store for our tasks.</p>"},{"location":"aca/04-aca-dapr-stateapi/#use-azure-cosmos-db-with-dapr-state-store-management-api","title":"Use Azure Cosmos DB with Dapr State Store Management API","text":"<p>1. Provision Cosmos DB Resources: Now we will create an Azure Cosmos DB account, Database, and a new container that will store our tasks.  You can use the PowerShell script below to create the Cosmos DB resources on the same resource group we used in the previous module.  You need to set the variable name of the <code>$COSMOS_DB_ACCOUNT</code> to a unique name as it needs to be unique globally. Remember to replace the placeholders with your own values:</p> <pre><code>$COSMOS_DB_ACCOUNT=\"&lt;choose a unique cosmos db account name e.g. taskstracker-state-store-your initials here&gt;\" `\n$COSMOS_DB_DBNAME=\"tasksmanagerdb\" `\n$COSMOS_DB_CONTAINER=\"taskscollection\" \n## Check if Cosmos account name already exists globally\naz cosmosdb check-name-exists `\n--name $COSMOS_DB_ACCOUNT\n## if it returns false continue with the next command \n## else try a new unique name\n## Create a Cosmos account for SQL API\naz cosmosdb create `\n--name $COSMOS_DB_ACCOUNT `\n--resource-group $RESOURCE_GROUP\n## Create a SQL API database\naz cosmosdb sql database create `\n--account-name $COSMOS_DB_ACCOUNT `\n--resource-group $RESOURCE_GROUP `\n--name $COSMOS_DB_DBNAME\n## Create a SQL API container\naz cosmosdb sql container create `\n--account-name $COSMOS_DB_ACCOUNT `\n--resource-group $RESOURCE_GROUP `\n--database-name $COSMOS_DB_DBNAME `\n--name $COSMOS_DB_CONTAINER `\n--partition-key-path \"/id\" `\n--throughput 400\n</code></pre> <p>Note</p> <p>The <code>primaryMasterKey</code> connection string is only needed for our local testing on the development machine, we'll be using a different approach (Managed Identities) when deploying Dapr component to  Azure Container Apps Environment.</p> <p>Once the scripts execution is completed, we need to get the <code>primaryMasterKey</code> of the CosmosDB account next. You can do this using the PowerShell script below.  Copy the value of <code>primaryMasterKey</code> as we will use it in the next step.</p> <pre><code>## List Azure CosmosDB keys\naz cosmosdb keys list `\n--name $COSMOS_DB_ACCOUNT `\n--resource-group $RESOURCE_GROUP\n</code></pre> <p>2. Create a Component File for State Store Management: Dapr uses a modular design where functionality is delivered as a component. Each component has an interface definition.  All the components are pluggable so that you can swap out one component with the same interface for another</p> <p>Components are configured at design-time with a YAML file which is stored in either a components/local folder within your solution, or globally in the <code>.dapr</code> folder created when invoking <code>dapr init</code>.  These YAML files adhere to the generic Dapr component schema, but each is specific to the component specification.</p> <p>It is important to understand that the component spec values, particularly the spec <code>metadata</code>, can change between components of the same component type.  As a result, it is strongly recommended to review a component\u2019s specs, paying particular attention to the sample payloads for requests to set the metadata used to interact with the component.</p> <p>The diagram below is from Dapr official documentation which shows some examples of the components for each component type. We are now looking at the State Stores components. Specifically the Azure Cosmos DB.</p> <p></p> <p>To add the component file state store, add a new folder named components under the directory TasksTracker.ContainerApps and add a new yaml file as show below:</p> <p>Info</p> <p>You need to replace the masterKey value with your Cosmos Account key. Remember this is only needed for local development debugging, we will not be using the masterKey when we deploy to ACA.</p> <p>Replace the url value with the URI value of your cosmos database account. You can get that from the Azure portal by navigating to the cosmos database account overview page and get the uri value from there.  Basically the uri should have the following structure. https://COSMOS_DB_ACCOUNT.documents.azure.com:443/.</p> dapr-statestore-cosmos.yaml <pre><code>apiVersion: dapr.io/v1alpha1\nkind: Component\nmetadata:\nname: statestore\nspec:\ntype: state.azure.cosmosdb\nversion: v1\nmetadata:\n- name: url\nvalue: &lt;value&gt;\n- name: masterKey\nvalue: \"&lt;value&gt;\"\n- name: database\nvalue: tasksmanagerdb\n- name: collection\nvalue: taskscollection\nscopes:\n- tasksmanager-backend-api\n</code></pre> Curious to learn more about the contents of the yaml file? <ul> <li>We've used the name <code>statestore</code> which should match the name of statestore we've used in the <code>TaskStoreManager.cs</code> file. As well, we have set the metadata key/value to allow us to connect to Azure Cosmos DB.</li> <li>We've updated the other metadata keys such as <code>database</code>, <code>collection</code>, etc... to match the values of your Cosmos DB instance. For full metadata specs, you can check this page.</li> <li>By default, all dapr-enabled container apps within the same environment will load the full set of deployed components. By adding <code>scopes</code> to a component, you tell the Dapr sidecars for each respective container app which components to load at runtime.  Using scopes is recommended for production workloads. In our case, we have set the scopes to <code>tasksmanager-backend-api</code> which represents the dapr-app-id which is associated to the container app that needs access to Azure Cosmos DB State Store as this will be the application that needs access to Azure Cosmos DB State Store. More about scopes can be found on this link.</li> </ul> <p>Note</p> <p>Dapr component scopes correspond to the Dapr application ID of a container app, not the container app name.</p> <p>Now you should be ready to launch both applications and start doing CRUD operations from the Frontend Web App including querying the store. All your data will be stored in Cosmos DB Database you just provisioned. </p> <p>If you have been running the different microservices using the debug and launch Dapr applications in VSCode then remember to uncomment the following line inside tasks.json file.  This will instruct dapr to load the local projects components ./components instead of the global components' folder.</p> <pre><code>{\n\"componentsPath\": \"./components\"\n}\n</code></pre> <p>If you have been using the dapr cli commands instead of the aforementioned debugging then you will need to execute the backend api with the resources-path property as follows.</p> <p>Note</p> <p>Remember to replace the placeholders. Remember to use https port number for the Web API application.</p> .NET 6 or below.NET 7 or above <pre><code>dapr run --app-id tasksmanager-backend-api --app-port &lt;web api application https port number found under properties-&gt;launchSettings.json. e.g. 7112&gt; --dapr-http-port 3500 --app-ssl --resources-path \"../components\" dotnet run\n</code></pre> <pre><code>dapr run --app-id tasksmanager-backend-api --app-port &lt;web api application https port number found under properties-&gt;launchSettings.json. e.g. 7112&gt; --dapr-http-port 3500 --app-ssl --resources-path \"../components\" -- dotnet run --launch-profile https\n</code></pre> <p>Deprecation Warning</p> <p>components-path is being deprecated in favor of --resources-path. At the time of producing this workshop the --resources-path was not supported yet by the VS code extension. Hence, you will notice the use of the property \"componentsPath\": \"./components\" in the tasks.json file. Check the extension documentation in case that has changed.</p> <p>After creating a new record you can navigate to the Data explorer on the Azure portal for the azure cosmos database account. It should look like the image below:</p> <p></p>"},{"location":"aca/04-aca-dapr-stateapi/#key-prefix-strategies","title":"Key Prefix Strategies","text":"<p>When you look at the key stored per entry and for example <code>tasksmanager-backend-api||aa3eb856-8309-4e68-93af-119be0d400e8</code>, you will notice that the key is prefixed with the Dapr application App Id responsible to store this entry which in our case is <code>tasksmanager-backend-api</code>. There might be some scenarios which you need to have another service to access the same data store (not recommended as each service should be responsible about its own data store), in which case you can change the default behavior. </p> <p>This can be done by adding the meta tag below to the component file. For example, if we need to set the value of the prefix to a constant value such as <code>TaskId</code> we can do the following:</p> <p><pre><code>spec:\nmetadata:\n- name: keyPrefix\n- value: TaskId\n</code></pre> If we need to totally omit the key prefix, so it is accessed across multiple Dapr applications, we can set the value to <code>none</code>.</p>"},{"location":"aca/04-aca-dapr-stateapi/#configure-managed-identities-in-container-app","title":"Configure Managed Identities in Container App","text":"<p>As we highlighted earlier, we'll not use a connection strings to establish the relation between our Container App and Azure Cosmos DB when we deploy to ACA. Cosmos DB Master Key/Connection string was only used when debugging locally. Now we will rely on Managed Identities to allow our container app to access Cosmos DB. With Manged Identities you do't worry about storing the keys securely and rotate them inside your application. This approach is safer and easier to manage.</p> <p>We will be using a <code>system-assigned</code> identity with a role assignment to grant our Backend API container app permissions to access data stored in Cosmos DB. We need to assign it a custom role for the Cosmos DB data plane. In this example ae are going to use a built-in role, named <code>Cosmos DB Built-in Data Contributor</code>, which grants our application full read-write access to the data. You can optionally create custom, fine-tuned roles following the instructions in the official docs.</p>"},{"location":"aca/04-aca-dapr-stateapi/#1-create-system-assigned-identity-for-our-container-app","title":"1. Create system-assigned identity for our container app","text":"<p>Run the command below to create <code>system-assigned</code> identity for our container app:</p> <pre><code>az containerapp identity assign `\n--resource-group $RESOURCE_GROUP `\n--name $BACKEND_API_NAME `\n--system-assigned\n</code></pre> <p>This command will create an Enterprise Application (basically a Service Principal) within Azure AD, which is linked to our container app. The output of this command will be similar to the one shown below.  Keep a note of the property <code>principalId</code> as we are going to use it in the next step.</p> <pre><code>{\n\"principalId\": \"[your principal id will be displayed here]\",\n\"tenantId\": \"[your tenant id will be displayed here]\",\n\"type\": \"SystemAssigned\"\n}\n</code></pre>"},{"location":"aca/04-aca-dapr-stateapi/#2-assign-the-container-app-system-identity-to-the-built-in-cosmos-db-role","title":"2. Assign the Container App System-Identity To the Built-in Cosmos DB Role","text":"<p>Next, we need to associate the container app system-identity with the target Cosmos DB resource.  You can read more about Azure built-in roles for Cosmos DB or how to create custom fine-tuned roles here.  Run the command below to associate the container app <code>system-assigned</code> identity with <code>Cosmos DB Built-in Data Contributor</code> role. </p> <p>Note</p> <p>Make sure you save this principal id somewhere as you will need it in later modules. You can't rely on having it saved in powershell under <code>$PRINCIPAL_ID</code> as this variable could replace later on.  Remember to replace the placeholders with your own values:</p> <pre><code> $PRINCIPAL_ID = \"&lt;your principal id goes here&gt;\" # Principal Id after creating system identity for container app \n$ROLE_ID = \"00000000-0000-0000-0000-000000000002\" #\"Cosmos DB Built-in Data Contributor\" \naz cosmosdb sql role assignment create `\n--account-name  $COSMOS_DB_ACCOUNT `\n--resource-group $RESOURCE_GROUP `\n--scope \"/\" `\n--principal-id $PRINCIPAL_ID `\n--role-definition-id $ROLE_ID\n</code></pre>"},{"location":"aca/04-aca-dapr-stateapi/#deploy-the-backend-api-and-frontend-web-app-projects-to-aca","title":"Deploy the Backend API and Frontend Web App Projects to ACA","text":"<p>Now we are ready to deploy all local changes from this module and the previous module to ACA. But before we do that, we need to do one more addition before deploying.</p> <p>We have to create a dapr component schema file for Azure Cosmos DB which meets the specs defined by  Azure Container Apps. Reason for this variance is that ACA Dapr schema is slightly simplified to support Dapr components and removes unnecessary fields, including <code>apiVersion</code>, <code>kind</code>, and redundant metadata and  spec properties.</p>"},{"location":"aca/04-aca-dapr-stateapi/#1-create-an-aca-dapr-component-file-for-state-store-management","title":"1. Create an ACA-Dapr Component File For State Store Management","text":"<p>Here it is recommended to separate the component files that will be used when deploying to Azure Container Apps from the ones which we will use when running our application locally (Dapr self-hosted). </p> <p>Create a new folder named aca-components under the directory TasksTracker.ContainerApps, then add a new file as shown below:</p> <p>Info</p> <p>Remember to replace the url value with the URI value of your cosmos database account. You can get that from the Azure portal by navigating to the cosmos database account overview page and get the uri value from there.  Basically the uri should have the following structure <code>https://COSMOS_DB_ACCOUNT.documents.azure.com:443/</code></p> containerapps-statestore-cosmos.yaml <pre><code>componentType: state.azure.cosmosdb\nversion: v1\nmetadata:\n- name: url\nvalue: &lt;The URI value of your cosmos database account&gt;\n- name: database\nvalue: tasksmanagerdb\n- name: collection\nvalue: taskscollection\nscopes:\n- tasksmanager-backend-api\n</code></pre> Curious to learn more about the contents of the yaml file? <ul> <li>We didn't specify the Cosmos DB component name <code>statestore</code> when we created this component file. We are going to specify it once we add this dapr component to Azure Container Apps Environment via CLI.</li> <li>We are not referencing any Cosmos DB Keys/Connection strings as the authentication between Dapr and Cosmos DB will be configured using Managed Identities. </li> <li>We are setting the <code>scopes</code> array value to <code>tasksmanager-backend-api</code> to ensure Cosmos DB component is loaded at runtime by only the appropriate container apps. In our case it will be needed only for the container apps with Dapr application IDs <code>tasksmanager-backend-api</code>. In future modules we are going to include another container app which needs to access Cosmos DB.</li> </ul>"},{"location":"aca/04-aca-dapr-stateapi/#2-build-frontend-web-app-and-backend-api-app-images-and-push-them-to-acr","title":"2. Build Frontend Web App and Backend API App Images and Push Them to ACR","text":"<p>As we have done previously we need to build and deploy both app images to ACR, so they are ready to be deployed to Azure Container Apps.  To do so, continue using the same PowerShell console and paste the code below (Make sure you are on the following directory TasksTracker.ContainerApps):</p> <pre><code>az acr build --registry $ACR_NAME --image \"tasksmanager/$BACKEND_API_NAME\" --file 'TasksTracker.TasksManager.Backend.Api/Dockerfile' .\naz acr build --registry $ACR_NAME --image \"tasksmanager/$FRONTEND_WEBAPP_NAME\" --file 'TasksTracker.WebPortal.Frontend.Ui/Dockerfile' .\n</code></pre>"},{"location":"aca/04-aca-dapr-stateapi/#3-add-cosmos-db-dapr-state-store-to-azure-container-apps-environment","title":"3. Add Cosmos DB Dapr State Store to Azure Container Apps Environment","text":"<p>We need to run the command below to add the yaml file <code>.\\aca-components\\containerapps-statestore-cosmos.yaml</code> to Azure Container Apps Environment.</p> <pre><code>az containerapp env dapr-component set `\n--name $ENVIRONMENT --resource-group $RESOURCE_GROUP `\n--dapr-component-name statestore `\n--yaml '.\\aca-components\\containerapps-statestore-cosmos.yaml'\n</code></pre>"},{"location":"aca/04-aca-dapr-stateapi/#4-enable-dapr-for-the-frontend-web-app-and-backend-api-container-apps","title":"4. Enable Dapr for the Frontend Web App and Backend API Container Apps","text":"<p>Until this moment Dapr was not enabled on the Container Apps we have provisioned. Enable Dapr for both Container Apps by running the two commands below in the PowerShell console. </p> <p>Info</p> <p>Remember to replace the placeholders with your own values</p> <pre><code>az containerapp dapr enable --name $BACKEND_API_NAME `\n--resource-group $RESOURCE_GROUP `\n--dapr-app-id  $BACKEND_API_NAME `\n--dapr-app-port  &lt;web api application port number found under Dockerfile for the web api project. e.g. 5160&gt;\naz containerapp dapr enable --name $FRONTEND_WEBAPP_NAME `\n--resource-group $RESOURCE_GROUP `\n--dapr-app-id  $FRONTEND_WEBAPP_NAME `\n--dapr-app-port  &lt;front end web application port number found under Dockerfile for the web api project. e.g. 5071&gt;\n</code></pre> Curious to learn more about the command above? <ul> <li>We've enabled Dapr on both container apps and specified a unique Dapr identifier for the Back End API and Front End Web App container apps. This <code>dapr-app-id</code> will be used for service discovery, state encapsulation and the pub/sub consumer ID.</li> <li>We've set the <code>dapr-app-port</code> which is the port our applications are listening on which will be used by Dapr for communicating to our applications.</li> </ul> <p>For a complete list of the supported Dapr sidecar configurations in Container Apps, you can refer to this link.</p>"},{"location":"aca/04-aca-dapr-stateapi/#5-deploy-new-revisions-of-the-frontend-web-app-and-backend-api-to-container-apps","title":"5. Deploy New Revisions of the Frontend Web App and Backend API to Container Apps","text":"<p>The last thing we need to do here is to update both container apps and deploy the new images from ACR. To do so we need to run the commands found below. </p> <pre><code>## Update Frontend web app container app and create a new revision \naz containerapp update `\n--name $FRONTEND_WEBAPP_NAME  `\n--resource-group $RESOURCE_GROUP `\n--revision-suffix v20230218\n## Update Backend API App container app and create a new revision \naz containerapp update `\n--name $BACKEND_API_NAME  `\n--resource-group $RESOURCE_GROUP `\n--revision-suffix v20230218-1\n</code></pre> <p>Tip</p> <p>Notice here that we used a <code>revision-suffix</code> property, so it will append to the revision name which offers you better visibility on which revision you are looking at.</p> <p>Success</p> <p>With this final step, we should be able to access the Frontend Web App, call the backend API app using Dapr sidecar, and store tasks to Azure Cosmos DB.</p> <p>In the next module, we will introduce the Dapr Pub/Sub Building block which we will publish messages to Azure Service Bus when a task is saved. We will also introduce a new background service will process those incoming messages and send an email to the task assignee.</p>"},{"location":"aca/05-aca-dapr-pubsubapi/","title":"Module 5 - ACA Async Communication with Dapr Pub/Sub API","text":"<p>Module Duration</p> <p>90 minutes</p> <p>In this module, we will introduce a new background service which is named <code>ACA-Processer Backend</code> according to our architecture diagram. This new service will be responsible for sending notification emails (simulated) to the task owners to notify them that a new task has been assigned to them. We can do this in the Backend API and send the email right after saving the task, but we want to offload this process to another service and keep the Backend API service responsible for managing tasks data only.</p> <p>As a best practice, it is recommended that we decouple the two services from each other. So this means we are going to rely on the Publisher-Subscriber pattern (Pub/Sub Pattern). The main advantage of this pattern is that it offers loose coupling between services, where the sender/publisher of the message doesn't know anything about the receiver/consumers.  You can even have multiple consumers consuming a copy of the message in a totally different way. You can imagine adding another consumer which is responsible to send push notification for the  task owner (e.g. if we had a mobile app channel).</p> <p>The publisher/subscriber pattern relies on a message broker which is responsible for receiving the message from the publisher, storing the message to ensure durability, and delivering this message to the interested  consumer(s) to process it. There is no need for the consumers to be available when the message is stored in the message broker. Consumers can process the messages at a later time in an async fashion.  The below diagram gives a high-level overview of how the pub/sub pattern works:</p> <p></p> <p>If you implemented the Pub/Sub pattern before, you already know that there is a lot of plumbing needed on the publisher and subscriber components in order to publish and consume messages.  In addition, each message broker has its own SDK and implementation. So you need to write your code in an abstracted way to hide the specific implementation details for each message broker SDK and make it easier  for the publisher and consumers to re-use this functionality. What Dapr offers here is a building block that significantly simplifies implementing pub/sub functionality.</p> <p>Put simply, the Dapr pub/sub building block provides a platform-agnostic API framework to send and receive messages. Your producer/publisher services publish messages to a named topic.  Your consumer services subscribe to a topic to consume messages.</p> <p>To try this out we can directly invoke the Pub/Sub API and publish a message to Redis locally. If you remember from module 3 once we initialized Dapr in a  local development environment, it installed Redis container instance locally. So we can use Redis locally to publish and subscribe to a message.  If you navigate to the path <code>%USERPROFILE%\\.dapr\\components (assuming you are using windows)</code> you will find a file named <code>pubsub.yaml</code>. Inside this file, you will see the properties needed to access the local Redis instance.  The publisher/subscriber brokers template component file structure can be found here.</p> <p>We want to have more control and provide our own component file, so let's create pub/sub component file in our components folder as shown below:</p> dapr-pubsub-redis.yaml <pre><code>apiVersion: dapr.io/v1alpha1\nkind: Component\nmetadata:\nname: taskspubsub\nspec:\ntype: pubsub.redis\nversion: v1\nmetadata:\n- name: redisHost\nvalue: localhost:6379\n- name: redisPassword\nvalue: \"\"\n</code></pre> <p>To try out the Pub/Sub API, run the Backend API from VS Code by running the below command or using the Run and Debug tasks we have created in the appendix. </p> <p>Note</p> <p>Don't forget to include the property <code>--resources-path</code>.  Remember to replace the placeholders with your own values</p> .NET 6 or below.NET 7 or above <pre><code>~\\TasksTracker.ContainerApps\\TasksTracker.TasksManager.Backend.Api&gt; dapr run --app-id tasksmanager-backend-api --app-port &lt;web api application https port number found under properties-&gt;launchSettings.json. e.g. 7112&gt; --dapr-http-port 3500 --app-ssl --resources-path \"../components\" -- dotnet run\n</code></pre> <pre><code>~\\TasksTracker.ContainerApps\\TasksTracker.TasksManager.Backend.Api&gt; dapr run --app-id tasksmanager-backend-api --app-port &lt;web api application https port number found under properties-&gt;launchSettings.json. e.g. 7112&gt; --dapr-http-port 3500 --app-ssl --resources-path \"../components\" -- dotnet run --launch-profile https\n</code></pre> <p>Now let's try to publish a message by sending a POST request to http://localhost:3500/v1.0/publish/taskspubsub/tasksavedtopic with the below request body,  don't forget to set the <code>Content-Type</code> header to <code>application/json</code></p> <pre><code>{\n\"taskId\": \"fbc55b2c-d9fa-405e-aec8-22e53f4306dd\",\n\"taskName\": \"Testing Pub Sub Publisher\",\n\"taskCreatedBy\": \"user@mail.net\",\n\"taskCreatedOn\": \"2023-02-12T00:24:37.7361348Z\",\n\"taskDueDate\": \"2023-02-20T00:00:00\",\n\"taskAssignedTo\": \"user2@mail.com\"\n}\n</code></pre> Curious about the details of the endpoint <p>We can break endpoint into the following:</p> <ul> <li>The value <code>3500</code>: is the Dapr app listing port, it is the port number upon which the Dapr sidecar is listening.</li> <li>The value <code>taskspubsub</code>: is the name of the selected Dapr pub/sub-component.</li> <li>The value <code>tasksavedtopic</code>: is the name of the topic to which the message is published.</li> </ul> <p>If all is configured correctly, you should receive HTTP response 204 from this endpoint which indicates that the message is published successfully by the service broker (Redis) into the topic named <code>tasksavedtopic</code>. You can also check that topic is created successfully by using the Redis Xplorer extension in VS Code which should look like this:</p> <p></p> <p>Right now those published messages are stored in the message broker topic doing nothing as we don't have any subscribers bound to the service broker on the topic <code>tasksavedtopic</code> which are interested in consuming and processing those messages. So let`s add a consumer to consume the message.</p> <p>Note</p> <p>Some Service Brokers allow the creation of topics automatically when sending a message to a topic which has not been created before. That's the reason why the topic <code>tasksavedtopic</code> was created automatically  here for us.</p>"},{"location":"aca/05-aca-dapr-pubsubapi/#setting-up-the-backend-background-processor-project","title":"Setting up the Backend Background Processor Project","text":""},{"location":"aca/05-aca-dapr-pubsubapi/#1-create-the-backend-service-project","title":"1. Create the Backend Service Project","text":"<p>Now we will add a new ASP.NET Core Web API project named TasksTracker.Processor.Backend.Svc. Open a command-line terminal and navigate to root folder of your project.</p> <pre><code>dotnet new webapi -o TasksTracker.Processor.Backend.Svc\n</code></pre> <p>We need to containerize this application, so we can push it to Azure Container Registry as a docker image then deploy it to ACA.  To do so Open the VS Code Command Palette (Ctrl+Shift+P) and select Docker: Add Docker Files to Workspace...</p> <ul> <li>Use <code>.NET: ASP.NET Core</code> when prompted for application platform.</li> <li>Choose <code>Linux</code> when prompted to choose the operating system.</li> <li>You will be asked if you want to add Docker Compose files. Select <code>No</code>.</li> <li>Take a note of the provided application port as we will be using later on. You can always find it again inside the designated <code>DockerFile</code> inside the newly created project's directory.</li> <li><code>Dockerfile</code> and <code>.dockerignore</code> files are added to the workspace.</li> </ul>"},{"location":"aca/05-aca-dapr-pubsubapi/#2-add-models","title":"2. Add Models","text":"<p>Now we will add the model which will be used to deserialize the published message. Add below file under new folder named Models.</p> TaskModel.cs <pre><code>namespace TasksTracker.Processor.Backend.Svc.Models\n{\npublic class TaskModel\n{\npublic Guid TaskId { get; set; }\npublic string TaskName { get; set; } = string.Empty;\npublic string TaskCreatedBy { get; set; } = string.Empty;\npublic DateTime TaskCreatedOn { get; set; }\npublic DateTime TaskDueDate { get; set; }\npublic string TaskAssignedTo { get; set; } = string.Empty;\npublic bool IsCompleted { get; set; }\npublic bool IsOverDue { get; set; }\n}\n}\n</code></pre> <p>Tip</p> <p>For sake of simplicity we are recreating the same model <code>TaskModel.cs</code> under each project. For production purposes it is recommended to  place the <code>TaskModel.cs</code> in a common project that can be referenced by all the projects and thus avoid code repetition which increases the  maintenance cost.</p>"},{"location":"aca/05-aca-dapr-pubsubapi/#3install-dapr-sdk-client-nuget-package","title":"3.Install Dapr SDK Client NuGet package","text":"<p>Now we will install Dapr SDK to be able to subscribe to the service broker topic in a programmatic way. To do so, add the highlighted NuGet package to the file shown below:</p> TasksTracker.Processor.Backend.Svc.csproj <pre><code>&lt;ItemGroup&gt; &lt;PackageReference Include=\"Dapr.AspNetCore\" Version=\"1.9.0\" /&gt; &lt;/ItemGroup&gt;\n</code></pre>"},{"location":"aca/05-aca-dapr-pubsubapi/#4-create-an-api-endpoint-for-the-consumer-to-subscribe-to-the-topic","title":"4. Create an API Endpoint for the Consumer to Subscribe to the Topic","text":"<p>Now we will add an endpoint that will be responsible to subscribe to the topic in the message broker we are interested in. This endpoint will start receiving the message published from the Backend API producer. To do so, add a new controller under Controllers folder.</p> TasksNotifierController.cs <pre><code>using Dapr.Client;\nusing Microsoft.AspNetCore.Mvc;\nusing SendGrid;\nusing SendGrid.Helpers.Mail;\nusing TasksTracker.Processor.Backend.Svc.Models;\nnamespace TasksTracker.Processor.Backend.Svc.Controllers\n{\n[Route(\"api/tasksnotifier\")]\n[ApiController]\npublic class TasksNotifierController : ControllerBase\n{\nprivate readonly IConfiguration _config;\nprivate readonly ILogger _logger;\nprivate readonly DaprClient _daprClient;\npublic TasksNotifierController(IConfiguration config, ILogger&lt;TasksNotifierController&gt; logger, DaprClient daprClient)\n{\n_config = config;\n_logger = logger;\n_daprClient = daprClient;\n}\n[Dapr.Topic(\"dapr-pubsub-servicebus\", \"tasksavedtopic\")]\n[HttpPost(\"tasksaved\")]\npublic async Task&lt;IActionResult&gt; TaskSaved([FromBody] TaskModel taskModel)\n{\n_logger.LogInformation(\"Started processing message with Task Name '{0}'\", taskModel.TaskName);\nvar sendGridResponse = await SendEmail(taskModel);\nif (sendGridResponse.Item1)\n{\nreturn Ok($\"SendGrid response staus code: {sendGridResponse.Item1}\");\n}\nreturn BadRequest($\"Failed to send email, SendGrid response status code: {sendGridResponse.Item1}\");\n}\nprivate async Task&lt;Tuple&lt;bool, string&gt;&gt; SendEmail(TaskModel taskModel)\n{\nvar apiKey = _config.GetValue&lt;string&gt;(\"SendGrid:ApiKey\");\nvar sendEmailResponse = true;\nvar sendEmailStatusCode = System.Net.HttpStatusCode.Accepted;\nvar client = new SendGridClient(apiKey);\nvar from = new EmailAddress(\"taiseer.joudeh@gmail.com\", \"Tasks Tracker Notification\");\nvar subject = $\"Task '{taskModel.TaskName}' is assigned to you!\";\nvar to = new EmailAddress(taskModel.TaskAssignedTo, taskModel.TaskAssignedTo);\nvar plainTextContent = $\"Task '{taskModel.TaskName}' is assigned to you. Task should be completed by the end of: {taskModel.TaskDueDate.ToString(\"dd/MM/yyyy\")}\";\nvar htmlContent = plainTextContent;\nvar msg = MailHelper.CreateSingleEmail(from, to, subject, plainTextContent, htmlContent);\nvar response = await client.SendEmailAsync(msg);\nsendEmailResponse = response.IsSuccessStatusCode;\nsendEmailStatusCode = response.StatusCode;\nreturn new Tuple&lt;bool, string&gt;(sendEmailResponse, sendEmailStatusCode.ToString());\n}\n}\n}\n</code></pre> Curious about what we have done so far <ul> <li>We have added an action method named <code>TaskSaved</code> which can be accessed on the route <code>api/tasksnotifier/tasksaved</code></li> <li>We have attributed this action method with the attribute <code>Dapr.Topic</code> which accepts the Dapr pub/sub component to target as the first argument,  and the second argument is the topic to subscribe to, which in our case is <code>tasksavedtopic</code>.</li> <li>The action method expects to receive a <code>TaskModel</code> object.</li> <li>Now once the message is received by this endpoint, we can start out the business logic to trigger sending an email (more about this next) and then return <code>200 OK</code> response to indicate that the consumer  processed the message successfully and the broker can delete this message.</li> <li>If anything went wrong during sending the email (i.e. Email service not responding) and we want to retry processing this message at a later time, we return <code>400 Bad Request</code>,  which will inform the message broker that the message needs to be retired based on the configuration in the message broker.</li> <li>If we need to drop the message as we are aware it will not be processed even after retries (i.e Email to is not formatted correctly) we return a <code>404 Not Found</code> response.  This will tell the message broker to drop the message and move it to dead-letter or poison queue.</li> </ul> <p>Now you are probably wondering how the consumer was able to identify what are the subscriptions available and on which route they can be found at.  The answer for this is that at startup on the consumer service (more on that below after we add app.MapSubscribeHandler()), the Dapr runtime will call the application on a well-known endpoint to identify and create  the required subscriptions. </p> <p>The well-known endpoint can be reached on this endpoint: <code>http://localhost:&lt;appPort&gt;/dapr/subscribe</code>. When you invoke this endpoint, the response will contain an array of all available topics for which the  applications will subscribe. Each includes a route to call when the topic receives a message. This was generated as we used the attribute <code>Dapr.Topic</code> on the action method <code>api/tasksnotifier/tasksaved</code>. </p> <p>That means when a message is published on the PubSubname <code>taskspubsub</code> on the topic <code>tasksavedtopic</code>, it will be routed to the action method <code>/api/tasksnotifier/tasksaved</code> and will be consumed in this action method.</p> <p>In our case, a sample response will be as follows:</p> <pre><code>[\n{\n\"pubsubname\": \"taskspubsub\",\n\"topic\": \"tasksavedtopic\",\n\"route\": \"/api/tasksnotifier/tasksaved\"\n}\n]\n</code></pre> <p>Tip</p> <p>Follow this link to find a detailed diagram of how the consumers will discover and subscribe to those endpoints.</p>"},{"location":"aca/05-aca-dapr-pubsubapi/#5-register-dapr-and-subscribe-handler-at-the-consumer-startup","title":"5. Register Dapr and Subscribe Handler at the Consumer Startup","text":"<p>Update below file in TasksTracker.Processor.Backend.Svc project.</p> Program.cs <pre><code>namespace TasksTracker.Processor.Backend.Svc\n{\npublic class Program\n{\npublic static void Main(string[] args)\n{\nvar builder = WebApplication.CreateBuilder(args);\n// Add services to the container.\nbuilder.Services.AddControllers().AddDapr();\nvar app = builder.Build();\napp.UseHttpsRedirection();\napp.UseAuthorization();\napp.UseCloudEvents();\napp.MapControllers();\napp.MapSubscribeHandler();\napp.Run();\n}\n}\n}\n</code></pre> Curious about the code above? <ul> <li>On line <code>builder.Services.AddControllers().AddDapr();</code>, the extension method <code>AddDapr</code> registers the necessary services to integrate Dapr into the MVC pipeline.  It also registers a <code>DaprClient</code> instance into the dependency injection container, which then can be injected anywhere into your service. We will see how we are injecting DaprClient in the controller constructor later on.</li> <li>On line <code>app.UseCloudEvents();</code>, the extension method <code>UseCloudEvents</code> adds CloudEvents middleware into the ASP.NET Core middleware pipeline.  This middleware will unwrap requests that use the CloudEvents structured format, so the receiving method can read the event payload directly.  You can read more about CloudEvents here which includes specs for describing event data in a common and standard way.</li> <li>On line <code>app.MapSubscribeHandler();</code>, we make the endpoint <code>http://localhost:&lt;appPort&gt;/dapr/subscribe</code> available for the consumer so it responds and returns available subscriptions.  When this endpoint is called, it will automatically find all WebAPI action methods decorated with the <code>Dapr.Topic</code> attribute and instruct Dapr to create subscriptions for them.</li> </ul> <p>With all those bits in place, we are ready to run the publisher service <code>Backend API</code> and the consumer service <code>Backend Background Service</code> and test pub/sub pattern end to end. </p> <p>To do so, run the below commands in PowerShell console, ensure you are on the right root folder of each respective project. </p> <p>Info</p> <p>Remember to replace the placeholders with your own values.</p> .NET 6 or below.NET 7 or above <pre><code>~\\TasksTracker.ContainerApps\\TasksTracker.TasksManager.Backend.Api&gt; dapr run --app-id tasksmanager-backend-api --app-port &lt;web api application https port number found under properties-&gt;launchSettings.json. e.g. 7112&gt; --dapr-http-port 3500 --app-ssl --resources-path \"../components\" dotnet run \n~\\TasksTracker.ContainerApps\\TasksTracker.Processor.Backend.Svc&gt; dapr run --app-id tasksmanager-backend-processor --app-port &lt;backend service application https port number found under properties-&gt;launchSettings.json. e.g. 7051&gt; --dapr-http-port 3502 --app-ssl --resources-path \"../components\" dotnet run\n</code></pre> <pre><code>~\\TasksTracker.ContainerApps\\TasksTracker.TasksManager.Backend.Api&gt; dapr run --app-id tasksmanager-backend-api --app-port &lt;web api application https port number found under properties-&gt;launchSettings.json. e.g. 7112&gt; --dapr-http-port 3500 --app-ssl --resources-path \"../components\" -- dotnet run --launch-profile https\n~\\TasksTracker.ContainerApps\\TasksTracker.Processor.Backend.Svc&gt; dapr run --app-id tasksmanager-backend-processor --app-port &lt;backend service application https port number found under properties-&gt;launchSettings.json. e.g. 7051&gt; --dapr-http-port 3502 --app-ssl --resources-path \"../components\" -- dotnet run --launch-profile https\n</code></pre> <p>Note</p> <p>Notice that we gave the new Backend background service a Dapr App Id with the name <code>tasksmanager-backend-processor</code> and a Dapr HTTP port with the value <code>3502</code>.</p> <p>Now let's try to publish a message by sending a POST request to http://localhost:3500/v1.0/publish/taskspubsub/tasksavedtopic with the below request body,  don't forget to set the <code>Content-Type</code> header to <code>application/json</code></p> <pre><code>POST /v1.0/publish/taskspubsub/tasksavedtopic HTTP/1.1\nHost: localhost:3500\nContent-Type: application/json\n{\n\"taskId\": \"fbc55b2c-d9fa-405e-aec8-22e53f4306dd\",\n\"taskName\": \"Testing Pub Sub Publisher\",\n\"taskCreatedBy\": \"user@mail.net\",\n\"taskCreatedOn\": \"2023-02-12T00:24:37.7361348Z\",\n\"taskDueDate\": \"2023-02-20T00:00:00\",\n\"taskAssignedTo\": \"user2@mail.com\"\n}\n</code></pre> <p>Keep an eye on the terminal logs of the Backend background processor as you will see that the message is received and consumed by the action method <code>api/tasksnotifier/tasksaved</code> and an information message is logged  in the terminal to indicate the processing of the message.</p> VS Code Dapr Extension <p>You can use the VS Code Dapr Extension to publish the message directly. It will be similar to the below image:</p> <p></p>"},{"location":"aca/05-aca-dapr-pubsubapi/#6-optional-update-vs-code-tasks-and-launch-configuration-files","title":"6. Optional: Update VS Code Tasks and Launch Configuration Files","text":"<p>If you have followed the steps in the appendix so far in order to be able to run the three services together (frontend, backend api, and backend processor)  and debug them in VS Code, we need to update the files <code>tasks.json</code> and <code>launch.json</code> to include the new service we have added. </p> Click to expand the files to update <p>You can use the below files to update the existing ones.</p> tasks.jsonlaunch.json <pre><code>{\n\"version\": \"2.0.0\",\n\"tasks\": [\n{\n\"label\": \"build-backend-api\",\n\"command\": \"dotnet\",\n\"type\": \"process\",\n\"args\": [\n\"build\",\n\"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api/TasksTracker.TasksManager.Backend.Api.csproj\",\n\"/property:GenerateFullPaths=true\",\n\"/consoleloggerparameters:NoSummary\"\n],\n\"problemMatcher\": \"$msCompile\"\n},\n{\n\"label\": \"publish-backend-api\",\n\"command\": \"dotnet\",\n\"type\": \"process\",\n\"args\": [\n\"publish\",\n\"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api/TasksTracker.TasksManager.Backend.Api.csproj\",\n\"/property:GenerateFullPaths=true\",\n\"/consoleloggerparameters:NoSummary\"\n],\n\"problemMatcher\": \"$msCompile\"\n},\n{\n\"label\": \"watch-backend-api\",\n\"command\": \"dotnet\",\n\"type\": \"process\",\n\"args\": [\n\"watch\",\n\"run\",\n\"--project\",\n\"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api/TasksTracker.TasksManager.Backend.Api.csproj\"\n],\n\"problemMatcher\": \"$msCompile\"\n},\n{\n\"label\": \"build-webapp-ui\",\n\"command\": \"dotnet\",\n\"type\": \"process\",\n\"args\": [\n\"build\",\n\"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui/TasksTracker.WebPortal.Frontend.Ui.csproj\",\n\"/property:GenerateFullPaths=true\",\n\"/consoleloggerparameters:NoSummary\"\n],\n\"problemMatcher\": \"$msCompile\"\n},\n{\n\"label\": \"publish-webapp-ui\",\n\"command\": \"dotnet\",\n\"type\": \"process\",\n\"args\": [\n\"publish\",\n\"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui/TasksTracker.WebPortal.Frontend.Ui.csproj\",\n\"/property:GenerateFullPaths=true\",\n\"/consoleloggerparameters:NoSummary\"\n],\n\"problemMatcher\": \"$msCompile\"\n},\n{\n\"label\": \"watch-webapp-ui\",\n\"command\": \"dotnet\",\n\"type\": \"process\",\n\"args\": [\n\"watch\",\n\"run\",\n\"--project\",\n\"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui/TasksTracker.WebPortal.Frontend.Ui.csproj\"\n],\n\"problemMatcher\": \"$msCompile\"\n},\n{\n\"label\": \"build-processor-svc\",\n\"command\": \"dotnet\",\n\"type\": \"process\",\n\"args\": [\n\"build\",\n\"${workspaceFolder}/TasksTracker.Processor.Backend.Svc/TasksTracker.Processor.Backend.Svc.csproj\",\n\"/property:GenerateFullPaths=true\",\n\"/consoleloggerparameters:NoSummary\"\n],\n\"problemMatcher\": \"$msCompile\"\n},\n{\n\"label\": \"publish-processor-svc\",\n\"command\": \"dotnet\",\n\"type\": \"process\",\n\"args\": [\n\"publish\",\n\"${workspaceFolder}/TasksTracker.Processor.Backend.Svc/TasksTracker.Processor.Backend.Svc.csproj\",\n\"/property:GenerateFullPaths=true\",\n\"/consoleloggerparameters:NoSummary\"\n],\n\"problemMatcher\": \"$msCompile\"\n},\n{\n\"label\": \"watch-processor-svc\",\n\"command\": \"dotnet\",\n\"type\": \"process\",\n\"args\": [\n\"watch\",\n\"run\",\n\"--project\",\n\"${workspaceFolder}/TasksTracker.Processor.Backend.Svc/TasksTracker.Processor.Backend.Svc.csproj\"\n],\n\"problemMatcher\": \"$msCompile\"\n},\n{\n\"label\": \"build-all\",\n\"dependsOn\": [\n\"build-backend-api\",\n\"build-webapp-ui\",\n\"build-processor-svc\"\n],\n\"problemMatcher\": [],\n\"group\": {\n\"kind\": \"build\",\n\"isDefault\": true\n}\n},\n{\n\"appId\": \"tasksmanager-backend-api\",\n\"appPort\": 7088,\n\"httpPort\": 3500,\n\"grpcPort\": 50001,\n\"appSsl\": true,\n\"label\": \"backend-api-dapr-debug\",\n\"type\": \"dapr\",\n\"dependsOn\": \"build-backend-api\",\n\"componentsPath\": \"./components\"\n},\n{\n\"appId\": \"tasksmanager-backend-api\",\n\"label\": \"daprd-down-backend-api\",\n\"type\": \"daprd-down\"\n},\n{\n\"appId\": \"tasksmanager-frontend-webapp\",\n\"appPort\": 7208,\n\"httpPort\": 3501,\n\"grpcPort\": 50002,\n\"appSsl\": true,\n\"label\": \"webapp-ui-dapr-debug\",\n\"type\": \"dapr\",\n\"dependsOn\": \"build-webapp-ui\"\n},\n{\n\"appId\": \"tasksmanager-frontend-webapp\",\n\"label\": \"webapp-ui-daprd-down\",\n\"type\": \"daprd-down\"\n},\n{\n\"appId\": \"tasksmanager-backend-processor\",\n\"appPort\": 7263,\n\"httpPort\": 3502,\n\"grpcPort\": 50003,\n\"appSsl\": true,\n\"label\": \"processor-svc-dapr-debug\",\n\"type\": \"dapr\",\n\"dependsOn\": \"build-processor-svc\",\n\"componentsPath\": \"./components\"\n},\n{\n\"appId\": \"tasksmanager-backend-processor\",\n\"label\": \"processor-svc-daprd-down\",\n\"type\": \"daprd-down\"\n}\n]\n}\n</code></pre> <pre><code>{\n\"version\": \"0.2.0\",\n\"configurations\": [\n{\n\"name\": \"Launch (web app)\",\n\"type\": \"coreclr\",\n\"request\": \"launch\",\n\"preLaunchTask\": \"build-backend-api\",\n\"program\": \"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui/bin/Debug/net6.0/TasksTracker.WebPortal.Frontend.Ui.dll\",\n\"args\": [],\n\"cwd\": \"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui\",\n\"stopAtEntry\": false,\n\"serverReadyAction\": {\n\"action\": \"openExternally\",\n\"pattern\": \"\\\\bNow listening on:\\\\s+(https?://\\\\S+)\"\n},\n\"env\": {\n\"ASPNETCORE_ENVIRONMENT\": \"Development\"\n},\n\"sourceFileMap\": {\n\"/Views\": \"${workspaceFolder}/Views\"\n}\n},\n{\n\"name\": \"Launch (backend api)\",\n\"type\": \"coreclr\",\n\"request\": \"launch\",\n\"preLaunchTask\": \"build-webapp-ui\",\n\"program\": \"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api/bin/Debug/net6.0/TasksTracker.TasksManager.Backend.Api.dll\",\n\"args\": [],\n\"cwd\": \"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api\",\n\"stopAtEntry\": false,\n\"serverReadyAction\": {\n\"action\": \"openExternally\",\n\"pattern\": \"\\\\bNow listening on:\\\\s+(https?://\\\\S+)\"\n},\n\"env\": {\n\"ASPNETCORE_ENVIRONMENT\": \"Development\"\n},\n\"sourceFileMap\": {\n\"/Views\": \"${workspaceFolder}/Views\"\n}\n},\n{\n\"name\": \"Launch (background processor)\",\n\"type\": \"coreclr\",\n\"request\": \"launch\",\n\"preLaunchTask\": \"build-processor-svc\",\n\"program\": \"${workspaceFolder}/TasksTracker.Processor.Backend.Svc/bin/Debug/net6.0/TasksTracker.Processor.Backend.Svc.dll\",\n\"args\": [],\n\"cwd\": \"${workspaceFolder}/TasksTracker.Processor.Backend.Svc\",\n\"stopAtEntry\": false,\n\"serverReadyAction\": {\n\"action\": \"openExternally\",\n\"pattern\": \"\\\\bNow listening on:\\\\s+(https?://\\\\S+)\"\n},\n\"env\": {\n\"ASPNETCORE_ENVIRONMENT\": \"Development\"\n},\n\"sourceFileMap\": {\n\"/Views\": \"${workspaceFolder}/Views\"\n}\n},\n{\n\"name\": \".NET Core Attach\",\n\"type\": \"coreclr\",\n\"request\": \"attach\"\n},\n{\n\"name\": \"Launch (backend api) with Dapr\",\n\"type\": \"coreclr\",\n\"request\": \"launch\",\n\"preLaunchTask\": \"backend-api-dapr-debug\",\n\"program\": \"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api/bin/Debug/net6.0/TasksTracker.TasksManager.Backend.Api.dll\",\n\"args\": [],\n\"cwd\": \"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api\",\n\"stopAtEntry\": false,\n\"serverReadyAction\": {\n\"action\": \"openExternally\",\n\"pattern\": \"\\\\bNow listening on:\\\\s+(https?://\\\\S+)\"\n},\n\"env\": {\n\"ASPNETCORE_ENVIRONMENT\": \"Development\"\n},\n\"sourceFileMap\": {\n\"/Views\": \"${workspaceFolder}/Views\"\n},\n\"postDebugTask\": \"daprd-down-backend-api\"\n},\n{\n\"name\": \"Launch (web app) with Dapr\",\n\"type\": \"coreclr\",\n\"request\": \"launch\",\n\"preLaunchTask\": \"webapp-ui-dapr-debug\",\n\"program\": \"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui/bin/Debug/net6.0/TasksTracker.WebPortal.Frontend.Ui.dll\",\n\"args\": [],\n\"cwd\": \"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui\",\n\"stopAtEntry\": false,\n\"serverReadyAction\": {\n\"action\": \"openExternally\",\n\"pattern\": \"\\\\bNow listening on:\\\\s+(https?://\\\\S+)\"\n},\n\"env\": {\n\"ASPNETCORE_ENVIRONMENT\": \"Development\"\n},\n\"sourceFileMap\": {\n\"/Views\": \"${workspaceFolder}/Views\"\n},\n\"postDebugTask\": \"webapp-ui-daprd-down\"\n},\n{\n\"name\": \"Launch (background processor) with Dapr\",\n\"type\": \"coreclr\",\n\"request\": \"launch\",\n\"preLaunchTask\": \"processor-svc-dapr-debug\",\n\"program\": \"${workspaceFolder}/TasksTracker.Processor.Backend.Svc/bin/Debug/net6.0/TasksTracker.Processor.Backend.Svc.dll\",\n\"args\": [],\n\"cwd\": \"${workspaceFolder}/TasksTracker.Processor.Backend.Svc\",\n\"stopAtEntry\": false,\n\"serverReadyAction\": {\n\"action\": \"openExternally\",\n\"pattern\": \"\\\\bNow listening on:\\\\s+(https?://\\\\S+)\"\n},\n\"env\": {\n\"ASPNETCORE_ENVIRONMENT\": \"Development\"\n},\n\"sourceFileMap\": {\n\"/Views\": \"${workspaceFolder}/Views\"\n},\n\"postDebugTask\": \"processor-svc-daprd-down\"\n}\n],\n\"compounds\": [\n{\n\"name\": \"RunAll\",\n\"configurations\": [\"Launch (web app)\", \"Launch (backend api)\", \"Launch (background processor)\",],\n\"stopAll\": true\n},\n{\n\"name\": \"RunAll with Dapr\",\n\"configurations\": [ \"Launch (backend api) with Dapr\", \"Launch (web app) with Dapr\", \"Launch (background processor) with Dapr\", ],\n\"stopAll\": true\n}\n]\n}\n</code></pre>"},{"location":"aca/05-aca-dapr-pubsubapi/#use-the-dapr-net-client-sdk-to-publish-messages","title":"Use the Dapr .NET Client SDK to Publish Messages","text":""},{"location":"aca/05-aca-dapr-pubsubapi/#1-update-backend-api-to-publish-a-message-when-a-task-is-saved","title":"1. Update Backend API to Publish a Message When a Task Is Saved","text":"<p>Now we need to update our Backend API to publish a message to the message broker when a task is saved (either due to a new task being added or an existing task assignee being updated).</p> <p>To do this update below file under the project TasksTracker.TasksManager.Backend.Api and update the file as highlighted below:</p> TasksStoreManager.cs <pre><code>//Add new private method\nprivate async Task PublishTaskSavedEvent(TaskModel taskModel)\n{\n_logger.LogInformation(\"Publish Task Saved event for task with Id: '{0}' and Name: '{1}' for Assigne: '{2}'\",\ntaskModel.TaskId, taskModel.TaskName, taskModel.TaskAssignedTo);\nawait _daprClient.PublishEventAsync(\"dapr-pubsub-servicebus\", \"tasksavedtopic\", taskModel);\n}\n//Update the below method:\npublic async Task&lt;Guid&gt; CreateNewTask(string taskName, string createdBy, string assignedTo, DateTime dueDate)\n{\nvar taskModel = new TaskModel()\n{\nTaskId = Guid.NewGuid(),\nTaskName = taskName,\nTaskCreatedBy = createdBy,\nTaskCreatedOn = DateTime.UtcNow,\nTaskDueDate = dueDate,\nTaskAssignedTo = assignedTo,\n};\n_logger.LogInformation(\"Save a new task with name: '{0}' to state store\", taskModel.TaskName);\nawait _daprClient.SaveStateAsync&lt;TaskModel&gt;(STORE_NAME, taskModel.TaskId.ToString(), taskModel);\nawait PublishTaskSavedEvent(taskModel);\nreturn taskModel.TaskId;\n}\n//Update the below method:\npublic async Task&lt;bool&gt; UpdateTask(Guid taskId, string taskName, string assignedTo, DateTime dueDate)\n{\n_logger.LogInformation(\"Update task with Id: '{0}'\", taskId);\nvar taskModel = await _daprClient.GetStateAsync&lt;TaskModel&gt;(STORE_NAME, taskId.ToString());\nvar currentAssignee = taskModel.TaskAssignedTo;\nif (taskModel != null)\n{\ntaskModel.TaskName = taskName;\ntaskModel.TaskAssignedTo = assignedTo;\ntaskModel.TaskDueDate = dueDate;\nawait _daprClient.SaveStateAsync&lt;TaskModel&gt;(STORE_NAME, taskModel.TaskId.ToString(), taskModel);\nif (!taskModel.TaskAssignedTo.Equals(currentAssignee, StringComparison.OrdinalIgnoreCase))\n{\nawait PublishTaskSavedEvent(taskModel);\n}\nreturn true;\n}\nreturn false;\n}\n</code></pre> <p>Tip</p> <p>Notice the new method <code>PublishTaskSavedEvent</code> added to the class. All we have to do is to call the method <code>PublishTaskSavedEvent</code> and pass the Pub/Sub name. In our case we named it <code>dapr-pubsub-servicebus</code>  as we are going to use Azure Service Bus as a message broker in the next step. </p> <p>The second parameter <code>tasksavedtopic</code> is the topic name the publisher going to send the task model to. That's all the changes required to start publishing async messages from the Backend API.</p>"},{"location":"aca/05-aca-dapr-pubsubapi/#2-update-backend-background-processor-to-consume-messages-and-simulate-sending-emails","title":"2. Update Backend Background Processor to Consume Messages and Simulate Sending Emails","text":"<p>Update the files below under the Backend Processor Project. We are installing the NuGet package named <code>SendGrid</code> to the Backend processor project which will allow us to send emails. </p> TasksNotifierController.csTasksTracker.Processor.Backend.Svc.csprojappsettings.json <pre><code>using Dapr.Client;\nusing Microsoft.AspNetCore.Mvc;\nusing SendGrid;\nusing SendGrid.Helpers.Mail;\nusing TasksTracker.Processor.Backend.Svc.Models;\nnamespace TasksTracker.Processor.Backend.Svc.Controllers\n{\n[Route(\"api/tasksnotifier\")]\n[ApiController]\npublic class TasksNotifierController : ControllerBase\n{\nprivate readonly IConfiguration _config;\nprivate readonly ILogger _logger;\nprivate readonly DaprClient _daprClient;\npublic TasksNotifierController(IConfiguration config, ILogger&lt;TasksNotifierController&gt; logger, DaprClient daprClient)\n{\n_config = config;\n_logger = logger;\n_daprClient = daprClient;\n}\n[Dapr.Topic(\"dapr-pubsub-servicebus\", \"tasksavedtopic\")]\n[HttpPost(\"tasksaved\")]\npublic async Task&lt;IActionResult&gt; TaskSaved([FromBody] TaskModel taskModel)\n{\n_logger.LogInformation(\"Started processing message with Task Name '{0}'\", taskModel.TaskName);\nvar sendGridResponse = await SendEmail(taskModel);\nif (sendGridResponse.Item1)\n{\nreturn Ok($\"SendGrid response staus code: {sendGridResponse.Item1}\");\n}\nreturn BadRequest($\"Failed to send email, SendGrid response status code: {sendGridResponse.Item1}\");\n}\nprivate async Task&lt;Tuple&lt;bool, string&gt;&gt; SendEmail(TaskModel taskModel)\n{\nvar apiKey = _config.GetValue&lt;string&gt;(\"SendGrid:ApiKey\");\nvar sendEmailResponse = true;\nvar sendEmailStatusCode = System.Net.HttpStatusCode.Accepted;\nvar client = new SendGridClient(apiKey);\nvar from = new EmailAddress(\"taiseer.joudeh@gmail.com\", \"Tasks Tracker Notification\");\nvar subject = $\"Task '{taskModel.TaskName}' is assigned to you!\";\nvar to = new EmailAddress(taskModel.TaskAssignedTo, taskModel.TaskAssignedTo);\nvar plainTextContent = $\"Task '{taskModel.TaskName}' is assigned to you. Task should be completed by the end of: {taskModel.TaskDueDate.ToString(\"dd/MM/yyyy\")}\";\nvar htmlContent = plainTextContent;\nvar msg = MailHelper.CreateSingleEmail(from, to, subject, plainTextContent, htmlContent);\nvar response = await client.SendEmailAsync(msg);\nsendEmailResponse = response.IsSuccessStatusCode;\nsendEmailStatusCode = response.StatusCode;\nreturn new Tuple&lt;bool, string&gt;(sendEmailResponse, sendEmailStatusCode.ToString());\n}\n}\n}\n</code></pre> <pre><code>&lt;ItemGroup&gt; &lt;PackageReference Include=\"SendGrid\" Version=\"9.28.1\" /&gt;\n&lt;/ItemGroup&gt;\n</code></pre> <pre><code>  {\n\"SendGrid\": {\n\"ApiKey\": \"\",\n\"IntegrationEnabled\":false\n}\n}\n</code></pre> <p>Tip</p> <p>Follow this link to set up a SendGrid account. Also follow these instructions to fetch your  SendGrid ApiKey. </p> <p>Please note that the SendGrid API KEY is generated and displayed to you just once. So be sure to copy and save it somewhere. After that only the subset key is displayed.</p> <p>Tip</p> <p>In the next module we will be using a new type of Dapr components to send emails using SendGrid.</p> <p>If you don't want to bother with signing up for a SendGrid account to send emails, you can just simulate sending emails by returning always <code>ok</code> from the <code>TaskSaved</code> method as shown below. </p> <pre><code>// If you prefer not to deal with setting up a SendGrid account then simply always return OK from the TaskSaved method\n[Dapr.Topic(\"dapr-pubsub-servicebus\", \"tasksavedtopic\")]\n[HttpPost(\"tasksaved\")]\npublic async Task&lt;IActionResult&gt; TaskSaved([FromBody] TaskModel taskModel)\n{\n_logger.LogInformation(\"Started processing message with Task Name '{0}'\", taskModel.TaskName);\n// I decided to simulate a call\n//var sendGridResponse = await SendEmail(taskModel);\n//if (sendGridResponse.Item1)\n//{\nreturn Ok($\"SendGrid response status code: 200\");\n//}\n//return BadRequest($\"Failed to send email, SendGrid response status code: {sendGridResponse.Item1}\");\n}\n</code></pre> Curious to learn what's happening in the code above? <ul> <li>We've updated the attribute <code>Dapr.Topic</code> to use the same Pub/Sub component name used in the publisher <code>dapr-pubsub-servicebus</code>. Then we added a new method that is responsible to consume the received message,  taking the assignee email and trying to send an email using SendGrid API.</li> <li>We are returning <code>200 Ok</code> if the SendGrid was able to send the email successfully, otherwise we are returning <code>400 Bad Request</code> if the SendGrid failed to send the email. This will allow the consumer service to re-try processing the message again on failure.</li> <li>We are reading the <code>SendGrid:ApiKey</code> from AppSettings and later we will read this value from environment variables once we deploy this service to Azure Container Apps. </li> </ul>"},{"location":"aca/05-aca-dapr-pubsubapi/#use-azure-service-bus-as-a-service-broker-for-dapr-pubsub-api","title":"Use Azure Service Bus as a Service Broker for Dapr Pub/Sub API","text":"<p>Now we will switch our implementation to use Azure Service Bus as a message broker. Redis worked perfectly for local development and testing, but we need to prepare ourselves for the cloud deployment.  To do so we need to create Service Bus Namespace followed by a Topic. A namespace provides a scoping container for Service Bus resources within your application.</p>"},{"location":"aca/05-aca-dapr-pubsubapi/#1-create-azure-service-bus-namespace-and-a-topic","title":"1. Create Azure Service Bus Namespace and a Topic","text":"<p>You can do this from Azure Portal or use the below PowerShell command to create the services. We will assume you are using the same PowerShell session from the previous module so variables still hold the right values. You need to change the namespace variable as this one should be unique globally across all Azure subscriptions. Also, you will notice that we are opting for standard sku (default if not passed) as topics only  available on the standard tier not and not on the basic tier. More details can be found here.</p> <pre><code>$NamespaceName=\"[your globally unique namespace goes here. e.g. taskstracker-wk-42 where wk are your initials and 42 is the year you were born]\"\n$TopicName=\"tasksavedtopic\"\n$TopicSubscription=\"tasks-processor-subscription\"\n##Create servicebus namespace\naz servicebus namespace create --resource-group $RESOURCE_GROUP --name $NamespaceName --location $LOCATION --sku Standard\n##Create a topic under the namespace\naz servicebus topic create --resource-group $RESOURCE_GROUP --namespace-name $NamespaceName --name $TopicName\n##Create a topic subscription\naz servicebus topic subscription create `\n--resource-group $RESOURCE_GROUP `\n--namespace-name $NamespaceName `\n--topic-name $TopicName `\n--name $TopicSubscription\n##List connection string\naz servicebus namespace authorization-rule keys list `\n--resource-group $RESOURCE_GROUP `\n--namespace-name $NamespaceName `\n--name RootManageSharedAccessKey `\n--query primaryConnectionString `\n--output tsv\n</code></pre> <p>Note</p> <p>Primary connection string is only needed for local dev testing. We will be using Managed Identities when publishing container apps to ACA.</p>"},{"location":"aca/05-aca-dapr-pubsubapi/#2-create-a-local-dapr-component-file-for-pubsub-api-using-azure-service-bus","title":"2. Create a local Dapr Component file for Pub/Sub API Using Azure Service Bus","text":"<p>Add a new files components as shown below:</p> dapr-pubsub-svcbus.yaml<pre><code>apiVersion: dapr.io/v1alpha1\nkind: Component\nmetadata:\nname: dapr-pubsub-servicebus\nspec:\ntype: pubsub.azure.servicebus\nversion: v1\nmetadata:\n- name: connectionString # Used for local dev testing.\nvalue: \"&lt;connection string from step 1&gt;\"\n- name: consumerID\nvalue: \"tasks-processor-subscription\"\nscopes:\n- tasksmanager-backend-api\n- tasksmanager-backend-processor\n</code></pre> <p>Note</p> <p>We used the name <code>dapr-pubsub-servicebus</code> which should match the name of Pub/Sub component we've used earlier in the TasksNotifierController.cs  controller on the action method with the attribute <code>Topic</code>. </p> <p>We set the metadata (key/value) to allow us to connect to Azure Service Bus topic. The metadata <code>consumerID</code> value should match the topic subscription name <code>tasks-processor-subscription</code>. </p> <p>We have set the scopes section to include the <code>tasksmanager-backend-api</code> and <code>tasksmanager-backend-processor</code> app ids, as those will be the Dapr apps that need access to Azure Service Bus for publishing and  consuming the messages.</p>"},{"location":"aca/05-aca-dapr-pubsubapi/#3-create-an-aca-dapr-component-file-for-pubsub-api-using-azure-service-bus","title":"3. Create an ACA Dapr Component file for Pub/Sub API Using Azure Service Bus","text":"<p>Add a new files aca-components as shown below: </p> <p>Note</p> <p>Remember to replace the namespace placeholder with the unique global name you chose earlier</p> containerapps-pubsub-svcbus.yaml<pre><code># pubsub.yaml for Azure Service Bus component\ncomponentType: pubsub.azure.servicebus\nversion: v1\nmetadata:\n- name: namespaceName\nvalue: \"&lt;your globally unique namespace&gt;.servicebus.windows.net\"\n- name: consumerID\nvalue: \"tasks-processor-subscription\"\n# Application scopes\nscopes:\n- tasksmanager-backend-api\n- tasksmanager-backend-processor\n</code></pre> Things to note here <ul> <li>We didn't specify the component name <code>dapr-pubsub-servicebus</code> when we created this component file. We are going to specify it once we add this dapr component to Azure Container Apps Environment via CLI.</li> <li>We are not referencing any service bus connection strings as the authentication between Dapr and Azure Service Bus will be configured using Managed Identities. </li> <li>The metadata <code>namespaceName</code> value is set to the address of the Service Bus namespace as a fully qualified domain name. The <code>namespaceName</code> key is mandatory when using Managed Identities for authentication.</li> <li>We are setting the metadata <code>consumerID</code> value to match the topic subscription name <code>tasks-processor-subscription</code>. If you didn't set this metadata, dapr runtime will try to create a subscription using the   dapr application ID.</li> </ul> <p>With all those bits in place, we are ready to run the publisher service <code>Backend API</code> and the consumer service <code>Backend Background Service</code> and test pub/sub pattern end to end. </p> <p>Note</p> <p>Ensure you are on the right root folder of each respective project. Remember to replace the placeholders with your own values.</p> .NET 6 or below.NET 7 or above <pre><code>~\\TasksTracker.ContainerApps\\TasksTracker.TasksManager.Backend.Api&gt; dapr run --app-id tasksmanager-backend-api --app-port &lt;web api application https port number found under properties-&gt;launchSettings.json. e.g. 7112&gt; --dapr-http-port 3500 --app-ssl --resources-path \"../components\" dotnet run \n~\\TasksTracker.ContainerApps\\TasksTracker.Processor.Backend.Svc&gt; dapr run --app-id tasksmanager-backend-processor --app-port &lt;backend service application https port number found under properties-&gt;launchSettings.json. e.g. 7051&gt; --dapr-http-port 3502 --app-ssl --resources-path \"../components\" dotnet run\n</code></pre> <pre><code>~\\TasksTracker.ContainerApps\\TasksTracker.TasksManager.Backend.Api&gt; dapr run --app-id tasksmanager-backend-api --app-port &lt;web api application https port number found under properties-&gt;launchSettings.json. e.g. 7112&gt; --dapr-http-port 3500 --app-ssl --resources-path \"../components\" -- dotnet run --launch-profile https\n~\\TasksTracker.ContainerApps\\TasksTracker.Processor.Backend.Svc&gt; dapr run --app-id tasksmanager-backend-processor --app-port &lt;backend service application https port number found under properties-&gt;launchSettings.json. e.g. 7051&gt; --dapr-http-port 3502 --app-ssl --resources-path \"../components\" -- dotnet run --launch-profile https\n</code></pre> <p>Note</p> <p>We gave the new Backend background service a Dapr App Id with the name <code>tasksmanager-backend-processor</code> and a Dapr HTTP port with the value 3502.</p> <p>Now let's try to publish a message by sending a POST request to http://localhost:3500/v1.0/publish/dapr-pubsub-servicebus/tasksavedtopic with the below request body, don't forget to set the <code>Content-Type</code>  header to <code>application/json</code></p> <pre><code>POST /v1.0/publish/taskspubsub/tasksavedtopic HTTP/1.1\nHost: localhost:3500\nContent-Type: application/json\n{\n\"taskId\": \"fbc55b2c-d9fa-405e-aec8-22e53f4306dd\",\n\"taskName\": \"Testing Pub Sub Publisher\",\n\"taskCreatedBy\": \"user@mail.net\",\n\"taskCreatedOn\": \"2023-02-12T00:24:37.7361348Z\",\n\"taskDueDate\": \"2023-02-20T00:00:00\",\n\"taskAssignedTo\": \"user2@mail.com\"\n}\n</code></pre>"},{"location":"aca/05-aca-dapr-pubsubapi/#deploy-the-backend-background-processor-and-the-backend-api-projects-to-azure-container-apps","title":"Deploy the Backend Background Processor and the Backend API Projects to Azure Container Apps","text":""},{"location":"aca/05-aca-dapr-pubsubapi/#1-build-the-backend-background-processor-and-the-backend-api-app-images-and-push-them-to-acr","title":"1. Build the Backend Background Processor and the Backend API App Images and Push Them to ACR","text":"<p>As we have done previously we need to build and deploy both app images to ACR, so they are ready to be deployed to Azure Container Apps.</p> <p>Note</p> <p>Make sure you are in root directory of the project, i.e. TasksTracker.ContainerApps</p> <pre><code>$BACKEND_SVC_NAME=\"tasksmanager-backend-processor\"\naz acr build --registry $ACR_NAME --image \"tasksmanager/$BACKEND_API_NAME\" --file 'TasksTracker.TasksManager.Backend.Api/Dockerfile' . \naz acr build --registry $ACR_NAME --image \"tasksmanager/$BACKEND_SVC_NAME\" --file 'TasksTracker.Processor.Backend.Svc/Dockerfile' .\n</code></pre>"},{"location":"aca/05-aca-dapr-pubsubapi/#2-create-a-new-azure-container-app-to-host-the-new-backend-background-processor","title":"2. Create a new Azure Container App to host the new Backend Background Processor","text":"<p>Now we need to create a new Azure Container App. We need to have this new container app with those capabilities in place:</p> <ul> <li>Ingress for this container app should be disabled (no access via HTTP at all as this is a background processor responsible to process published messages).</li> <li>Dapr needs to be enabled.</li> <li>Optional (only if you activated your SendGrid account and received an api key. Otherwise, remove the <code>--secrets</code> and <code>--env-var</code> from the powershell command below).    Setting the value of SendGrid API in the secrets store and referencing it in the environment variables, as well setting the flag <code>IntegrationEnabled</code> to <code>true</code> so it will send actual emails.</li> </ul> <p>To achieve the above, run the PowerShell script below. </p> <p>Note</p> <p>Notice how we removed the Ingress property totally which disables the Ingress for this Container App. Remember to replace the placeholders with your own values:</p> <pre><code>az containerapp create `\n--name \"$BACKEND_SVC_NAME\"  `\n--resource-group $RESOURCE_GROUP `\n--environment $ENVIRONMENT `\n--image \"$ACR_NAME.azurecr.io/tasksmanager/$BACKEND_SVC_NAME\" `\n--registry-server \"$ACR_NAME.azurecr.io\" `\n--min-replicas 1 `\n--max-replicas 1 `\n--cpu 0.25 --memory 0.5Gi `\n--enable-dapr `\n--dapr-app-id  $BACKEND_SVC_NAME `\n--dapr-app-port  &lt;web api application port number found under Dockerfile for the web api project. e.g. 5071&gt; `\n#comment out these two lines if you are not using sendgrid\n--secrets \"sendgrid-apikey=&lt;Replace with your SendGrid API Key&gt;\" `\n--env-vars \"SendGrid__ApiKey=secretref:sendgrid-apikey\" \"SendGrid__IntegrationEnabled=true\"\n</code></pre>"},{"location":"aca/05-aca-dapr-pubsubapi/#3-deploy-new-revisions-of-the-backend-api-to-azure-container-apps","title":"3. Deploy New Revisions of the Backend API to Azure Container Apps","text":"<p>We need to update the Azure Container App hosting the Backend API with a new revision so our code changes for publishing messages after a task is saved is available for users. </p> <pre><code>## Update Backend API App container app and create a new revision \naz containerapp update `\n--name $BACKEND_API_NAME `\n--resource-group $RESOURCE_GROUP `\n--revision-suffix v20230220-1 \n</code></pre>"},{"location":"aca/05-aca-dapr-pubsubapi/#4-add-azure-service-bus-dapr-pubsub-component-to-azure-container-apps-environment","title":"4. Add Azure Service Bus Dapr Pub/Sub Component to Azure Container Apps Environment","text":"<p>Deploy the Dapr Pub/Sub Component to the Azure Container Apps Environment using the following command:</p> <pre><code>az containerapp env dapr-component set `\n--name $ENVIRONMENT --resource-group $RESOURCE_GROUP `\n--dapr-component-name dapr-pubsub-servicebus `\n--yaml '.\\aca-components\\containerapps-pubsub-svcbus.yaml'\n</code></pre> <p>Note</p> <p>Notice that we set the component name <code>dapr-pubsub-servicebus</code> when we added it to the Container Apps Environment.</p>"},{"location":"aca/05-aca-dapr-pubsubapi/#configure-managed-identities-for-both-container-apps","title":"Configure Managed Identities for Both Container Apps","text":"<p>In the previous module we have already configured and used system-assigned identity for the Backend API container app.  We follow the same steps here to create an association between the backend processor container app and Azure Service Bus.</p>"},{"location":"aca/05-aca-dapr-pubsubapi/#1-create-system-assigned-identity-for-backend-processor-app","title":"1. Create system-assigned identity for Backend Processor App","text":"<p>Run the command below to create <code>system-assigned</code> identity for our Backend Processor App:</p> <pre><code>az containerapp identity assign `\n--resource-group $RESOURCE_GROUP `\n--name $BACKEND_SVC_NAME `\n--system-assigned\n</code></pre> <p>This command will create an Enterprise Application (basically a Service Principal) within Azure AD, which is linked to our container app. The output of this command will be as the below, keep a note of the property <code>principalId</code> as we are going to use it in the next step.</p> <pre><code>{\n\"principalId\": \"&lt;your principal id will be displayed here&gt;\",\n\"tenantId\": \"&lt;your tenant id will be displayed here&gt;\",\n\"type\": \"SystemAssigned\"\n}\n</code></pre>"},{"location":"aca/05-aca-dapr-pubsubapi/#2-grant-backend-processor-app-the-azure-service-bus-data-receiver-role","title":"2. Grant Backend Processor App the Azure Service Bus Data Receiver Role","text":"<p>We will be using a <code>system-assigned</code> identity with a role assignments to grant our Backend Processor App the <code>Azure Service Bus Data Receiver</code> role which will allow it to receive messages from Service Bus queues  and subscriptions.</p> <p>You can read more about <code>Azure built-in roles for Azure Service Bus</code> here. </p> <p>Run the command below to associate the <code>system-assigned</code> identity with the access-control role <code>Azure Service Bus Data Receiver</code>:</p> <pre><code>$subscriptionID = \"&lt;Your Azure Subscription ID&gt;\" ## Your Azure Subscription id which you can find on the azure portal\n$principalId = \"&lt;your principal id which was generated above&gt;\" ## Principal Id after creating system identity for Backend Processor Container app \n$roleNameOrId =  \"Azure Service Bus Data Receiver\" ## Built in role name\naz role assignment create `\n--assignee $principalId `\n--role $roleNameOrId `\n--scope /subscriptions/$subscriptionID/resourcegroups/$RESOURCE_GROUP/providers/Microsoft.ServiceBus/namespaces/$NamespaceName\n</code></pre>"},{"location":"aca/05-aca-dapr-pubsubapi/#3-grant-backend-api-app-the-azure-service-bus-data-sender-role","title":"3. Grant Backend API App the Azure Service Bus Data Sender Role","text":"<p>We'll do the same with Backend API container app, but we will use a different Azure built-in roles for Azure Service Bus which is the role <code>Azure Service Bus Data Sender</code> as the Backend API is a publisher of the  messages. Run the command below to associate the <code>system-assigned</code> with access-control role <code>Azure Service Bus Data Sender</code>:</p> <pre><code>$subscriptionID = \"&lt;Your Azure Subscription ID&gt;\" ## Your Azure Subscription\n$principalId = \"&lt;your principal id which was generated in module 4. You can find it on the azure portal under the specific container identity section&gt;\" ## Principal Id after creating system identity for Backend API Container app\n$roleNameOrId =  \"Azure Service Bus Data Sender\" ## Built in role name\naz role assignment create `\n--assignee $principalId `\n--role $roleNameOrId `\n--scope /subscriptions/$subscriptionID/resourcegroups/$RESOURCE_GROUP/providers/Microsoft.ServiceBus/namespaces/$NamespaceName\n</code></pre>"},{"location":"aca/05-aca-dapr-pubsubapi/#4-restart-container-apps","title":"4. Restart Container Apps","text":"<p>Lastly, we need to restart both container apps revisions to pick up the role assignment.</p> <pre><code>##Get revision name and assign it to a variable\n$REVISION_NAME = (az containerapp revision list `\n--name $BACKEND_SVC_NAME  `\n--resource-group $RESOURCE_GROUP `\n--query [0].name)\n##Restart revision by name                            \naz containerapp revision restart `\n--resource-group $RESOURCE_GROUP `\n--name $BACKEND_SVC_NAME  `\n--revision $REVISION_NAME\n$REVISION_NAME = (az containerapp revision list `\n--name $BACKEND_API_NAME  `\n--resource-group $RESOURCE_GROUP `\n--query [0].name)\n##Restart revision by name                            \naz containerapp revision restart `\n--resource-group $RESOURCE_GROUP `\n--name $BACKEND_API_NAME  `\n--revision $REVISION_NAME\n</code></pre> <p>Success</p> <p>With this in place, you should be able to test the 3 services end to end and should receive a notification email to the task assignee email, the email will look like the below. </p> <p></p> <p>Note</p> <p>If you opted not to activate the SendGrid then you won't receive the email. In this case you can get the backend processor logs using the command below. Start by running the command below and then launch the application and start creating new tasks. You should start seeing logs similar to the ones shown in the image below. The command will stop executing after 60 seconds of inactivity.</p> <pre><code>az containerapp logs show --follow `\n-n $BACKEND_SVC_NAME `\n-g $RESOURCE_GROUP\n</code></pre> <p></p> <p>The next module will delve into the implementation of Dapr bindings with ACA.</p>"},{"location":"aca/06-aca-dapr-bindingsapi/","title":"Module 6 - ACA with Dapr Bindings Building Block","text":"<p>Module Duration</p> <p>90 minutes</p> <p>In this module we are going to extend the backend background processor service  (<code>ACA-Processor Backend</code>) to interface with an external system which is outside our Tasks Tracker microservice application. To achieve this in a simple way we will utilize Dapr Input and Output Bindings. </p> <p>The external system owns an Azure Storage Queue which the Tasks Tracker microservice application reacts to through an event handler (aka Input Binding) that receives and processes the message coming to  the storage queue. Once the processing of the message completes and stores the task into Cosmos DB, the system will trigger an event (aka Output binding) that invokes the external service which in turn stores the content of the message into an Azure Blob Storage container. Here it is important to emphasize that both the Azure Storage Queue and the Azure Storage Blob belong to the external system.</p> <p>The rest of this module will implement the three scenarios mentioned below:</p> <ul> <li>Trigger a process on the <code>ACA-Processor Backend</code> based on a message sent to a specific Azure Storage Queue. This scenario will assume that the Azure Storage Queue is an external system to which external clients can submit tasks.</li> <li>From the service <code>ACA-Processor Backend</code> we will invoke an external resource that stores the content of the incoming task from the external queue as a JSON blob file on Azure Storage Blobs. </li> <li>Remove the SendGrid SDK as well as the custom code created in the previous module to send emails and replace it with Dapr SendGrid output binding.</li> </ul> <p>Take a look at the high-level architecture diagram below to understand the flow of input and output bindings in Dapr:</p> <p></p> <p>Note</p> <p>Those 3rd party external services could be a services hosted on another cloud provider, different Azure subscription or even on premise. Dapr bindings are usually used to trigger an application with  events coming in from external systems as well as interface with external systems. </p> <p>For simplicity of the workshop we are going to host those two supposedly external services in the same subscription of our  Tasks Tracker microservice application.</p> <p>If you look at Dapr Bindings Building Block, you will notice a lot of similarities with the Pub/Sub Building Block that we covered in the previous module. But remember that Pub/Sub Building Block is meant to be used for Async communication between services within your solution. The Binding Building Block has a wider scope and it mainly focuses on connectivity and interoperability across different systems, disparate applications, and services outside the boundaries of your own application. For a full list of supported bindings visit this link.</p>"},{"location":"aca/06-aca-dapr-bindingsapi/#overview-of-dapr-bindings-building-block","title":"Overview of Dapr Bindings Building Block","text":"<p>Let's take a look at the detailed Dapr Binding Building Block architecture diagram that we are going to implement in this module to fulfill the use case we discussed earlier: </p> <p>Looking at the diagram we notice the following:</p> <ul> <li>In order to receive events and data from the external resource (Azure Storage Queue) our <code>ACA-Processor Backend</code> service needs to register a public endpoint that will become an event handler.</li> <li>This binding configuration between the external resource and our service will be configured by using the <code>Input Binding Configuration yaml</code> file. The Dapr sidecar of the background service will read the configuration and subscribe to the endpoint defined for the external resource. In our case, it will be a specific Azure Storage Queue.</li> <li>When a message is published to the storage queue, the input binding component running in the Dapr sidecar picks it up and triggers the event.</li> <li>The Dapr sidecar invokes the endpoint (event handler defined in the <code>ACA-Processor Backend</code> Service) configured for the binding. In our case, it will be an endpoint that can be reached by invoking a <code>POST</code> operation <code>http://localhost:3502/ExternalTasksProcessor/Process</code> and the request body content will be the JSON payload of the published message to the Azure Storage Queue.</li> <li>When the event is handled in our <code>ACA-Processor Backend</code> and the business logic is completed, this endpoint needs to return an HTTP response with a <code>200 ok</code> status to acknowledge that processing is complete. If the event handling is not completed or there is an error, this endpoint should return HTTP 400 or 500 status code.</li> <li>In order to enable the service <code>ACA-Processor Backend</code> to trigger an event that invokes an external resource, we need to use the <code>Output Binding Configuration Yaml</code> file to configure the binding between our service and the external resource (Azure Blob Storage) and how to connect to it.</li> <li>Once the Dapr sidecar reads the binding configuration file, our service can trigger an event that invokes the output binding API on the Dapr sidecar. In our case, the event will be creating a new blob file containing the content of the message we read earlier from the Azure Storage Queue.</li> <li>With this in place, our service <code>ACA-Processor Backend</code> will be ready to invoke the external resource by sending a POST operation to the endpoint <code>http://localhost:3502/v1.0/bindings/ExternalTasksBlobstore</code> and the JSON payload will contain the content below. Alternatively, we can use the Dapr client SDK to invoke this output biding to invoke the external service and store the file in Azure Blob Storage.</li> </ul> <p><pre><code>{\n\"data\": \"{\n        \"taskName\": \"Task Coming from External System\",\n        \"taskAssignedTo\": \"user1@hotmail.com\",\n        \"taskCreatedBy\": \"tjoudeh@bitoftech.net\",\n        \"taskDueDate\": \"2022-08-19T12:45:22.0983978Z\"\n    }\",\n\"operation\": \"create\"\n}\n</code></pre> Let's start by updating our Backend Background Processor project and define the input and output bindings configuration files and event handlers.</p> <p>To proceed with this workshop we need to provision the Azure Storage Account to start responding to messages published to a queue and then later use the same storage account to store blob files as an external event. Run the PowerShell script below to create Azure Storage Account and get the master key. </p> <p>Tip</p> <p>We will be retrieving the storage account key for local dev testing purposes. Note that the command below will return two keys. You will only need one of them for this exercise.  When deploying the changes to ACA, we are going to store the storage key securely into Azure Key Vault using Dapr Secrets Store Building Block with AKV. </p> <p>We didn't use Azure Manged Identity here because the assumption is that those services are not part of our solution and thus they could theoretically be a non AD compliant services or hosted on another cloud.  If these services where part of your application's ecosystem it is always recommended that you use Azure Managed Identity.</p> <pre><code>$STORAGE_ACCOUNT_NAME = \"&lt;replace with a globally unique storage name.The field can contain only lowercase letters and numbers. Name must be between 3 and 24 characters.&gt;\"\naz storage account create `\n--name $STORAGE_ACCOUNT_NAME `\n--resource-group $RESOURCE_GROUP `\n--location $LOCATION `\n--sku Standard_LRS `\n--kind StorageV2\n# list azure storage keys\naz storage account keys list -g $RESOURCE_GROUP -n $STORAGE_ACCOUNT_NAME\n</code></pre>"},{"location":"aca/06-aca-dapr-bindingsapi/#updating-the-backend-background-processor-project","title":"Updating the Backend Background Processor Project","text":""},{"location":"aca/06-aca-dapr-bindingsapi/#1-create-an-event-handler-api-endpoint-to-respond-to-messages-published-to-azure-storage-queue","title":"1. Create an event handler (API endpoint) to respond to messages published to Azure Storage Queue","text":"<p>Let's add an endpoint that will be responsible to handle the event when a message is published to Azure Storage Queue. This endpoint will start receiving the message published from the external service. </p> <p>Start by adding a new controller Controllers folder under the TasksTracker.Processor.Backend.Svc project:</p> ExternalTasksProcessorController.cs <pre><code>using Dapr.Client;\nusing Microsoft.AspNetCore.Mvc;\nusing TasksTracker.Processor.Backend.Svc.Models;\nnamespace TasksTracker.Processor.Backend.Svc.Controllers\n{\n[Route(\"ExternalTasksProcessor\")]\n[ApiController]\npublic class ExternalTasksProcessorController : ControllerBase\n{\nprivate readonly ILogger&lt;ExternalTasksProcessorController&gt; _logger;\nprivate readonly DaprClient _daprClient;\npublic ExternalTasksProcessorController(ILogger&lt;ExternalTasksProcessorController&gt; logger,\nDaprClient daprClient)\n{\n_logger = logger;\n_daprClient = daprClient;\n}\n[HttpPost(\"process\")]\npublic async Task&lt;IActionResult&gt; ProcessTaskAndStore([FromBody] TaskModel taskModel)\n{\ntry\n{\n_logger.LogInformation(\"Started processing external task message from storage queue. Task Name: '{0}'\", taskModel.TaskName);\ntaskModel.TaskId = Guid.NewGuid();\ntaskModel.TaskCreatedOn = DateTime.UtcNow;\n//Dapr SideCar Invocation (save task to a state store)\nawait _daprClient.InvokeMethodAsync(HttpMethod.Post, \"tasksmanager-backend-api\", $\"api/tasks\", taskModel);\n_logger.LogInformation(\"Saved external task to the state store successfully. Task name: '{0}', Task Id: '{1}'\", taskModel.TaskName, taskModel.TaskId);\n//ToDo: code to invoke external binding and store queue message content into blob file in Azure storage\nreturn Ok();\n}\ncatch (Exception)\n{\nthrow;\n}\n}\n}\n}\n</code></pre> Curious to know more about the code? <ul> <li> <p>We defined an action method named <code>ProcessTaskAndStore</code> which can be accessed by sending HTTP POST operation on the  endpoint <code>ExternalTasksProcessor/Process</code>. </p> </li> <li> <p>This action method accepts the TaskModel in the request body as JSON payload.This is what will be received from the external service (Azure Storage Queue). </p> </li> <li> <p>Within this action method, we are going to store the received task by sending a POST request to <code>/api/tasks</code> which is part of the backend api named <code>tasksmanager-backend-api</code>.</p> </li> <li> <p>Then we return <code>200 OK</code> to acknowledge that message received is processed successfully and should be removed from the external service queue.</p> </li> </ul>"},{"location":"aca/06-aca-dapr-bindingsapi/#2-create-dapr-input-binding-component-file","title":"2. Create Dapr Input Binding Component File","text":"<p>Now we need to create the component configuration file which will describe the configuration as well as how our backend background processor will start handling events coming from the  external service (Azure Storage Queues). To do so, add a new file under components folder.</p> dapr-bindings-in-storagequeue.yaml <pre><code>apiVersion: dapr.io/v1alpha1\nkind: Component\nmetadata:\nname: externaltasksmanager\nspec:\ntype: bindings.azure.storagequeues\nversion: v1\nmetadata:\n- name: storageAccount\nvalue: \"&lt;Your Storage Account Name&gt;\"\n- name: storageAccessKey\nvalue: \"&lt;Your Storage Account Key&gt;\"\n- name: queue\nvalue: \"external-tasks-queue\"\n- name: decodeBase64\nvalue: \"true\"\n- name: route\nvalue: /externaltasksprocessor/process\n</code></pre> Curious to learn more about the specification of yaml file? <p>The full specifications of yaml file with Azure Storage Queues can be found on this link,  but let's go over the configuration we have added here:</p> <ul> <li>The type of binding is <code>bindings.azure.storagequeues</code>.</li> <li>The name of this input binding is <code>externaltasksmanager</code>.</li> <li>We are setting the <code>storageAccount</code> name, <code>storageAccessKey</code> value, and the <code>queue</code> name. Those properties will describe how the event handler we added can connect to the external service. You can create any queue you prefer on the Azure Storage Account we created to simulate an external system.</li> <li>We are setting the <code>route</code> property to the value <code>/externaltasksprocessor/process</code> which is the address of the endpoint we have just added so POST requests are sent to this endpoint.</li> <li>We are setting the property <code>decodeBase64</code> to <code>true</code> as the message queued in the Azure Storage Queue is Base64 encoded.</li> </ul> <p>Note</p> <p>The value of the Metadata <code>storageAccessKey</code> is used as plain text here for local dev scenario. We will see how we are going to store this key  securely in Azure Key Vault and use Dapr Secrets Store API to read the access key.</p>"},{"location":"aca/06-aca-dapr-bindingsapi/#3-create-dapr-output-binding-component-file","title":"3. Create Dapr Output Binding Component File","text":"<p>Now we need to create the component configuration file which will describe the configuration and how our service <code>ACA-Processor Backend</code> will be able to invoke the external service (Azure Blob Storage)  and be able to create and store a JSON blob file that contains the content of the message received from Azure Storage Queues. </p> <p>To do so, add a new file folder components.</p> dapr-bindings-out-blobstorage.yaml <pre><code>apiVersion: dapr.io/v1alpha1\nkind: Component\nmetadata:\nname: externaltasksblobstore\nspec:\ntype: bindings.azure.blobstorage\nversion: v1\nmetadata:\n- name: storageAccount\nvalue: \"&lt;Your Storage Account Name&gt;\"\n- name: storageAccessKey\nvalue: \"&lt;Your Storage Account Key&gt;\"\n- name: container\nvalue: \"externaltaskscontainer\"\n- name: decodeBase64\nvalue: false\n</code></pre> Curious to learn more about the specification of yaml file? <p>The full specifications of yaml file with Azure blob storage can be found on this link,  but let's go over the configuration we have added here:</p> <ul> <li>The type of binding is <code>bindings.azure.blobstorage</code>.</li> <li>The name of this output binding is <code>externaltasksblobstore</code>. We will use this name when we use the Dapr SDK to trigger the output binding.</li> <li>We are setting the <code>storageAccount</code> name, <code>storageAccessKey</code> value, and the <code>container</code> name. Those properties will describe how our backend background service will be able to connect to the external service and create a blob file. We will assume that there is a container already created on the external service and named <code>externaltaskscontainer</code> as shown in the image below</li> </ul> <p></p> <ul> <li>We are setting the property <code>decodeBase64</code>  to <code>false</code> as we don\u2019t want to encode file content to base64 images, we need to store the file content as is.</li> </ul>"},{"location":"aca/06-aca-dapr-bindingsapi/#5-use-dapr-client-sdk-to-invoke-the-output-binding","title":"5. Use Dapr client SDK to Invoke the Output Binding","text":"<p>Now we need to invoke the output binding by using the .NET SDK.</p> <p>Update and replace the code in the file with the code below. Pay close attention to the updated ProcessTaskAndStore action method:</p> ExternalTasksProcessorController.cs <pre><code>using Dapr.Client;\nusing Microsoft.AspNetCore.Mvc;\nusing TasksTracker.Processor.Backend.Svc.Models;\nnamespace TasksTracker.Processor.Backend.Svc.Controllers\n{\n[Route(\"ExternalTasksProcessor\")]\n[ApiController]\npublic class ExternalTasksProcessorController : ControllerBase\n{\nprivate readonly ILogger&lt;ExternalTasksProcessorController&gt; _logger;\nprivate readonly DaprClient _daprClient;\nprivate const string OUTPUT_BINDING_NAME = \"externaltasksblobstore\";\nprivate const string OUTPUT_BINDING_OPERATION = \"create\";\npublic ExternalTasksProcessorController(ILogger&lt;ExternalTasksProcessorController&gt; logger,\nDaprClient daprClient)\n{\n_logger = logger;\n_daprClient = daprClient;\n}\n[HttpPost(\"process\")]\npublic async Task&lt;IActionResult&gt; ProcessTaskAndStore([FromBody] TaskModel taskModel)\n{\ntry\n{\n_logger.LogInformation(\"Started processing external task message from storage queue. Task Name: '{0}'\", taskModel.TaskName);\ntaskModel.TaskId = Guid.NewGuid();\ntaskModel.TaskCreatedOn = DateTime.UtcNow;\n//Dapr SideCar Invocation (save task to a state store)\nawait _daprClient.InvokeMethodAsync(HttpMethod.Post, \"tasksmanager-backend-api\", $\"api/tasks\", taskModel);\n_logger.LogInformation(\"Saved external task to the state store successfully. Task name: '{0}', Task Id: '{1}'\", taskModel.TaskName, taskModel.TaskId);\n//code to invoke external binding and store queue message content into blob file in Azure storage\nIReadOnlyDictionary&lt;string,string&gt; metaData = new Dictionary&lt;string, string&gt;()\n{\n{ \"blobName\", $\"{taskModel.TaskId}.json\" },\n};\nawait _daprClient.InvokeBindingAsync(OUTPUT_BINDING_NAME, OUTPUT_BINDING_OPERATION, taskModel, metaData);\n_logger.LogInformation(\"Invoked output binding '{0}' for external task. Task name: '{1}', Task Id: '{2}'\", OUTPUT_BINDING_NAME, taskModel.TaskName, taskModel.TaskId);\nreturn Ok();\n}\ncatch (Exception)\n{\nthrow;\n}\n}\n}\n}\n</code></pre> Curious to know more about the code? <p>Looking at the <code>ProcessTaskAndStore</code> action method above, you will see that we are calling the method <code>InvokeBindingAsync</code> and we are passing the binding name <code>externaltasksblobstore</code>  defined in the configuration file, as well the second parameter <code>create</code> which is the action we need to carry against the external blob storage. </p> <p>You can for example delete or get a content of a certain file. For a full list of supported actions on Azure Blob Storage, visit this link.</p> <p>Notice how are setting the file name we are storing at the external service. We need the file names to be created using the same Task Identifier, so we will pass the key <code>blobName</code> with the file name values  into the <code>metaData</code> dictionary.</p>"},{"location":"aca/06-aca-dapr-bindingsapi/#6-test-dapr-bindings-locally","title":"6. Test Dapr Bindings Locally","text":"<p>Now we are ready to give it an end-to-end test on our dev machines. Run the 3 applications together using Debug and Run button from VS Code. You can read how we configured the 3 apps to run together  in this section.</p> <p>Open Azure Storage Explorer on your local machine. If you don't have it installed you can install it from here.  Login to your Azure Subscription and navigate to the storage account already created, create a queue, and use the same name you already used in the Dapr Input configuration file. In our case the name of the queue in the configuration file is <code>external-tasks-queue</code>.</p> <p></p> <p>The content of the message that Azure Storage Queue excepts should be as below, so try to queue a new message using the tool as the image below:</p> <pre><code>{\n\"taskName\": \"Task from External System\",\n\"taskAssignedTo\": \"user1@hotmail.com\",\n\"taskCreatedBy\": \"tjoudeh@bitoftech.net\",\n\"taskDueDate\": \"2022-08-19T12:45:22.0983978Z\"\n}\n</code></pre> <p></p> <p>If all is configured successfully you should be able to see a JSON file created as a blob in the Azure Storage Container named <code>externaltaskscontainer</code> based on your configuration.</p> <p></p>"},{"location":"aca/06-aca-dapr-bindingsapi/#use-dapr-sendgrid-output-bindings","title":"Use Dapr SendGrid Output Bindings","text":"<p>In the previous module we've seen how we are sending notification emails when a task is assigned to a user by installing the SendGrid SDK NuGet package and writing some custom code to trigger sending emails.  Dapr Can simplify this process by using the Dapr SendGrid Output binding component. </p> <p>So let's see how we can simplify this and by replacing the external SendGrid SDK with dapr output binding.</p>"},{"location":"aca/06-aca-dapr-bindingsapi/#1-create-dapr-sendgrid-output-binding-component-file","title":"1. Create Dapr SendGrid Output Binding Component file","text":"<p>We need to create the component configuration file which will describe the configuration and how our service <code>ACA-Processor Backend</code> will be able to invoke SendGrid service and notify the task owner by email. </p> <p>Add a new file under the components folder as shown below:</p> dapr-bindings-out-sendgrid.yaml <pre><code>apiVersion: dapr.io/v1alpha1\nkind: Component\nmetadata:\nname: sendgrid\nspec:\ntype: bindings.twilio.sendgrid\nversion: v1\nmetadata:\n- name: emailFrom\nvalue: \"&lt;Your email which was white listed with SendGrid when you obtained the API Key&gt;\"\n- name: emailFromName\nvalue: \"Tasks Tracker Notification\"\n- name: apiKey\nvalue: \"&lt;Send Grid API Key&gt;\"\n</code></pre> Curious to learn more about the specification of yaml file? <p>The full specifications of yaml file with SendGrid binding can be found on this link, but let's go over the configuration we have added here:</p> <ul> <li>The type of binding is <code>bindings.twilio.sendgrid</code>.</li> <li>The name of this output binding is <code>sendgrid</code>. We will use this name when we use the Dapr SDK to trigger the output binding.</li> <li>We are setting the metadata <code>emailFrom</code>, <code>emailFromName</code>, and the <code>apiKey</code>. Those properties will describe how our backend background service will be able to connect to SendGrid API and send the email.</li> </ul>"},{"location":"aca/06-aca-dapr-bindingsapi/#2-remove-sendgrid-package-reference","title":"2. Remove SendGrid package reference","text":"<ul> <li>Update file TasksTracker.Processor.Backend.Svc.csproj and remove the NuGet package reference PackageReference Include=\"SendGrid\" Version=\"9.28.1\". With the introduction of Dapr SendGrid Output bindings there is no need to include the external SDKs.</li> </ul> <pre><code>// delete these using statements\nusing SendGrid;\nusing SendGrid.Helpers.Mail;\n</code></pre>"},{"location":"aca/06-aca-dapr-bindingsapi/#3-update-sendemail-code-to-use-output-bindings-instead-of-sendgrid-sdk","title":"3. Update SendEmail Code to Use Output Bindings Instead of SendGrid SDK","text":"<p>Now we need to invoke the SendGrid output binding by using the Dapr .NET SDK. Replace the content of the <code>TasksNotifierController.cs</code> file with the code below. Also its very important that you open the <code>appsettings.json</code> file and set the <code>IntegrationEnabled</code> to false to avoid sending any emails. This is important as we don't want to send several emails later on when simulate high load in module 9 while demonstrating autoscaling with KEDA. </p> TasksNotifierController.csappsettings.json <pre><code>using Dapr.Client;\nusing Microsoft.AspNetCore.Http;\nusing Microsoft.AspNetCore.Mvc;\nusing TasksTracker.Processor.Backend.Svc.Models;\nnamespace TasksTracker.Processor.Backend.Svc.Controllers\n{\n[Route(\"api/tasksnotifier\")]\n[ApiController]\npublic class TasksNotifierController : ControllerBase\n{\nprivate readonly IConfiguration _config;\nprivate readonly ILogger _logger;\nprivate readonly DaprClient _daprClient;\npublic TasksNotifierController(IConfiguration config, ILogger&lt;TasksNotifierController&gt; logger, DaprClient daprClient)\n{\n_config = config;\n_logger = logger;\n_daprClient = daprClient;\n}\n[Dapr.Topic(\"dapr-pubsub-servicebus\", \"tasksavedtopic\")]\n[HttpPost(\"tasksaved\")]\npublic async Task&lt;IActionResult&gt; TaskSaved([FromBody] TaskModel taskModel)\n{\n_logger.LogInformation(\"Started processing message with Task Name '{0}'\", taskModel.TaskName);\nvar sendGridResponse = await SendEmail(taskModel);\nif (sendGridResponse)\n{\nreturn Ok();\n}\nreturn BadRequest(\"Failed to send an email\");\n}\nprivate async Task&lt;bool&gt; SendEmail(TaskModel taskModel)\n{\nvar integrationEnabled = _config.GetValue&lt;bool&gt;(\"SendGrid:IntegrationEnabled\");\nvar sendEmailResponse = true;\nvar subject = $\"Task '{taskModel.TaskName}' is assigned to you!\";\nvar plainTextContent = $\"Task '{taskModel.TaskName}' is assigned to you. Task should be completed by the end of: {taskModel.TaskDueDate.ToString(\"dd/MM/yyyy\")}\";\ntry\n{\n//Send actual email using Dapr SendGrid Outbound Binding (Disabled when running load test)\nif (integrationEnabled)\n{\nIReadOnlyDictionary&lt;string, string&gt; metaData = new Dictionary&lt;string, string&gt;()\n{\n{ \"emailTo\", taskModel.TaskAssignedTo },\n{ \"emailToName\", taskModel.TaskAssignedTo },\n{ \"subject\", subject }\n};\nawait _daprClient.InvokeBindingAsync(\"sendgrid\", \"create\", plainTextContent, metaData);\n}\nelse\n{\n//Introduce artificial delay to slow down message processing\n_logger.LogInformation(\"Simulate slow processing for email sending for Email with Email subject '{0}' Email to: '{1}'\", subject, taskModel.TaskAssignedTo);\nThread.Sleep(1000);\n}\nif (sendEmailResponse)\n{\n_logger.LogInformation(\"Email with subject '{0}' sent to: '{1}' successfully\", subject, taskModel.TaskAssignedTo);\n}\n}\ncatch (System.Exception ex)\n{\nsendEmailResponse = false;\n_logger.LogError(ex, \"Failed to send email with subject '{0}' To: '{1}'.\", subject, taskModel.TaskAssignedTo);\nthrow;\n}\nreturn sendEmailResponse;\n}\n}\n}\n</code></pre> <pre><code>    {\n\"SendGrid\": {\n\"IntegrationEnabled\":false\n}\n}\n</code></pre> <p>Note</p> <p>Even though we restored the code to send emails it won't actually trigger sending emails as we set the <code>IntegrationEnabled</code> flag to false. Also notice that we introduced a Thread.Sleep(1000) statement. This will come in handy in module 9 where it will be used to simulate artificial delay within the <code>ACA-Processor Backend</code> service to demonstrate autoscaling with KEDA.</p> Curious to learn more about the code above? <p>You will see that we calling the method <code>InvokeBindingAsync()</code> and we are passing the binding name <code>sendgrid</code> defined in the configuration file,  as well the second parameter <code>create</code> which is the action we need to carry to trigger email sending using SendGrid. </p> <p>For a full list of supported actions on SendGrid outbound binding spec, visit this link.</p> <p>Notice how are setting the recipient, display name, and email subject by passing the setting the keys <code>emailTo</code>, <code>emailToName</code>, and <code>subject</code> into the <code>metaData</code> dictionary.</p>"},{"location":"aca/06-aca-dapr-bindingsapi/#configure-dapr-secret-store-component-with-azure-key-vault","title":"Configure Dapr Secret Store Component with Azure Key Vault","text":"<p>Currently, we have 3 Dapr components which are not Azure AD enabled services. As you may have noticed so far, the different component files are storing sensitive keys to access the different external services. The recommended approach for retrieving these secrets is to reference an existing Dapr secret store component that securely accesses the secrets.</p> <p>We need Create a Dapr secret store component using the Container Apps schema. The Dapr secret store will be configured with Azure Key Vault secret store.</p>"},{"location":"aca/06-aca-dapr-bindingsapi/#1-create-an-azure-key-vault-resource","title":"1. Create an Azure Key Vault resource","text":"<p>Create an Azure Key Vault which will be used to store securely any secret or key used in our application.</p> <pre><code>$KEYVAULTNAME = \"&lt;your akv name. Should be globally unique. \nVault name must only contain alphanumeric characters and dashes and cannot start with a number.&gt;\"\naz keyvault create `\n--name $KEYVAULTNAME `\n--resource-group $RESOURCE_GROUP `\n--enable-rbac-authorization true `\n--location $LOCATION\n</code></pre> <p>Note</p> <p>It is important to create the Azure Key Vault with Azure RBAC for authorization by setting <code>--enable-rbac-authorization true</code> because the role we are going to assign to the Azure AD  application will work only when RBAC authorization is enabled.</p>"},{"location":"aca/06-aca-dapr-bindingsapi/#2-grant-backend-processor-app-a-role-to-read-secrets-from-azure-key-vault","title":"2. Grant Backend Processor App a Role To Read Secrets from Azure Key Vault","text":"<p>In the previous module we have configured the <code>system-assigned</code> identity for the service <code>ACA-Processor Backend</code>. Now we need to assign a role named <code>Key Vault Secrets User</code> to it, so it access and read  secrets from Azure Key Vault.</p> <p>You can read more about Azure built-in roles for Key Vault data plane operations. </p> <pre><code>$KV_SECRETSUSER_ROLEID = \"4633458b-17de-408a-b874-0445c86b69e6\" # ID for 'Key Vault Secrets User' Role\n$subscriptionID= az account show --query id -o tsv\n# Get PRINCIPALID of BACKEND Processor Service\n$BACKEND_SVC_PRINCIPALID = az containerapp show `\n-n $BACKEND_SVC_NAME `\n-g $RESOURCE_GROUP `\n--query identity.principalId\naz role assignment create `\n--role $KV_SECRETSUSER_ROLEID `\n--assignee $BACKEND_SVC_PRINCIPALID `\n--scope \"/subscriptions/$subscriptionID/resourcegroups/$RESOURCE_GROUP/providers/Microsoft.KeyVault/vaults/$KEYVAULTNAME\"\n</code></pre>"},{"location":"aca/06-aca-dapr-bindingsapi/#3-create-secrets-in-the-azure-key-vault","title":"3. Create Secrets in the Azure Key Vault","text":"<p>To create a secret in Azure Key Vault you need to have a role which allows you to create secrets. From the Azure CLI we will assign the role <code>Key Vault Secrets Officer</code> to the user signed in to AZ CLI to be able to create secrets. To do so use the script below:</p> <pre><code>$SIGNEDIN_UERID =  az ad signed-in-user show --query id\n$KV_SECRETSOFFICER_ROLEID = \"b86a8fe4-44ce-4948-aee5-eccb2c155cd7\" #ID for 'Key Vault Secrets Office' Role \naz role assignment create --role $KV_SECRETSOFFICER_ROLEID `\n--assignee $SIGNEDIN_UERID `\n--scope \"/subscriptions/$subscriptionID/resourcegroups/$RESOURCE_GROUP/providers/Microsoft.KeyVault/vaults/$KEYVAULTNAME\"\n</code></pre> <p>Now we will create 2 secrets in the Azure Key Vault using the commands below:</p> <pre><code># Set SendGrid API Key as a secret named 'sendgrid-api-key'\naz keyvault secret set `\n--vault-name $KEYVAULTNAME `\n--name \"sendgrid-api-key\" `\n--value \"&lt;Send Grid API Key&gt;.leave this empty if you opted not to register with the sendgrip api\"\n# Set External Azure Storage Access Key as a secret named 'external-azure-storage-key'\naz keyvault secret set `\n--vault-name $KEYVAULTNAME `\n--name \"external-azure-storage-key\" `\n--value \"&lt;Your Storage Account Key&gt;\"\n</code></pre>"},{"location":"aca/06-aca-dapr-bindingsapi/#4-create-a-aca-dapr-secrets-store-component-file","title":"4. Create a ACA Dapr Secrets Store Component file","text":"<p>Create a new yaml file under the aca-components folder.</p> containerapps-secretstore-kv.yaml <pre><code>componentType: secretstores.azure.keyvault\nversion: v1\nmetadata:\n- name: vaultName\nvalue: &lt;Your keyvault name goes here&gt;\nscopes:\n- tasksmanager-backend-processor\n</code></pre> Curious to learn more about the yaml file? <ul> <li>We didn't specify the component name <code>secretstoreakv</code> in the metadata of the this component yaml file. We are going to specify it once we add this dapr component to Azure Container Apps Environment  via CLI similar to what we did in earlier modules.</li> <li>We are not referencing any service bus connection strings as the authentication between Dapr and Azure Service Bus will be configured using Managed Identities. </li> <li>The metadata <code>vaultName</code> value is set to the name of the Azure Key Vault we've just created. </li> <li>We are allowing this component only to be accessed by the dapr with application id <code>tasksmanager-backend-processor</code>. This means that our Backend API or Frontend Web App services will not be able to access the Dapr secret store. If we want to allow them to access the secrets we need to update this component file and grant the system-identity of those services a <code>Key Vault Secrets User</code> role.</li> </ul>"},{"location":"aca/06-aca-dapr-bindingsapi/#5-create-input-and-output-binding-component-files-matching-azure-container-apps-specs","title":"5. Create Input and Output Binding Component Files Matching Azure Container Apps Specs","text":"<p>Add new files under the aca-components use the yaml below:</p> containerapps-bindings-in-storagequeue.yamlcontainerapps-bindings-out-blobstorage.yaml <pre><code>componentType: bindings.azure.storagequeues\nversion: v1\nsecretStoreComponent: \"secretstoreakv\"\nmetadata:\n- name: storageAccount\nvalue: \"&lt;Your Storage Account Name&gt;\"\n- name: storageAccessKey\nsecretRef: external-azure-storage-key\n- name: queue\nvalue: \"external-tasks-queue\"\n- name: decodeBase64\nvalue: \"true\"\n- name: route\nvalue: /externaltasksprocessor/process\nscopes:\n- tasksmanager-backend-processor\n</code></pre> Curious to learn more about the yaml file? <p>The properties of this file are matching the ones used in Dapr component-specific file. It is a component of type <code>bindings.azure.storagequeues</code>.  The only differences are the following: </p> <ul> <li>We are setting the property <code>secretStoreComponent</code> value to <code>secretstoreakv</code> which is the name of Dapr secret store component.</li> <li>We are using <code>secretRef</code> when setting the metadata <code>storageAccessKey</code>. The value <code>external-azure-storage-key</code> represents the AKV secret created earlier.</li> </ul> <pre><code>componentType: bindings.azure.blobstorage\nversion: v1\nsecretStoreComponent: \"secretstoreakv\"\nmetadata:\n- name: storageAccount\nvalue: \"&lt;Your Storage Account Name&gt;\"\n- name: storageAccessKey\nsecretRef: external-azure-storage-key\n- name: container\nvalue: \"externaltaskscontainer\"\n- name: decodeBase64\nvalue: \"false\"\n- name: publicAccessLevel\nvalue: \"none\"\nscopes:\n- tasksmanager-backend-processor\n</code></pre> Curious to learn more about the yaml file? <p>The properties of this file are matching the ones used in Dapr component-specific file. It is a component of type <code>bindings.azure.blobstorage</code>.  The only differences are the following:</p> <ul> <li>We are setting the property <code>secretStoreComponent</code> value to <code>secretstoreakv</code> which is the name of Dapr secret store component.</li> <li>We are using <code>secretRef</code> when setting the metadata <code>storageAccessKey</code>. The value <code>external-azure-storage-key</code> represents the AKV secret created earlier</li> </ul>"},{"location":"aca/06-aca-dapr-bindingsapi/#6-create-sendgrid-output-binding-component-file-matching-azure-container-apps-specs","title":"6. Create SendGrid Output Binding Component File Matching Azure Container Apps Specs","text":"<p>Add a new file under the aca-components use the yaml below:</p> containerapps-bindings-out-sendgrid.yaml <pre><code>componentType: bindings.twilio.sendgrid\nversion: v1\nsecretStoreComponent: \"secretstoreakv\"\nmetadata:\n- name: emailFrom\nvalue: \"mail@gmail.com\"\n- name: emailFromName\nvalue: \"Tasks Tracker Notification\"\n- name: apiKey\nsecretRef: sendgrid-api-key\nscopes:\n- tasksmanager-backend-processor\n</code></pre> Curious to learn more about the yaml file? <p>The properties of this file are similar to the previous ones. The difference is that the metadata 'apiKey' value is set to <code>sendgrid-api-key</code> which is the name of the secret in AKV that holds SendGrid API key.</p> <p>With those changes in place, we are ready to rebuild the backend background processor container image, update Azure Container Apps Env, and redeploy a new revision.</p>"},{"location":"aca/06-aca-dapr-bindingsapi/#deploy-a-new-revision-of-the-backend-background-processor-app-to-aca","title":"Deploy a New Revision of the Backend Background Processor App to ACA","text":""},{"location":"aca/06-aca-dapr-bindingsapi/#1-build-the-backend-background-processor-image-and-push-it-to-acr","title":"1. Build the Backend Background Processor Image and Push it To ACR","text":"<p>As we have done previously we need to build and deploy the Backend Background Processor image to ACR, so it is ready to be deployed to ACA.  Continue using the same PowerShell console and paste the code below (make sure you are under the  TasksTracker.ContainerApps directory):</p> <pre><code>az acr build --registry $ACR_NAME --image \"tasksmanager/$BACKEND_SVC_NAME\" --file 'TasksTracker.Processor.Backend.Svc/Dockerfile' .\n</code></pre>"},{"location":"aca/06-aca-dapr-bindingsapi/#2-add-dapr-secret-store-component-to-aca-environment","title":"2. Add Dapr Secret Store Component to ACA Environment","text":"<p>We need to run the command below to create the Dapr secret store component:</p> <pre><code>az containerapp env dapr-component set `\n--name $ENVIRONMENT --resource-group $RESOURCE_GROUP `\n--dapr-component-name secretstoreakv `\n--yaml '.\\aca-components\\containerapps-secretstore-kv.yaml'\n</code></pre>"},{"location":"aca/06-aca-dapr-bindingsapi/#3-add-three-bindings-dapr-components-to-aca-environment","title":"3. Add three Bindings Dapr Components to ACA Environment","text":"<p>Next, we will add create the three Dapr bindings components using the component files created.</p> <p>Important</p> <p>At the time of producing this workshop, executing the commands below was throwing an error due an issue on the CLI when trying to create  a component file which contains reference to a <code>secretStoreComponent</code> via CLI. </p> <p>You can attempt to execute these commands but if the error still persists at the time you are consuming this workshop you can create the 3 components from the Azure Portal as shown below.</p> <pre><code>##Input binding component for Azure Storage Queue\naz containerapp env dapr-component set `\n--name $ENVIRONMENT --resource-group $RESOURCE_GROUP `\n--dapr-component-name externaltasksmanager `\n--yaml '.\\aca-components\\containerapps-bindings-in-storagequeue.yaml'\n##Output binding component for Azure Blob Storage\naz containerapp env dapr-component set `\n--name $ENVIRONMENT --resource-group $RESOURCE_GROUP `\n--dapr-component-name externaltasksblobstore `\n--yaml '.\\aca-components\\containerapps-bindings-out-blobstorage.yaml'\n##Output binding component for SendGrid\naz containerapp env dapr-component set `\n--name $ENVIRONMENT --resource-group $RESOURCE_GROUP `\n--dapr-component-name sendgrid `\n--yaml '.\\aca-components\\containerapps-bindings-out-sendgrid.yaml'\n</code></pre> CLI issue still exits? <p>From Azure Portal, navigate to your Container Apps Environment, select <code>Dapr Components</code>, then click on <code>Add</code> component, and provide the values of the component as shown in the image below.</p> <p>Note</p> <p>Image shown is for <code>externaltasksmanager</code> and you can do the other 2 components (<code>externaltasksblobstore</code> and <code>sendgrid</code>) using the values in the yaml file for each component.</p> <p></p>"},{"location":"aca/06-aca-dapr-bindingsapi/#4-deploy-new-revisions-of-the-backend-background-processor-to-aca","title":"4. Deploy new revisions of the Backend Background Processor to ACA","text":"<p>Update the Azure Container App hosting the Backend Background Processor with a new revision so our code changes are available for end users.</p> <p>Tip</p> <p>Notice how we are removing the environments variable named <code>SendGrid__ApiKey</code> as we are reading the key value from Dapr secret store. </p> <pre><code>## Update Backend Background Processor container app and create a new revision \naz containerapp update `\n--name $BACKEND_SVC_NAME `\n--resource-group $RESOURCE_GROUP `\n--revision-suffix v20230224-1 `\n--remove-env-vars \"SendGrid__ApiKey\"\n</code></pre>"},{"location":"aca/06-aca-dapr-bindingsapi/#5-remove-sendgrid-secret-from-the-backend-background-processor-app","title":"5. Remove SendGrid Secret from the Backend Background Processor App","text":"<p>Remove the secret stored in <code>Secrets</code> of the Backend Background Processor as this secret is not used anymore.</p> <p>Info</p> <p>You can skip executing the powershell script below if you opted not to set up a sendgrid account in module 5</p> <pre><code>az containerapp secret remove --name $BACKEND_SVC_NAME `\n--resource-group $RESOURCE_GROUP `\n--secret-names \"sendgrid-apikey\"\n</code></pre> <p>Success</p> <p>With those changes in place and deployed, from the Azure Portal you can open the log streams section of the container app hosting the <code>ACA-Processor-Backend</code> and check the logs generated after queuing a  message into Azure Storage Queue (using Azure Storage Explorer tool used earlier) as an external system. </p> <pre><code>{\n\"taskName\": \"Task from External System\",\n\"taskAssignedTo\": \"user42@hotmail.com\",\n\"taskCreatedBy\": \"tjoudeh@bitoftech.net\",\n\"taskDueDate\": \"2022-08-19T12:45:22.0983978Z\"\n}\n</code></pre> <p>You should receive logs similar to the below:</p> <p></p> <p>In the next module, we will cover a special type of Dapr input binding named Cron Binding.</p>"},{"location":"aca/07-aca-cron-bindings/","title":"Module 7 - ACA Scheduled Jobs with Dapr Cron Binding","text":"<p>Module Duration</p> <p>60 minutes</p> <p>In the preceding module, we discussed how Dapr bindings can simplify the integration process with external systems by facilitating the handling of events and the invocation of external resources.  In this module we will focus on a special type of Dapr input binding named Cron Binding.</p> <p>The Cron binding doesn't subscribe for events coming from an external system. Instead, this binding can be used to trigger application code in our service periodically based on a configurable interval.  The binding provides a simple way to implement a background worker to wake up and do some work at a regular interval, without the need to implement an endless loop with a configurable delay.</p> <p>We intend to utilize this binding for a specific use case, wherein it will be triggered once daily at a particular time (12:05 am), and search for tasks that have a due date matching the previous day of its  execution and are still pending. Once the service identifies tasks that meet these criteria, it will designate them as overdue tasks and save the revised status on Azure Cosmos DB.</p>"},{"location":"aca/07-aca-cron-bindings/#updating-the-backend-background-processor-project","title":"Updating the Backend Background Processor Project","text":""},{"location":"aca/07-aca-cron-bindings/#1-add-cron-binding-configuration","title":"1. Add Cron Binding Configuration","text":"<p>To set up the Cron binding, the initial step involves adding a component file that specifies the location of the code that requires triggering and the intervals at which it should occur.  To accomplish this, create a new file called dapr-scheduled-cron.yaml within the components folder and insert the following code:</p> <p>Add new file under components as shown below:</p> dapr-scheduled-cron.yaml <pre><code>apiVersion: dapr.io/v1alpha1\nkind: Component\nmetadata:\nname: ScheduledTasksManager\nnamespace: default\nspec:\ntype: bindings.cron\nversion: v1\nmetadata:\n- name: schedule\nvalue: \"5 0 * * *\"\nscopes:\n- tasksmanager-backend-processor\n</code></pre> Curious to learn more about above yaml file configuration? <p>The actions performed above are as follows:</p> <ul> <li>Added a new input binding of type <code>bindings.cron</code>.</li> <li>Provided the name <code>ScheduledTasksManager</code> for this binding. This means that an HTTP POST endpoint on the URL <code>/ScheduledTasksManager</code> should be added as it will be invoked when the job is triggered based on  the Cron interval.</li> <li>Setting the interval for this Cron job to be triggered once a day at 12:05am. For full details and available options on how to set this value,  visit the Cron binding specs..</li> </ul>"},{"location":"aca/07-aca-cron-bindings/#2-add-the-endpoint-which-will-be-invoked-by-cron-binding","title":"2. Add the Endpoint Which Will be Invoked by Cron Binding","text":"<p>Let's add an endpoint which will be triggered when the Cron configuration is met. This endpoint will contain the routine needed to run at a regular interval. </p> <p>Add new file under controllers folder in the project TasksTracker.Processor.Backend.Svc as shown below:</p> ScheduledTasksManagerController.cs <pre><code>using Dapr.Client;\nusing Microsoft.AspNetCore.Mvc;\nusing TasksTracker.Processor.Backend.Svc.Models;\nnamespace TasksTracker.Processor.Backend.Svc.Controllers\n{\n[Route(\"ScheduledTasksManager\")]\n[ApiController]\npublic class ScheduledTasksManagerController : ControllerBase\n{\nprivate readonly ILogger&lt;ScheduledTasksManagerController&gt; _logger;\nprivate readonly DaprClient _daprClient;\npublic ScheduledTasksManagerController(ILogger&lt;ScheduledTasksManagerController&gt; logger,\nDaprClient daprClient)\n{\n_logger = logger;\n_daprClient = daprClient;\n}\n[HttpPost]\npublic async Task CheckOverDueTasksJob()\n{\nvar runAt = DateTime.UtcNow;\n_logger.LogInformation($\"ScheduledTasksManager::Timer Services triggered at: {runAt}\");\nvar overdueTasksList = new List&lt;TaskModel&gt;();\nvar tasksList = await _daprClient.InvokeMethodAsync&lt;List&lt;TaskModel&gt;&gt;(HttpMethod.Get, \"tasksmanager-backend-api\", $\"api/overduetasks\");\n_logger.LogInformation($\"ScheduledTasksManager::completed query state store for tasks, retrieved tasks count: {tasksList?.Count()}\");\ntasksList?.ForEach(taskModel =&gt;\n{\nif (runAt.Date&gt; taskModel.TaskDueDate.Date)\n{\noverdueTasksList.Add(taskModel);\n}\n});\nif (overdueTasksList.Count&gt; 0)\n{\n_logger.LogInformation($\"ScheduledTasksManager::marking {overdueTasksList.Count()} as overdue tasks\");\nawait _daprClient.InvokeMethodAsync(HttpMethod.Post, \"tasksmanager-backend-api\", $\"api/overduetasks/markoverdue\", overdueTasksList);\n}\n}\n}\n}\n</code></pre> <p>Here, we have added a new action method called <code>CheckOverDueTasksJob</code>, which includes the relevant business logic that will be executed by the Cron job configuration at specified intervals.  This action method must be of the <code>POST</code> type, allowing it to be invoked when the job is triggered in accordance with the Cron interval.</p>"},{"location":"aca/07-aca-cron-bindings/#3-update-the-backend-web-api-project","title":"3. Update the Backend Web API Project","text":"<p>Now we need to add two new methods which are used by the scheduled job. </p> <p>Update below files under services folder in the project TasksTracker.TasksManager.Backend.Api as highlighted below:</p> ITasksManager.csTasksStoreManager.cs <pre><code>public interface ITasksManager\n{\nTask MarkOverdueTasks(List&lt;TaskModel&gt; overdueTasksList);\nTask&lt;List&lt;TaskModel&gt;&gt; GetYesterdaysDueTasks();\n}\n</code></pre> <pre><code>using System.Text.Json;\nusing System.Text.Encodings.Web;\nusing System.Text.Json.Serialization;\npublic async Task&lt;List&lt;TaskModel&gt;&gt; GetYesterdaysDueTasks()\n{\nvar options = new JsonSerializerOptions\n{\nPropertyNamingPolicy = JsonNamingPolicy.CamelCase,\nWriteIndented = true,\nConverters =\n{\nnew JsonStringEnumConverter(),\nnew DateTimeConverter(\"yyyy-MM-ddTHH:mm:ss\")\n},\nPropertyNameCaseInsensitive = true,\nDefaultIgnoreCondition = JsonIgnoreCondition.WhenWritingNull,\nEncoder = JavaScriptEncoder.UnsafeRelaxedJsonEscaping\n};\nvar yesterday = DateTime.Today.AddDays(-1);\nvar jsonDate = JsonSerializer.Serialize(yesterday, options);\n_logger.LogInformation(\"Getting overdue tasks for yesterday date: '{0}'\", jsonDate);\nvar query = \"{\" +\n\"\\\"filter\\\": {\" +\n\"\\\"EQ\\\": { \\\"taskDueDate\\\": \" + jsonDate + \" }\" +\n\"}}\";\nvar queryResponse = await _daprClient.QueryStateAsync&lt;TaskModel&gt;(STORE_NAME, query);\nvar tasksList = queryResponse.Results.Select(q =&gt; q.Data).Where(q=&gt;q.IsCompleted==false &amp;&amp; q.IsOverDue==false).OrderBy(o=&gt;o.TaskCreatedOn);\nreturn tasksList.ToList();\n}\npublic async Task MarkOverdueTasks(List&lt;TaskModel&gt; overDueTasksList)\n{\nforeach (var taskModel in overDueTasksList)\n{\n_logger.LogInformation(\"Mark task with Id: '{0}' as OverDue task\", taskModel.TaskId);\ntaskModel.IsOverDue = true;\nawait _daprClient.SaveStateAsync&lt;TaskModel&gt;(STORE_NAME, taskModel.TaskId.ToString(), taskModel);\n}\n}\n</code></pre> <p>Add below file under Utilities folder in the project TasksTracker.TasksManager.Backend.Api as shown below:</p> DateTimeConverter.cs <pre><code>using System.Text.Json;\nusing System.Text.Json.Serialization;\nnamespace TasksTracker.TasksManager.Backend.Api.Services\n{\npublic class DateTimeConverter : JsonConverter&lt;DateTime&gt;\n{\nprivate readonly string _dateFormatString;\npublic DateTimeConverter(string dateFormatString)\n{\n_dateFormatString = dateFormatString;\n}\npublic override DateTime Read(ref Utf8JsonReader reader, Type typeToConvert, JsonSerializerOptions options)\n{\nreturn DateTime.ParseExact(reader.GetString(), _dateFormatString, System.Globalization.CultureInfo.InvariantCulture);\n}\npublic override void Write(Utf8JsonWriter writer, DateTime value, JsonSerializerOptions options)\n{\nwriter.WriteStringValue(value.ToString(_dateFormatString));\n}\n}\n}\n</code></pre> Curious to learn more about above code? <p>What we've implemented here is the following:</p> <ul> <li>Method <code>GetYesterdaysDueTasks</code> will query the Cosmos DB state store using Dapr State API to lookup all the yesterday's task which are not completed yet. Remember that Cron job is configured to run each day  at 12:05am so we are interested to check only the day before when the service runs. We initially made this implementation simple. There might be some edge cases not handled with the current implementation.</li> <li>Method <code>MarkOverdueTasks</code> will take list of all tasks which passed the due date and set the flag <code>IsOverDue</code> to <code>true</code>.</li> </ul> <p>Do not forget to add fake implementation for class <code>FakeTasksManager.cs</code> so the project TasksTracker.TasksManager.Backend.Api builds successfully.</p> FakeTasksManager.cs <pre><code>public Task MarkOverdueTasks(List&lt;TaskModel&gt; overDueTasksList)\n{\nthrow new NotImplementedException();\n}\npublic Task&lt;List&lt;TaskModel&gt;&gt; GetYesterdaysDueTasks()\n{\nvar tasksList = _tasksList.Where(t =&gt; t.TaskDueDate.Equals(DateTime.Today.AddDays(-1))).ToList();\nreturn Task.FromResult(tasksList);\n}     </code></pre>"},{"location":"aca/07-aca-cron-bindings/#4-add-action-methods-to-backend-web-api-project","title":"4. Add Action Methods to Backend Web API project","text":"<p>As you've seen in the previous step, we are using Dapr Service to Service invocation API to call methods <code>api/overduetasks</code> and <code>api/overduetasks/markoverdue</code> in the Backend Web API from the Backend Background Processor.</p> <p>Add below file under controllers folder in the project TasksTracker.TasksManager.Backend.Api as shown below:</p> OverdueTasksController.cs <pre><code>using Microsoft.AspNetCore.Mvc;\nusing TasksTracker.TasksManager.Backend.Api.Models;\nusing TasksTracker.TasksManager.Backend.Api.Services;\nnamespace TasksTracker.TasksManager.Backend.Api.Controllers\n{\n[Route(\"api/overduetasks\")]\n[ApiController]\npublic class OverdueTasksController : ControllerBase\n{\nprivate readonly ILogger&lt;TasksController&gt; _logger;\nprivate readonly ITasksManager _tasksManager;\npublic OverdueTasksController(ILogger&lt;TasksController&gt; logger, ITasksManager tasksManager)\n{\n_logger = logger;\n_tasksManager = tasksManager;\n}\n[HttpGet]\npublic async Task&lt;IEnumerable&lt;TaskModel&gt;&gt; Get()\n{\nreturn await _tasksManager.GetYesterdaysDueTasks();\n}\n[HttpPost(\"markoverdue\")]\npublic async Task&lt;IActionResult&gt; Post([FromBody] List&lt;TaskModel&gt; overdueTasksList)\n{\nawait _tasksManager.MarkOverdueTasks(overdueTasksList);\nreturn Ok();\n}\n}\n}\n</code></pre>"},{"location":"aca/07-aca-cron-bindings/#5-add-cron-binding-configuration-matching-aca-specs","title":"5. Add Cron Binding Configuration Matching ACA Specs","text":"<p>Add a new file folder aca-components. This file will be used when updating the Azure Container App Env and enable this binding.</p> containerapps-scheduled-cron.yaml <pre><code>componentType: bindings.cron\nversion: v1\nmetadata:\n- name: schedule\nvalue: \"5 0 * * *\" # Everyday at 12:05am\nscopes:\n- tasksmanager-backend-processor\n</code></pre> <p>Note</p> <p>The name of the binding is not part of the file metadata. We are going to set the name of the binding to the value <code>ScheduledTasksManager</code> when we update the Azure Container Apps Env.</p>"},{"location":"aca/07-aca-cron-bindings/#deploy-the-backend-background-processor-and-the-backend-api-projects-to-azure-container-apps","title":"Deploy the Backend Background Processor and the Backend API Projects to Azure Container Apps","text":""},{"location":"aca/07-aca-cron-bindings/#1-build-the-backend-background-processor-and-the-backend-api-app-images-and-push-them-to-acr","title":"1. Build the Backend Background Processor and the Backend API App Images and Push them to ACR","text":"<p>To prepare for deployment to Azure Container Apps, we must build and deploy both application images to ACR, just as we did before. We can use the same PowerShell console use the  following code (make sure you are on directory TasksTracker.ContainerApps):</p> <pre><code>az acr build --registry $ACR_NAME --image \"tasksmanager/$BACKEND_API_NAME\" --file 'TasksTracker.TasksManager.Backend.Api/Dockerfile' . \naz acr build --registry $ACR_NAME --image \"tasksmanager/$BACKEND_SVC_NAME\" --file 'TasksTracker.Processor.Backend.Svc/Dockerfile' .\n</code></pre>"},{"location":"aca/07-aca-cron-bindings/#2-add-cron-dapr-component-to-aca-environment","title":"2. Add Cron Dapr Component to ACA Environment","text":"<pre><code>##Cron binding component\naz containerapp env dapr-component set `\n--name $ENVIRONMENT --resource-group $RESOURCE_GROUP `\n--dapr-component-name scheduledtasksmanager `\n--yaml '.\\aca-components\\containerapps-scheduled-cron.yaml'\n</code></pre>"},{"location":"aca/07-aca-cron-bindings/#3-deploy-new-revisions-of-the-backend-api-and-backend-background-processor-to-aca","title":"3. Deploy New Revisions of the Backend API and Backend Background Processor to ACA","text":"<p>As we did before, we need to update the Azure Container App hosting the Backend API &amp; Backend Background Processor with a new revision so our code changes are available for the end users.  To accomplish this run the PowerShell script below:</p> <pre><code>## Update Backend API App container app and create a new revision \naz containerapp update `\n--name $BACKEND_API_NAME `\n--resource-group $RESOURCE_GROUP `\n--revision-suffix v20230227-1 \n## Update Backend Background Processor container app and create a new revision \naz containerapp update `\n--name $BACKEND_SVC_NAME `\n--resource-group $RESOURCE_GROUP `\n--revision-suffix v20230227-1 \n</code></pre> <p>Note</p> <p>The service <code>ScheduledTasksManager</code> which will be triggered by the Cron job on certain intervals is hosted in the ACA service <code>ACA-Processor Backend</code>. In the future module we are going to scale this  ACA <code>ACA-Processor Backend</code> to multiple replicas/instances. </p> <p>It is highly recommended that background periodic jobs are hosted in a container app with one single replica, you don't want your background periodic job to run on multiple replicas trying to do the same thing.</p> <p>Success</p> <p>With those changes in place and deployed, from the Azure Portal, you can open the log streams of the container app hosting the <code>ACA-Processor-Backend</code> and check the logs generated when the Cron job is triggered, you should see logs similar to the below image</p> <p></p> <p>Note</p> <p>Keep in mind though that you won't be able to see the results instantaneously as the cron job searches for tasks that have a due date matching the previous day of its execution and are still pending.</p>"},{"location":"aca/08-aca-monitoring/","title":"Module 8 - ACA Monitoring and Observability with Application Insights","text":"<p>Module Duration</p> <p>60 minutes</p> <p>In this module, we will explore how we can configure ACA and ACA Environment with Application Insights which will provide a holistic view of our container apps health, performance metrics, logs data, various telemetries and traces. ACA do not support Auto-Instrumentation for Application Insights,  so in this module, we will be focusing on how we can integrate Application Insights into our microservice application.</p>"},{"location":"aca/08-aca-monitoring/#application-insights-overview","title":"Application Insights Overview","text":"<p>Application Insights is an offering from Azure Monitor that will help us to monitor all ACAs under the same Container App Environment and collect telemetry about the services within the solution, as well as understand the usage of the services and users' engagement via integrated analytics tools.</p> <p>The term \"Telemetry\" refers to the information gathered to monitor our application, which can be classified into three distinct groups.</p> <ol> <li>Distributed Tracing: Distributed Tracing allows for visibility into the communication between services participating in distributed transactions. For instance, when the Frontend Web Application interacts with the Backend API Application to add or retrieve information. An application map of how calls are flowing between services is very important for any distributed application.</li> <li>Metrics: This offers a view of a service's performance and its use of resources. For instance, it helps in monitoring the CPU and memory usage of the Backend Background Processor, and identifying when it is necessary to scale up the number of replicas.</li> <li>Logging: provides insights into how code is executing and if errors have occurred.</li> </ol> <p>In module 1 we have already provisioned a Workspace-based Application Insights Instance and configured it with ACA environment by setting the property <code>--dapr-instrumentation-key</code> when creating the environment. We will presume that you have already set up an instance of Application Insights that is available for use across the three Container Apps.</p>"},{"location":"aca/08-aca-monitoring/#installing-application-insights-sdk-into-the-three-microservices-apps","title":"Installing Application Insights SDK Into the Three Microservices Apps","text":""},{"location":"aca/08-aca-monitoring/#1-install-the-application-insights-sdk-using-nuget","title":"1. Install the Application Insights SDK Using NuGet","text":"<p>Our next step is to incorporate the Application Insights SDK into the three services, which is a uniform procedure.</p> <p>Note</p> <p>While we will outline the process of configuring Application Insights for the Backend API service, the identical steps must be followed for the other two services.</p> <p>To incorporate the SDK, use the NuGet reference below in the <code>csproj</code> file of the Backend API project. You may locate the csproj file in the project directory TasksTracker.TasksManager.Backend.Api:</p> TasksTracker.TasksManager.Backend.Api.csproj <pre><code>  &lt;ItemGroup&gt;\n&lt;!--Other packages are removed for brevity--&gt;\n&lt;PackageReference Include=\"Microsoft.ApplicationInsights.AspNetCore\" Version=\"2.21.0\" /&gt;\n&lt;/ItemGroup&gt;\n</code></pre>"},{"location":"aca/08-aca-monitoring/#2-set-rolename-property-in-all-the-services","title":"2. Set RoleName Property in All the Services","text":"<p>For each project, we will add a new file on the root directory of the project TasksTracker.TasksManager.Backend.Api.</p> AppInsightsTelemetryInitializer.cs <pre><code>namespace TasksTracker.TasksManager.Backend.Api\n{\npublic class AppInsightsTelemetryInitializer : ITelemetryInitializer\n{\npublic void Initialize(ITelemetry telemetry)\n{\nif (string.IsNullOrEmpty(telemetry.Context.Cloud.RoleName))\n{\n//set custom role name here\ntelemetry.Context.Cloud.RoleName = \"tasksmanager-backend-api\";\n}\n}\n}\n}\n</code></pre> <p>RoleName property for three services</p> <p>The only difference between each file on the 3 projects is the RoleName property value. </p> <p>Application Insights will utilize this property to recognize the elements on the application map. Additionally, it will prove beneficial for us in case we want to filter through all the warning logs produced by the Backend API service. Therefore, we will apply the tasksmanager-backend-api value for filtering purposes.</p> RoleName property values for other two service <p>You can check the <code>AppInsightsTelemetryInitializer.cs</code> files and the RoleName value used in the other projects below: </p> TasksTracker.WebPortal.Frontend.UiTasksTracker.Processor.Backend.Svc <pre><code>using Microsoft.ApplicationInsights.Channel;\nusing Microsoft.ApplicationInsights.Extensibility;\nnamespace TasksTracker.WebPortal.Frontend.Ui\n{\npublic class AppInsightsTelemetryInitializer : ITelemetryInitializer\n{\npublic void Initialize(ITelemetry telemetry)\n{\nif (string.IsNullOrEmpty(telemetry.Context.Cloud.RoleName))\n{\n//set custom role name here\ntelemetry.Context.Cloud.RoleName = \"tasksmanager-frontend-webapp\";\n}\n}\n}\n}\n</code></pre> <pre><code>using Microsoft.ApplicationInsights.Channel;\nusing Microsoft.ApplicationInsights.Extensibility;\nnamespace TasksTracker.Processor.Backend.Svc\n{\npublic class AppInsightsTelemetryInitializer : ITelemetryInitializer\n{\npublic void Initialize(ITelemetry telemetry)\n{\nif (string.IsNullOrEmpty(telemetry.Context.Cloud.RoleName))\n{\n//set custom role name here\ntelemetry.Context.Cloud.RoleName = \"tasksmanager-backend-processor\";\n}\n}\n}\n}\n</code></pre> <p>Next, we need to register this <code>AppInsightsTelemetryInitializer</code> class. Update the Program.cs file located under TasksTracker.TasksManager.Backend.Api as highlighted below:</p> <p>Note</p> <p>Don't forget that you need to do the same for the remaining two projects.</p> Program.cs <pre><code>using Microsoft.ApplicationInsights.Extensibility;\nusing TasksTracker.TasksManager.Backend.Api;\n//Code removed for brevity \nbuilder.Services.AddApplicationInsightsTelemetry();\nbuilder.Services.Configure&lt;TelemetryConfiguration&gt;((o) =&gt; {\no.TelemetryInitializers.Add(new AppInsightsTelemetryInitializer());\n});\nvar app = builder.Build();\n//Code removed for brevity\n</code></pre>"},{"location":"aca/08-aca-monitoring/#3-set-the-application-insights-instrumentation-key","title":"3. Set the Application Insights Instrumentation Key","text":"<p>In the previous module, we've used Dapr Secret Store to store connection strings and keys. In this module we will demonstrate how we can use another approach to secrets in Container Apps.</p> <p>We need to set the Application Insights Instrumentation Key so the projects are able to send telemetry data to the Application Insights instance. We are going to set this via secrets and environment variables once we redeploy the Container Apps and create new revisions.</p> appsettings.json <pre><code>{\n\"ApplicationInsights\": {\n\"InstrumentationKey\": \"&lt;Application Insights Key here for local development purposes. Not required for ACA as it is being set via --set-env-vars as you will see later&gt;\"\n} }\n</code></pre> <p>With this step completed, we have done all the changes needed. Let's now deploy the changes and create new ACA revisions.</p>"},{"location":"aca/08-aca-monitoring/#deploy-services-to-aca-and-create-new-revisions","title":"Deploy Services to ACA and Create New Revisions","text":""},{"location":"aca/08-aca-monitoring/#1-add-application-insights-instrumentation-key-as-a-secret","title":"1. Add Application Insights Instrumentation Key As a Secret","text":"<p>Let's create a secret named <code>appinsights-key</code> on each Container App which contains the value of the Application Insights instrumentation key.  Remember that we can obtain this value from Azure Portal by going to Application Insights instance we created in module 1, or we can get it from Azure CLI as we did in module 1. To create the secret use your existing PowerShell session and paste the code below:</p> <pre><code>az containerapp secret set `\n--name $BACKEND_API_NAME `\n--resource-group $RESOURCE_GROUP `\n--secrets \"appinsights-key=&lt;Application Insights Key Here&gt;\"\naz containerapp secret set `\n--name $FRONTEND_WEBAPP_NAME `\n--resource-group $RESOURCE_GROUP `\n--secrets \"appinsights-key=&lt;Application Insights Key Here&gt;\"\naz containerapp secret set `\n--name $BACKEND_SVC_NAME `\n--resource-group $RESOURCE_GROUP `\n--secrets \"appinsights-key=&lt;Application Insights Key Here&gt;\"\n</code></pre>"},{"location":"aca/08-aca-monitoring/#2-build-new-images-and-push-them-to-acr","title":"2. Build New Images and Push Them to ACR","text":"<p>As we did before, we are required to build and push the images of the three applications to ACR. By doing so, they will be prepared to be deployed in ACA.</p> <p>To accomplish this, continue using the same PowerShell console and paste the code below (make sure you are on the following directory TasksTracker.ContainerApps):</p> <pre><code>## Build Backend API on ACR and Push to ACR\naz acr build --registry $ACR_NAME --image \"tasksmanager/$BACKEND_API_NAME\" --file 'TasksTracker.TasksManager.Backend.Api/Dockerfile' . \n## Build Backend Service on ACR and Push to ACR\naz acr build --registry $ACR_NAME --image \"tasksmanager/$BACKEND_SVC_NAME\" --file 'TasksTracker.Processor.Backend.Svc/Dockerfile' .\n## Build Frontend Web App on ACR and Push to ACR\naz acr build --registry $ACR_NAME --image \"tasksmanager/$FRONTEND_WEBAPP_NAME\" --file 'TasksTracker.WebPortal.Frontend.Ui/Dockerfile' .\n</code></pre>"},{"location":"aca/08-aca-monitoring/#3-deploy-new-revisions-of-the-services-to-aca-and-set-a-new-environment-variable","title":"3. Deploy New Revisions of the Services to ACA and Set a New Environment Variable","text":"<p>We need to update the ACA hosting the three services with a new revision so our code changes are available for end users. </p> <p>Tip</p> <p>Notice how we used the property <code>--set-env-vars</code> to set new environment variable named <code>ApplicationInsights__InstrumentationKey</code>. Its value is a secret reference obtained from the secret <code>appinsights-key</code> we added in step 1.</p> <pre><code>## Update Backend API App container app and create a new revision \naz containerapp update `\n--name $BACKEND_API_NAME  `\n--resource-group $RESOURCE_GROUP `\n--revision-suffix v20230301-1 `\n--set-env-vars \"ApplicationInsights__InstrumentationKey=secretref:appinsights-key\"\n## Update Frontend Web App container app and create a new revision \naz containerapp update `\n--name $FRONTEND_WEBAPP_NAME  `\n--resource-group $RESOURCE_GROUP `\n--revision-suffix v20230301-1 `\n--set-env-vars \"ApplicationInsights__InstrumentationKey=secretref:appinsights-key\"\n## Update Backend Background Service container app and create a new revision \naz containerapp update `\n--name $BACKEND_SVC_NAME `\n--resource-group $RESOURCE_GROUP `\n--revision-suffix v20230301-1 `\n--set-env-vars \"ApplicationInsights__InstrumentationKey=secretref:appinsights-key\"\n</code></pre> <p>Success</p> <p>With those changes in place, you should start seeing telemetry coming to the Application Insights instance provisioned. Let's review Application Insights' key dashboards and panels in Azure Portal.</p>"},{"location":"aca/08-aca-monitoring/#distributed-tracing-via-application-map","title":"Distributed Tracing Via Application Map","text":"<p>Application Map will help us spot any performance bottlenecks or failure hotspots across all our services of our distributed microservice application.  Each node on the map represents an application component (service) or its dependencies and has a health KPI and alerts status.</p> <p></p> <p>Looking at the image above, you will see for example how the Backend Api with could RoleName <code>tasksmanager-backend-api</code> is depending on the Cosmos DB instance, showing the number of calls and average time to service these calls. The application map is interactive so you can select a service/component and drill down into details.</p> <p>For example, when we drill down into the Dapr State node to understand how many times the backend API invoked the Dapr Sidecar state service to Save/Delete state, you will see results similar to the  image below:</p> <p></p> <p>Note</p> <p>It will take some time for the application map to fully populate.</p>"},{"location":"aca/08-aca-monitoring/#monitor-production-application-using-live-metrics","title":"Monitor Production Application Using Live Metrics","text":"<p>This is one of the key monitoring panels. It provides you with near real-time (1-second latency) status of your entire distributed application. We have the ability to observe both the successes and failures of our system, monitor any occurring exceptions and trace them in real-time. Additionally, we can monitor the live servers (including replicas) and track their CPU and memory usage, as well as the number of requests they are currently handling.</p> <p>These live metrics provide very powerful diagnostics for our production microservice application. Check the image below and see the server names and some of the incoming requests to the system.</p> <p></p>"},{"location":"aca/08-aca-monitoring/#logs-search-using-transaction-search","title":"Logs Search Using Transaction Search","text":"<p>Transaction search in Application Insights will help us find and explore individual telemetry items, such as exceptions, web requests, or dependencies as well as any log traces and events that we\u2019ve added to the application.</p> <p>For example, if we want to see all the event types of type <code>Request</code> for the cloud RoleName <code>tasksmanager-backend-api</code> in the past 24 hours, we can use the transaction search dashboard to do this.  See how the filters are set and the results are displayed nicely. We can drill down on each result to have more details and what telemetry was captured before and after. A very useful feature when troubleshooting exceptions and reading logs.</p> <p></p>"},{"location":"aca/08-aca-monitoring/#failures-and-performance-panels","title":"Failures and Performance Panels","text":"<p>The failure panel enables us to assess the frequency of failures across various operations, which assists us in prioritizing our efforts towards the ones that have the most significant impact.</p> <p></p> <p>The Performance panel displays performance details for the different operations in our system. By identifying those operations with the longest duration, we can diagnose potential problems or best target our ongoing development to improve the overall performance of the system.</p> <p></p>"},{"location":"aca/09-aca-autoscale-keda/","title":"Module 9 - ACA Auto Scaling with KEDA","text":"<p>Module Duration</p> <p>30 minutes</p> <p>In this module, we will explore how we can configure Auto Scaling rules in Container Apps. The Auto Scaling feature is one of the key features of any Serverless hosting platform, since it allows your application to adjust dynamically to handle higher workloads, ensuring your system maintains its availability and performance. Azure Container Apps support Horizontal Scaling (Scaling Out) by adding more replicas (new instances of the Container App) and splitting the workload across multiple replicas to process the work in parallel. When the demand decreases, Azure Container Apps will (Scale In) by removing the unutilized replicas according to your configured scaling rule. With this approach, you pay only for the replicas provisioned during the increased demand period. You can also configure the scaling rule to scale to Zero replicas, resulting in no costs being incurred when your Container App scales down to zero.</p> <p>Azure Container Apps supports different scaling triggers including:</p> <ul> <li>HTTP traffic: Scaling based on the number of concurrent HTTP requests to your revision.</li> <li>CPU or Memory usage: Scaling based on the amount of CPU utilized or memory consumed by a replica.</li> <li>Azure Storage Queues: Scaling based on the number of messages in Azure Storage Queue.</li> <li>Event-driven using KEDA: Scaling based on events triggers, such as the number of messages in Azure Service Bus Topic or the number of blobs in Azure Blob Storage container.</li> </ul> <p>As we previously covered in the introductory module, Azure Container Apps utilize different open source technologies, including KEDA, which facilitates event-driven autoscaling. KEDA is installed by default when you provision your Container App so you don't need to worry about installing it. All we need to focus on is enabling and configuring our Container App scaling rules.</p> <p>In this module, we will be focusing on event-driven autoscaling using KEDA.</p>"},{"location":"aca/09-aca-autoscale-keda/#an-overview-of-keda","title":"An Overview of KEDA","text":"<p>KEDA stands for Kubernetes Event-Driven Autoscaler. It is an open-source project initially started by Microsoft and Red Hat to allow any Kubernetes workload to benefit from the event-driven architecture model. Prior to KEDA, horizontally scaling Kubernetes deployment was achieved through the Horizontal Pod Autoscaler (HPA). The HPA relies on resource metrics such as Memory and CPU to determine when additional replicas should be deployed. In an enterprise application, there may be additional external metrics that we want to use to scale our application, such as the length of a Kafka topic log, an Azure Service Bus Queue, or metrics obtained from a Prometheus query. KEDA offers more than 50 scalers to pick from based on your business need. KEDA exists to fill this gap and provides a framework for scaling based on events in conjunction with HPA scaling based on CPU and Memory.</p>"},{"location":"aca/09-aca-autoscale-keda/#configure-scaling-rule-in-backend-background-processor-project","title":"Configure Scaling Rule in Backend Background Processor Project","text":"<p>We need to configure our Backend Background Processor <code>tasksmanager-backend-processor</code> service to scale out and increase the number of replicas based on the number of messages in the Topic named <code>tasksavedtopic</code>. When our service is under heavy workload and a single replica is insufficient to handle the number of messages on the topic, we require the Container App to create additional replicas to distribute the processing of messages on this topic.</p> <p>So our requirements for scaling the backend processor are as follows:</p> <ul> <li>For every 10 messages on the Azure Service Bus Topic, scale-out by one replica.</li> <li>When there are no messages on the topic, scale-in to a one single replica.</li> <li>The maximum number of replicas should not exceed 5.</li> </ul> <p>To achieve this, we will start looking into KEDA Azure Service Bus scaler. This specification describes the <code>azure-servicebus</code> trigger for Azure Service Bus Queue or Topic. Let's take a look at the yaml file below which contains a generic template for the KEDA specification: <pre><code>triggers:\n- type: azure-servicebus\nmetadata:\n# Required: queueName OR topicName and subscriptionName\nqueueName: queueName\n# or\ntopicName: topicName\nsubscriptionName: subscriptionName\n# Optional, required when pod identity is used\nnamespace: service-bus-namespace\n# Optional, can use TriggerAuthentication as well\nconnectionFromEnv: SERVICEBUS_CONNECTIONSTRING_ENV_NAME # This must be a connection string for a queue itself, and not a namespace level (e.g. RootAccessPolicy) connection string \n# Optional\nmessageCount: \"5\" # Optional. Count of messages to trigger scaling on. Default: 5 messages\ncloud: Private # Optional. Default: AzurePublicCloud\nendpointSuffix: servicebus.airgap.example # Required when cloud=Private\n</code></pre></p> Curious to learn more about the contents of the yaml file? <ul> <li>The property <code>type</code> is set to <code>azure-servicebus</code>. Each KEDA scaler specification file has a unique type.</li> <li>One of the properties <code>queueName</code> or <code>topicName</code> should be provided. In our case, it will be <code>topicName</code> and we will use the value <code>tasksavedtopic</code>.</li> <li>The property <code>subscriptionName</code> will be set to use <code>tasksmanager-backend-processor</code>. This represents the subscription associated with the topic. Not needed if we are using queues.</li> <li>The property <code>connectionFromEnv</code> will be set to reference a secret stored in our Container App. We will not use the Azure Service Bus shared access policy (connection string) directly. The shared access policy will be stored in the Container App secrets, and the secret will be referenced here. Please note that the Service Bus Shared Access Policy needs to be of type <code>Manage</code>. It is required for KEDA to be able to get metrics from Service Bus and read the length of messages in the queue or topic.</li> <li>The property <code>messageCount</code> is used to decide when scaling out should be triggered. In our case, it will be set to <code>10</code>.</li> <li>The property <code>cloud</code> represents the name of the cloud environment that the service bus belongs to.</li> </ul> <p>Note</p> <p>Note about authentication: KEDA scaler for Azure Service Bus supports different authentication mechanisms such as Pod Managed Identity, Azure AD Workload Identity, and shared access policy (connection string). At the time of writing this workshop, when using KEDA with Azure Container Apps the only supported authentication mechanism is Connection Strings. There is a work item in the ACA product backlog that involves enabling KEDA Scale with Managed Identity.</p> <p>Azure Container Apps has its own proprietary schema to map KEDA Scaler template to its own when defining a custom scale rule. You can define this scaling rule via Container Apps ARM templates, yaml manifest, Azure CLI, or from the Azure Portal. In this module, we will cover how to do it from the Azure CLI.</p>"},{"location":"aca/09-aca-autoscale-keda/#1-create-a-new-secret-in-the-container-app","title":"1. Create a New Secret In The Container App","text":"<p>Let's now create a secret named <code>svcbus-connstring</code> in our <code>tasksmanager-backend-processor</code> Container App. This secret will contain the value of Azure Service Bus shared access policy (connection string) with <code>Manage</code> policy. To accomplish this, run the following commands in the Azure CLI to get the connection string, and then add this secret using the second command:</p> <pre><code>##List Service Bus Access Policy RootManageSharedAccessKey\n$ServiceBusConnectionString = az servicebus namespace authorization-rule keys list `\n--resource-group $RESOURCE_GROUP `\n--namespace-name $NamespaceName `\n--name RootManageSharedAccessKey `\n--query primaryConnectionString `\n--output tsv\n##Create a new secret named 'svcbus-connstring' in backend processer container app\naz containerapp secret set `\n--name $BACKEND_SVC_NAME `\n--resource-group $RESOURCE_GROUP `\n--secrets \"svcbus-connstring=$ServiceBusConnectionString\"\n</code></pre>"},{"location":"aca/09-aca-autoscale-keda/#2-create-a-custom-scaling-rule-from-azure-cli","title":"2. Create a Custom Scaling Rule from Azure CLI","text":"<p>Now we are ready to add a new custom scaling rule to match the business requirements. To accomplish this, we need to run the Azure CLI command below:</p> <p>Note</p> <p>You might need to upgrade the extension if you are on an older version of <code>az containerapp</code> which didn't allow you to create a scaling rule from CLI. To update the extension you can run the following command <code>az extension update --name containerapp</code> inside your powershell terminal. </p> <pre><code>az containerapp update `\n--name $BACKEND_SVC_NAME `\n--resource-group $RESOURCE_GROUP `\n--min-replicas 1 `\n--max-replicas 5 `\n--revision-suffix v20230227-3 `\n--set-env-vars \"SendGrid__IntegrationEnabled=false\" `\n--scale-rule-name \"topic-msgs-length\" `\n--scale-rule-type \"azure-servicebus\" `\n--scale-rule-auth \"connection=svcbus-connstring\" `\n--scale-rule-metadata \"topicName=&lt;Your topic name&gt;\" `\n\"subscriptionName=&lt;Your topic subscription name&gt;\" `\n\"namespace=$NamespaceName\" `\n\"messageCount=10\" `\n\"connectionFromEnv=svcbus-connstring\"\n</code></pre> Curious to learn more about the different parameters passed to the <code>az containerapp update</code> command? <ul> <li>Setting the minimum number of replicas to <code>1</code>. This means that this Container App could be scaled-in to a single replica if there are no new messages on the topic.</li> <li>Setting the maximum number of replicas to <code>5</code>. This means that this Container App will not exceed more than 5 replicas regardless of the number of messages on the topic.</li> <li>Setting a friendly name for the scale rule <code>topic-msgs-length</code> which will be visible in the Azure Portal.</li> <li>Setting the scale rule type to <code>azure-servicebus</code>. This is important to tell KEDA which type of scalers our Container App is configuring.</li> <li>Setting the authentication mechanism to type <code>connection</code> and indicating which secret reference will be used. In our case <code>svcbus-connstring</code>.</li> <li>Setting the <code>metadata</code> dictionary of the scale rule. Those match the metadata properties in KEDA template we discussed earlier.</li> <li>Disabled the integration with SendGrid as we are going to send several messages to test the scale out rule.</li> </ul> <p>Note</p> <p>Note About Setting Minimum Replicas To 0:</p> <ul> <li> <p>We can set the minimum number of replicas to <code>zero</code> to avoid any charges when the backend processor is not processing any message from Azure Service Bus Topic, but this will impact running the other features within this backend processor such as the periodic cron job as well as the external input bidding and output bindings. We are configuring the minimum number of replicas to one, ensuring that a backend processor instance is always running and capable of handling tasks, even if there are no messages being received by the Azure Service Bus Topic.</p> </li> <li> <p>When the single replica of the backend processor is not doing anything, it will be running in an <code>idle mode</code>. When the replica is in idle mode usage is charged at a reduced idle rate. A replica enters an active mode and is charged at the active rate when it is starting up, and when it is processing requests. For more details about the ACA pricing visit the link.</p> </li> </ul>"},{"location":"aca/09-aca-autoscale-keda/#3-run-an-end-to-end-test-and-generate-a-several-messages","title":"3. Run an End-to-End Test and Generate a Several Messages","text":"<p>Now we are ready to test out our Azure Service Bus Scaling Rule. To produce a high volume of messages, you can utilize Service Bus Explorer located within your Azure Service Bus namespace. Navigate to Azure Service Bus, choose your topic/subscription, and then select the Service Bus Explorer option. </p> <p>To get the number of current replicas of service <code>tasksmanager-backend-processor</code> we could run the command below, this should run single replica as we didn't load the service bus topic yet.</p> <p><pre><code>az containerapp replica list `\n--name $BACKEND_SVC_NAME `\n--resource-group $RESOURCE_GROUP `\n--query [].name\n</code></pre> The message structure our backend processor expects is similar to the JSON shown below. So copy this message and click on Send messages button, paste the message content, set the content type to <code>application/json</code>, check the <code>Repeat Send</code> check box, select <code>500</code> messages and put an interval of <code>5ms</code> between them. Finally click <code>Send</code> when you are ready.</p> <p><pre><code>{\n\"data\": {\n\"isCompleted\": false,\n\"isOverDue\": true,\n\"taskAssignedTo\": \"temp@mail.com\",\n\"taskCreatedBy\": \"someone@mail.com\",\n\"taskCreatedOn\": \"2022-08-18T12:45:22.0984036Z\",\n\"taskDueDate\": \"2023-02-24T12:45:22.0983978Z\",\n\"taskId\": \"6a051aeb-f567-40dd-a434-39927f2b93c5\",\n\"taskName\": \"Auto scale Task\"\n}\n}\n</code></pre> </p>"},{"location":"aca/09-aca-autoscale-keda/#4-verify-that-multiple-replicas-are-created","title":"4. Verify that Multiple Replicas Are Created","text":"<p>Success</p> <p>If all is setup correctly, 5 replicas will be created based on the number of messages we generated into the topic. There are various ways to verify this:</p> <ul> <li>You can run the Azure CLI command used in previous step to list the names of replicas.</li> <li>You can verify this from Container Apps <code>Console</code> tab where you will see those replicas in the drop-down list </li> </ul> <p>Note</p> <p>Note About KEDA Scale In: Container Apps implements the KEDA ScaledObject with the following default settings:</p> <ul> <li>pollingInterval: 30 seconds. This is the interval to check each trigger on. By default, KEDA will check each trigger source on every ScaledObject every 30 seconds.</li> <li>cooldownPeriod: 300 seconds. The period to wait after the last trigger is reported active before scaling in the resource back to 0. By default, it\u2019s 5 minutes (300 seconds). Currently, there is no way to override this value, yet there is an open issue on the Container Apps repo and the PG is tracking it as 5 minutes might be a long period to wait for instances to be scaled in after they finish processing messages.</li> </ul>"},{"location":"aca/10-aca-iac-bicep/","title":"Module 10 - Deployment Via Bicep","text":"<p>Throughout the various modules, we have utilized various Azure CLI commands to provision different resources. While this approach is suitable for this workshop, in a production environment, you will likely require a more automated process to deploy the same resources. In this module, we will be working on defining the proper process to automate the infrastructure provisioning by creating the scripts/templates to provision the resources. This process is known as IaC (Infrastructure as Code).</p> <p>Once we have this in place, IaC deployments will benefit us in key ways such as:</p> <ol> <li>By ensuring consistency and reducing human errors in resource provisioning, deployments can be made with greater confidence and consistency.</li> <li>Avoid configuration drifts as IaC is an idempotent operation, which means it provides the same result each time it\u2019s run.</li> <li>With Infrastructure as Code (IaC) in place, recreating an identical environment to the production one becomes a simple task of executing the scripts. This can be particularly useful during the application's lifecycle when short-term isolation is needed for tasks such as penetration testing or load testing.</li> <li>The Azure Portal abstracts several processes when you provision resources. For instance, when you create an Azure Container Apps Environment from the portal, it automatically creates a log analytics workspace and associates it with the environment without your direct involvement. However, using Infrastructure as Code (IaC) can provide you with a deeper understanding of Azure and help you troubleshoot any issues that may arise more effectively.</li> </ol>"},{"location":"aca/10-aca-iac-bicep/#arm-templates-in-azure","title":"ARM Templates in Azure","text":"<p>ARM templates are files that define the infrastructure and configuration for your deployment. The templates use declarative syntax, which lets you state what you intend to deploy without having to write the sequence of programming commands to create it.</p> <p>Within Azure there are two ways to create IaC. We can either use the JSON ARM templates or Bicep (domain-specific language). As a project grows and the number of components and dependencies increases, working with JSON ARM templates in real-world scenarios can become increasingly complex and difficult to manage and maintain. Bicep provides a more user-friendly and straightforward experience when compared to ARM templates, resulting in increased productivity. However, it's worth noting that Bicep code is eventually compiled into ARM templates through a process called \"transpilation.\"</p> <p></p> <p>Tip</p> <p>For those interested in learning more about Bicep, it is recommended to visit the Microsoft Learn website Fundamentals of Bicep.</p>"},{"location":"aca/10-aca-iac-bicep/ci-cd-git-action/","title":"Deploy infrastructure using GitHub Actions","text":"<p>GitHub Actions is a great way to automate your workflow. In this section, we will create a GitHub Action workflow to  deploy the infrastructure components of our application.</p> <p>The workshop repository contains a GitHub Action workflow file that will be used to deploy the infrastructure  components of our application. Follow the steps below to create a GitHub Action workflow to deploy the  infrastructure components of our application.</p>"},{"location":"aca/10-aca-iac-bicep/ci-cd-git-action/#fork-the-github-repository","title":"Fork the GitHub repository","text":"<p>Start by forking the workshop repository to your GitHub account. Follow the steps below to fork the workshop:</p> <ol> <li>Navigate to the workshop repository at  Azure/aca-dotnet-workshop</li> <li>Click the Fork button in the top-right corner of the page.</li> <li>Select your GitHub account to fork the repository to.</li> <li>Wait for the repository to be forked.</li> </ol>"},{"location":"aca/10-aca-iac-bicep/ci-cd-git-action/#configure-repository-for-oidc-authentication-with-azure-ad","title":"Configure Repository for OIDC Authentication with Azure AD","text":"<p>In order to use the GitHub Actions workflow to deploy the infrastructure components of our application, we need to  log in to Azure using the Azure CLI with Azure login action.</p> <p>The Azure login action supports two different ways of authenticating with Azure:</p> <ul> <li>Service principal with secrets</li> <li>OpenID Connect (OIDC) with a Azure service principal using a Federated Identity Credential</li> </ul> <p>In this workshop, we will use the OIDC authentication method. Assuming you are already logged in using azure cli  locally, follow the steps below to configure the repository for OIDC authentication with Azure AD either using powershell or bash/wsl:</p> PowerShellBash/WSL <ul> <li>Execute the following commands in PowerShell to create an Azure AD application and service principal.</li> </ul> <pre><code>$AZURE_TENANT = az account show -o tsv --query tenantId\n$SUBSCRIPTION_ID = az account show -o tsv --query id\n$APP_ID = az ad app create --display-name aca-dotnet-workshop-oidc --query appId -otsv\naz ad sp create --id $APP_ID --query appId -otsv\n$OBJECT_ID = az ad app show --id $APP_ID --query id -otsv\n</code></pre> <ul> <li>Execute below command to create a federated identity credential for the Azure AD application.</li> </ul> <p>Note</p> <p>Replace <code>&lt;Repo owner&gt;</code> in below json with your GitHub username where you forked the workshop repository.</p> <pre><code>az rest --method POST --uri \"https://graph.microsoft.com/beta/applications/$OBJECT_ID/federatedIdentityCredentials\" --body '{\\\"name\\\":\\\"aca-dotnet-workshop-federated-identity\\\",\\\"issuer\\\":\\\"https://token.actions.githubusercontent.com\\\",\\\"subject\\\":\\\"repo:&lt;Repo owner&gt;/aca-dotnet-workshop:ref:refs/heads/main\\\",\\\"description\\\":\\\"GitHub\\\",\\\"audiences\\\":[\\\"api://AzureADTokenExchange\\\"]}' --headers \"Content-Type=application/json\"\n</code></pre> <ul> <li>Perform role assignment for the Azure AD application to access the subscription.</li> </ul> <pre><code>az role assignment create --assignee $APP_ID --role contributor --scope /subscriptions/$SUBSCRIPTION_ID\naz role assignment create --assignee $APP_ID --role 'User Access Administrator' --scope /subscriptions/$SUBSCRIPTION_ID\n</code></pre> <ul> <li>Execute the following commands in PowerShell to create an Azure AD application and service principal.</li> </ul> <pre><code>AZURE_TENANT = $(az account show -o tsv --query tenantId)\nSUBSCRIPTION_ID = $(az account show -o tsv --query id)\nAPP_ID = $(az ad app create --display-name serverless-webapp-kotlin-oidc --query appId -otsv)\naz ad sp create --id $APP_ID --query appId -otsv\n\nOBJECT_ID = $(az ad app show --id $APP_ID --query id -otsv)\n</code></pre> <ul> <li>Execute below command to create a federated identity credential for the Azure AD application.</li> </ul> <p>Note</p> <p>Replace <code>&lt;Repo owner&gt;</code> in below json with your GitHub username where you forked the workshop repository.</p> <pre><code>cat &lt;&lt;EOF &gt; body.json\n{\n    \"name\": \"aca-dotnet-workshop-federated-identity\",\n    \"issuer\": \"https://token.actions.githubusercontent.com\",\n    \"subject\": \"repo:&lt;Repo owner&gt;/aca-dotnet-workshop:ref:refs/heads/main\",\n    \"description\": \"GitHub\",\n    \"audiences\": [\n        \"api://AzureADTokenExchange\"\n    ]\n}\nEOF\naz rest --method POST --uri \"https://graph.microsoft.com/beta/applications/$OBJECT_ID/federatedIdentityCredentials\" --body @body.json\n</code></pre> <ul> <li>Perform role assignment for the Azure AD application to access the subscription.</li> </ul> <pre><code>az role assignment create --assignee $APP_ID --role contributor --scope /subscriptions/$SUBSCRIPTION_ID\naz role assignment create --assignee $APP_ID --role 'User Access Administrator' --scope /subscriptions/$SUBSCRIPTION_ID\n</code></pre>"},{"location":"aca/10-aca-iac-bicep/ci-cd-git-action/#configure-github-repository-secrets","title":"Configure GitHub Repository Secrets","text":"<p>Configure secrets details in GitHub repo as described here in create GitHub secrets.  Use below values mapped to relevant secrets in GitHub. </p> <pre><code># AZURE_SUBSCRIPTION_ID\necho $SUBSCRIPTION_ID # AZURE_TENANT_ID   \necho $AZURE_TENANT    # AZURE_CLIENT_ID      \necho $APP_ID             </code></pre>"},{"location":"aca/10-aca-iac-bicep/ci-cd-git-action/#configure-github-repository-variables","title":"Configure GitHub Repository Variables","text":"<p>Configure repository variables as shown below:</p> <p><pre><code># LOCATION: Azure region where resources will be deployed\nLOCATION=&lt;location&gt;\n\n# RESOURCE_GROUP: Name of the resource group which will be created and resources will be deployed\nRESOURCE_GROUP=&lt;resource group name&gt;\n\n# (OPTIONAL)CONTAINER_REGISTRY_NAME: Unique name of the container registry which will be created and where images will be imported\nCONTAINER_REGISTRY_NAME=&lt;container registry name&gt;\n</code></pre> !!! note:</p> <pre><code>Repository variables `CONTAINER_REGISTRY_NAME` is only needed by workflow, if you wish the images to be deployed from private ACR.\n\nYou may chose to skip defining this variable and the workflow will use the [public github container registry images](https://github.com/orgs/Azure/packages?repo_name=aca-dotnet-workshop) to deploy the images.\n</code></pre>"},{"location":"aca/10-aca-iac-bicep/ci-cd-git-action/#trigger-github-actions-workflow","title":"Trigger GitHub Actions Workflow","text":"<p>With these steps completed, you are now ready to trigger the GitHub Actions workflow using workflow dispatch to deploy the infrastructure components of our application.</p> <p>Success</p> <p>Your GitHub Actions workflow should be triggered and the infrastructure components of our application should be deployed successfully.</p> <p></p>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/","title":"Build the Infrastructure as Code Using Bicep","text":"<p>Module Duration</p> <p>30 minutes</p> <p>To begin, we need to define the Bicep modules that will be required to generate the Infrastructure code. Our goal for this module is to have a freshly created resource group that encompasses all the necessary resources and configurations - such as connection strings, secrets, environment variables, and Dapr components - which we utilized to construct our solution. By the end, we will have a new resource group that includes the following resources. </p> <p>Note</p> <p>To simplify the execution of the module, we will assume that you have already created latest images of three services and pushed them to a container registry. This section below guides you through different options of getting images pushed to either Azure Container Registry (ACR) or GitHub Container Registry (GHCR).</p> <p>If we created and deployed container registery as part of the Bicep scripts, then we can't build and push images to the created ACR in an automated way because creating the three ACA container apps is reliant on ACR's images.</p> <p>In a production setting, a DevOps pipeline would be in place to automate the whole process - commencing with ACR creation, followed by building and pushing docker images, and concluding with executing the  Bicep script to establish the remaining resources. As it is outside the scope of this workshop, we will not delve into the creation of a DevOps pipeline here.</p>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/#1-add-the-needed-extension-to-vs-code","title":"1. Add the Needed Extension to VS Code","text":"<p>To proceed, you must install an extension called Bicep. This extension will simplify building Bicep files as it offers IntelliSense, Validation, listing all available resource types, etc..</p>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/#2-define-an-azure-container-apps-environment","title":"2. Define an Azure Container Apps Environment","text":"<p>Add a new folder named <code>bicep</code> on the root project directory, then add another folder named <code>modules</code>. Add file as shown below:</p> container-apps-environment.bicep <pre><code>targetScope = 'resourceGroup'\n\n// ------------------\n//    PARAMETERS\n// ------------------\n@description('The location where the resources will be created.')\nparam location string = resourceGroup().location\n\n@description('Optional. The tags to be assigned to the created resources.')\nparam tags object = {}\n\n@description('The name of the container apps environment. If set, it overrides the name generated by the template.')\nparam containerAppsEnvironmentName string \n\n@description('The name of the log analytics workspace. If set, it overrides the name generated by the template.')\nparam logAnalyticsWorkspaceName string \n\n@description(' The name of the application insights. If set, it overrides the name generated by the template.')\nparam applicationInsightName string \n\n// ------------------\n// VARIABLES\n// ------------------\n\n// ------------------\n// RESOURCES\n// ------------------\nresource logAnalyticsWorkspace 'Microsoft.OperationalInsights/workspaces@2021-06-01' = {\n  name: logAnalyticsWorkspaceName\n  location: location\n  tags: tags\n  properties: any({\n    features: {\n      searchVersion: 1\n    }\n    sku: {\n      name: 'PerGB2018'\n    }\n    retentionInDays: 30\n  })\n}\n\nresource applicationInsights 'Microsoft.Insights/components@2020-02-02' = {\n  name: applicationInsightName\n  location: location\n  tags: tags\n  kind: 'web'\n  properties: {\n    Application_Type: 'web'\n    WorkspaceResourceId: logAnalyticsWorkspace.id\n  }\n}\n\nresource containerAppsEnvironment 'Microsoft.App/managedEnvironments@2022-10-01' = {\n  name: containerAppsEnvironmentName\n  location: location\n  tags: tags\n  sku: {\n    name: 'Consumption'\n  }\n  properties: {\n    daprAIInstrumentationKey: applicationInsights.properties.InstrumentationKey\n    appLogsConfiguration: {\n      destination: 'log-analytics'\n      logAnalyticsConfiguration: {\n        customerId: logAnalyticsWorkspace.properties.customerId\n        sharedKey:  logAnalyticsWorkspace.listKeys().primarySharedKey\n      }\n    }\n  }\n}\n\n// ------------------\n// OUTPUTS\n// ------------------\n\n@description('The name of the application insights.')\noutput applicationInsightsName string  = applicationInsights.name\n</code></pre> What we've added in the Bicep file above <ul> <li>The module takes multiple parameters, all of which are set to default values. This indicates that if no value is specified, the default value will be utilized. </li> <li>The <code>location</code> parameter defaults to the location of the container resource group. Bicep has a function called <code>resourceGroup()</code>, which can be used to retrieve the location.</li> <li>The parameters <code>prefix</code> and <code>suffix</code> could be used if you want to add a prefix or suffix to the resource names.</li> <li>The parameter <code>tag</code> is used to tag the created resources. Tags are key-value pairs that help you identify resources based on settings that are relevant to your organization and deployment.</li> <li>The parameters <code>containerAppsEnvironmentName</code>, <code>logAnalyticsWorkspaceName</code>, and <code>applicationInsightName</code> have default values of resource names using the helper function named <code>uniqueString</code>. This function performs a 64-bit hash of the provided strings to create a unique string. This function is helpful when you need to create a unique name for a resource. We are passing the <code>resourceGroup().id</code> to this function to ensure that if we executed this module on two different resource groups, the generated string will be a global unique name.</li> <li>This module will create two resources. It will start by creating a <code>logAnalyticsWorkspace</code>, then an <code>applicationInsights</code> resource. Notice how we are setting the <code>logAnalyticsWorkspace.id</code> as an application insights <code>WorkspaceResourceId</code>.</li> <li>Lastly we are creating the <code>containerAppsEnvironment</code>. Notice how we are setting the <code>daprAIInstrumentationKey</code> by using the Application Insights <code>InstrumentationKey</code> and then setting <code>logAnalyticsConfiguration.customerId</code> and <code>logAnalyticsConfiguration.sharedKey</code>.</li> <li>The output of this module are a is parameter named <code>applicationInsightsName</code>. This output is needed as an input for a subsequent module.</li> </ul>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/#3-define-an-azure-key-vault-resource","title":"3. Define an Azure Key Vault Resource","text":"<p>Add file as shown below under the folder <code>bicep\\modules</code>:</p> key-vault.bicep <pre><code>targetScope = 'resourceGroup'\n\n// ------------------\n//    PARAMETERS\n// ------------------\n\n@description('The location where the resources will be created.')\nparam location string = resourceGroup().location\n\n@description('The name of the Key Vault. If set, it overrides the name generated by the template.')\nparam keyVaultName string\n\n@description('Optional. The tags to be assigned to the created resources.')\nparam tags object = {}\n\n// ------------------\n// RESOURCES\n// ------------------\n\nresource keyVault 'Microsoft.KeyVault/vaults@2022-07-01' = {\n  name: keyVaultName\n  location: location  \n  tags: tags\n  properties: {\n    tenantId: subscription().tenantId\n    sku: {\n      family: 'A'\n      name: 'standard'\n    }\n    enableSoftDelete: false\n    softDeleteRetentionInDays: 7\n    enablePurgeProtection: null  // It seems that you cannot set it to False even the first time. workaround is not to set it at all: https://github.com/Azure/bicep/issues/5223\n    enableRbacAuthorization: true\n    enabledForTemplateDeployment: true\n  }\n}\n\n// ------------------\n// OUTPUTS\n// ------------------\n\n@description('The resource ID of the key vault.')\noutput keyVaultId string = keyVault.id\n</code></pre> What we've added in the Bicep file above <ul> <li>This module will create the Azure Key Vault resource which will be used to store secrets.</li> <li>The output of this module is a single parameter named <code>keyVaultId</code>. This output is needed as an input for a subsequent module.</li> </ul>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/#4-define-a-azure-service-bus-resource","title":"4. Define a Azure Service Bus Resource","text":"<p>Add file as shown below under the folder <code>bicep\\modules</code>:</p> service-bus.bicep <pre><code>targetScope = 'resourceGroup'\n\n// ------------------\n//    PARAMETERS\n// ------------------\n\n@description('The location where the resources will be created.')\nparam location string = resourceGroup().location\n\n@description('Optional. The name of the service bus namespace. If set, it overrides the name generated by the template.')\nparam serviceBusName string\n\n@description('Optional. The tags to be assigned to the created resources.')\nparam tags object = {}\n\n@description('The name of the service bus topic.')\nparam serviceBusTopicName string\n\n@description('The name of the service bus topic\\'s authorization rule.')\nparam serviceBusTopicAuthorizationRuleName string\n\n@description('The name of the service for the backend processor service. The name is used as Dapr App ID and as the name of service bus topic subscription.')\nparam backendProcessorServiceName string\n\n// ------------------\n// RESOURCES\n// ------------------\n\nresource serviceBusNamespace 'Microsoft.ServiceBus/namespaces@2021-11-01' = {\n  name: serviceBusName\n  location: location\n  tags: tags\n  sku: {\n    name: 'Standard'\n  }\n}\n\nresource serviceBusTopic 'Microsoft.ServiceBus/namespaces/topics@2021-11-01' = {\n  name: serviceBusTopicName\n  parent: serviceBusNamespace\n}\n\nresource serviceBusTopicAuthRule 'Microsoft.ServiceBus/namespaces/topics/authorizationRules@2021-11-01' = {\n  name: serviceBusTopicAuthorizationRuleName\n  parent: serviceBusTopic\n  properties: {\n    rights: [\n      'Manage'\n      'Send'\n      'Listen'\n    ]\n  }\n}\n\nresource serviceBusTopicSubscription 'Microsoft.ServiceBus/namespaces/topics/subscriptions@2022-10-01-preview' = {\n  name: backendProcessorServiceName\n  parent: serviceBusTopic\n}\n\n// ------------------\n// OUTPUTS\n// ------------------\n\n@description('The name of the service bus namespace.')\noutput serviceBusName string = serviceBusNamespace.name\n\n@description('The name of the service bus topic.')\noutput serviceBusTopicName string = serviceBusTopic.name\n\n@description('The name of the service bus topic\\'s authorization rule.')\noutput serviceBusTopicAuthorizationRuleName string = serviceBusTopicAuthRule.name\n</code></pre> What we've added in the Bicep file above <ul> <li>This module will create the Azure Service resource, a topic, a subscription for the consumer, and an authorization rule with <code>Manage</code> permissions.</li> <li>The output of this module will return three output parameters which will be used as an input for a subsequent module.</li> </ul>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/#5-define-an-azure-cosmosdb-resource","title":"5. Define an Azure CosmosDb Resource","text":"<p>Add file as shown below under the folder <code>bicep\\modules</code>:</p> cosmos-db.bicep <pre><code>targetScope = 'resourceGroup'\n\n// ------------------\n//    PARAMETERS\n// ------------------\n\n@description('The location where the resources will be created.')\nparam location string = resourceGroup().location\n\n@description('Optional. The tags to be assigned to the created resources.')\nparam tags object = {}\n\n@description('The name of Cosmos DB resource.')\nparam cosmosDbName string\n\n@description('The name of Cosmos DB\\'s database.')\nparam cosmosDbDatabaseName string\n\n@description('The name of Cosmos DB\\'s collection.')\nparam cosmosDbCollectionName string\n\n// ------------------\n// RESOURCES\n// ------------------\nresource cosmosDbAccount 'Microsoft.DocumentDB/databaseAccounts@2022-08-15' = {\n  name: cosmosDbName\n  location: location\n  tags: tags\n  kind: 'GlobalDocumentDB'\n  properties: {\n    locations: [\n      {\n        locationName: location\n        failoverPriority: 0\n        isZoneRedundant: false\n      }\n    ]\n    databaseAccountOfferType: 'Standard'\n    publicNetworkAccess:'Enabled'\n  }\n}\n\nresource cosmosDbDatabase 'Microsoft.DocumentDB/databaseAccounts/sqlDatabases@2021-04-15' = {\n  name: cosmosDbDatabaseName\n  parent: cosmosDbAccount\n  tags: tags\n  properties: {\n    resource: {\n      id: cosmosDbDatabaseName\n    }\n  }\n}\n\nresource cosmosDbDatabaseCollection 'Microsoft.DocumentDB/databaseAccounts/sqlDatabases/containers@2021-05-15' = {\n  name: cosmosDbCollectionName\n  parent: cosmosDbDatabase\n  tags: tags\n  properties: {\n    resource: {\n      id: cosmosDbCollectionName\n      partitionKey: {\n        paths: [\n          '/partitionKey'\n        ]\n        kind: 'Hash'\n      }\n    }\n    options: {\n      autoscaleSettings: {\n        maxThroughput: 4000\n      }\n    }\n  }\n}\n\n// ------------------\n// OUTPUTS\n// ------------------\n\n@description('The name of Cosmos DB resource.')\noutput cosmosDbName string = cosmosDbAccount.name\n@description('The name of Cosmos DB\\'s database.')\noutput cosmosDbDatabaseName string = cosmosDbDatabase.name\n@description('The name of Cosmos DB\\'s collection.')\noutput cosmosDbCollectionName string = cosmosDbDatabaseCollection.name\n</code></pre> What we've added in the Bicep file above <ul> <li>This module will create the Azure CosmosDB account, a CosmosDB database, and a CosmosDB collection.</li> <li>The output of this module will return three output parameters which will be used as an input for a subsequent module.</li> </ul>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/#6-define-an-azure-storage-resource","title":"6. Define an Azure Storage Resource","text":"<p>Add file as shown below under the folder <code>bicep\\modules</code>:</p> storage-account.bicep <pre><code>targetScope = 'resourceGroup'\n\n// ------------------\n//    PARAMETERS\n// ------------------\n\n@description('The location where the resources will be created.')\nparam location string = resourceGroup().location\n\n@description('Optional. The tags to be assigned to the created resources.')\nparam tags object = {}\n\n@description('The name of the external Azure Storage Account.')\nparam storageAccountName string\n\n@description('The name of the external Queue in Azure Storage.')\nparam externalTasksQueueName string\n\n// ------------------\n// RESOURCES\n// ------------------\n\nresource storageAccount 'Microsoft.Storage/storageAccounts@2021-09-01' = {\n  name: storageAccountName\n  tags: tags\n  location: location\n  sku: {\n    name: 'Standard_LRS'\n  }\n  kind: 'StorageV2'\n}\n\nresource storageQueuesService 'Microsoft.Storage/storageAccounts/queueServices@2021-09-01' = {\n  name: 'default'\n  parent: storageAccount\n}\n\nresource externalQueue 'Microsoft.Storage/storageAccounts/queueServices/queues@2021-09-01' = {\n  name: externalTasksQueueName\n  parent: storageQueuesService\n}\n\n// ------------------\n// OUTPUTS\n// ------------------\n\n@description('The external storage account name.')\noutput storageAccountName string = storageAccount.name\n</code></pre> What we've added in the Bicep file above <ul> <li>This module will create the Azure Storage account, a storage queue service, and a queue.</li> <li>The output of this module will be a single output parameter which will be used as an input for a subsequent module.</li> </ul>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/#7-define-dapr-components","title":"7. Define Dapr Components","text":"<p>Next we will define all dapr components used in the solution in a single bicep module. To accomplish this, add a new file under the folder <code>bicep\\modules</code> as shown below:</p> dapr-components.bicep <pre><code>targetScope = 'resourceGroup'\n\n// ------------------\n//    PARAMETERS\n// ------------------\n\n@description('The name of the container apps environment.')\nparam containerAppsEnvironmentName string\n\n@description('The name of Dapr component for the secret store building block.')\n// We disable lint of this line as it is not a secret but the name of the Dapr component\n#disable-next-line secure-secrets-in-params\nparam secretStoreComponentName string\n\n@description('The name of the key vault resource.')\nparam keyVaultName string\n\n@description('The name of the service bus namespace.')\nparam serviceBusName string\n\n@description('The name of Cosmos DB resource.')\nparam cosmosDbName string\n\n@description('The name of Cosmos DB\\'s database.')\nparam cosmosDbDatabaseName string\n\n@description('The name of Cosmos DB\\'s collection.')\nparam cosmosDbCollectionName string\n\n@description('The name of the external Azure Storage Account.')\nparam storageAccountName string\n\n@description('The name of the external Queue in Azure Storage.')\nparam externalTasksQueueName string\n\n@description('The name of the external blob container in Azure Storage.')\nparam externalTasksContainerBlobName string\n\n@description('The name of the secret containing the External Azure Storage Access key.')\nparam externalStorageKeySecretName string\n\n@description('The name of the Send Grid Email From.')\nparam sendGridEmailFrom string\n\n@description('The name of the Send Grid Email From Name.')\nparam sendGridEmailFromName string\n\n@description('The name of the secret containing the SendGrid API key value.')\nparam sendGridKeySecretName string\n\n@description('The cron settings for scheduled job.')\nparam scheduledJobCron string \n\n@description('The name of the service for the backend api service. The name is used as Dapr App ID.')\nparam backendApiServiceName string\n\n@description('The name of the service for the backend processor service. The name is used as Dapr App ID and as the name of service bus topic subscription.')\nparam backendProcessorServiceName string\n\n// ------------------\n// RESOURCES\n// ------------------\n\nresource containerAppsEnvironment 'Microsoft.App/managedEnvironments@2022-03-01' existing = {\n  name: containerAppsEnvironmentName\n}\n\nresource cosmosDbAccount 'Microsoft.DocumentDB/databaseAccounts@2022-08-15' existing = {\n  name: cosmosDbName\n}\n\n//Secret Store Component\nresource secretstoreComponent 'Microsoft.App/managedEnvironments/daprComponents@2022-03-01' = {\n  name: secretStoreComponentName\n  parent: containerAppsEnvironment\n  properties: {\n    componentType: 'secretstores.azure.keyvault'\n    version: 'v1'\n    metadata: [\n      {\n        name: 'vaultName'\n        value: keyVaultName\n      }\n    ]\n    scopes: [\n      backendApiServiceName\n      backendProcessorServiceName\n    ]\n  }\n}\n\n//Cosmos DB State Store Component\nresource statestoreComponent 'Microsoft.App/managedEnvironments/daprComponents@2022-06-01-preview' = {\n  name: 'statestore'\n  parent: containerAppsEnvironment\n  properties: {\n    componentType: 'state.azure.cosmosdb'\n    version: 'v1'\n    secrets: [\n    ]\n    metadata: [\n      {\n        name: 'url'\n        value: cosmosDbAccount.properties.documentEndpoint\n      }\n      {\n        name: 'database'\n        value: cosmosDbDatabaseName\n      }\n      {\n        name: 'collection'\n        value: cosmosDbCollectionName\n      }\n    ]\n    scopes: [\n      backendApiServiceName\n    ]\n  }\n}\n\n//PubSub service bus Component\nresource pubsubComponent 'Microsoft.App/managedEnvironments/daprComponents@2022-06-01-preview' = {\n  name: 'dapr-pubsub-servicebus'\n  parent: containerAppsEnvironment\n  properties: {\n    componentType: 'pubsub.azure.servicebus'\n    version: 'v1'\n    secrets: [\n    ]\n    metadata: [\n      {\n        name: 'namespaceName'\n        value: '${serviceBusName}.servicebus.windows.net'\n      }\n      {\n        name: 'consumerID'\n        value: backendProcessorServiceName\n      }\n    ]\n    scopes: [\n      backendApiServiceName\n      backendProcessorServiceName\n    ]\n  }\n}\n\n//Scheduled Tasks Manager Component\nresource scheduledtasksmanagerDaprComponent 'Microsoft.App/managedEnvironments/daprComponents@2022-06-01-preview' = {\n  name: 'scheduledtasksmanager'\n  parent: containerAppsEnvironment\n  properties: {\n    componentType: 'bindings.cron'\n    version: 'v1'\n    metadata: [\n      {\n        name: 'schedule'\n        value: scheduledJobCron\n      }\n    ]\n    scopes: [\n      backendProcessorServiceName\n    ]\n  }\n}\n\n//External tasks manager Component (Storage Queue)\nresource externaltasksmanagerDaprComponent 'Microsoft.App/managedEnvironments/daprComponents@2022-06-01-preview' = {\n  name: 'externaltasksmanager'\n  parent: containerAppsEnvironment\n  properties: {\n    componentType: 'bindings.azure.storagequeues'\n    version: 'v1'\n    secretStoreComponent: secretStoreComponentName\n    metadata: [\n      {\n        name: 'storageAccount'\n        value: storageAccountName\n      }\n      {\n        name: 'queue'\n        value: externalTasksQueueName\n      }\n      {\n        name: 'decodeBase64'\n        value: 'true'\n      }\n      {\n        name: 'route'\n        value: '/externaltasksprocessor/process'\n      }\n      {\n        name: 'storageAccessKey'\n        secretRef: externalStorageKeySecretName\n      }\n    ]\n    scopes: [\n      backendProcessorServiceName\n    ]\n  }\n  dependsOn: [\n    secretstoreComponent\n  ]\n}\n\n//External tasks blob store Component (Blob Store)\nresource externaltasksblobstoreDaprComponent 'Microsoft.App/managedEnvironments/daprComponents@2022-06-01-preview' = {\n  name: 'externaltasksblobstore'\n  parent: containerAppsEnvironment\n  properties: {\n    componentType: 'bindings.azure.blobstorage'\n    version: 'v1'\n    secretStoreComponent: secretStoreComponentName\n    metadata: [\n      {\n        name: 'storageAccount'\n        value: storageAccountName\n      }\n      {\n        name: 'container'\n        value: externalTasksContainerBlobName\n      }\n      {\n        name: 'decodeBase64'\n        value: 'false'\n      }\n      {\n        name: 'publicAccessLevel'\n        value: 'none'\n      }\n      {\n        name: 'storageAccessKey'\n        secretRef: externalStorageKeySecretName\n      }\n    ]\n    scopes: [\n      backendProcessorServiceName\n    ]\n  }\n  dependsOn: [\n    secretstoreComponent\n  ]\n}\n\n//SendGrid outbound Component\nresource sendgridDaprComponent 'Microsoft.App/managedEnvironments/daprComponents@2022-06-01-preview' = {\n  name: 'sendgrid'\n  parent: containerAppsEnvironment\n  properties: {\n    componentType: 'bindings.twilio.sendgrid'\n    version: 'v1'\n    secretStoreComponent: secretStoreComponentName\n    metadata: [\n      {\n        name: 'emailFrom'\n        value: sendGridEmailFrom\n      }\n      {\n        name: 'emailFromName'\n        value: sendGridEmailFromName\n      }\n      {\n        name: 'apiKey'\n        secretRef: sendGridKeySecretName\n      }\n    ]\n    scopes: [\n      backendProcessorServiceName\n    ]\n  }\n  dependsOn:[\n    secretstoreComponent\n  ]\n}\n</code></pre> What we've added in the Bicep file above <ul> <li>This module will be responsible for creating all dapr components used in the solution. It accepts various input parameters needed by the dapr components.</li> <li> <p>Notice how we are using the keyword <code>existing</code> to obtain a strongly typed reference to the pre-created resource</p> <pre><code>resource containerAppsEnvironment 'Microsoft.App/managedEnvironments@2022-03-01' existing = {\nname: containerAppsEnvironmentName\n}\nresource cosmosDbAccount 'Microsoft.DocumentDB/databaseAccounts@2022-08-15' existing = {\nname: cosmosDbName\n}\n</code></pre> </li> </ul>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/#8-create-secrets-into-azure-key-vault","title":"8. Create Secrets Into Azure Key Vault","text":"<p>This module will have the responsibility of generating the secrets and saving them in Azure Key Vault. Additionally, it will establish a role assignment for the backend processor service, specifically of type <code>Azure Role Key Vault Secrets User</code>, which will allow the service to access the Key Vault and retrieve the secrets.</p> <p>To achieve this, create a new directory called <code>container-apps\\secrets</code> within the <code>modules</code> folder. Add new file as shown below under the folder <code>bicep\\modules\\container-apps\\secrets</code>:</p> processor-backend-service-secrets.bicep <pre><code>targetScope = 'resourceGroup'\n\n// ------------------\n//    PARAMETERS\n// ------------------\n\n@description('Optional. The tags to be assigned to the created resources.')\nparam tags object = {}\n\n@description('The name of the Key Vault.')\nparam keyVaultName string\n\n@description('The name of the secret containing the SendGrid API key value for the Backend Background Processor Service.')\nparam sendGridKeySecretName string\n\n@secure()\n@description('The SendGrid API key for for Backend Background Processor Service.')\nparam sendGridKeySecretValue string\n\n@description('The name of the secret containing the External Azure Sorage Access key for the Backend Background Processor Service.')\nparam externalAzureStorageKeySecretName string\n\n@secure()\n@description('The External Azure Stroage Access key for the Backend Background Processor Service.')\nparam externalAzureStorageKeySecretValue string\n\n@description('The principal ID of the Backend Processor Service.')\nparam backendProcessorServicePrincipalId string\n\n// ------------------\n// VARIABLES\n// ------------------\n\nvar keyVaultSecretUserRoleGuid = '4633458b-17de-408a-b874-0445c86b69e6'\n\n// ------------------\n// RESOURCES\n// ------------------\n\nresource keyVault 'Microsoft.KeyVault/vaults@2021-04-01-preview' existing = {\n  name: keyVaultName\n}\n\n// Send Grid API key secret used by Backend Background Processor Service.\nresource sendGridKeySecret 'Microsoft.KeyVault/vaults/secrets@2022-07-01' = {\n  parent: keyVault\n  tags: tags\n  name: sendGridKeySecretName\n  properties: {\n    value: sendGridKeySecretValue\n  }\n}\n\n// External Azure storage key secret used by Backend Background Processor Service.\nresource externalAzureStorageKeySecret 'Microsoft.KeyVault/vaults/secrets@2022-07-01' = {\n  parent: keyVault\n  tags: tags\n  name: externalAzureStorageKeySecretName\n  properties: {\n    value: externalAzureStorageKeySecretValue\n  }\n}\n\nresource keyVaultSecretUserRoleAssignment 'Microsoft.Authorization/roleAssignments@2022-04-01' = {\n  name: guid(subscription().id, keyVault.id, backendProcessorServicePrincipalId, keyVaultSecretUserRoleGuid) \n  scope: keyVault\n  properties: {\n    principalId: backendProcessorServicePrincipalId\n    roleDefinitionId: resourceId('Microsoft.Authorization/roleDefinitions', keyVaultSecretUserRoleGuid)\n    principalType: 'ServicePrincipal'\n  }\n}\n</code></pre>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/#9-define-the-frontend-service-azure-container-app","title":"9. Define the Frontend Service Azure Container App","text":"<p>We will now begin defining the modules that are necessary for producing the container apps, starting with the Frontend App. To initiate this process, add a new file under the folder <code>bicep\\modules\\container-apps</code> as shown below:</p> webapp-frontend-service.bicep <pre><code>targetScope = 'resourceGroup'\n\n// ------------------\n//    PARAMETERS\n// ------------------\n\n@description('The location where the resources will be created.')\nparam location string = resourceGroup().location\n\n@description('Optional. The tags to be assigned to the created resources.')\nparam tags object = {}\n\n@description('The resource Id of the container apps environment.')\nparam containerAppsEnvironmentId string\n\n@description('The name of the service for the frontend web app service. The name is use as Dapr App ID.')\nparam frontendWebAppServiceName string\n\n// Container Registry &amp; Image\n@description('The name of the container registry.')\nparam containerRegistryName string\n\n@description('The username of the container registry user.')\nparam containerRegistryUsername string\n\n@description('The password name of the container registry.')\n// We disable lint of this line as it is not a secret\n#disable-next-line secure-secrets-in-params\nparam containerRegistryPasswordRefName string\n\n@secure()\nparam containerRegistryPassword string\n\n@description('The image for the frontend web app service.')\nparam frontendWebAppServiceImage string\n\n@secure()\n@description('The Application Insights Instrumentation.')\nparam appInsightsInstrumentationKey string\n\n// ------------------\n// RESOURCES\n// ------------------\n\nresource frontendWebAppService 'Microsoft.App/containerApps@2022-06-01-preview' = {\n  name: frontendWebAppServiceName\n  location: location\n  tags: tags\n  properties: {\n    managedEnvironmentId: containerAppsEnvironmentId\n    configuration: {\n      activeRevisionsMode: 'single'\n      ingress: {\n        external: true\n        targetPort: 80\n      }\n      dapr: {\n        enabled: true\n        appId: frontendWebAppServiceName\n        appProtocol: 'http'\n        appPort: 80\n        logLevel: 'info'\n        enableApiLogging: true\n      }\n      secrets: [\n        {\n          name: 'appinsights-key'\n          value: appInsightsInstrumentationKey\n        }\n        {\n          name: containerRegistryPasswordRefName\n          value: containerRegistryPassword\n        }\n      ]\n      registries: [\n        {\n          server: '${containerRegistryName}.azurecr.io'\n          username: containerRegistryUsername\n          passwordSecretRef: containerRegistryPasswordRefName\n        }\n      ]\n    }\n    template: {\n      containers: [\n        {\n          name: frontendWebAppServiceName\n          image: frontendWebAppServiceImage\n          resources: {\n            cpu: json('0.25')\n            memory: '0.5Gi'\n          }\n          env: [\n            {\n              name: 'ApplicationInsights__InstrumentationKey'\n              secretRef: 'appinsights-key'\n            }\n          ]\n        }\n      ]\n      scale: {\n        minReplicas: 1\n        maxReplicas: 1\n      }\n    }\n  }\n}\n\n// ------------------\n// OUTPUTS\n// ------------------\n\n@description('The name of the container app for the frontend web app service.')\noutput frontendWebAppServiceContainerAppName string = frontendWebAppService.name\n\n@description('The FQDN of the frontend web app service.')\noutput frontendWebAppServiceFQDN string = frontendWebAppService.properties.configuration.ingress.fqdn\n</code></pre> What we've added in the Bicep file above <ul> <li>Observe the usage of the <code>@secure</code> attribute on input parameters that contain confidential information or keys. This attribute may be applied to both string and object parameters that encompass secretive values. By implementing this attribute, Azure will abstain from presenting the parameter values within the deployment logs or on the terminal if you happen to be utilizing Azure CLI.</li> <li>The output parameters of this module will provide the fully qualified domain name (FQDN) for the frontend container application.</li> </ul>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/#10-define-the-backend-api-service-azure-container-app","title":"10. Define the Backend Api Service Azure Container App","text":"<p>Add a new file under the folder <code>bicep\\modules\\container-apps</code> as shown below:</p> webapi-backend-service.bicep <pre><code>targetScope = 'resourceGroup'\n\n// ------------------\n//    PARAMETERS\n// ------------------\n\n@description('The location where the resources will be created.')\nparam location string = resourceGroup().location\n\n@description('Optional. The tags to be assigned to the created resources.')\nparam tags object = {}\n\n@description('The resource Id of the container apps environment.')\nparam containerAppsEnvironmentId string\n\n@description('The name of the service for the backend api service. The name is use as Dapr App ID.')\nparam backendApiServiceName string\n\n// Service Bus\n@description('The name of the service bus namespace.')\nparam serviceBusName string\n\n@description('The name of the service bus topic.')\nparam serviceBusTopicName string\n\n// Cosmos DB\n@description('The name of the provisioned Cosmos DB resource.')\nparam cosmosDbName string \n\n@description('The name of the provisioned Cosmos DB\\'s database.')\nparam cosmosDbDatabaseName string\n\n@description('The name of Cosmos DB\\'s collection.')\nparam cosmosDbCollectionName string\n\n// Container Registry &amp; Image\n@description('The name of the container registry.')\nparam containerRegistryName string\n\n@description('The username of the container registry user.')\nparam containerRegistryUsername string\n\n@description('The password name of the container registry.')\n// We disable lint of this line as it is not a secret\n#disable-next-line secure-secrets-in-params\nparam containerRegistryPasswordRefName string\n\n@secure()\nparam containerRegistryPassword string \n\n@description('The image for the backend api service.')\nparam backendApiServiceImage string\n\n@secure()\n@description('The Application Insights Instrumentation.')\nparam appInsightsInstrumentationKey string\n\n// ------------------\n// RESOURCES\n// ------------------\n\nresource serviceBusNamespace 'Microsoft.ServiceBus/namespaces@2021-11-01' existing = {\n  name: serviceBusName\n}\n\nresource serviceBusTopic 'Microsoft.ServiceBus/namespaces/topics@2021-11-01' existing = {\n  name: serviceBusTopicName\n  parent: serviceBusNamespace\n}\n\nresource cosmosDbAccount 'Microsoft.DocumentDB/databaseAccounts@2022-08-15' existing = {\n  name: cosmosDbName\n}\n\nresource cosmosDbDatabase 'Microsoft.DocumentDB/databaseAccounts/sqlDatabases@2021-04-15' existing = {\n  name: cosmosDbDatabaseName\n  parent: cosmosDbAccount\n}\n\nresource cosmosDbDatabaseCollection 'Microsoft.DocumentDB/databaseAccounts/sqlDatabases/containers@2021-05-15' existing = {\n  name: cosmosDbCollectionName\n  parent: cosmosDbDatabase\n}\n\nresource backendApiService 'Microsoft.App/containerApps@2022-06-01-preview' = {\n  name: backendApiServiceName\n  location: location\n  tags: tags\n  identity: {\n    type: 'SystemAssigned'\n  }\n  properties: {\n    managedEnvironmentId: containerAppsEnvironmentId\n    configuration: {\n      activeRevisionsMode: 'single'\n      ingress: {\n        external: false\n        targetPort: 80\n      }\n      dapr: {\n        enabled: true\n        appId: backendApiServiceName\n        appProtocol: 'http'\n        appPort: 80\n        logLevel: 'info'\n        enableApiLogging: true\n      }\n      registries: [\n        {\n          server: '${containerRegistryName}.azurecr.io'\n          username: containerRegistryUsername\n          passwordSecretRef: containerRegistryPasswordRefName\n        }\n      ]\n      secrets: [\n        {\n          name: 'appinsights-key'\n          value: appInsightsInstrumentationKey\n        }\n        {\n          name: containerRegistryPasswordRefName\n          value: containerRegistryPassword\n        }\n      ]\n    }\n    template: {\n      containers: [\n        {\n          name: backendApiServiceName\n          image: backendApiServiceImage\n          resources: {\n            cpu: json('0.25')\n            memory: '0.5Gi'\n          }\n          env: [\n            {\n              name: 'ApplicationInsights__InstrumentationKey'\n              secretRef: 'appinsights-key'\n            }\n          ]\n        }\n      ]\n      scale: {\n        minReplicas: 1\n        maxReplicas: 1\n      }\n    }\n  }\n}\n\n// Assign cosmosdb account read/write access to aca system assigned identity\n// To know more: https://learn.microsoft.com/en-us/azure/cosmos-db/how-to-setup-rbac\nresource backendApiService_cosmosdb_role_assignment 'Microsoft.DocumentDB/databaseAccounts/sqlRoleAssignments@2022-08-15' = {\n  name: guid(subscription().id, backendApiService.name, '00000000-0000-0000-0000-000000000002')\n  parent: cosmosDbAccount\n  properties: {\n    principalId: backendApiService.identity.principalId\n    roleDefinitionId:  resourceId('Microsoft.DocumentDB/databaseAccounts/sqlRoleDefinitions', cosmosDbAccount.name, '00000000-0000-0000-0000-000000000002')//DocumentDB Data Contributor\n    scope: '${cosmosDbAccount.id}/dbs/${cosmosDbDatabase.name}/colls/${cosmosDbDatabaseCollection.name}'\n  }\n}\n\n// Enable publish message to Service Bus using app managed identity.\nresource backendApiService_sb_role_assignment 'Microsoft.Authorization/roleAssignments@2020-04-01-preview' = {\n  name: guid(resourceGroup().id, backendApiService.name, '69a216fc-b8fb-44d8-bc22-1f3c2cd27a39')\n  properties: {\n    principalId: backendApiService.identity.principalId\n    roleDefinitionId: resourceId('Microsoft.Authorization/roleDefinitions', '69a216fc-b8fb-44d8-bc22-1f3c2cd27a39')//Azure Service Bus Data Sender\n    principalType: 'ServicePrincipal'\n  }\n  scope: serviceBusTopic\n}\n\n// ------------------\n// OUTPUTS\n// ------------------\n\n@description('The name of the container app for the backend api service.')\noutput backendApiServiceContainerAppName string = backendApiService.name\n\n@description('The FQDN of the backend api service.')\noutput backendApiServiceFQDN string = backendApiService.properties.configuration.ingress.fqdn\n</code></pre> What we've added in the Bicep file above <ul> <li> <p>Notice how we are assigning the Cosmosdb account a read/write access using the <code>Cosmos DB Built-in Data Contributor</code> role to the Backend API system assigned identity, by using the code below:</p> <pre><code>resource backendApiService_cosmosdb_role_assignment 'Microsoft.DocumentDB/databaseAccounts/sqlRoleAssignments@2022-08-15' = {\nname: guid(subscription().id, backendApiService.name, '00000000-0000-0000-0000-000000000002')\nparent: cosmosDbAccount\nproperties: {\nprincipalId: backendApiService.identity.principalId\n    roleDefinitionId:  resourceId('Microsoft.DocumentDB/databaseAccounts/sqlRoleDefinitions', cosmosDbAccount.name, '00000000-0000-0000-0000-000000000002')//DocumentDB Data Contributor\n    scope: '${cosmosDbAccount.id}/dbs/${cosmosDbDatabase.name}/colls/${cosmosDbDatabaseCollection.name}'\n}\n</code></pre> </li> <li> <p>A similar technique was applied when assigning the Azure Service Bus Data Sender role to the Backend API, enabling it to publish messages to Azure Service Bus utilizing the Backend API system-assigned identity. This was accomplished utilizing the following code:     <pre><code>resource backendApiService_sb_role_assignment 'Microsoft.Authorization/roleAssignments@2020-04-01-preview' = {\nname: guid(resourceGroup().id, backendApiService.name, '69a216fc-b8fb-44d8-bc22-1f3c2cd27a39')\nproperties: {\nprincipalId: backendApiService.identity.principalId\n    roleDefinitionId: resourceId('Microsoft.Authorization/roleDefinitions', '69a216fc-b8fb-44d8-bc22-1f3c2cd27a39')//Azure Service Bus Data Sender\n    principalType: 'ServicePrincipal'\n}\nscope: serviceBusTopic\n}\n</code></pre></p> </li> </ul>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/#11-define-the-backend-processor-service-azure-container-app","title":"11. Define the Backend Processor Service Azure Container App","text":"<p>Add a new file under the folder <code>bicep\\modules\\container-apps</code> as shown below:</p> processor-backend-service.bicep <pre><code>targetScope = 'resourceGroup'\n\n// ------------------\n//    PARAMETERS\n// ------------------\n\n@description('The location where the resources will be created.')\nparam location string = resourceGroup().location\n\n@description('Optional. The tags to be assigned to the created resources.')\nparam tags object = {}\n\n@description('The resource Id of the container apps environment.')\nparam containerAppsEnvironmentId string\n\n@description('The name of the service for the backend processor service. The name is use as Dapr App ID and as the name of service bus topic subscription.')\nparam backendProcessorServiceName string\n\n// Key Vault\n@description('The resource ID of the key vault to store the license key for the backend processor service.')\nparam keyVaultId string\n\n@description('The name of the secret containing the SendGrid API key value for the Backend Background Processor Service.')\nparam sendGridKeySecretName string\n\n@secure()\n@description('The SendGrid API key for for Backend Background Processor Service.')\nparam sendGridKeySecretValue string\n\n@description('The name of the secret containing the External Azure Storage Access key for the Backend Background Processor Service.')\nparam externalStorageKeySecretName string\n\n@secure()\n@description('The Application Insights Instrumentation.')\nparam appInsightsInstrumentationKey string\n\n// Service Bus\n@description('The name of the service bus namespace.')\nparam serviceBusName string\n\n@description('The name of the service bus topic.')\nparam serviceBusTopicName string\n\n@description('The name of the service bus topic\\'s authorization rule.')\nparam serviceBusTopicAuthorizationRuleName string\n\n// External Storage\n@description('The name of the external Azure Storage Account.')\nparam externalStorageAccountName string\n\n// Container Registry &amp; Image\n@description('The name of the container registry.')\nparam containerRegistryName string\n\n@description('The username of the container registry user.')\nparam containerRegistryUsername string\n\n@description('The password name of the container registry.')\n// We disable lint of this line as it is not a secret\n#disable-next-line secure-secrets-in-params\nparam containerRegistryPasswordRefName string\n\n@secure()\nparam containerRegistryPassword string\n\n@description('The image for the backend processor service.')\nparam backendProcessorServiceImage string\n\n// ------------------\n// VARIABLES\n// ------------------\n\nvar keyVaultIdTokens = split(keyVaultId, '/')\nvar keyVaultSubscriptionId = keyVaultIdTokens[2]\nvar keyVaultResourceGroupName = keyVaultIdTokens[4]\nvar keyVaultName = keyVaultIdTokens[8]\n\n// ------------------\n// RESOURCES\n// ------------------\n\nresource serviceBusNamespace 'Microsoft.ServiceBus/namespaces@2021-11-01' existing = {\n  name: serviceBusName\n}\n\nresource serviceBusTopic 'Microsoft.ServiceBus/namespaces/topics@2021-11-01' existing = {\n  name: serviceBusTopicName\n  parent: serviceBusNamespace\n}\n\nresource serviceBusTopicAuthorizationRule 'Microsoft.ServiceBus/namespaces/topics/authorizationRules@2021-11-01' existing = {\n  name: serviceBusTopicAuthorizationRuleName\n  parent: serviceBusTopic\n}\n\nresource storageAccount 'Microsoft.Storage/storageAccounts@2021-09-01' existing = {\n  name: externalStorageAccountName\n}\n\nresource backendProcessorService 'Microsoft.App/containerApps@2022-06-01-preview' = {\n  name: backendProcessorServiceName\n  location: location\n  tags: tags\n  identity: {\n    type: 'SystemAssigned'\n  }\n  properties: {\n    managedEnvironmentId: containerAppsEnvironmentId\n    configuration: {\n      activeRevisionsMode: 'single'\n      dapr: {\n        enabled: true\n        appId: backendProcessorServiceName\n        appProtocol: 'http'\n        appPort: 80\n        logLevel: 'info'\n        enableApiLogging: true\n      }\n      secrets: [\n        {\n          name: 'svcbus-connstring'\n          value: serviceBusTopicAuthorizationRule.listKeys().primaryConnectionString\n        }\n        {\n          name: 'appinsights-key'\n          value: appInsightsInstrumentationKey\n        }\n        {\n          name: containerRegistryPasswordRefName\n          value: containerRegistryPassword\n        }\n      ]\n      registries: [\n        {\n          server: '${containerRegistryName}.azurecr.io'\n          username: containerRegistryUsername\n          passwordSecretRef: containerRegistryPasswordRefName\n        }\n      ]\n    }\n    template: {\n      containers: [\n        {\n          name: backendProcessorServiceName\n          image: backendProcessorServiceImage\n          resources: {\n            cpu: json('0.25')\n            memory: '0.5Gi'\n          }\n          env: [\n            {\n              name: 'SendGrid__IntegrationEnabled'\n              value: 'true'\n            }\n            {\n              name: 'ApplicationInsights__InstrumentationKey'\n              secretRef: 'appinsights-key'\n            }\n          ]\n        }\n      ]\n      scale: {\n        minReplicas: 1\n        maxReplicas: 5\n        rules: [\n          {\n            name: 'topic-msgs-length'\n            custom: {\n              type: 'azure-servicebus'\n              auth: [\n                {\n                  secretRef: 'svcbus-connstring'\n                  triggerParameter: 'connection'\n                }\n              ]\n              metadata: {\n                namespace: serviceBusName\n                subscriptionName: backendProcessorServiceName\n                topicName: serviceBusTopicName\n                messageCount: '10'\n                connectionFromEnv: 'svcbus-connstring'\n              }\n            }\n          }\n        ]\n      }\n    }\n  }\n}\n\n// Enable consume from servicebus using system managed identity.\nresource backendProcessorService_sb_role_assignment 'Microsoft.Authorization/roleAssignments@2020-04-01-preview' = {\n  name: guid(resourceGroup().id, backendProcessorServiceName, '4f6d3b9b-027b-4f4c-9142-0e5a2a2247e0')\n  properties: {\n    principalId: backendProcessorService.identity.principalId\n    roleDefinitionId: resourceId('Microsoft.Authorization/roleDefinitions', '4f6d3b9b-027b-4f4c-9142-0e5a2a2247e0') // Azure Service Bus Data Receiver.\n    principalType: 'ServicePrincipal'\n  } \n  scope: serviceBusNamespace\n}\n\n// Invoke create secrets and assign role 'Azure Role Key Vault Secrets User' to the backend processor service\nmodule backendProcessorKeySecret 'secrets/processor-backend-service-secrets.bicep' = {\n  name: 'backendProcessorKeySecret-${uniqueString(resourceGroup().id)}'\n  params: {\n    keyVaultName: keyVaultName\n    sendGridKeySecretName: sendGridKeySecretName\n    sendGridKeySecretValue: sendGridKeySecretValue\n    externalAzureStorageKeySecretName: externalStorageKeySecretName\n    externalAzureStorageKeySecretValue: storageAccount.listKeys().keys[0].value\n    backendProcessorServicePrincipalId: backendProcessorService.identity.principalId\n  }\n  scope: resourceGroup(keyVaultSubscriptionId, keyVaultResourceGroupName)\n}\n\n// ------------------\n// OUTPUTS\n// ------------------\n\n@description('The name of the container app for the backend processor service.')\noutput backendProcessorServiceContainerAppName string = backendProcessorService.name\n</code></pre> What we've added in the Bicep file above <ul> <li>Notice how we are assigning the role <code>Azure Service Bus Data Receiver</code> to the Backend Processor to be able to consume/read messages from Azure Service Bus Topic using Backend Processor system assigned identity, by using the code below:     <pre><code>resource backendProcessorService_sb_role_assignment 'Microsoft.Authorization/roleAssignments@2020-04-01-preview' = {\nname: guid(resourceGroup().id, backendProcessorServiceName, '4f6d3b9b-027b-4f4c-9142-0e5a2a2247e0')\nproperties: {\nprincipalId: backendProcessorService.identity.principalId\n    roleDefinitionId: resourceId('Microsoft.Authorization/roleDefinitions', '4f6d3b9b-027b-4f4c-9142-0e5a2a2247e0') // Azure Service Bus Data Receiver.\n    principalType: 'ServicePrincipal'\n} scope: serviceBusNamespace\n}\n</code></pre></li> <li>Within this module, we've invoked the module defined in step 8 which is responsible to create the secrets in Azure Key Vault and assign the role <code>Azure Role Key Vault Secrets User</code> to the Backend Processor Service, by using the code below:     <pre><code>module backendProcessorKeySecret 'secrets/processor-backend-service-secrets.bicep' = {\nname: 'backendProcessorKeySecret-${uniqueString(resourceGroup().id)}'\nparams: {\nkeyVaultName: keyVaultName\n    sendGridKeySecretName: sendGridKeySecretName\n    sendGridKeySecretValue: sendGridKeySecretValue\n    externalAzureStorageKeySecretName: externalStorageKeySecretName\n    externalAzureStorageKeySecretValue: storageAccount.listKeys().keys[0].value\n    backendProcessorServicePrincipalId: backendProcessorService.identity.principalId\n}\nscope: resourceGroup(keyVaultSubscriptionId, keyVaultResourceGroupName)\n}\n</code></pre></li> </ul>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/#12-define-a-container-module-for-the-three-container-apps","title":"12. Define a Container Module For the Three Container Apps","text":"<p>This module will act as a container for the three Container Apps modules defined in the previous three steps. It is optional to create it, but it makes it easier when we invoke all the created modules as you  will see in the next step. </p> <p>Add a new file under the folder <code>bicep\\modules</code> as shown below:</p> container-apps.bicep <pre><code>targetScope = 'resourceGroup'\n\n// ------------------\n//    PARAMETERS\n// ------------------\n\n@description('The location where the resources will be created.')\nparam location string = resourceGroup().location\n\n@description('The tags to be assigned to the created resources.')\nparam tags object = {}\n\n@description('The name of the container apps environment.')\nparam containerAppsEnvironmentName string\n\n// Services\n@description('The name of the service for the backend api service. The name is use as Dapr App ID.')\nparam backendApiServiceName string\n\n@description('The name of the service for the backend processor service. The name is use as Dapr App ID and as the name of service bus topic subscription.')\nparam backendProcessorServiceName string\n\n@description('The name of the service for the frontend web app service. The name is use as Dapr App ID.')\nparam frontendWebAppServiceName string\n\n// Service Bus\n@description('The name of the service bus namespace.')\nparam serviceBusName string\n\n@description('The name of the service bus topic.')\nparam serviceBusTopicName string\n\n@description('The name of the service bus topic\\'s authorization rule.')\nparam serviceBusTopicAuthorizationRuleName string\n\n// Cosmos DB\n@description('The name of the provisioned Cosmos DB resource.')\nparam cosmosDbName string \n\n@description('The name of the provisioned Cosmos DB\\'s database.')\nparam cosmosDbDatabaseName string\n\n@description('The name of Cosmos DB\\'s collection.')\nparam cosmosDbCollectionName string\n\n// Key Vault\n@description('The resource ID of the key vault.')\nparam keyVaultId string\n\n@description('The name of the secret containing the SendGrid API key value for the Backend Background Processor Service.')\nparam sendGridKeySecretName string\n\n@secure()\n@description('The SendGrid API key for for Backend Background Processor Service.')\nparam sendGridKeySecretValue string\n\n@description('The name of the secret containing the External Azure Storage Access key for the Backend Background Processor Service.')\nparam externalStorageKeySecretName string\n\n// External Storage\n@description('The name of the external Azure Storage Account.')\nparam externalStorageAccountName string\n\n// Container Registry &amp; Images\n@description('The name of the container registry.')\nparam containerRegistryName string\n\n@description('The username of the container registry user.')\nparam containerRegistryUsername string\n\n// We disable lint of this line as it is not a secret\n#disable-next-line secure-secrets-in-params\nparam containerRegistryPasswordRefName string\n\n@secure()\nparam containerRegistryPassword string\n\n@description('The image for the backend api service.')\nparam backendApiServiceImage string\n\n@description('The image for the backend processor service.')\nparam backendProcessorServiceImage string\n\n@description('The image for the frontend web app service.')\nparam frontendWebAppServiceImage string\n\n@description('The name of the application insights.')\nparam applicationInsightsName string\n\n// ------------------\n// RESOURCES\n// ------------------\n\nresource containerAppsEnvironment 'Microsoft.App/managedEnvironments@2022-03-01' existing = {\n  name: containerAppsEnvironmentName\n}\n\n//Reference to AppInsights resource\nresource applicationInsights 'Microsoft.Insights/components@2020-02-02' existing = {\n  name: applicationInsightsName\n}\n\nmodule frontendWebAppService 'container-apps/webapp-frontend-service.bicep' = {\n  name: 'frontendWebAppService-${uniqueString(resourceGroup().id)}'\n  params: {\n    frontendWebAppServiceName: frontendWebAppServiceName\n    location: location\n    tags: tags\n    containerAppsEnvironmentId: containerAppsEnvironment.id\n    containerRegistryName: containerRegistryName\n    containerRegistryUsername: containerRegistryUsername\n    containerRegistryPasswordRefName: containerRegistryPasswordRefName\n    containerRegistryPassword: containerRegistryPassword\n    frontendWebAppServiceImage: frontendWebAppServiceImage\n    appInsightsInstrumentationKey: applicationInsights.properties.InstrumentationKey\n  }\n}\n\nmodule backendApiService 'container-apps/webapi-backend-service.bicep' = {\n  name: 'backendApiService-${uniqueString(resourceGroup().id)}'\n  params: {\n    backendApiServiceName: backendApiServiceName\n    location: location\n    tags: tags\n    containerAppsEnvironmentId: containerAppsEnvironment.id\n    serviceBusName: serviceBusName\n    serviceBusTopicName: serviceBusTopicName\n    containerRegistryName: containerRegistryName\n    containerRegistryUsername: containerRegistryUsername\n    containerRegistryPasswordRefName: containerRegistryPasswordRefName\n    containerRegistryPassword: containerRegistryPassword\n    backendApiServiceImage: backendApiServiceImage\n    cosmosDbName: cosmosDbName\n    cosmosDbDatabaseName: cosmosDbDatabaseName\n    cosmosDbCollectionName: cosmosDbCollectionName\n    appInsightsInstrumentationKey: applicationInsights.properties.InstrumentationKey\n  }\n}\n\nmodule backendProcessorService 'container-apps/processor-backend-service.bicep' = {\n  name: 'backendProcessorService-${uniqueString(resourceGroup().id)}'\n  params: {\n    backendProcessorServiceName: backendProcessorServiceName\n    location: location\n    tags: tags\n    containerAppsEnvironmentId: containerAppsEnvironment.id\n    keyVaultId: keyVaultId\n    serviceBusName: serviceBusName\n    serviceBusTopicName: serviceBusTopicName\n    serviceBusTopicAuthorizationRuleName: serviceBusTopicAuthorizationRuleName\n    containerRegistryName: containerRegistryName\n    containerRegistryUsername: containerRegistryUsername\n    containerRegistryPasswordRefName: containerRegistryPasswordRefName\n    containerRegistryPassword: containerRegistryPassword\n    sendGridKeySecretName: sendGridKeySecretName\n    sendGridKeySecretValue: sendGridKeySecretValue\n    externalStorageAccountName: externalStorageAccountName\n    externalStorageKeySecretName:externalStorageKeySecretName\n    backendProcessorServiceImage: backendProcessorServiceImage\n    appInsightsInstrumentationKey: applicationInsights.properties.InstrumentationKey\n  }\n}\n\n// ------------------\n// OUTPUTS\n// ------------------\n\n@description('The name of the container app for the backend processor service.')\noutput backendProcessorServiceContainerAppName string = backendProcessorService.outputs.backendProcessorServiceContainerAppName\n\n@description('The name of the container app for the backend api service.')\noutput backendApiServiceContainerAppName string = backendApiService.outputs.backendApiServiceContainerAppName\n\n@description('The name of the container app for the front end web app service.')\noutput frontendWebAppServiceContainerAppName string = frontendWebAppService.outputs.frontendWebAppServiceContainerAppName\n\n@description('The FQDN of the front end web app.')\noutput frontendWebAppServiceFQDN string = frontendWebAppService.outputs.frontendWebAppServiceFQDN\n\n@description('The FQDN of the backend web app')\noutput backendApiServiceFQDN string  = backendApiService.outputs.backendApiServiceFQDN\n</code></pre>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/#13-define-the-main-module-for-the-solution","title":"13. Define the Main Module For the Solution","text":"<p>Finally, we must specify the Main Bicep module that will connect all other modules together. This file will be referenced by the AZ CLI command when producing all resources.</p> <p>To achieve this, add a new file under the <code>bicep</code> directory as shown below:</p> main.bicep <pre><code>targetScope = 'resourceGroup'\n\n// ------------------\n//    PARAMETERS\n// ------------------\n\n@description('The location where the resources will be created.')\nparam location string = resourceGroup().location\n\n@description('Optional. The prefix to be used for all resources created by this template.')\nparam prefix string = ''\n\n@description('Optional. The suffix to be used for all resources created by this template.')\nparam suffix string = ''\n\n@description('Optional. The tags to be assigned to the created resources.')\nparam tags object = {}\n\n// Container Apps Env / Log Analytics Workspace / Application Insights\n@description('Optional. The name of the container apps environment. If set, it overrides the name generated by the template.')\nparam containerAppsEnvironmentName string = '${prefix}cae-${uniqueString(resourceGroup().id)}${suffix}'\n\n@description('Optional. The name of the log analytics workspace. If set, it overrides the name generated by the template.')\nparam logAnalyticsWorkspaceName string = '${prefix}log-${uniqueString(resourceGroup().id)}${suffix}'\n\n@description('Optional. The name of the application insights. If set, it overrides the name generated by the template.')\nparam applicationInsightName string = '${prefix}appi-${uniqueString(resourceGroup().id)}${suffix}'\n\n// Servivces\n@description('The name of the service for the backend processor service. The name is use as Dapr App ID and as the name of service bus topic subscription.')\nparam backendProcessorServiceName string\n\n@description('The name of the service for the backend api service. The name is use as Dapr App ID.')\nparam backendApiServiceName string\n\n@description('The name of the service for the frontend web app service. The name is use as Dapr App ID.')\nparam frontendWebAppServiceName string\n\n// Service Bus\n@description('Optional. The name of the service bus namespace. If set, it overrides the name generated by the template.')\nparam serviceBusName string = '${prefix}sb-${uniqueString(resourceGroup().id)}${suffix}'\n\n@description('The name of the service bus topic.')\nparam serviceBusTopicName string\n\n@description('The name of the service bus topic\\'s authorization rule.')\nparam serviceBusTopicAuthorizationRuleName string\n\n// Cosmos DB\n@description('Optional. The name of Cosmos DB resource. If set, it overrides the name generated by the template.')\nparam cosmosDbName string ='${prefix}cosno-${uniqueString(resourceGroup().id)}${suffix}'\n\n@description('The name of Cosmos DB\\'s database.')\nparam cosmosDbDatabaseName string\n\n@description('The name of Cosmos DB\\'s collection.')\nparam cosmosDbCollectionName string\n\n// Azure Stroage\n@description('The name of the external Azure Storage Account.')\nparam storageAccountName string = '${prefix}storage${uniqueString(resourceGroup().id)}${suffix}'\n\n@description('The name of the external Queue in Azure Storage.')\nparam externalTasksQueueName string\n\n@description('The name of the external blob container in Azure Storage.')\nparam externalTasksContainerBlobName string\n\n@description('The name of the secret containing the External Azure Storage Access key for the Backend Background Processor Service.')\nparam externalStorageKeySecretName string \n\n//Send grid\n@description('The name of the secret containing the SendGrid API key value for the Backend Background Processor Service.')\nparam sendGridKeySecretName string\n\n@description('The name of the Send Grid Email From.')\nparam sendGridEmailFrom string\n\n@description('The name of the Send Grid Email From Name.')\nparam sendGridEmailFromName string\n\n//Cron Shedule Jon\n@description('The cron settings for scheduled job.')\nparam scheduledJobCron string\n\n@secure()\n@description('The SendGrid API key for for Backend Background Processor Service.')\nparam sendGridKeySecretValue string\n\n// Dapr components\n@description('The name of Dapr component for the secret store building block.')\n// We disable lint of this line as it is not a secret but the name of the Dapr component\n#disable-next-line secure-secrets-in-params\nparam secretStoreComponentName string\n\n@description('The key vault name store secrets')\nparam keyVaultName string = '${prefix}kv-${uniqueString(resourceGroup().id)}${suffix}'\n\n// Container Registry &amp; Images\n@description('The name of the container registry.')\nparam containerRegistryName string\n\n@description('The username of the container registry user.')\nparam containerRegistryUsername string\n\n@description('The password name of the container registry.')\n// We disable lint of this line as it is not a secret\n#disable-next-line secure-secrets-in-params\nparam containerRegistryPasswordRefName string\n\n@secure()\nparam containerRegistryPassword string\n\n@description('The image for the backend processor service.')\nparam backendProcessorServiceImage string\n\n@description('The image for the backend api service.')\nparam backendApiServiceImage string\n\n@description('The image for the frontend web app service.')\nparam frontendWebAppServiceImage string\n\n// ------------------\n// RESOURCES\n// ------------------\n\nmodule containerAppsEnvironment 'modules/container-apps-environment.bicep' ={\n  name: 'containerAppsEnv-${uniqueString(resourceGroup().id)}'\n  params: {\n   containerAppsEnvironmentName: containerAppsEnvironmentName\n   logAnalyticsWorkspaceName: logAnalyticsWorkspaceName\n   applicationInsightName: applicationInsightName\n    location: location\n    tags: tags\n  }\n}\n\nmodule keyVault 'modules/key-vault.bicep' = {\n  name: 'keyVault-${uniqueString(resourceGroup().id)}'\n  params: {\n    keyVaultName: keyVaultName\n    location: location\n    tags: tags\n  }\n}\n\nmodule serviceBus 'modules/service-bus.bicep' = {\n  name: 'serviceBus-${uniqueString(resourceGroup().id)}'\n  params: {\n    serviceBusName: serviceBusName\n    location: location\n    tags: tags\n    serviceBusTopicName: serviceBusTopicName\n    serviceBusTopicAuthorizationRuleName: serviceBusTopicAuthorizationRuleName\n    backendProcessorServiceName: backendProcessorServiceName\n  }\n}\n\nmodule cosmosDb 'modules/cosmos-db.bicep' = {\n  name: 'cosmosDb-${uniqueString(resourceGroup().id)}'\n  params: {\n    cosmosDbName: cosmosDbName\n    location: location\n    tags: tags\n    cosmosDbDatabaseName: cosmosDbDatabaseName\n    cosmosDbCollectionName: cosmosDbCollectionName \n  }\n}\n\nmodule externalStorageAccount 'modules/storage-account.bicep' = {\n  name: 'storageAccount-${uniqueString(resourceGroup().id)}'\n  params: {\n    storageAccountName: storageAccountName\n    externalTasksQueueName: externalTasksQueueName\n    location: location\n    tags: tags\n  }\n}\n\nmodule daprComponents 'modules/dapr-components.bicep' = {\n  name: 'daprComponents-${uniqueString(resourceGroup().id)}'\n  params: {\n    secretStoreComponentName: secretStoreComponentName \n    containerAppsEnvironmentName: containerAppsEnvironmentName    \n    keyVaultName: keyVaultName    \n    serviceBusName: serviceBus.outputs.serviceBusName\n    cosmosDbName: cosmosDb.outputs.cosmosDbName\n    cosmosDbDatabaseName: cosmosDb.outputs.cosmosDbDatabaseName\n    cosmosDbCollectionName: cosmosDb.outputs.cosmosDbCollectionName    \n    backendApiServiceName: backendApiServiceName\n    backendProcessorServiceName: backendProcessorServiceName\n    storageAccountName: storageAccountName\n    sendGridKeySecretName: sendGridKeySecretName\n    sendGridEmailFrom: sendGridEmailFrom\n    sendGridEmailFromName: sendGridEmailFromName\n    scheduledJobCron: scheduledJobCron\n    externalTasksQueueName: externalTasksQueueName\n    externalTasksContainerBlobName: externalTasksContainerBlobName\n    externalStorageKeySecretName: externalStorageKeySecretName\n  }\n  dependsOn: [\n    containerAppsEnvironment\n  ]\n}\n\nmodule containerApps 'modules/container-apps.bicep' = {\n  name: 'containerApps-${uniqueString(resourceGroup().id)}'\n  params: {\n    location: location\n    tags: tags\n    backendProcessorServiceName: backendProcessorServiceName\n    backendApiServiceName: backendApiServiceName\n    frontendWebAppServiceName: frontendWebAppServiceName    \n    containerAppsEnvironmentName: containerAppsEnvironmentName\n    containerRegistryUsername: containerRegistryUsername\n    containerRegistryPasswordRefName: containerRegistryPasswordRefName\n    containerRegistryPassword: containerRegistryPassword\n    keyVaultId: keyVault.outputs.keyVaultId\n    serviceBusName: serviceBus.outputs.serviceBusName\n    serviceBusTopicName: serviceBus.outputs.serviceBusTopicName\n    serviceBusTopicAuthorizationRuleName: serviceBus.outputs.serviceBusTopicAuthorizationRuleName    \n    cosmosDbName: cosmosDb.outputs.cosmosDbName\n    cosmosDbDatabaseName: cosmosDb.outputs.cosmosDbDatabaseName\n    cosmosDbCollectionName: cosmosDb.outputs.cosmosDbCollectionName    \n    containerRegistryName: containerRegistryName\n    backendProcessorServiceImage: backendProcessorServiceImage\n    backendApiServiceImage: backendApiServiceImage\n    frontendWebAppServiceImage: frontendWebAppServiceImage\n    sendGridKeySecretName: sendGridKeySecretName\n    sendGridKeySecretValue: sendGridKeySecretValue\n    applicationInsightsName: containerAppsEnvironment.outputs.applicationInsightsName\n    externalStorageAccountName: externalStorageAccount.outputs.storageAccountName\n    externalStorageKeySecretName: externalStorageKeySecretName\n  }\n  dependsOn: [\n    daprComponents\n  ]\n}\n\n// ------------------\n// OUTPUTS\n// ------------------\n\n@description('The name of the container app for the backend processor service.')\noutput backendProcessorServiceContainerAppName string = containerApps.outputs.backendProcessorServiceContainerAppName\n\n@description('The name of the container app for the backend api service.')\noutput backendApiServiceContainerAppName string = containerApps.outputs.backendApiServiceContainerAppName\n\n@description('The name of the container app for the front end web app service.')\noutput frontendWebAppServiceContainerAppName string = containerApps.outputs.frontendWebAppServiceContainerAppName\n\n@description('The FQDN of the front end web app.')\noutput frontendWebAppServiceFQDN string = containerApps.outputs.frontendWebAppServiceFQDN\n\n@description('The FQDN of the backend web app')\noutput backendApiServiceFQDN string  = containerApps.outputs.backendApiServiceFQDN\n</code></pre> What we've added in the Bicep file above <ul> <li> <p>When calling the module <code>dapr-components.bicep</code> we are setting the value of the array <code>dependsOn</code> to the Container Apps Environment. This is called explicit dependency which aids the Bicep interpreter in comprehending the relationships between components. In this instance, the Container Apps Environment must be provisioned before the Dapr Components to guarantee a successful deployment.</p> </li> <li> <p>When calling the module <code>container-apps.bicep</code>, some of the input params are expecting are referencing another resource, for example consider the input param named <code>cosmosDbName</code> and the value used is <code>cosmosDb.outputs.cosmosDbName</code>. This means that the module <code>cosmos-db.bicep</code> should be created successfully before creating the container apps module, this called Implicit dependency.</p> </li> </ul>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/#deploy-the-infrastructure-and-create-the-components","title":"Deploy the Infrastructure and Create the Components","text":"<p>Start by creating a new resource group which will contain all the resources to be created by the Bicep scripts.</p> <pre><code>$RESOURCE_GROUP=\"&lt;your RG name&gt;\"\n$LOCATION=\"&lt;your location&gt;\"\naz group create `\n--name $RESOURCE_GROUP `\n--location $LOCATION\n</code></pre> <p>Create a parameters file which will simplify the invocation of the main bicep file. To achieve this, right click on file <code>main.bicep</code> and select Generate Parameter File.  This will result in creating a file named <code>main.parameters.json</code> similar to the file below:</p> Example main.parameters.json <pre><code>{\n\"$schema\": \"https://schema.management.azure.com/schemas/2015-01-01/deploymentParameters.json#\",\n\"contentVersion\": \"1.0.0.0\",\n\"parameters\": {\n\"prefix\": {\n\"value\": \"\"\n},\n\"suffix\": {\n\"value\": \"\"\n},\n\"tags\": {\n\"value\": {}\n},\n\"backendProcessorServiceName\": {\n\"value\": \"tasksmanager-backend-processor\"\n},\n\"backendApiServiceName\": {\n\"value\": \"tasksmanager-backend-api\"\n},\n\"frontendWebAppServiceName\": {\n\"value\": \"tasksmanager-frontend-webapp\"\n},\n\"serviceBusTopicName\": {\n\"value\": \"tasksavedtopic\"\n},\n\"serviceBusTopicAuthorizationRuleName\": {\n\"value\": \"tasksavedtopic-manage-policy\"\n},\n\"cosmosDbDatabaseName\": {\n\"value\": \"tasksmanagerdb\"\n},\n\"cosmosDbCollectionName\": {\n\"value\": \"taskscollection\"\n},\n\"sendGridKeySecretName\": {\n\"value\": \"sendgrid-api-key\"\n},\n\"sendGridKeySecretValue\": {\n\"value\": \"&lt;SEND_GRID_API_KEY&gt;\"\n},\n\"sendGridEmailFrom\": {\n\"value\": \"&lt;SEND_GRID_FROM_EMAIL&gt;\"\n},\n\"sendGridEmailFromName\": {\n\"value\": \"Tasks Tracker Notification\"\n},\n\"externalTasksQueueName\": {\n\"value\": \"external-tasks-queue\"\n},\n\"externalTasksContainerBlobName\": {\n\"value\": \"externaltasksblob\"\n},\n\"externalStorageKeySecretName\": {\n\"value\": \"external-azure-storage-key\"\n},\n\"scheduledJobCron\": {\n\"value\": \"5 0 * * *\"\n},\n\"secretStoreComponentName\": {\n\"value\": \"secretstoreakv\"\n},\n\"containerRegistryName\": {\n\"value\": \"&lt;CONTAINER_REGISTRY_NAME&gt;\"\n},\n\"containerRegistryUsername\": {\n\"value\": \"&lt;CONTAINER_REGISTRY_ADMIN&gt;\"\n},\n\"containerRegistryPasswordRefName\": {\n\"value\": \"acaworkshopacrazurecrio-acaworkshopacr\"\n},\n\"containerRegistryPassword\": {\n\"value\": \"&lt;CONTAINER_REGISTRY_PASSWORD&gt;\"\n},\n\"backendProcessorServiceImage\": {\n\"value\": \"&lt;CONTAINER_REGISTRY_NAME&gt;.azurecr.io/tasksmanager/tasksmanager-backend-processor:latest\"\n},\n\"backendApiServiceImage\": {\n\"value\": \"&lt;CONTAINER_REGISTRY_NAME&gt;.azurecr.io/tasksmanager/tasksmanager-backend-api:latest\"\n},\n\"frontendWebAppServiceImage\": {\n\"value\": \"&lt;CONTAINER_REGISTRY_NAME&gt;.azurecr.io/tasksmanager/tasksmanager-frontend-webapp:latest\"\n}\n}\n}\n</code></pre> <p>Note</p> <p>To use this file, you need to edit this generated file and provide values for the parameters. You can use the same values shown above in sample file. </p> <p>You only need to replace parameter values between the angle brackets <code>&lt;&gt;</code> with values related to your container registry and SendGrid. Values for container registry and container images can be dervied by following one of the three options in next step.</p> <p>Next, we will prepare container images for the three container apps and update the values in <code>main.parameters.json</code> file. You can do so by any of the three options below:</p> Option 1: Build and Push the Images to Azure Container Registry (ACR)Option 2: Import pre-built public images to your private Azure Container RegistryOption 3: Use the pre-built images from the public repository <ol> <li> <p>Create an Azure Container Registry (ACR) inside the newly created Resource Group:</p> <pre><code>$CONTAINER_REGISTRY_NAME=\"&lt;your ACR name&gt;\"\naz acr create `\n--resource-group $RESOURCE_GROUP `\n--name $CONTAINER_REGISTRY_NAME `\n--sku Basic\n</code></pre> </li> <li> <p>Build and push the images to ACR as guided in this section. Make sure you are at the root project directory when executing the following commands:</p> <pre><code>## Build Backend API on ACR and Push to ACR\naz acr build --registry $CONTAINER_REGISTRY_NAME `\n--image \"tasksmanager/$BACKEND_API_NAME\" `\n--file 'TasksTracker.TasksManager.Backend.Api/Dockerfile' .\n## Build Backend Service on ACR and Push to ACR\naz acr build --registry $CONTAINER_REGISTRY_NAME `\n--image \"tasksmanager/$BACKEND_SVC_NAME\" `\n--file 'TasksTracker.Processor.Backend.Svc/Dockerfile' .\n## Build Frontend Web App on ACR and Push to ACR\naz acr build --registry $CONTAINER_REGISTRY_NAME `\n--image \"tasksmanager/$FRONTEND_WEBAPP_NAME\" `\n--file 'TasksTracker.WebPortal.Frontend.Ui/Dockerfile' .\n</code></pre> </li> <li> <p>Update the <code>main.parameters.jsonc</code> file with the container registry name and the container images names as shown below:</p> <pre><code>{\n\"containerRegistryName\": {\n\"value\": \"&lt;CONTAINER_REGISTRY_NAME&gt;\"\n},\n\"backendProcessorServiceImage\": {\n\"value\": \"&lt;CONTAINER_REGISTRY_NAME&gt;.azurecr.io/tasksmanager/&lt;BACKEND_API_NAME&gt;:latest\"\n},\n\"backendApiServiceImage\": {\n\"value\": \"&lt;CONTAINER_REGISTRY_NAME&gt;.azurecr.io/tasksmanager/&lt;FRONTEND_WEBAPP_NAME&gt;:latest\"\n},\n\"frontendWebAppServiceImage\": {\n\"value\": \"&lt;CONTAINER_REGISTRY_NAME&gt;.azurecr.io/tasksmanager/&lt;BACKEND_SVC_NAME&gt;:latest\"\n}\n}\n</code></pre> </li> </ol> <p>All the container image are available in a public image repository. If you do not wish to build the container images from code directly, you can import it directly into  your private container instance as shown below.</p> <ol> <li> <p>Create an Azure Container Registry (ACR) inside the newly created Resource Group:</p> <pre><code>$CONTAINER_REGISTRY_NAME=\"&lt;your ACR name&gt;\"\naz acr create `\n--resource-group $RESOURCE_GROUP `\n--name $CONTAINER_REGISTRY_NAME `\n--sku Basic\n</code></pre> </li> <li> <p>Import the images to your private ACR as shown below:</p> <pre><code>    az acr import `\n--name $CONTAINER_REGISTRY_NAME  `\n--image tasksmanager/tasksmanager-backend-api  `\n--source ghcr.io/azure/tasksmanager-backend-api:latest\naz acr import  `\n--name $CONTAINER_REGISTRY_NAME  `\n--image tasksmanager/tasksmanager-frontend-webapp  `\n--source ghcr.io/azure/tasksmanager-frontend-webapp:latest\naz acr import  `\n--name $CONTAINER_REGISTRY_NAME  `\n--image tasksmanager/tasksmanager-backend-processor  `\n--source ghcr.io/azure/tasksmanager-backend-processor:latest\n</code></pre> </li> <li> <p>Update the <code>main.parameters.jsonc</code> file with the container registry name and the container images names as shown below:</p> <pre><code>{\n\"containerRegistryName\": {\n\"value\": \"&lt;CONTAINER_REGISTRY_NAME&gt;\"\n},\n\"backendProcessorServiceImage\": {\n\"value\": \"&lt;CONTAINER_REGISTRY_NAME&gt;.azurecr.io/tasksmanager/tasksmanager-backend-processor:latest\"\n},\n\"backendApiServiceImage\": {\n\"value\": \"&lt;CONTAINER_REGISTRY_NAME&gt;.azurecr.io/tasksmanager/tasksmanager-backend-api:latest\"\n},\n\"frontendWebAppServiceImage\": {\n\"value\": \"&lt;CONTAINER_REGISTRY_NAME&gt;.azurecr.io/tasksmanager/tasksmanager-frontend-webapp:latest\"\n}\n}\n</code></pre> </li> </ol> <p>All the container image are available in a public image repository. If you do not wish to build the container images from code directly, you can use the pre-built images from the public repository as shown below.</p> <p>The public images can be set directly in the <code>main.parameters.jsonc</code> file:</p> <pre><code>{\n\"containerRegistryName\": {\n\"value\": \"\"\n},\n\"backendProcessorServiceImage\": {\n\"value\": \"ghcr.io/azure/tasksmanager-backend-processor:latest\"\n},\n\"backendApiServiceImage\": {\n\"value\": \"ghcr.io/azure/tasksmanager-backend-api:latest\"\n},\n\"frontendWebAppServiceImage\": {\n\"value\": \"ghcr.io/azure/tasksmanager-frontend-webapp:latest\"\n},\n}   </code></pre> <p>Start the deployment by calling <code>az deployment group create</code>. To accomplish this, open the PowerShell console and use the content below.</p> <pre><code>az deployment group create `\n--resource-group $RESOURCE_GROUP `\n--template-file \"./bicep/main.bicep\" `\n--parameters \"./bicep/main.parameters.json\"\n</code></pre> <p>The Azure CLI will take the Bicep module and start creating the deployment in the resource group.</p>"},{"location":"aca/10-aca-iac-bicep/iac-bicep/#verify-the-final-results","title":"Verify the Final Results","text":"<p>Success</p> <p>Upon successful deployment, you should observe all resources generated within the designated resource group. Additionally, you may navigate to the <code>Deployments</code> section to confirm that the ARM templates have been deployed, which should resemble the image provided below:</p> <p></p>"},{"location":"aca/11-about-the-authors/","title":"Authors","text":""},{"location":"aca/11-about-the-authors/#taiseer-joudeh","title":"Taiseer Joudeh","text":"<p>Taiseer works for Microsoft Consultation Services as a Lead App Dev Consultant. He has more than 15 years of experience in developing and managing different software solutions for the finance, transportation, logistics, and e-commerce sectors.\u00a0</p> <p>Taiseer has been deeply involved in .NET development since early framework versions with a deep knowledge of distributed systems, microservices architecture, cloud-native apps, and Microsoft Azure.</p> <p>He frequently publishes articles on his blog. Connect with Taiseer on  LinkedIn.</p>"},{"location":"aca/11-about-the-authors/#wael-kdouh","title":"Wael Kdouh","text":"<p>Wael is Principal Cloud Solution Architect at Microsoft with over 20 years of experience developing innovative solutions for leading software companies. He has successfully led the completion of several mission-critical projects in multiple sectors such Airline Solutions and Retail to name a few. </p> <p>You will find him actively blogging on  Medium and occasionally tweeting on  Twitter. Connect with Wael on  LinkedIn. </p>"},{"location":"aca/11-about-the-authors/#pankaj-agrawal","title":"Pankaj Agrawal","text":"<p>Pankaj is Developer at heart, currently working as Senior Cloud Solutions Architect at Microsoft and based out of Oslo, Norway. Pankaj works with several customers across Nordics, helping them to make best use of Cloud native technologies and accelerate their journey to cloud. In his spare time, Pankaj enjoys running into the woods and love to learn new technical skills. He is quite passionate about DevOps and Serverless technologies and truly believe in automating everything.</p> <p>Pankaj loves writing technical blogs and contributing to open source projects. He keeps a journal of his blog and projects here. Connect with Pankaj on  Twitter or on  LinkedIn.</p>"},{"location":"aca/12-contributing/1-contribution-guide/","title":"Contribution Guide","text":"<p>If you'd like to contribute to this guide, please read the following guidelines. Contributors are more than welcome to share your learnings with others from a centralized location.</p>"},{"location":"aca/12-contributing/1-contribution-guide/#what-can-i-do","title":"What Can I Do?","text":"<ul> <li>Submit an issue or suggestion</li> <li>Minor update or fix to an existing challenge and adding a new challenge</li> </ul>"},{"location":"aca/12-contributing/1-contribution-guide/#contributing","title":"Contributing","text":"<p>This project welcomes contributions and suggestions.  Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.</p> <p>When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.</p> <p>This project has adopted the Microsoft Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments.</p>"},{"location":"aca/12-contributing/2-Submit-issue-suggestion/","title":"Support","text":""},{"location":"aca/12-contributing/2-Submit-issue-suggestion/#how-to-file-issues-and-get-help","title":"How to file issues and get help","text":"<p>This project uses GitHub Issues to track bugs and feature requests. Please search the existing  issues before filing new issues to avoid duplicates.  For new issues, file your bug or  feature request as a new Issue.</p> <p>There are two templates added to the repo for the following requests:</p> <ul> <li>Bug report</li> <li>Suggestion report </li> </ul>"},{"location":"aca/12-contributing/3-minor-update-fix/","title":"Typos, minor updates, or fixes to existing challenges","text":"<p>Whenever you are submitting any changes to the guide, please follow these recommendations:</p> <ul> <li>Always fork repository to your own account for applying modifications</li> <li>Do not combine multiple changes to one pull request, please submit any challenges and documentation updates using separate PRs</li> <li>If you are submitting multiple challenges, please create specific PR for each of them</li> <li>If you are submitting typo or documentation fix, you can combine modifications to single PR where suitable</li> </ul>"},{"location":"aca/13-appendix/01-run-debug-dapr-app-vscode/","title":"Debug and launch Dapr applications in VSCode","text":"<p>This page shows you how to configure VSCode to run and debug multiple Dapr applications at same time.</p>"},{"location":"aca/13-appendix/01-run-debug-dapr-app-vscode/#debug-and-launch-dapr-applications-in-vscode","title":"Debug and launch Dapr applications in VSCode","text":"<p>We need to update VS code <code>tasks.json</code> and <code>launch.json</code> configuration files included in your workspace. Once completed you should be able to use the Run and Debug button on the activity bar within  VS Code to launch all services to be able to debug them locally.</p> <p>First we need to add a new launch configuration for the Backend Web API and Frontend Web App projects.  To accomplish this, open file <code>launch.json</code> and add the two configurations shown below. </p> <p>Note</p> <p>Make sure you append the configurations below to the existing array instead of replacing what you have. This way you will preserve your existing configuration and simply add two new ones. </p> Looking for complete launch.json? launch.json <pre><code>{\n\"version\": \"0.2.0\",\n\"configurations\": [\n{\n\"name\": \"Launch (web app)\",\n\"type\": \"coreclr\",\n\"request\": \"launch\",\n\"preLaunchTask\": \"build-backend-api\",\n\"program\": \"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui/bin/Debug/net6.0/TasksTracker.WebPortal.Frontend.Ui.dll\",\n\"args\": [],\n\"cwd\": \"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui\",\n\"stopAtEntry\": false,\n\"serverReadyAction\": {\n\"action\": \"openExternally\",\n\"pattern\": \"\\\\bNow listening on:\\\\s+(https?://\\\\S+)\"\n},\n\"env\": {\n\"ASPNETCORE_ENVIRONMENT\": \"Development\"\n},\n\"sourceFileMap\": {\n\"/Views\": \"${workspaceFolder}/Views\"\n}\n},\n{\n\"name\": \"Launch (backend api)\",\n\"type\": \"coreclr\",\n\"request\": \"launch\",\n\"preLaunchTask\": \"build-webapp-ui\",\n\"program\": \"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api/bin/Debug/net6.0/TasksTracker.TasksManager.Backend.Api.dll\",\n\"args\": [],\n\"cwd\": \"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api\",\n\"stopAtEntry\": false,\n\"serverReadyAction\": {\n\"action\": \"openExternally\",\n\"pattern\": \"\\\\bNow listening on:\\\\s+(https?://\\\\S+)\"\n},\n\"env\": {\n\"ASPNETCORE_ENVIRONMENT\": \"Development\"\n},\n\"sourceFileMap\": {\n\"/Views\": \"${workspaceFolder}/Views\"\n}\n},\n{\n\"name\": \"Launch (background processor)\",\n\"type\": \"coreclr\",\n\"request\": \"launch\",\n\"preLaunchTask\": \"build-processor-svc\",\n\"program\": \"${workspaceFolder}/TasksTracker.Processor.Backend.Svc/bin/Debug/net6.0/TasksTracker.Processor.Backend.Svc.dll\",\n\"args\": [],\n\"cwd\": \"${workspaceFolder}/TasksTracker.Processor.Backend.Svc\",\n\"stopAtEntry\": false,\n\"serverReadyAction\": {\n\"action\": \"openExternally\",\n\"pattern\": \"\\\\bNow listening on:\\\\s+(https?://\\\\S+)\"\n},\n\"env\": {\n\"ASPNETCORE_ENVIRONMENT\": \"Development\"\n},\n\"sourceFileMap\": {\n\"/Views\": \"${workspaceFolder}/Views\"\n}\n},\n{\n\"name\": \".NET Core Attach\",\n\"type\": \"coreclr\",\n\"request\": \"attach\"\n},\n{\n\"name\": \"Launch (backend api) with Dapr\",\n\"type\": \"coreclr\",\n\"request\": \"launch\",\n\"preLaunchTask\": \"backend-api-dapr-debug\",\n\"program\": \"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api/bin/Debug/net6.0/TasksTracker.TasksManager.Backend.Api.dll\",\n\"args\": [],\n\"cwd\": \"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api\",\n\"stopAtEntry\": false,\n\"serverReadyAction\": {\n\"action\": \"openExternally\",\n\"pattern\": \"\\\\bNow listening on:\\\\s+(https?://\\\\S+)\"\n},\n\"env\": {\n\"ASPNETCORE_ENVIRONMENT\": \"Development\"\n},\n\"sourceFileMap\": {\n\"/Views\": \"${workspaceFolder}/Views\"\n},\n\"postDebugTask\": \"daprd-down-backend-api\"\n},\n{\n\"name\": \"Launch (web app) with Dapr\",\n\"type\": \"coreclr\",\n\"request\": \"launch\",\n\"preLaunchTask\": \"webapp-ui-dapr-debug\",\n\"program\": \"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui/bin/Debug/net6.0/TasksTracker.WebPortal.Frontend.Ui.dll\",\n\"args\": [],\n\"cwd\": \"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui\",\n\"stopAtEntry\": false,\n\"serverReadyAction\": {\n\"action\": \"openExternally\",\n\"pattern\": \"\\\\bNow listening on:\\\\s+(https?://\\\\S+)\"\n},\n\"env\": {\n\"ASPNETCORE_ENVIRONMENT\": \"Development\"\n},\n\"sourceFileMap\": {\n\"/Views\": \"${workspaceFolder}/Views\"\n},\n\"postDebugTask\": \"webapp-ui-daprd-down\"\n},\n{\n\"name\": \"Launch (background processor) with Dapr\",\n\"type\": \"coreclr\",\n\"request\": \"launch\",\n\"preLaunchTask\": \"processor-svc-dapr-debug\",\n\"program\": \"${workspaceFolder}/TasksTracker.Processor.Backend.Svc/bin/Debug/net6.0/TasksTracker.Processor.Backend.Svc.dll\",\n\"args\": [],\n\"cwd\": \"${workspaceFolder}/TasksTracker.Processor.Backend.Svc\",\n\"stopAtEntry\": false,\n\"serverReadyAction\": {\n\"action\": \"openExternally\",\n\"pattern\": \"\\\\bNow listening on:\\\\s+(https?://\\\\S+)\"\n},\n\"env\": {\n\"ASPNETCORE_ENVIRONMENT\": \"Development\"\n},\n\"sourceFileMap\": {\n\"/Views\": \"${workspaceFolder}/Views\"\n},\n\"postDebugTask\": \"processor-svc-daprd-down\"\n}\n],\n\"compounds\": [\n{\n\"name\": \"RunAll\",\n\"configurations\": [\"Launch (web app)\", \"Launch (backend api)\", \"Launch (background processor)\",],\n\"stopAll\": true\n},\n{\n\"name\": \"RunAll with Dapr\",\n\"configurations\": [ \"Launch (backend api) with Dapr\", \"Launch (web app) with Dapr\", \"Launch (background processor) with Dapr\", ],\n\"stopAll\": true\n}\n]\n}\n</code></pre> <p>Note</p> <p>The configuration below assumes that you are using .net 6. If you are using a different .net version make sure you update the paths to use the correct version.  For example if using .net 7 then change the path to say net7.0 instead of net6.0.</p> launch.json <pre><code>{\"configurations\":\n[\n{\n\"name\": \"Launch (backend api) with Dapr\",\n\"type\": \"coreclr\",\n\"request\": \"launch\",\n\"preLaunchTask\": \"backend-api-dapr-debug\",\n\"program\": \"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api/bin/Debug/net6.0/TasksTracker.TasksManager.Backend.Api.dll\",\n\"args\": [],\n\"cwd\": \"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api\",\n\"stopAtEntry\": false,\n\"serverReadyAction\": {\n\"action\": \"openExternally\",\n\"pattern\": \"\\\\bNow listening on:\\\\s+(https?://\\\\S+)\"\n},\n\"env\": {\n\"ASPNETCORE_ENVIRONMENT\": \"Development\"\n},\n\"sourceFileMap\": {\n\"/Views\": \"${workspaceFolder}/Views\"\n},\n\"postDebugTask\": \"daprd-down-backend-api\"\n},\n{\n\"name\": \"Launch (web app) with Dapr\",\n\"type\": \"coreclr\",\n\"request\": \"launch\",\n\"preLaunchTask\": \"webapp-ui-dapr-debug\",\n\"program\": \"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui/bin/Debug/net6.0/TasksTracker.WebPortal.Frontend.Ui.dll\",\n\"args\": [],\n\"cwd\": \"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui\",\n\"stopAtEntry\": false,\n\"serverReadyAction\": {\n\"action\": \"openExternally\",\n\"pattern\": \"\\\\bNow listening on:\\\\s+(https?://\\\\S+)\"\n},\n\"env\": {\n\"ASPNETCORE_ENVIRONMENT\": \"Development\"\n},\n\"sourceFileMap\": {\n\"/Views\": \"${workspaceFolder}/Views\"\n},\n\"postDebugTask\": \"webapp-ui-daprd-down\"\n}\n]}\n</code></pre> <p>Note</p> <p>We have a <code>preLaunchTask</code> and a <code>postDebugTask</code> which we need to define right now. Those tasks are Dapr tasks.</p> <p>The Dapr VSCode extension we have previously installed helps us to define those pre- and post-debug  tasks. </p> <p>To accomplish this, open the file tasks.json and click Ctrl+Shift+P, and type Dapr: Scaffold Dapr Tasks. </p> <p>The Dapr VS Code extension will allow us to manage Dapr application and test it out in an easier way, the below image shows a full list of helper commands.</p> <p></p> <p>Now we will add 4 tasks, for each application, there will be a task to support the <code>preLaunch</code> activity and the <code>postDebug</code> activity (Terminate/Exit Dapr Sidecar process), so open file tasks.json and add the tasks below:</p> tasks.json <pre><code>{\n\"tasks\": [\n{\n\"appId\": \"tasksmanager-backend-api\",\n\"appPort\": [web api application port number found under properties-&gt;launchSettings.json. e.g. 7112],\n\"httpPort\": 3500,\n\"grpcPort\": 50001,\n\"appSsl\": true,\n\"label\": \"backend-api-dapr-debug\",\n\"type\": \"dapr\",\n\"dependsOn\": \"build-backend-api\",\n// Uncomment this line after adding Azure Cosmos DB in module 4\n//\"componentsPath\": \"./components\"\n},\n{\n\"appId\": \"tasksmanager-backend-api\",\n\"label\": \"daprd-down-backend-api\",\n\"type\": \"daprd-down\"\n},\n{\n\"appId\": \"tasksmanager-frontend-webapp\",\n\"appPort\": [frontend application port number found under properties-&gt;launchSettings.json. e.g. 7112],\n\"httpPort\": 3501,\n\"grpcPort\": 50002,\n\"appSsl\": true,\n\"label\": \"webapp-ui-dapr-debug\",\n\"type\": \"dapr\",\n\"dependsOn\": \"build-webapp-ui\"\n},\n{\n\"appId\": \"tasksmanager-frontend-webapp\",\n\"label\": \"webapp-ui-daprd-down\",\n\"type\": \"daprd-down\"\n}\n]}\n</code></pre> Curious to learn more about the tasks.json file above? <ul> <li>The tasks with the label <code>backend-api-dapr-debug</code> will invoke the <code>daprd</code> task. This task is similar to calling dapr run from CLI.</li> <li>We are setting the appPort, httpPort, and grpcPort properties (grpcPort is needed in future modules when we start using the state manager building block.  If you didn't set it, you might face a similar issue)</li> <li>We are setting the \u201ccomponentsPath\u201d property. This is needed when start working with the state manager, pub/sub, etc.</li> <li>We are setting the dependsOn property, so this means this task will fire after the dependsOn tasks complete successfully. We need to add those dependsOn tasks.</li> <li>The tasks with the label <code>daprd-down-backend-api</code> will terminate the Dapr Sidecar process. This will be used for the <code>postDebug</code> activity in configuration.json.</li> <li>For a complete list of available properties please check this link.</li> </ul> <p>Next let's add the dependsOn tasks. Open <code>tasks.json</code> and add the tasks below:</p> tasks.json<pre><code>{\n\"label\": \"build-backend-api\",\n\"command\": \"dotnet\",\n\"type\": \"process\",\n\"args\": [\n\"build\",\n\"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api/TasksTracker.TasksManager.Backend.Api.csproj\",\n\"/property:GenerateFullPaths=true\",\n\"/consoleloggerparameters:NoSummary\"\n],\n\"problemMatcher\": \"$msCompile\"\n},\n{\n\"label\": \"build-webapp-ui\",\n\"command\": \"dotnet\",\n\"type\": \"process\",\n\"args\": [\n\"build\",\n\"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui/TasksTracker.WebPortal.Frontend.Ui.csproj\",\n\"/property:GenerateFullPaths=true\",\n\"/consoleloggerparameters:NoSummary\"\n],\n\"problemMatcher\": \"$msCompile\"\n}\n</code></pre> Looking for complete tasks.json? tasks.json <pre><code>{\n\"version\": \"2.0.0\",\n\"tasks\": [\n{\n\"label\": \"build-backend-api\",\n\"command\": \"dotnet\",\n\"type\": \"process\",\n\"args\": [\n\"build\",\n\"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api/TasksTracker.TasksManager.Backend.Api.csproj\",\n\"/property:GenerateFullPaths=true\",\n\"/consoleloggerparameters:NoSummary\"\n],\n\"problemMatcher\": \"$msCompile\"\n},\n{\n\"label\": \"publish-backend-api\",\n\"command\": \"dotnet\",\n\"type\": \"process\",\n\"args\": [\n\"publish\",\n\"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api/TasksTracker.TasksManager.Backend.Api.csproj\",\n\"/property:GenerateFullPaths=true\",\n\"/consoleloggerparameters:NoSummary\"\n],\n\"problemMatcher\": \"$msCompile\"\n},\n{\n\"label\": \"watch-backend-api\",\n\"command\": \"dotnet\",\n\"type\": \"process\",\n\"args\": [\n\"watch\",\n\"run\",\n\"--project\",\n\"${workspaceFolder}/TasksTracker.TasksManager.Backend.Api/TasksTracker.TasksManager.Backend.Api.csproj\"\n],\n\"problemMatcher\": \"$msCompile\"\n},\n{\n\"label\": \"build-webapp-ui\",\n\"command\": \"dotnet\",\n\"type\": \"process\",\n\"args\": [\n\"build\",\n\"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui/TasksTracker.WebPortal.Frontend.Ui.csproj\",\n\"/property:GenerateFullPaths=true\",\n\"/consoleloggerparameters:NoSummary\"\n],\n\"problemMatcher\": \"$msCompile\"\n},\n{\n\"label\": \"publish-webapp-ui\",\n\"command\": \"dotnet\",\n\"type\": \"process\",\n\"args\": [\n\"publish\",\n\"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui/TasksTracker.WebPortal.Frontend.Ui.csproj\",\n\"/property:GenerateFullPaths=true\",\n\"/consoleloggerparameters:NoSummary\"\n],\n\"problemMatcher\": \"$msCompile\"\n},\n{\n\"label\": \"watch-webapp-ui\",\n\"command\": \"dotnet\",\n\"type\": \"process\",\n\"args\": [\n\"watch\",\n\"run\",\n\"--project\",\n\"${workspaceFolder}/TasksTracker.WebPortal.Frontend.Ui/TasksTracker.WebPortal.Frontend.Ui.csproj\"\n],\n\"problemMatcher\": \"$msCompile\"\n},\n{\n\"label\": \"build-processor-svc\",\n\"command\": \"dotnet\",\n\"type\": \"process\",\n\"args\": [\n\"build\",\n\"${workspaceFolder}/TasksTracker.Processor.Backend.Svc/TasksTracker.Processor.Backend.Svc.csproj\",\n\"/property:GenerateFullPaths=true\",\n\"/consoleloggerparameters:NoSummary\"\n],\n\"problemMatcher\": \"$msCompile\"\n},\n{\n\"label\": \"publish-processor-svc\",\n\"command\": \"dotnet\",\n\"type\": \"process\",\n\"args\": [\n\"publish\",\n\"${workspaceFolder}/TasksTracker.Processor.Backend.Svc/TasksTracker.Processor.Backend.Svc.csproj\",\n\"/property:GenerateFullPaths=true\",\n\"/consoleloggerparameters:NoSummary\"\n],\n\"problemMatcher\": \"$msCompile\"\n},\n{\n\"label\": \"watch-processor-svc\",\n\"command\": \"dotnet\",\n\"type\": \"process\",\n\"args\": [\n\"watch\",\n\"run\",\n\"--project\",\n\"${workspaceFolder}/TasksTracker.Processor.Backend.Svc/TasksTracker.Processor.Backend.Svc.csproj\"\n],\n\"problemMatcher\": \"$msCompile\"\n},\n{\n\"label\": \"build-all\",\n\"dependsOn\": [\n\"build-backend-api\",\n\"build-webapp-ui\",\n\"build-processor-svc\"\n],\n\"problemMatcher\": [],\n\"group\": {\n\"kind\": \"build\",\n\"isDefault\": true\n}\n},\n{\n\"appId\": \"tasksmanager-backend-api\",\n\"appPort\": 7088,\n\"httpPort\": 3500,\n\"grpcPort\": 50001,\n\"appSsl\": true,\n\"label\": \"backend-api-dapr-debug\",\n\"type\": \"dapr\",\n\"dependsOn\": \"build-backend-api\",\n\"componentsPath\": \"./components\"\n},\n{\n\"appId\": \"tasksmanager-backend-api\",\n\"label\": \"daprd-down-backend-api\",\n\"type\": \"daprd-down\"\n},\n{\n\"appId\": \"tasksmanager-frontend-webapp\",\n\"appPort\": 7208,\n\"httpPort\": 3501,\n\"grpcPort\": 50002,\n\"appSsl\": true,\n\"label\": \"webapp-ui-dapr-debug\",\n\"type\": \"dapr\",\n\"dependsOn\": \"build-webapp-ui\"\n},\n{\n\"appId\": \"tasksmanager-frontend-webapp\",\n\"label\": \"webapp-ui-daprd-down\",\n\"type\": \"daprd-down\"\n},\n{\n\"appId\": \"tasksmanager-backend-processor\",\n\"appPort\": 7263,\n\"httpPort\": 3502,\n\"grpcPort\": 50003,\n\"appSsl\": true,\n\"label\": \"processor-svc-dapr-debug\",\n\"type\": \"dapr\",\n\"dependsOn\": \"build-processor-svc\",\n\"componentsPath\": \"./components\"\n},\n{\n\"appId\": \"tasksmanager-backend-processor\",\n\"label\": \"processor-svc-daprd-down\",\n\"type\": \"daprd-down\"\n}\n]\n}\n</code></pre> <p>Lastly, we need to add a <code>compound launch</code> property, so we launch and debug both applications together. </p> <p>To accomplish this, open the file <code>launch.json</code> again and add the below array after the <code>configuration</code> array.</p> launch.json<pre><code>\"compounds\": [\n{\n\"name\": \"RunAll with Dapr\",\n\"configurations\": [\n\"Launch (backend api) with Dapr\",\n\"Launch (web app) with Dapr\"\n],\n\"stopAll\": true\n}\n]\n</code></pre> <p>Success</p> <p>If all is done correctly, you should be able to see a debug configuration named <code>RunAll with Dapr</code> and you should be able to just hit ++F5++, sit breakpoints and debug both applications locally in VS Code.</p> <p></p>"},{"location":"aca/13-appendix/02-github-local-codespaces/","title":"Inner loop, testing your changes locally or using GitHub Codespaces","text":"<ul> <li><code>docs/aca</code> folder , contains all the mark-down documentation files for all the modules</li> <li><code>docs/assets</code> folder, contains all the images, slides, and files used in the lab</li> <li>This site uses, Material for MkDocs.  Take some time to familiarize yourself with the theme and the features it provides.</li> </ul>"},{"location":"aca/13-appendix/02-github-local-codespaces/#locally","title":"Locally","text":"<p>Checkout the repo locally using below command:</p> <pre><code>git clone  https://github.com/Azure/aca-dotnet-workshop.git\n</code></pre> <p>Using bash terminal or wsl terminal, navigate to the repo root folder and run the below command to build and run the website locally:</p> <pre><code>make docs-local\n</code></pre>"},{"location":"aca/13-appendix/02-github-local-codespaces/#using-github-codespaces","title":"Using GitHub Codespaces","text":"<p>This repo has a github codespaces dev container defined. This container is based on ubuntu 20.04 and contains all the libraries and components to run github pages locally in Github Codespaces. To test your changes follow these steps:</p> <ul> <li>Enable GitHub codespaces for your account</li> <li>Fork this repo</li> <li>Open the repo in github codespaces</li> <li>Wait for the container to build and connect to it</li> <li>Run the website in github codespaces using below command</li> </ul> <p><pre><code>make docs-local\n</code></pre> </p>"}]}